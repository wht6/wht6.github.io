{"meta":{"title":"WHT","subtitle":"Enjoy your life","description":"分享技术,分享知识,分享感悟","author":"并指如刀","url":"http://wht6.github.io","root":"/"},"pages":[{"title":"about","date":"2021-03-14T05:54:32.000Z","updated":"2022-02-28T02:04:39.999Z","comments":true,"path":"about/index.html","permalink":"http://wht6.github.io/about/index.html","excerpt":"","text":"关于我从事后端运维，主要开发语言 Golang和shell，熟练使用Linux操作系统，熟悉K8S 、LVS、Nginx等主流框架。 对网络运维、前后端开发、嵌入式等技能有所了解。 热爱开源项目、热爱新技术、热爱新事物。 关于工作城市：北京 关于学习正在往终身学习者前进…近期学习方向：Go自动化运维 关于座右铭 已识乾坤大，犹怜草木青。 关于爱好崇尚道家思想，喜爱养生、阅读、电影、旅行。 联系我 Home: wht6 Email: wanght586@gmail.com GitHub: wht6"},{"title":"friends","date":"2021-03-14T05:55:08.000Z","updated":"2021-03-14T05:55:28.248Z","comments":true,"path":"friends/index.html","permalink":"http://wht6.github.io/friends/index.html","excerpt":"","text":""},{"title":"contact","date":"2021-03-14T13:02:01.000Z","updated":"2021-03-14T13:02:47.365Z","comments":true,"path":"contact/index.html","permalink":"http://wht6.github.io/contact/index.html","excerpt":"","text":""},{"title":"tags","date":"2021-03-14T05:53:45.000Z","updated":"2021-03-14T05:54:10.945Z","comments":true,"path":"tags/index.html","permalink":"http://wht6.github.io/tags/index.html","excerpt":"","text":""},{"title":"musics","date":"2021-03-15T08:46:07.000Z","updated":"2021-03-15T08:47:22.470Z","comments":true,"path":"musics/index.html","permalink":"http://wht6.github.io/musics/index.html","excerpt":"","text":""},{"title":"categories","date":"2021-03-14T05:52:18.000Z","updated":"2021-03-14T05:53:15.911Z","comments":true,"path":"categories/index.html","permalink":"http://wht6.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"Kubernetes集群搭建与实践","slug":"Kubernetes集群搭建与实践","date":"2022-03-27T08:00:00.000Z","updated":"2022-03-27T11:43:24.944Z","comments":true,"path":"posts/3588.html","link":"","permalink":"http://wht6.github.io/posts/3588.html","excerpt":"","text":"kubeadm要真正发挥容器技术的实力，你就不能仅仅局限于对 Linux 容器本身的钻研和使用。 这些知识更适合作为你的技术储备，以便在需要的时候可以帮你更快的定位问题，并解决问题。 而更深入的学习容器技术的关键在于，如何使用这些技术来“容器化”你的应用。 比如，我们的应用既可能是 Java Web 和 MySQL 这样的组合，也可能是 Cassandra 这样的分布式系统。而要使用容器把后者运行起来，你单单通过 Docker 把一个 Cassandra 镜像跑起来是没用的。 要把 Cassandra 应用容器化的关键，在于如何处理好这些 Cassandra 容器之间的编排关系。比如，哪些 Cassandra 容器是主，哪些是从？主从容器如何区分？它们之间又如何进行自动发现和通信？Cassandra 容器的持久化数据又如何保持，等等。 这也是为什么我们要反复强调 Kubernetes 项目的主要原因：这个项目体现出来的容器化“表达能力”，具有独有的先进性和完备性。这就使得它不仅能运行 Java Web 与 MySQL 这样的常规组合，还能够处理 Cassandra 容器集群等复杂编排问题。 作为一个典型的分布式项目，Kubernetes 的部署一直以来都是挡在初学者前面的一只“拦路虎”。尤其是在 Kubernetes 项目发布初期，它的部署完全要依靠一堆由社区维护的脚本。 其实，Kubernetes 作为一个 Golang 项目，已经免去了很多类似于 Python 项目要安装语言级别依赖的麻烦。但是，除了将各个组件编译成二进制文件外，用户还要负责为这些二进制文件编写对应的配置文件、配置自启动脚本，以及为 kube-apiserver 配置授权文件等等诸多运维工作。 目前，各大云厂商最常用的部署的方法，是使用 SaltStack、Ansible 等运维工具自动化地执行这些步骤。 但即使这样，这个部署过程依然非常繁琐。因为，SaltStack 这类专业运维工具本身的学习成本，就可能比 Kubernetes 项目还要高。 难道 Kubernetes 项目就没有简单的部署方法了吗？ 这个问题，在 Kubernetes 社区里一直没有得到足够重视。直到 2017 年，在志愿者的推动下，社区才终于发起了一个独立的部署工具，名叫：kubeadm。 这个项目的目的，就是要让用户能够通过这样两条指令完成一个 Kubernetes 集群的部署： 12345# 创建一个 Master 节点$ kubeadm init # 将一个 Node 节点加入到当前集群中$ kubeadm join &lt;Master 节点的 IP 和端口 &gt; 是不是非常方便呢？ 不过，你可能也会有所顾虑：Kubernetes 的功能那么多，这样一键部署出来的集群，能用于生产环境吗？ 为了回答这个问题，我就先和你介绍一下 kubeadm 的工作原理吧。 kubeadm 的工作原理在部署时，Kubernetes 的每一个组件都是一个需要被执行的、单独的二进制文件。所以不难想象，SaltStack 这样的运维工具或者由社区维护的脚本的功能，就是要把这些二进制文件传输到指定的机器当中，然后编写控制脚本来启停这些组件。 不过，在理解了容器技术之后，你可能已经萌生出了这样一个想法，为什么不用容器部署 Kubernetes 呢？ 这样，我只要给每个 Kubernetes 组件做一个容器镜像，然后在每台宿主机上用 docker run 指令启动这些组件容器，部署不就完成了吗？ 事实上，在 Kubernetes 早期的部署脚本里，确实有一个脚本就是用 Docker 部署 Kubernetes 项目的，这个脚本相比于 SaltStack 等的部署方式，也的确简单了不少。 但是，这样做会带来一个很麻烦的问题，即：如何容器化 kubelet。 kubelet 是 Kubernetes 项目用来操作 Docker 等容器运行时的核心组件。可是，除了跟容器运行时打交道外，kubelet 在配置容器网络、管理容器数据卷时，都需要直接操作宿主机。 而如果现在 kubelet 本身就运行在一个容器里，那么直接操作宿主机就会变得很麻烦。对于网络配置来说还好，kubelet 容器可以通过不开启 Network Namespace（即 Docker 的 host network 模式）的方式，直接共享宿主机的网络栈。可是，要让 kubelet 隔着容器的 Mount Namespace 和文件系统，操作宿主机的文件系统，就有点儿困难了。 比如，如果用户想要使用 NFS 做容器的持久化数据卷，那么 kubelet 就需要在容器进行绑定挂载前，在宿主机的指定目录上，先挂载 NFS 的远程目录。 可是，这时候问题来了。由于现在 kubelet 是运行在容器里的，这就意味着它要做的这个“mount -F nfs”命令，被隔离在了一个单独的 Mount Namespace 中。即，kubelet 做的挂载操作，不能被“传播”到宿主机上。 对于这个问题，有人说，可以使用 setns() 系统调用，在宿主机的 Mount Namespace 中执行这些挂载操作；也有人说，应该让 Docker 支持一个–mnt=host 的参数。 但是，到目前为止，在容器里运行 kubelet，依然没有很好的解决办法，我也不推荐你用容器去部署 Kubernetes 项目。 正因为如此，kubeadm 选择了一种妥协方案： 把 kubelet 直接运行在宿主机上，然后使用容器部署其他的 Kubernetes 组件。 所以，你使用 kubeadm 的第一步，是在机器上手动安装 kubeadm、kubelet 和 kubectl 这三个二进制文件。当然，kubeadm 的作者已经为各个发行版的 Linux 准备好了安装包，所以你只需要执行： 1$ apt-get install kubeadm 就可以了。 接下来，你就可以使用“kubeadm init”部署 Master 节点了。 kubeadm init 的工作流程当你执行 kubeadm init 指令后，kubeadm 首先要做的，是一系列的检查工作，以确定这台机器可以用来部署 Kubernetes。这一步检查，我们称为“Preflight Checks”，它可以为你省掉很多后续的麻烦。 其实，Preflight Checks 包括了很多方面，比如： Linux 内核的版本必须是否是 3.10 以上？ Linux Cgroups 模块是否可用？ 机器的 hostname 是否标准？在 Kubernetes 项目里，机器的名字以及一切存储在 Etcd 中的 API 对象，都必须使用标准的 DNS 命名（RFC 1123）。 用户安装的 kubeadm 和 kubelet 的版本是否匹配？ 机器上是不是已经安装了 Kubernetes 的二进制文件？ Kubernetes 的工作端口 10250/10251/10252 端口是不是已经被占用？ ip、mount 等 Linux 指令是否存在？ Docker 是否已经安装？ …… 在通过了 Preflight Checks 之后，kubeadm 要为你做的，是生成 Kubernetes 对外提供服务所需的各种证书和对应的目录。 Kubernetes 对外提供服务时，除非专门开启“不安全模式”，否则都要通过 HTTPS 才能访问 kube-apiserver。这就需要为 Kubernetes 集群配置好证书文件。 kubeadm 为 Kubernetes 项目生成的证书文件都放在 Master 节点的 /etc/kubernetes/pki 目录下。在这个目录下，最主要的证书文件是 ca.crt 和对应的私钥 ca.key。 此外，用户使用 kubectl 获取容器日志等 streaming 操作时，需要通过 kube-apiserver 向 kubelet 发起请求，这个连接也必须是安全的。kubeadm 为这一步生成的是 apiserver-kubelet-client.crt 文件，对应的私钥是 apiserver-kubelet-client.key。 除此之外，Kubernetes 集群中还有 Aggregate APIServer 等特性，也需要用到专门的证书，这里我就不再一一列举了。需要指出的是，你可以选择不让 kubeadm 为你生成这些证书，而是拷贝现有的证书到如下证书的目录里： 1/etc/kubernetes/pki/ca.&#123;crt,key&#125; 这时，kubeadm 就会跳过证书生成的步骤，把它完全交给用户处理。 证书生成后，kubeadm 接下来会为其他组件生成访问 kube-apiserver 所需的配置文件。这些文件的路径是：/etc/kubernetes/xxx.conf： 12ls /etc/kubernetes/admin.conf controller-manager.conf kubelet.conf scheduler.conf 这些文件里面记录的是，当前这个 Master 节点的服务器地址、监听端口、证书目录等信息。这样，对应的客户端（比如 scheduler，kubelet 等），可以直接加载相应的文件，使用里面的信息与 kube-apiserver 建立安全连接。 接下来，kubeadm 会为 Master 组件生成 Pod 配置文件。我已经和你介绍过 Kubernetes 有三个 Master 组件 kube-apiserver、kube-controller-manager、kube-scheduler，而它们都会被使用 Pod 的方式部署起来。 你可能会有些疑问：这时，Kubernetes 集群尚不存在，难道 kubeadm 会直接执行 docker run 来启动这些容器吗？ 当然不是。 在 Kubernetes 中，有一种特殊的容器启动方法叫做“Static Pod”。它允许你把要部署的 Pod 的 YAML 文件放在一个指定的目录里。这样，当这台机器上的 kubelet 启动时，它会自动检查这个目录，加载所有的 Pod YAML 文件，然后在这台机器上启动它们。 从这一点也可以看出，kubelet 在 Kubernetes 项目中的地位非常高，在设计上它就是一个完全独立的组件，而其他 Master 组件，则更像是辅助性的系统容器。 在 kubeadm 中，Master 组件的 YAML 文件会被生成在 /etc/kubernetes/manifests 路径下。比如，kube-apiserver.yaml： 123456789101112131415161718192021222324252627282930313233343536373839404142apiVersion: v1kind: Podmetadata: annotations: scheduler.alpha.kubernetes.io/critical-pod: &quot;&quot; creationTimestamp: null labels: component: kube-apiserver tier: control-plane name: kube-apiserver namespace: kube-systemspec: containers: - command: - kube-apiserver - --authorization-mode=Node,RBAC - --runtime-config=api/all=true - --advertise-address=10.168.0.2 ... - --tls-cert-file=/etc/kubernetes/pki/apiserver.crt - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key image: k8s.gcr.io/kube-apiserver-amd64:v1.11.1 imagePullPolicy: IfNotPresent livenessProbe: ... name: kube-apiserver resources: requests: cpu: 250m volumeMounts: - mountPath: /usr/share/ca-certificates name: usr-share-ca-certificates readOnly: true ... hostNetwork: true priorityClassName: system-cluster-critical volumes: - hostPath: path: /etc/ca-certificates type: DirectoryOrCreate name: etc-ca-certificates ... 在这里，你只需要关注这样几个信息： 这个 Pod 里只定义了一个容器，它使用的镜像是：k8s.gcr.io/kube-apiserver-amd64:v1.11.1 。这个镜像是 Kubernetes 官方维护的一个组件镜像。 这个容器的启动命令（commands）是 kube-apiserver —authorization-mode=Node,RBAC …，这样一句非常长的命令。其实，它就是容器里 kube-apiserver 这个二进制文件再加上指定的配置参数而已。 如果你要修改一个已有集群的 kube-apiserver 的配置，需要修改这个 YAML 文件。 这些组件的参数也可以在部署时指定，我很快就会讲解到。 在这一步完成后，kubeadm 还会再生成一个 Etcd 的 Pod YAML 文件，用来通过同样的 Static Pod 的方式启动 Etcd。所以，最后 Master 组件的 Pod YAML 文件如下所示： 12$ ls /etc/kubernetes/manifests/etcd.yaml kube-apiserver.yaml kube-controller-manager.yaml kube-scheduler.yaml 而一旦这些 YAML 文件出现在被 kubelet 监视的 /etc/kubernetes/manifests 目录下，kubelet 就会自动创建这些 YAML 文件中定义的 Pod，即 Master 组件的容器。 Master 容器启动后，kubeadm 会通过检查 localhost:6443/healthz 这个 Master 组件的健康检查 URL，等待 Master 组件完全运行起来。 然后，kubeadm 就会为集群生成一个 bootstrap token。在后面，只要持有这个 token，任何一个安装了 kubelet 和 kubadm 的节点，都可以通过 kubeadm join 加入到这个集群当中。 这个 token 的值和使用方法会，会在 kubeadm init 结束后被打印出来。 在 token 生成之后，kubeadm 会将 ca.crt 等 Master 节点的重要信息，通过 ConfigMap 的方式保存在 Etcd 当中，供后续部署 Node 节点使用。这个 ConfigMap 的名字是 cluster-info。 kubeadm init 的最后一步，就是安装默认插件。Kubernetes 默认 kube-proxy 和 DNS 这两个插件是必须安装的。它们分别用来提供整个集群的服务发现和 DNS 功能。其实，这两个插件也只是两个容器镜像而已，所以 kubeadm 只要用 Kubernetes 客户端创建两个 Pod 就可以了。 kubeadm join 的工作流程这个流程其实非常简单，kubeadm init 生成 bootstrap token 之后，你就可以在任意一台安装了 kubelet 和 kubeadm 的机器上执行 kubeadm join 了。 可是，为什么执行 kubeadm join 需要这样一个 token 呢？ 因为，任何一台机器想要成为 Kubernetes 集群中的一个节点，就必须在集群的 kube-apiserver 上注册。可是，要想跟 apiserver 打交道，这台机器就必须要获取到相应的证书文件（CA 文件）。可是，为了能够一键安装，我们就不能让用户去 Master 节点上手动拷贝这些文件。 所以，kubeadm 至少需要发起一次“不安全模式”的访问到 kube-apiserver，从而拿到保存在 ConfigMap 中的 cluster-info（它保存了 APIServer 的授权信息）。而 bootstrap token，扮演的就是这个过程中的安全验证的角色。 只要有了 cluster-info 里的 kube-apiserver 的地址、端口、证书，kubelet 就可以以“安全模式”连接到 apiserver 上，这样一个新的节点就部署完成了。 接下来，你只要在其他节点上重复这个指令就可以了。 配置 kubeadm 的部署参数我在前面讲解了 kubeadm 部署 Kubernetes 集群最关键的两个步骤，kubeadm init 和 kubeadm join。相信你一定会有这样的疑问：kubeadm 确实简单易用，可是我又该如何定制我的集群组件参数呢？ 比如，我要指定 kube-apiserver 的启动参数，该怎么办？ 在这里，我强烈推荐你在使用 kubeadm init 部署 Master 节点时，使用下面这条指令： 1$ kubeadm init --config kubeadm.yaml 这时，你就可以给 kubeadm 提供一个 YAML 文件（比如，kubeadm.yaml），它的内容如下所示（我仅列举了主要部分）： 123456789101112131415161718192021222324252627apiVersion: kubeadm.k8s.io/v1alpha2kind: MasterConfigurationkubernetesVersion: v1.11.0api: advertiseAddress: 192.168.0.102 bindPort: 6443 ...etcd: local: dataDir: /var/lib/etcd image: &quot;&quot;imageRepository: k8s.gcr.iokubeProxy: config: bindAddress: 0.0.0.0 ...kubeletConfiguration: baseConfig: address: 0.0.0.0 ...networking: dnsDomain: cluster.local podSubnet: &quot;&quot; serviceSubnet: 10.96.0.0/12nodeRegistration: criSocket: /var/run/dockershim.sock ... 通过制定这样一个部署参数配置文件，你就可以很方便地在这个文件里填写各种自定义的部署参数了。比如，我现在要指定 kube-apiserver 的参数，那么我只要在这个文件里加上这样一段信息： 123456...apiServerExtraArgs: advertise-address: 192.168.0.103 anonymous-auth: false enable-admission-plugins: AlwaysPullImages,DefaultStorageClass audit-log-path: /home/johndoe/audit.log 然后，kubeadm 就会使用上面这些信息替换 /etc/kubernetes/manifests/kube-apiserver.yaml 里的 command 字段里的参数了。 而这个 YAML 文件提供的可配置项远不止这些。比如，你还可以修改 kubelet 和 kube-proxy 的配置，修改 Kubernetes 使用的基础镜像的 URL（默认的k8s.gcr.io/xxx镜像 URL 在国内访问是有困难的），指定自己的证书文件，指定特殊的容器运行时等等。 搭建完整Kubernetes集群这里所说的“完整”，指的是这个集群具备 Kubernetes 项目在 GitHub 上已经发布的所有功能，并能够模拟生产环境的所有使用需求。但并不代表这个集群是生产级别可用的：类似于高可用、授权、多租户、灾难备份等生产级别集群的功能暂时不在本篇文章的讨论范围。 这次部署，我不会依赖于任何公有云或私有云的能力，而是完全在 Bare-metal 环境中完成。这样的部署经验会更有普适性。 准备工作首先，准备机器。最直接的办法，自然是到公有云上申请几个虚拟机。当然，如果条件允许的话，拿几台本地的物理服务器来组集群是最好不过了。这些机器只要满足如下几个条件即可： 满足安装 Docker 项目所需的要求，比如 64 位的 Linux 操作系统、3.10 及以上的内核版本； x86 或者 ARM 架构均可； 机器之间网络互通，这是将来容器之间网络互通的前提； 有外网访问权限，因为需要拉取镜像； 能够访问到gcr.io、quay.io这两个 docker registry，因为有小部分镜像需要在这里拉取； 单机可用资源建议 2 核 CPU、8 GB 内存或以上，再小的话问题也不大，但是能调度的 Pod 数量就比较有限了； 30 GB 或以上的可用磁盘空间，这主要是留给 Docker 镜像和日志文件用的。 在本次部署中，我准备的机器配置如下： 2 核 CPU、 7.5 GB 内存； 30 GB 磁盘； Ubuntu 16.04； 内网互通； 外网访问权限不受限制。 然后，我再和你介绍一下今天实践的目标： 在所有节点上安装 Docker 和 kubeadm； 部署 Kubernetes Master； 部署容器网络插件； 部署 Kubernetes Worker； 部署 Dashboard 可视化插件； 部署容器存储插件。 安装 kubeadm 和 Docker前面已经介绍过 kubeadm 的基础用法，它的一键安装非常方便，我们只需要添加 kubeadm 的源，然后直接使用 apt-get 安装即可，具体流程如下所示： 123456$ curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -$ cat &lt;&lt;EOF &gt; /etc/apt/sources.list.d/kubernetes.listdeb http://apt.kubernetes.io/ kubernetes-xenial mainEOF$ apt-get update$ apt-get install -y docker.io kubeadm 在上述安装 kubeadm 的过程中，kubeadm 和 kubelet、kubectl、kubernetes-cni 这几个二进制文件都会被自动安装好。 另外，这里我直接使用 Ubuntu 的 docker.io 的安装源，原因是 Docker 公司每次发布的最新的 Docker CE（社区版）产品往往还没有经过 Kubernetes 项目的验证，可能会有兼容性方面的问题。 部署 Kubernetes 的 Master 节点前面已经介绍过 kubeadm 可以一键部署 Master 节点，这里既然要部署一个“完整”的 Kubernetes 集群，那我们不妨稍微提高一下难度：通过配置文件来开启一些实验性功能。 所以，这里我编写了一个给 kubeadm 用的 YAML 文件（名叫：kubeadm.yaml）： 123456789apiVersion: kubeadm.k8s.io/v1alpha1kind: MasterConfigurationcontrollerManagerExtraArgs: horizontal-pod-autoscaler-use-rest-clients: &quot;true&quot; horizontal-pod-autoscaler-sync-period: &quot;10s&quot; node-monitor-grace-period: &quot;10s&quot;apiServerExtraArgs: runtime-config: &quot;api/all=true&quot;kubernetesVersion: &quot;stable-1.11&quot; 这个配置中，我给 kube-controller-manager 设置了： 1horizontal-pod-autoscaler-use-rest-clients: &quot;true&quot; 这意味着，将来部署的 kube-controller-manager 能够使用自定义资源（Custom Metrics）进行自动水平扩展。 其中，“stable-1.11”就是 kubeadm 帮我们部署的 Kubernetes 版本号，即：Kubernetes release 1.11 最新的稳定版，在我的环境下，它是 v1.11.1。你也可以直接指定这个版本，比如：kubernetesVersion: “v1.11.1”。 然后，我们只需要执行一句指令： 1$ kubeadm init --config kubeadm.yaml 就可以完成 Kubernetes Master 的部署了，这个过程只需要几分钟。部署完成后，kubeadm 会生成一行指令： 1kubeadm join 10.168.0.2:6443 --token 00bwbx.uvnaa2ewjflwu1ry --discovery-token-ca-cert-hash sha256:00eb62a2a6020f94132e3fe1ab721349bbcd3e9b94da9654cfe15f2985ebd711 这个 kubeadm join 命令，就是用来给这个 Master 节点添加更多工作节点（Worker）的命令。我们在后面部署 Worker 节点的时候马上会用到它，所以找一个地方把这条命令记录下来。 此外，kubeadm 还会提示我们第一次使用 Kubernetes 集群所需要的配置命令： 123mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config 而需要这些配置命令的原因是：Kubernetes 集群默认需要加密方式访问。所以，这几条命令，就是将刚刚部署生成的 Kubernetes 集群的安全配置文件，保存到当前用户的.kube 目录下，kubectl 默认会使用这个目录下的授权信息访问 Kubernetes 集群。 如果不这么做的话，我们每次都需要通过 export KUBECONFIG 环境变量告诉 kubectl 这个安全配置文件的位置。 现在，我们就可以使用 kubectl get 命令来查看当前唯一一个节点的状态了： 1234$ kubectl get nodes NAME STATUS ROLES AGE VERSIONmaster NotReady master 1d v1.11.1 可以看到，这个 get 指令输出的结果里，Master 节点的状态是 NotReady，这是为什么呢？ 在调试 Kubernetes 集群时，最重要的手段就是用 kubectl describe 来查看这个节点（Node）对象的详细信息、状态和事件（Event），我们来试一下： 1234567$ kubectl describe node master ...Conditions:... Ready False ... KubeletNotReady runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized 通过 kubectl describe 指令的输出，我们可以看到 NodeNotReady 的原因在于，我们尚未部署任何网络插件。 另外，我们还可以通过 kubectl 检查这个节点上各个系统 Pod 的状态，其中，kube-system 是 Kubernetes 项目预留的系统 Pod 的工作空间（Namepsace，注意它并不是 Linux Namespace，它只是 Kubernetes 划分不同工作空间的单位）： 12345678910$ kubectl get pods -n kube-system NAME READY STATUS RESTARTS AGEcoredns-78fcdf6894-j9s52 0/1 Pending 0 1hcoredns-78fcdf6894-jm4wf 0/1 Pending 0 1hetcd-master 1/1 Running 0 2skube-apiserver-master 1/1 Running 0 1skube-controller-manager-master 0/1 Pending 0 1skube-proxy-xbd47 1/1 NodeLost 0 1hkube-scheduler-master 1/1 Running 0 1s 可以看到，CoreDNS、kube-controller-manager 等依赖于网络的 Pod 都处于 Pending 状态，即调度失败。这当然是符合预期的：因为这个 Master 节点的网络尚未就绪。 部署网络插件在 Kubernetes 项目“一切皆容器”的设计理念指导下，部署网络插件非常简单，只需要执行一句 kubectl apply 指令，以 Weave 为例： 1$ kubectl apply -f https://git.io/weave-kube-1.6 部署完成后，我们可以通过 kubectl get 重新检查 Pod 的状态： 1234567891011$ kubectl get pods -n kube-system NAME READY STATUS RESTARTS AGEcoredns-78fcdf6894-j9s52 1/1 Running 0 1dcoredns-78fcdf6894-jm4wf 1/1 Running 0 1detcd-master 1/1 Running 0 9skube-apiserver-master 1/1 Running 0 9skube-controller-manager-master 1/1 Running 0 9skube-proxy-xbd47 1/1 Running 0 1dkube-scheduler-master 1/1 Running 0 9sweave-net-cmk27 2/2 Running 0 19s 可以看到，所有的系统 Pod 都成功启动了，而刚刚部署的 Weave 网络插件则在 kube-system 下面新建了一个名叫 weave-net-cmk27 的 Pod，一般来说，这些 Pod 就是容器网络插件在每个节点上的控制组件。 Kubernetes 支持容器网络插件，使用的是一个名叫 CNI 的通用接口，它也是当前容器网络的事实标准，市面上的所有容器网络开源项目都可以通过 CNI 接入 Kubernetes，比如 Flannel、Calico、Canal、Romana 等等，它们的部署方式也都是类似的“一键部署”。 至此，Kubernetes 的 Master 节点就部署完成了。如果你只需要一个单节点的 Kubernetes，现在你就可以使用了。不过，在默认情况下，Kubernetes 的 Master 节点是不能运行用户 Pod 的，所以还需要额外做一个小操作。稍后我会介绍到它。 部署 Kubernetes 的 Worker 节点Kubernetes 的 Worker 节点跟 Master 节点几乎是相同的，它们运行着的都是一个 kubelet 组件。唯一的区别在于，在 kubeadm init 的过程中，kubelet 启动后，Master 节点上还会自动运行 kube-apiserver、kube-scheduler、kube-controller-manger 这三个系统 Pod。 所以，相比之下，部署 Worker 节点反而是最简单的，只需要两步即可完成。 第一步，在所有 Worker 节点上执行“安装 kubeadm 和 Docker”一节的所有步骤。 第二步，执行部署 Master 节点时生成的 kubeadm join 指令： 1$ kubeadm join 10.168.0.2:6443 --token 00bwbx.uvnaa2ewjflwu1ry --discovery-token-ca-cert-hash sha256:00eb62a2a6020f94132e3fe1ab721349bbcd3e9b94da9654cfe15f2985ebd711 通过 Taint/Toleration 调整 Master 执行 Pod 的策略我在前面提到过，默认情况下 Master 节点是不允许运行用户 Pod 的。而 Kubernetes 做到这一点，依靠的是 Kubernetes 的 Taint/Toleration 机制。 它的原理非常简单：一旦某个节点被加上了一个 Taint，即被“打上了污点”，那么所有 Pod 就都不能在这个节点上运行，因为 Kubernetes 的 Pod 都有“洁癖”。 除非，有个别的 Pod 声明自己能“容忍”这个“污点”，即声明了 Toleration，它才可以在这个节点上运行。 其中，为节点打上“污点”（Taint）的命令是： 1$ kubectl taint nodes node1 foo=bar:NoSchedule 这时，该 node1 节点上就会增加一个键值对格式的 Taint，即：foo=bar:NoSchedule。其中值里面的 NoSchedule，意味着这个 Taint 只会在调度新 Pod 时产生作用，而不会影响已经在 node1 上运行的 Pod，哪怕它们没有 Toleration。 那么 Pod 又如何声明 Toleration 呢？ 我们只要在 Pod 的.yaml 文件中的 spec 部分，加入 tolerations 字段即可： 123456789apiVersion: v1kind: Pod...spec: tolerations: - key: &quot;foo&quot; operator: &quot;Equal&quot; value: &quot;bar&quot; effect: &quot;NoSchedule&quot; 这个 Toleration 的含义是，这个 Pod 能“容忍”所有键值对为 foo=bar 的 Taint（ operator: “Equal”，“等于”操作）。 现在回到我们已经搭建的集群上来。这时，如果你通过 kubectl describe 检查一下 Master 节点的 Taint 字段，就会有所发现了： 12345$ kubectl describe node master Name: masterRoles: masterTaints: node-role.kubernetes.io/master:NoSchedule 可以看到，Master 节点默认被加上了node-role.kubernetes.io/master:NoSchedule这样一个“污点”，其中“键”是node-role.kubernetes.io/master，而没有提供“值”。 此时，你就需要像下面这样用“Exists”操作符（operator: “Exists”，“存在”即可）来说明，该 Pod 能够容忍所有以 foo 为键的 Taint，才能让这个 Pod 运行在该 Master 节点上： 12345678apiVersion: v1kind: Pod...spec: tolerations: - key: &quot;foo&quot; operator: &quot;Exists&quot; effect: &quot;NoSchedule&quot; 当然，如果你就是想要一个单节点的 Kubernetes，删除这个 Taint 才是正确的选择： 1$ kubectl taint nodes --all node-role.kubernetes.io/master- 如上所示，我们在“node-role.kubernetes.io/master”这个键后面加上了一个短横线“-”，这个格式就意味着移除所有以“node-role.kubernetes.io/master”为键的 Taint。 到了这一步，一个基本完整的 Kubernetes 集群就部署完毕了。是不是很简单呢？ 有了 kubeadm 这样的原生管理工具，Kubernetes 的部署已经被大大简化。更重要的是，像证书、授权、各个组件的配置等部署中最麻烦的操作，kubeadm 都已经帮你完成了。 接下来，我们再在这个 Kubernetes 集群上安装一些其他的辅助插件，比如 Dashboard 和存储插件。 部署 Dashboard 可视化插件在 Kubernetes 社区中，有一个很受欢迎的 Dashboard 项目，它可以给用户提供一个可视化的 Web 界面来查看当前集群的各种信息。毫不意外，它的部署也相当简单： 1$ kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml 部署完成之后，我们就可以查看 Dashboard 对应的 Pod 的状态了： 123$ kubectl get pods -n kube-system kubernetes-dashboard-6948bdb78-f67xk 1/1 Running 0 1m 需要注意的是，由于 Dashboard 是一个 Web Server，很多人经常会在自己的公有云上无意地暴露 Dashboard 的端口，从而造成安全隐患。所以，1.7 版本之后的 Dashboard 项目部署完成后，默认只能通过 Proxy 的方式在本地访问。具体的操作，你可以查看 Dashboard 项目的官方文档。 而如果你想从集群外访问这个 Dashboard 的话，就需要用到 Ingress。 部署容器存储插件接下来，让我们完成这个 Kubernetes 集群的最后一块拼图：容器持久化存储。 我在前面介绍容器原理时已经提到过，很多时候我们需要用数据卷（Volume）把外面宿主机上的目录或者文件挂载进容器的 Mount Namespace 中，从而达到容器和宿主机共享这些目录或者文件的目的。容器里的应用，也就可以在这些数据卷中新建和写入文件。 可是，如果你在某一台机器上启动的一个容器，显然无法看到其他机器上的容器在它们的数据卷里写入的文件。这是容器最典型的特征之一：无状态。 而容器的持久化存储，就是用来保存容器存储状态的重要手段：存储插件会在容器里挂载一个基于网络或者其他机制的远程数据卷，使得在容器里创建的文件，实际上是保存在远程存储服务器上，或者以分布式的方式保存在多个节点上，而与当前宿主机没有任何绑定关系。这样，无论你在其他哪个宿主机上启动新的容器，都可以请求挂载指定的持久化存储卷，从而访问到数据卷里保存的内容。这就是“持久化”的含义。 由于 Kubernetes 本身的松耦合设计，绝大多数存储项目，比如 Ceph、GlusterFS、NFS 等，都可以为 Kubernetes 提供持久化存储能力。在这次的部署实战中，我会选择部署一个很重要的 Kubernetes 存储插件项目：Rook。 Rook 项目是一个基于 Ceph 的 Kubernetes 存储插件（它后期也在加入对更多存储实现的支持）。不过，不同于对 Ceph 的简单封装，Rook 在自己的实现中加入了水平扩展、迁移、灾难备份、监控等大量的企业级功能，使得这个项目变成了一个完整的、生产级别可用的容器存储插件。 得益于容器化技术，用两条指令，Rook 就可以把复杂的 Ceph 存储后端部署起来： 123$ kubectl apply -f https://raw.githubusercontent.com/rook/rook/master/cluster/examples/kubernetes/ceph/operator.yaml $ kubectl apply -f https://raw.githubusercontent.com/rook/rook/master/cluster/examples/kubernetes/ceph/cluster.yaml 在部署完成后，你就可以看到 Rook 项目会将自己的 Pod 放置在由它自己管理的两个 Namespace 当中： 12345678910$ kubectl get pods -n rook-ceph-systemNAME READY STATUS RESTARTS AGErook-ceph-agent-7cv62 1/1 Running 0 15srook-ceph-operator-78d498c68c-7fj72 1/1 Running 0 44srook-discover-2ctcv 1/1 Running 0 15s $ kubectl get pods -n rook-cephNAME READY STATUS RESTARTS AGErook-ceph-mon0-kxnzh 1/1 Running 0 13srook-ceph-mon1-7dn2t 1/1 Running 0 2s 这样，一个基于 Rook 持久化存储集群就以容器的方式运行起来了，而接下来在 Kubernetes 项目上创建的所有 Pod 就能够通过 Persistent Volume（PV）和 Persistent Volume Claim（PVC）的方式，在容器里挂载由 Ceph 提供的数据卷了。 而 Rook 项目，则会负责这些数据卷的生命周期管理、灾难备份等运维工作。 这时候，你可能会有个疑问：为什么我要选择 Rook 项目呢？ 其实，是因为这个项目很有前途。 如果你去研究一下 Rook 项目的实现，就会发现它巧妙地依赖了 Kubernetes 提供的编排能力，合理的使用了很多诸如 Operator、CRD 等重要的扩展特性。这使得 Rook 项目，成为了目前社区中基于 Kubernetes API 构建的最完善也最成熟的容器存储插件。 备注：其实，在很多时候，大家说的所谓“云原生”，就是“Kubernetes 原生”的意思。而像 Rook、Istio 这样的项目，正是贯彻这个思路的典范。在我们后面讲解了声明式 API 之后，相信你对这些项目的设计思想会有更深刻的体会。 这个集群的部署过程并不像传说中那么繁琐，这主要得益于： kubeadm 项目大大简化了部署 Kubernetes 的准备工作，尤其是配置文件、证书、二进制文件的准备和制作，以及集群版本管理等操作，都被 kubeadm 接管了。 Kubernetes 本身“一切皆容器”的设计思想，加上良好的可扩展机制，使得插件的部署非常简便。 上述思想，也是开发和使用 Kubernetes 的重要指导思想，即：基于 Kubernetes 开展工作时，你一定要优先考虑这两个问题： 我的工作是不是可以容器化？ 我的工作是不是可以借助 Kubernetes API 和可扩展机制来完成？ 而一旦这项工作能够基于 Kubernetes 实现容器化，就很有可能像上面的部署过程一样，大幅简化原本复杂的运维工作。对于时间宝贵的技术人员来说，这个变化的重要性是不言而喻的。 发布容器化应用在开始实践之前，我先给你讲解一下 Kubernetes 里面与开发者关系最密切的几个概念。 作为一个应用开发者，你首先要做的，是制作容器的镜像。而有了容器镜像之后，你需要按照 Kubernetes 项目的规范和要求，将你的镜像组织为它能够“认识”的方式，然后提交上去。 那么，什么才是 Kubernetes 项目能“认识”的方式呢？ 这就是使用 Kubernetes 的必备技能：编写配置文件。 备注：这些配置文件可以是 YAML 或者 JSON 格式的。为方便阅读与理解，在后面的讲解中，我会统一使用 YAML 文件来指代它们。 Kubernetes 跟 Docker 等很多项目最大的不同，就在于它不推荐你使用命令行的方式直接运行容器（虽然 Kubernetes 项目也支持这种方式，比如：kubectl run），而是希望你用 YAML 文件的方式，即：把容器的定义、参数、配置，统统记录在一个 YAML 文件中，然后用这样一句指令把它运行起来： 1$ kubectl create -f 我的配置文件 这么做最直接的好处是，你会有一个文件能记录下 Kubernetes 到底“run”了什么。比如下面这个例子： 12345678910111213141516171819apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deploymentspec: selector: matchLabels: app: nginx replicas: 2 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 像这样的一个 YAML 文件，对应到 Kubernetes 中，就是一个 API Object（API 对象）。当你为这个对象的各个字段填好值并提交给 Kubernetes 之后，Kubernetes 就会负责创建出这些对象所定义的容器或者其他类型的 API 资源。 可以看到，这个 YAML 文件中的 Kind 字段，指定了这个 API 对象的类型（Type），是一个 Deployment。 所谓 Deployment，是一个定义多副本应用（即多个副本 Pod）的对象。此外，Deployment 还负责在 Pod 定义发生变化时，对每个副本进行滚动更新（Rolling Update）。 在上面这个 YAML 文件中，我给它定义的 Pod 副本个数 (spec.replicas) 是：2。 而这些 Pod 具体的又长什么样子呢？ 为此，我定义了一个 Pod 模版（spec.template），这个模版描述了我想要创建的 Pod 的细节。在上面的例子里，这个 Pod 里只有一个容器，这个容器的镜像（spec.containers.image）是 nginx:1.7.9，这个容器监听端口（containerPort）是 80。 Pod 就是 Kubernetes 世界里的“应用”；而一个应用，可以由多个容器组成。 需要注意的是，像这样使用一种 API 对象（Deployment）管理另一种 API 对象（Pod）的方法，在 Kubernetes 中，叫作“控制器”模式（controller pattern）。在我们的例子中，Deployment 扮演的正是 Pod 的控制器的角色。 你可能还注意到，这样的每一个 API 对象都有一个叫作 Metadata 的字段，这个字段就是 API 对象的“标识”，即元数据，它也是我们从 Kubernetes 里找到这个对象的主要依据。这其中最主要使用到的字段是 Labels。 顾名思义，Labels 就是一组 key-value 格式的标签。而像 Deployment 这样的控制器对象，就可以通过这个 Labels 字段从 Kubernetes 中过滤出它所关心的被控制对象。 比如，在上面这个 YAML 文件中，Deployment 会把所有正在运行的、携带“app: nginx”标签的 Pod 识别为被管理的对象，并确保这些 Pod 的总数严格等于两个。 而这个过滤规则的定义，是在 Deployment 的“spec.selector.matchLabels”字段。我们一般称之为：Label Selector。 另外，在 Metadata 中，还有一个与 Labels 格式、层级完全相同的字段叫 Annotations，它专门用来携带 key-value 格式的内部信息。所谓内部信息，指的是对这些信息感兴趣的，是 Kubernetes 组件本身，而不是用户。所以大多数 Annotations，都是在 Kubernetes 运行过程中，被自动加在这个 API 对象上。 一个 Kubernetes 的 API 对象的定义，大多可以分为 Metadata 和 Spec 两个部分。前者存放的是这个对象的元数据，对所有 API 对象来说，这一部分的字段和格式基本上是一样的；而后者存放的，则是属于这个对象独有的定义，用来描述它所要表达的功能。 在了解了上述 Kubernetes 配置文件的基本知识之后，我们现在就可以把这个 YAML 文件“运行”起来。正如前所述，你可以使用 kubectl create 指令完成这个操作： 1$ kubectl create -f nginx-deployment.yaml 然后，通过 kubectl get 命令检查这个 YAML 运行起来的状态是不是与我们预期的一致： 1234$ kubectl get pods -l app=nginxNAME READY STATUS RESTARTS AGEnginx-deployment-67594d6bf6-9gdvr 1/1 Running 0 10mnginx-deployment-67594d6bf6-v6j7w 1/1 Running 0 10m kubectl get 指令的作用，就是从 Kubernetes 里面获取（GET）指定的 API 对象。可以看到，在这里我还加上了一个 -l 参数，即获取所有匹配 app: nginx 标签的 Pod。需要注意的是，在命令行中，所有 key-value 格式的参数，都使用“=”而非“:”表示。 从这条指令返回的结果中，我们可以看到现在有两个 Pod 处于 Running 状态，也就意味着我们这个 Deployment 所管理的 Pod 都处于预期的状态。 此外， 你还可以使用 kubectl describe 命令，查看一个 API 对象的细节，比如： 12345678910111213141516171819202122232425$ kubectl describe pod nginx-deployment-67594d6bf6-9gdvrName: nginx-deployment-67594d6bf6-9gdvrNamespace: defaultPriority: 0PriorityClassName: &lt;none&gt;Node: node-1/10.168.0.3Start Time: Thu, 16 Aug 2018 08:48:42 +0000Labels: app=nginx pod-template-hash=2315082692Annotations: &lt;none&gt;Status: RunningIP: 10.32.0.23Controlled By: ReplicaSet/nginx-deployment-67594d6bf6...Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 1m default-scheduler Successfully assigned default/nginx-deployment-67594d6bf6-9gdvr to node-1 Normal Pulling 25s kubelet, node-1 pulling image &quot;nginx:1.7.9&quot; Normal Pulled 17s kubelet, node-1 Successfully pulled image &quot;nginx:1.7.9&quot; Normal Created 17s kubelet, node-1 Created container Normal Started 17s kubelet, node-1 Started container 在 kubectl describe 命令返回的结果中，你可以清楚地看到这个 Pod 的详细信息，比如它的 IP 地址等等。其中，有一个部分值得你特别关注，它就是Events（事件）。 在 Kubernetes 执行的过程中，对 API 对象的所有重要操作，都会被记录在这个对象的 Events 里，并且显示在 kubectl describe 指令返回的结果中。 比如，对于这个 Pod，我们可以看到它被创建之后，被调度器调度（Successfully assigned）到了 node-1，拉取了指定的镜像（pulling image），然后启动了 Pod 里定义的容器（Started container）。 所以，这个部分正是我们将来进行 Debug 的重要依据。如果有异常发生，你一定要第一时间查看这些 Events，往往可以看到非常详细的错误信息。 接下来，如果我们要对这个 Nginx 服务进行升级，把它的镜像版本从 1.7.9 升级为 1.8，要怎么做呢？ 很简单，我们只要修改这个 YAML 文件即可。 1234567... spec: containers: - name: nginx image: nginx:1.8 # 这里被从 1.7.9 修改为 1.8 ports: - containerPort: 80 可是，这个修改目前只发生在本地，如何让这个更新在 Kubernetes 里也生效呢？ 我们可以使用 kubectl replace 指令来完成这个更新： 1$ kubectl replace -f nginx-deployment.yaml 不过，在本专栏里，我推荐你使用 kubectl apply 命令，来统一进行 Kubernetes 对象的创建和更新操作，具体做法如下所示： 12345$ kubectl apply -f nginx-deployment.yaml # 修改 nginx-deployment.yaml 的内容 $ kubectl apply -f nginx-deployment.yaml 这样的操作方法，是 Kubernetes“声明式 API”所推荐的使用方法。也就是说，作为用户，你不必关心当前的操作是创建，还是更新，你执行的命令始终是 kubectl apply，而 Kubernetes 则会根据 YAML 文件的内容变化，自动进行具体的处理。 而这个流程的好处是，它有助于帮助开发和运维人员，围绕着可以版本化管理的 YAML 文件，而不是“行踪不定”的命令行进行协作，从而大大降低开发人员和运维人员之间的沟通成本。 举个例子，一位开发人员开发好一个应用，制作好了容器镜像。那么他就可以在应用的发布目录里附带上一个 Deployment 的 YAML 文件。 而运维人员，拿到这个应用的发布目录后，就可以直接用这个 YAML 文件执行 kubectl apply 操作把它运行起来。 这时候，如果开发人员修改了应用，生成了新的发布内容，那么这个 YAML 文件，也就需要被修改，并且成为这次变更的一部分。 而接下来，运维人员可以使用 git diff 命令查看到这个 YAML 文件本身的变化，然后继续用 kubectl apply 命令更新这个应用。 所以说，如果通过容器镜像，我们能够保证应用本身在开发与部署环境里的一致性的话，那么现在，Kubernetes 项目通过这些 YAML 文件，就保证了应用的“部署参数”在开发与部署环境中的一致性。 而当应用本身发生变化时，开发人员和运维人员可以依靠容器镜像来进行同步；当应用部署参数发生变化时，这些 YAML 文件就是他们相互沟通和信任的媒介。 以上，就是 Kubernetes 发布应用的最基本操作了。 接下来，我们再在这个 Deployment 中尝试声明一个 Volume。 在 Kubernetes 中，Volume 是属于 Pod 对象的一部分。所以，我们就需要修改这个 YAML 文件里的 template.spec 字段，如下所示： 12345678910111213141516171819202122232425apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deploymentspec: selector: matchLabels: app: nginx replicas: 2 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.8 ports: - containerPort: 80 volumeMounts: - mountPath: &quot;/usr/share/nginx/html&quot; name: nginx-vol volumes: - name: nginx-vol emptyDir: &#123;&#125; 可以看到，我们在 Deployment 的 Pod 模板部分添加了一个 volumes 字段，定义了这个 Pod 声明的所有 Volume。它的名字叫作 nginx-vol，类型是 emptyDir。 那什么是 emptyDir 类型呢？ 它其实就等同于我们之前讲过的 Docker 的隐式 Volume 参数，即：不显式声明宿主机目录的 Volume。所以，Kubernetes 也会在宿主机上创建一个临时目录，这个目录将来就会被绑定挂载到容器所声明的 Volume 目录上。 备注：不难看到，Kubernetes 的 emptyDir 类型，只是把 Kubernetes 创建的临时目录作为 Volume 的宿主机目录，交给了 Docker。这么做的原因，是 Kubernetes 不想依赖 Docker 自己创建的那个 _data 目录。 而 Pod 中的容器，使用的是 volumeMounts 字段来声明自己要挂载哪个 Volume，并通过 mountPath 字段来定义容器内的 Volume 目录，比如：/usr/share/nginx/html。 当然，Kubernetes 也提供了显式的 Volume 定义，它叫做 hostPath。比如下面的这个 YAML 文件： 12345... volumes: - name: nginx-vol hostPath: path: /var/data 这样，容器 Volume 挂载的宿主机目录，就变成了 /var/data。 在上述修改完成后，我们还是使用 kubectl apply 指令，更新这个 Deployment: 1$ kubectl apply -f nginx-deployment.yaml 接下来，你可以通过 kubectl get 指令，查看两个 Pod 被逐一更新的过程： 123456789$ kubectl get podsNAME READY STATUS RESTARTS AGEnginx-deployment-5c678cfb6d-v5dlh 0/1 ContainerCreating 0 4snginx-deployment-67594d6bf6-9gdvr 1/1 Running 0 10mnginx-deployment-67594d6bf6-v6j7w 1/1 Running 0 10m$ kubectl get podsNAME READY STATUS RESTARTS AGEnginx-deployment-5c678cfb6d-lg9lw 1/1 Running 0 8snginx-deployment-5c678cfb6d-v5dlh 1/1 Running 0 19s 从返回结果中，我们可以看到，新旧两个 Pod，被交替创建、删除，最后剩下的就是新版本的 Pod。这个滚动更新的过程，我也会在后续进行详细的讲解。 然后，你可以使用 kubectl describe 查看一下最新的 Pod，就会发现 Volume 的信息已经出现在了 Container 描述部分： 12345678910111213...Containers: nginx: Container ID: docker://07b4f89248791c2aa47787e3da3cc94b48576cd173018356a6ec8db2b6041343 Image: nginx:1.8 ... Environment: &lt;none&gt; Mounts: /usr/share/nginx/html from nginx-vol (rw)...Volumes: nginx-vol: Type: EmptyDir (a temporary directory that shares a pod&#x27;s lifetime) 最后，你还可以使用 kubectl exec 指令，进入到这个 Pod 当中（即容器的 Namespace 中）查看这个 Volume 目录： 12$ kubectl exec -it nginx-deployment-5c678cfb6d-lg9lw -- /bin/bash# ls /usr/share/nginx/html 此外，你想要从 Kubernetes 集群中删除这个 Nginx Deployment 的话，直接执行： 1$ kubectl delete -f nginx-deployment.yaml 就可以了。 可以看到，Kubernetes 推荐的使用方式，是用一个 YAML 文件来描述你所要部署的 API 对象。然后，统一使用 kubectl apply 命令完成对这个对象的创建和更新操作。 而 Kubernetes 里“最小”的 API 对象是 Pod。Pod 可以等价为一个应用，所以，Pod 可以由多个紧密协作的容器组成。 在 Kubernetes 中，我们经常会看到它通过一种 API 对象来管理另一种 API 对象，比如 Deployment 和 Pod 之间的关系；而由于 Pod 是“最小”的对象，所以它往往都是被其他对象控制的。这种组合方式，正是 Kubernetes 进行容器编排的重要模式。 而像这样的 Kubernetes API 对象，往往由 Metadata 和 Spec 两部分组成，其中 Metadata 里的 Labels 字段是 Kubernetes 过滤对象的主要手段。 在这些字段里面，容器想要使用的数据卷，也就是 Volume，正是 Pod 的 Spec 字段的一部分。而 Pod 里的每个容器，则需要显式的声明自己要挂载哪个 Volume。 上面这些基于 YAML 文件的容器管理方式，跟 Docker、Mesos 的使用习惯都是不一样的，而从 docker run 这样的命令行操作，向 kubectl apply YAML 文件这样的声明式 API 的转变，是每一个容器技术学习者，必须要跨过的第一道门槛。 所以，如果你想要快速熟悉 Kubernetes，请按照下面的流程进行练习： 首先，在本地通过 Docker 测试代码，制作镜像； 然后，选择合适的 Kubernetes API 对象，编写对应 YAML 文件（比如，Pod，Deployment）； 最后，在 Kubernetes 上部署这个 YAML 文件。 更重要的是，在部署到 Kubernetes 之后，接下来的所有操作，要么通过 kubectl 来执行，要么通过修改 YAML 文件来实现，就尽量不要再碰 Docker 的命令行了。 参考链接：https://time.geekbang.org/column/intro/100015201","categories":[{"name":"云原生","slug":"云原生","permalink":"http://wht6.github.io/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://wht6.github.io/tags/Kubernetes/"},{"name":"集群","slug":"集群","permalink":"http://wht6.github.io/tags/%E9%9B%86%E7%BE%A4/"}]},{"title":"Docker容器实现原理","slug":"Docker容器实现原理","date":"2022-03-26T08:00:00.000Z","updated":"2022-03-27T01:38:44.180Z","comments":true,"path":"posts/bbe1.html","link":"","permalink":"http://wht6.github.io/posts/bbe1.html","excerpt":"","text":"容器与进程的关系假如，现在你要写一个计算加法的小程序，这个程序需要的输入来自于一个文件，计算完成后的结果则输出到另一个文件中。 由于计算机只认识 0 和 1，所以无论用哪种语言编写这段代码，最后都需要通过某种方式翻译成二进制文件，才能在计算机操作系统中运行起来。 而为了能够让这些代码正常运行，我们往往还要给它提供数据，比如我们这个加法程序所需要的输入文件。这些数据加上代码本身的二进制文件，放在磁盘上，就是我们平常所说的一个“程序”，也叫代码的可执行镜像（executable image）。 然后，我们就可以在计算机上运行这个“程序”了。 首先，操作系统从“程序”中发现输入数据保存在一个文件中，所以这些数据就被会加载到内存中待命。同时，操作系统又读取到了计算加法的指令，这时，它就需要指示 CPU 完成加法操作。而 CPU 与内存协作进行加法计算，又会使用寄存器存放数值、内存堆栈保存执行的命令和变量。同时，计算机里还有被打开的文件，以及各种各样的 I/O 设备在不断地调用中修改自己的状态。 就这样，一旦“程序”被执行起来，它就从磁盘上的二进制文件，变成了计算机内存中的数据、寄存器里的值、堆栈中的指令、被打开的文件，以及各种设备的状态信息的一个集合。像这样一个程序运起来后的计算机执行环境的总和，就是我们今天的主角：进程。 所以，对于进程来说，它的静态表现就是程序，平常都安安静静地待在磁盘上；而一旦运行起来，它就变成了计算机里的数据和状态的总和，这就是它的动态表现。 而容器技术的核心功能，就是通过约束和修改进程的动态表现，从而为其创造出一个“边界”。 对于 Docker 等大多数 Linux 容器来说，Cgroups 技术是用来制造约束的主要手段，而Namespace 技术则是用来修改进程视图的主要方法。 你可能会觉得 Cgroups 和 Namespace 这两个概念很抽象，别担心，接下来我们一起动手实践一下，你就很容易理解这两项技术了。 假设你已经有了一个 Linux 操作系统上的 Docker 项目在运行，比如我的环境是 Ubuntu 16.04 和 Docker CE 18.05。 接下来，让我们首先创建一个容器来试试。 1$ docker run -it busybox /bin/sh 这个命令是 Docker 项目最重要的一个操作，即大名鼎鼎的 docker run。 而 -it 参数告诉了 Docker 项目在启动容器后，需要给我们分配一个文本输入 / 输出环境，也就是 TTY，跟容器的标准输入相关联，这样我们就可以和这个 Docker 容器进行交互了。而 /bin/sh 就是我们要在 Docker 容器里运行的程序。 所以，上面这条指令翻译成人类的语言就是：请帮我启动一个容器，在容器里执行 /bin/sh，并且给我分配一个命令行终端跟这个容器交互。 这样，我的 Ubuntu 16.04 机器就变成了一个宿主机，而一个运行着 /bin/sh 的容器，就跑在了这个宿主机里面。 上面的例子和原理，如果你已经玩过 Docker，一定不会感到陌生。此时，如果我们在容器里执行一下 ps 指令，就会发现一些更有趣的事情： 1234/ # psPID USER TIME COMMAND 1 root 0:00 /bin/sh 10 root 0:00 ps 可以看到，我们在 Docker 里最开始执行的 /bin/sh，就是这个容器内部的第 1 号进程（PID=1），而这个容器里一共只有两个进程在运行。这就意味着，前面执行的 /bin/sh，以及我们刚刚执行的 ps，已经被 Docker 隔离在了一个跟宿主机完全不同的世界当中。 这究竟是怎么做到呢？ 本来，每当我们在宿主机上运行了一个 /bin/sh 程序，操作系统都会给它分配一个进程编号，比如 PID=100。这个编号是进程的唯一标识，就像员工的工牌一样。所以 PID=100，可以粗略地理解为这个 /bin/sh 是我们公司里的第 100 号员工，而第 1 号员工就自然是比尔 · 盖茨这样统领全局的人物。 而现在，我们要通过 Docker 把这个 /bin/sh 程序运行在一个容器当中。这时候，Docker 就会在这个第 100 号员工入职时给他施一个“障眼法”，让他永远看不到前面的其他 99 个员工，更看不到比尔 · 盖茨。这样，他就会错误地以为自己就是公司里的第 1 号员工。 这种机制，其实就是对被隔离应用的进程空间做了手脚，使得这些进程只能看到重新计算过的进程编号，比如 PID=1。可实际上，他们在宿主机的操作系统里，还是原来的第 100 号进程。 这种技术，就是 Linux 里面的 Namespace 机制。而 Namespace 的使用方式也非常有意思：它其实只是 Linux 创建新进程的一个可选参数。我们知道，在 Linux 系统中创建线程的系统调用是 clone()，比如： 1int pid = clone(main_function, stack_size, SIGCHLD, NULL); 这个系统调用就会为我们创建一个新的进程，并且返回它的进程号 pid。 而当我们用 clone() 系统调用创建一个新进程时，就可以在参数中指定 CLONE_NEWPID 参数，比如： 1int pid = clone(main_function, stack_size, CLONE_NEWPID | SIGCHLD, NULL); 这时，新创建的这个进程将会“看到”一个全新的进程空间，在这个进程空间里，它的 PID 是 1。之所以说“看到”，是因为这只是一个“障眼法”，在宿主机真实的进程空间里，这个进程的 PID 还是真实的数值，比如 100。 当然，我们还可以多次执行上面的 clone() 调用，这样就会创建多个 PID Namespace，而每个 Namespace 里的应用进程，都会认为自己是当前容器里的第 1 号进程，它们既看不到宿主机里真正的进程空间，也看不到其他 PID Namespace 里的具体情况。 而除了我们刚刚用到的 PID Namespace，Linux 操作系统还提供了 Mount、UTS、IPC、Network 和 User 这些 Namespace，用来对各种不同的进程上下文进行“障眼法”操作。 比如，Mount Namespace，用于让被隔离进程只看到当前 Namespace 里的挂载点信息；Network Namespace，用于让被隔离进程看到当前 Namespace 里的网络设备和配置。 这，就是 Linux 容器最基本的实现原理了。 所以，Docker 容器这个听起来玄而又玄的概念，实际上是在创建容器进程时，指定了这个进程所需要启用的一组 Namespace 参数。这样，容器就只能“看”到当前 Namespace 所限定的资源、文件、设备、状态，或者配置。而对于宿主机以及其他不相关的程序，它就完全看不到了。 所以说，容器，其实是一种特殊的进程而已。 谈到为“进程划分一个独立空间”的思想，相信你一定会联想到虚拟机。而且，你应该还看过一张虚拟机和容器的对比图。 这幅图的左边，画出了虚拟机的工作原理。其中，名为 Hypervisor 的软件是虚拟机最主要的部分。它通过硬件虚拟化功能，模拟出了运行一个操作系统需要的各种硬件，比如 CPU、内存、I/O 设备等等。然后，它在这些虚拟的硬件上安装了一个新的操作系统，即 Guest OS。 这样，用户的应用进程就可以运行在这个虚拟的机器中，它能看到的自然也只有 Guest OS 的文件和目录，以及这个机器里的虚拟设备。这就是为什么虚拟机也能起到将不同的应用进程相互隔离的作用。 而这幅图的右边，则用一个名为 Docker Engine 的软件替换了 Hypervisor。这也是为什么，很多人会把 Docker 项目称为“轻量级”虚拟化技术的原因，实际上就是把虚拟机的概念套在了容器上。 可是这样的说法，却并不严谨。 在理解了 Namespace 的工作方式之后，你就会明白，跟真实存在的虚拟机不同，在使用 Docker 的时候，并没有一个真正的“Docker 容器”运行在宿主机里面。Docker 项目帮助用户启动的，还是原来的应用进程，只不过在创建这些进程时，Docker 为它们加上了各种各样的 Namespace 参数。 这时，这些进程就会觉得自己是各自 PID Namespace 里的第 1 号进程，只能看到各自 Mount Namespace 里挂载的目录和文件，只能访问到各自 Network Namespace 里的网络设备，就仿佛运行在一个个“容器”里面，与世隔绝。 隔离与限制你应该能够明白，Namespace 技术实际上修改了应用进程看待整个计算机“视图”，即它的“视线”被操作系统做了限制，只能“看到”某些指定的内容。但对于宿主机来说，这些被“隔离”了的进程跟其他进程并没有太大区别。 说到这一点，相信你也能够知道我在上一篇文章最后给你留下的第一个思考题的答案了：在之前虚拟机与容器技术的对比图里，不应该把 Docker Engine 或者任何容器管理工具放在跟 Hypervisor 相同的位置，因为它们并不像 Hypervisor 那样对应用进程的隔离环境负责，也不会创建任何实体的“容器”，真正对隔离环境负责的是宿主机操作系统本身： 所以，在这个对比图里，我们应该把 Docker 画在跟应用同级别并且靠边的位置。这意味着，用户运行在容器里的应用进程，跟宿主机上的其他进程一样，都由宿主机操作系统统一管理，只不过这些被隔离的进程拥有额外设置过的 Namespace 参数。而 Docker 项目在这里扮演的角色，更多的是旁路式的辅助和管理工作。 这样的架构也解释了为什么 Docker 项目比虚拟机更受欢迎的原因。 这是因为，使用虚拟化技术作为应用沙盒，就必须要由 Hypervisor 来负责创建虚拟机，这个虚拟机是真实存在的，并且它里面必须运行一个完整的 Guest OS 才能执行用户的应用进程。这就不可避免地带来了额外的资源消耗和占用。 根据实验，一个运行着 CentOS 的 KVM 虚拟机启动后，在不做优化的情况下，虚拟机自己就需要占用 100~200 MB 内存。此外，用户应用运行在虚拟机里面，它对宿主机操作系统的调用就不可避免地要经过虚拟化软件的拦截和处理，这本身又是一层性能损耗，尤其对计算资源、网络和磁盘 I/O 的损耗非常大。 而相比之下，容器化后的用户应用，却依然还是一个宿主机上的普通进程，这就意味着这些因为虚拟化而带来的性能损耗都是不存在的；而另一方面，使用 Namespace 作为隔离手段的容器并不需要单独的 Guest OS，这就使得容器额外的资源占用几乎可以忽略不计。 所以说，“敏捷”和“高性能”是容器相较于虚拟机最大的优势，也是它能够在 PaaS 这种更细粒度的资源管理平台上大行其道的重要原因。 不过，有利就有弊，基于 Linux Namespace 的隔离机制相比于虚拟化技术也有很多不足之处，其中最主要的问题就是：隔离得不彻底。 首先，既然容器只是运行在宿主机上的一种特殊的进程，那么多个容器之间使用的就还是同一个宿主机的操作系统内核。 尽管你可以在容器里通过 Mount Namespace 单独挂载其他不同版本的操作系统文件，比如 CentOS 或者 Ubuntu，但这并不能改变共享宿主机内核的事实。这意味着，如果你要在 Windows 宿主机上运行 Linux 容器，或者在低版本的 Linux 宿主机上运行高版本的 Linux 容器，都是行不通的。 而相比之下，拥有硬件虚拟化技术和独立 Guest OS 的虚拟机就要方便得多了。最极端的例子是，Microsoft 的云计算平台 Azure，实际上就是运行在 Windows 服务器集群上的，但这并不妨碍你在它上面创建各种 Linux 虚拟机出来。 其次，在 Linux 内核中，有很多资源和对象是不能被 Namespace 化的，最典型的例子就是：时间。 这就意味着，如果你的容器中的程序使用 settimeofday(2) 系统调用修改了时间，整个宿主机的时间都会被随之修改，这显然不符合用户的预期。相比于在虚拟机里面可以随便折腾的自由度，在容器里部署应用的时候，“什么能做，什么不能做”，就是用户必须考虑的一个问题。 此外，由于上述问题，尤其是共享宿主机内核的事实，容器给应用暴露出来的攻击面是相当大的，应用“越狱”的难度自然也比虚拟机低得多。 更为棘手的是，尽管在实践中我们确实可以使用 Seccomp 等技术，对容器内部发起的所有系统调用进行过滤和甄别来进行安全加固，但这种方法因为多了一层对系统调用的过滤，一定会拖累容器的性能。何况，默认情况下，谁也不知道到底该开启哪些系统调用，禁止哪些系统调用。 所以，在生产环境中，没有人敢把运行在物理机上的 Linux 容器直接暴露到公网上。当然，基于虚拟化或者独立内核技术的容器实现，则可以比较好地在隔离与性能之间做出平衡。 在介绍完容器的“隔离”技术之后，我们再来研究一下容器的“限制”问题。 也许你会好奇，我们不是已经通过 Linux Namespace 创建了一个“容器”吗，为什么还需要对容器做“限制”呢？ 我还是以 PID Namespace 为例，来给你解释这个问题。 虽然容器内的第 1 号进程在“障眼法”的干扰下只能看到容器里的情况，但是宿主机上，它作为第 100 号进程与其他所有进程之间依然是平等的竞争关系。这就意味着，虽然第 100 号进程表面上被隔离了起来，但是它所能够使用到的资源（比如 CPU、内存），却是可以随时被宿主机上的其他进程（或者其他容器）占用的。当然，这个 100 号进程自己也可能把所有资源吃光。这些情况，显然都不是一个“沙盒”应该表现出来的合理行为。 而Linux Cgroups 就是 Linux 内核中用来为进程设置资源限制的一个重要功能。 有意思的是，Google 的工程师在 2006 年发起这项特性的时候，曾将它命名为“进程容器”（process container）。实际上，在 Google 内部，“容器”这个术语长期以来都被用于形容被 Cgroups 限制过的进程组。后来 Google 的工程师们说，他们的 KVM 虚拟机也运行在 Borg 所管理的“容器”里，其实也是运行在 Cgroups“容器”当中。这和我们今天说的 Docker 容器差别很大。 Linux Cgroups 的全称是 Linux Control Group。它最主要的作用，就是限制一个进程组能够使用的资源上限，包括 CPU、内存、磁盘、网络带宽等等。 此外，Cgroups 还能够对进程进行优先级设置、审计，以及将进程挂起和恢复等操作。这里只重点探讨它与容器关系最紧密的“限制”能力，并通过一组实践来带你认识一下 Cgroups。 在 Linux 中，Cgroups 给用户暴露出来的操作接口是文件系统，即它以文件和目录的方式组织在操作系统的 /sys/fs/cgroup 路径下。在 Ubuntu 16.04 机器里，我可以用 mount 指令把它们展示出来，这条命令是： 1234567$ mount -t cgroup cpuset on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)cpu on /sys/fs/cgroup/cpu type cgroup (rw,nosuid,nodev,noexec,relatime,cpu)cpuacct on /sys/fs/cgroup/cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpuacct)blkio on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,blkio)memory on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,memory)... 它的输出结果，是一系列文件系统目录。如果你在自己的机器上没有看到这些目录，那你就需要自己去挂载 Cgroups。 可以看到，在 /sys/fs/cgroup 下面有很多诸如 cpuset、cpu、 memory 这样的子目录，也叫子系统。这些都是我这台机器当前可以被 Cgroups 进行限制的资源种类。而在子系统对应的资源种类下，你就可以看到该类资源具体可以被限制的方法。比如，对 CPU 子系统来说，我们就可以看到如下几个配置文件，这个指令是： 123$ ls /sys/fs/cgroup/cpucgroup.clone_children cpu.cfs_period_us cpu.rt_period_us cpu.shares notify_on_releasecgroup.procs cpu.cfs_quota_us cpu.rt_runtime_us cpu.stat tasks 如果熟悉 Linux CPU 管理的话，你就会在它的输出里注意到 cfs_period 和 cfs_quota 这样的关键词。这两个参数需要组合使用，可以用来限制进程在长度为 cfs_period 的一段时间内，只能被分配到总量为 cfs_quota 的 CPU 时间。 而这样的配置文件又如何使用呢？ 你需要在对应的子系统下面创建一个目录，比如，我们现在进入 /sys/fs/cgroup/cpu 目录下： 1234root@ubuntu:/sys/fs/cgroup/cpu$ mkdir containerroot@ubuntu:/sys/fs/cgroup/cpu$ ls container/cgroup.clone_children cpu.cfs_period_us cpu.rt_period_us cpu.shares notify_on_releasecgroup.procs cpu.cfs_quota_us cpu.rt_runtime_us cpu.stat tasks 这个目录就称为一个“控制组”。你会发现，操作系统会在你新创建的 container 目录下，自动生成该子系统对应的资源限制文件。 现在，我们在后台执行这样一条脚本： 12$ while : ; do : ; done &amp;[1] 226 显然，它执行了一个死循环，可以把计算机的 CPU 吃到 100%，根据它的输出，我们可以看到这个脚本在后台运行的进程号（PID）是 226。 这样，我们可以用 top 指令来确认一下 CPU 有没有被打满： 12$ top%Cpu0 :100.0 us, 0.0 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st 在输出里可以看到，CPU 的使用率已经 100% 了（%Cpu0 :100.0 us）。 而此时，我们可以通过查看 container 目录下的文件，看到 container 控制组里的 CPU quota 还没有任何限制（即：-1），CPU period 则是默认的 100 ms（100000 us）： 1234$ cat /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us -1$ cat /sys/fs/cgroup/cpu/container/cpu.cfs_period_us 100000 接下来，我们可以通过修改这些文件的内容来设置限制。 比如，向 container 组里的 cfs_quota 文件写入 20 ms（20000 us）： 1$ echo 20000 &gt; /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us 结合前面的介绍，你应该能明白这个操作的含义，它意味着在每 100 ms 的时间里，被该控制组限制的进程只能使用 20 ms 的 CPU 时间，也就是说这个进程只能使用到 20% 的 CPU 带宽。 接下来，我们把被限制的进程的 PID 写入 container 组里的 tasks 文件，上面的设置就会对该进程生效了： 1$ echo 226 &gt; /sys/fs/cgroup/cpu/container/tasks 我们可以用 top 指令查看一下： 12$ top%Cpu0 : 20.3 us, 0.0 sy, 0.0 ni, 79.7 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st 可以看到，计算机的 CPU 使用率立刻降到了 20%（%Cpu0 : 20.3 us）。 除 CPU 子系统外，Cgroups 的每一项子系统都有其独有的资源限制能力，比如： blkio，为块设备设定I/O 限制，一般用于磁盘等设备； cpuset，为进程分配单独的 CPU 核和对应的内存节点； memory，为进程设定内存使用的限制。 Linux Cgroups 的设计还是比较易用的，简单粗暴地理解呢，它就是一个子系统目录加上一组资源限制文件的组合。而对于 Docker 等 Linux 容器项目来说，它们只需要在每个子系统下面，为每个容器创建一个控制组（即创建一个新目录），然后在启动容器进程之后，把这个进程的 PID 填写到对应控制组的 tasks 文件中就可以了。 而至于在这些控制组下面的资源文件里填上什么值，就靠用户执行 docker run 时的参数指定了，比如这样一条命令： 1docker run -it --cpu-period=100000 --cpu-quota=20000 ubuntu /bin/bash 在启动这个容器后，我们可以通过查看 Cgroups 文件系统下，CPU 子系统中，“docker”这个控制组里的资源限制文件的内容来确认： 1234$ cat /sys/fs/cgroup/cpu/docker/5d5c9f67d/cpu.cfs_period_us 100000$ cat /sys/fs/cgroup/cpu/docker/5d5c9f67d/cpu.cfs_quota_us 20000 这就意味着这个 Docker 容器，只能使用到 20% 的 CPU 带宽。 你现在应该能够理解，一个正在运行的 Docker 容器，其实就是一个启用了多个 Linux Namespace 的应用进程，而这个进程能够使用的资源量，则受 Cgroups 配置的限制。 这也是容器技术中一个非常重要的概念，即：容器是一个“单进程”模型。 由于一个容器的本质就是一个进程，用户的应用进程实际上就是容器里 PID=1 的进程，也是其他后续创建的所有进程的父进程。这就意味着，在一个容器中，你没办法同时运行两个不同的应用，除非你能事先找到一个公共的 PID=1 的程序来充当两个不同应用的父进程，这也是为什么很多人都会用 systemd 或者 supervisord 这样的软件来代替应用本身作为容器的启动进程。 但是，在后面分享容器设计模式时，我还会推荐其他更好的解决办法。这是因为容器本身的设计，就是希望容器和应用能够同生命周期，这个概念对后续的容器编排非常重要。否则，一旦出现类似于“容器是正常运行的，但是里面的应用早已经挂了”的情况，编排系统处理起来就非常麻烦了。 另外，跟 Namespace 的情况类似，Cgroups 对资源的限制能力也有很多不完善的地方，被提及最多的自然是 /proc 文件系统的问题。 众所周知，Linux 下的 /proc 目录存储的是记录当前内核运行状态的一系列特殊文件，用户可以通过访问这些文件，查看系统以及当前正在运行的进程的信息，比如 CPU 使用情况、内存占用率等，这些文件也是 top 指令查看系统信息的主要数据来源。 但是，你如果在容器里执行 top 指令，就会发现，它显示的信息居然是宿主机的 CPU 和内存数据，而不是当前容器的数据。 造成这个问题的原因就是，/proc 文件系统并不知道用户通过 Cgroups 给这个容器做了什么样的资源限制，即：/proc 文件系统不了解 Cgroups 限制的存在。 在生产环境中，这个问题必须进行修正，否则应用程序在容器里读取到的 CPU 核数、可用内存等信息都是宿主机上的数据，这会给应用的运行带来非常大的困惑和风险。这也是在企业中，容器化应用碰到的一个常见问题，也是容器相较于虚拟机另一个不尽如人意的地方。 问题：如何修复容器中的 top 指令以及 /proc 文件系统中的信息呢？ 其实，这个问题的答案在提示里其实已经给出了，即 lxcfs 方案。通过 lxcfs，你可以把宿主机的 /var/lib/lxcfs/proc 文件系统挂载到 Docker 容器的 /proc 目录下。使得容器中进程读取相应文件内容时，实际上会从容器对应的 Cgroups 中读取正确的资源限制。 从而得到正确的 top 命令的返回值。 容器镜像Namespace 的作用是“隔离”，它让应用进程只能看到该 Namespace 内的“世界”；而 Cgroups 的作用是“限制”，它给这个“世界”围上了一圈看不见的墙。这么一折腾，进程就真的被“装”在了一个与世隔绝的房间里，而这些房间就是 PaaS 项目赖以生存的应用“沙盒”。 可是，还有一个问题不知道你有没有仔细思考过：这个房间四周虽然有了墙，但是如果容器进程低头一看地面，又是怎样一副景象呢？ 换句话说，容器里的进程看到的文件系统又是什么样子的呢？ 可能你立刻就能想到，这一定是一个关于 Mount Namespace 的问题：容器里的应用进程，理应看到一份完全独立的文件系统。这样，它就可以在自己的容器目录（比如 /tmp）下进行操作，而完全不会受宿主机以及其他容器的影响。 那么，真实情况是这样吗？ 下面这段小程序的作用是，在创建子进程时开启指定的 Namespace。使用它来验证一下刚刚提到的问题。 12345678910111213141516171819202122232425262728293031#define _GNU_SOURCE#include &lt;sys/mount.h&gt; #include &lt;sys/types.h&gt;#include &lt;sys/wait.h&gt;#include &lt;stdio.h&gt;#include &lt;sched.h&gt;#include &lt;signal.h&gt;#include &lt;unistd.h&gt;#define STACK_SIZE (1024 * 1024)static char container_stack[STACK_SIZE];char* const container_args[] = &#123; &quot;/bin/bash&quot;, NULL&#125;; int container_main(void* arg)&#123; printf(&quot;Container - inside the container!\\n&quot;); execv(container_args[0], container_args); printf(&quot;Something&#x27;s wrong!\\n&quot;); return 1;&#125; int main()&#123; printf(&quot;Parent - start a container!\\n&quot;); int container_pid = clone(container_main, container_stack+STACK_SIZE, CLONE_NEWNS | SIGCHLD , NULL); waitpid(container_pid, NULL, 0); printf(&quot;Parent - container stopped!\\n&quot;); return 0;&#125; 这段代码的功能非常简单：在 main 函数里，我们通过 clone() 系统调用创建了一个新的子进程 container_main，并且声明要为它启用 Mount Namespace（即：CLONE_NEWNS 标志）。 而这个子进程执行的，是一个“/bin/bash”程序，也就是一个 shell。所以这个 shell 就运行在了 Mount Namespace 的隔离环境中。 我们来一起编译一下这个程序： 1234$ gcc -o ns ns.c$ ./nsParent - start a container!Container - inside the container! 这样，我们就进入了这个“容器”当中。可是，如果在“容器”里执行一下 ls 指令的话，我们就会发现一个有趣的现象： /tmp 目录下的内容跟宿主机的内容是一样的。 12$ ls /tmp# 你会看到好多宿主机的文件 也就是说： 即使开启了 Mount Namespace，容器进程看到的文件系统也跟宿主机完全一样。 这是怎么回事呢？ 仔细思考一下，你会发现这其实并不难理解：Mount Namespace 修改的，是容器进程对文件系统“挂载点”的认知。但是，这也就意味着，只有在“挂载”这个操作发生之后，进程的视图才会被改变。而在此之前，新创建的容器会直接继承宿主机的各个挂载点。 这时，你可能已经想到了一个解决办法：创建新进程时，除了声明要启用 Mount Namespace 之外，我们还可以告诉容器进程，有哪些目录需要重新挂载，就比如这个 /tmp 目录。于是，我们在容器进程执行前可以添加一步重新挂载 /tmp 目录的操作： 12345678910int container_main(void* arg)&#123; printf(&quot;Container - inside the container!\\n&quot;); // 如果你的机器的根目录的挂载类型是 shared，那必须先重新挂载根目录 // mount(&quot;&quot;, &quot;/&quot;, NULL, MS_PRIVATE, &quot;&quot;); mount(&quot;none&quot;, &quot;/tmp&quot;, &quot;tmpfs&quot;, 0, &quot;&quot;); execv(container_args[0], container_args); printf(&quot;Something&#x27;s wrong!\\n&quot;); return 1;&#125; 可以看到，在修改后的代码里，我在容器进程启动之前，加上了一句 mount(“none”, “/tmp”, “tmpfs”, 0, “”) 语句。就这样，我告诉了容器以 tmpfs（内存盘）格式，重新挂载了 /tmp 目录。 这段修改后的代码，编译执行后的结果又如何呢？我们可以试验一下： 12345$ gcc -o ns ns.c$ ./nsParent - start a container!Container - inside the container!$ ls /tmp 可以看到，这次 /tmp 变成了一个空目录，这意味着重新挂载生效了。我们可以用 mount -l 检查一下： 12$ mount -l | grep tmpfsnone on /tmp type tmpfs (rw,relatime) 可以看到，容器里的 /tmp 目录是以 tmpfs 方式单独挂载的。 更重要的是，因为我们创建的新进程启用了 Mount Namespace，所以这次重新挂载的操作，只在容器进程的 Mount Namespace 中有效。如果在宿主机上用 mount -l 来检查一下这个挂载，你会发现它是不存在的： 12# 在宿主机上$ mount -l | grep tmpfs 这就是 Mount Namespace 跟其他 Namespace 的使用略有不同的地方：它对容器进程视图的改变，一定是伴随着挂载操作（mount）才能生效。 可是，作为一个普通用户，我们希望的是一个更友好的情况：每当创建一个新容器时，我希望容器进程看到的文件系统就是一个独立的隔离环境，而不是继承自宿主机的文件系统。怎么才能做到这一点呢？ 不难想到，我们可以在容器进程启动之前重新挂载它的整个根目录“/”。而由于 Mount Namespace 的存在，这个挂载对宿主机不可见，所以容器进程就可以在里面随便折腾了。 在 Linux 操作系统里，有一个名为 chroot 的命令可以帮助你在 shell 中方便地完成这个工作。顾名思义，它的作用就是帮你“change root file system”，即改变进程的根目录到你指定的位置。它的用法也非常简单。 假设，我们现在有一个 $HOME/test 目录，想要把它作为一个 /bin/bash 进程的根目录。 首先，创建一个 test 目录和几个 lib 文件夹： 123$ mkdir -p $HOME/test$ mkdir -p $HOME/test/&#123;bin,lib64,lib&#125;$ cd $T 然后，把 bash 命令拷贝到 test 目录对应的 bin 路径下： 1$ cp -v /bin/&#123;bash,ls&#125; $HOME/test/bin 接下来，把 bash 命令需要的所有 so 文件，也拷贝到 test 目录对应的 lib 路径下。找到 so 文件可以用 ldd 命令： 123$ T=$HOME/test$ list=&quot;$(ldd /bin/ls | egrep -o &#x27;/lib.*\\.[0-9]&#x27;)&quot;$ for i in $list; do cp -v &quot;$i&quot; &quot;$&#123;T&#125;$&#123;i&#125;&quot;; done 最后，执行 chroot 命令，告诉操作系统，我们将使用 $HOME/test 目录作为 /bin/bash 进程的根目录： 1$ chroot $HOME/test /bin/bash 这时，你如果执行 “ls /“，就会看到，它返回的都是 $HOME/test 目录下面的内容，而不是宿主机的内容。 更重要的是，对于被 chroot 的进程来说，它并不会感受到自己的根目录已经被“修改”成 $HOME/test 了。 这种视图被修改的原理，是不是跟我之前介绍的 Linux Namespace 很类似呢？ 没错！ 实际上，Mount Namespace 正是基于对 chroot 的不断改良才被发明出来的，它也是 Linux 操作系统里的第一个 Namespace。 当然，为了能够让容器的这个根目录看起来更“真实”，我们一般会在这个容器的根目录下挂载一个完整操作系统的文件系统，比如 Ubuntu16.04 的 ISO。这样，在容器启动之后，我们在容器里通过执行 “ls /“ 查看根目录下的内容，就是 Ubuntu 16.04 的所有目录和文件。 而这个挂载在容器根目录上、用来为容器进程提供隔离后执行环境的文件系统，就是所谓的“容器镜像”。它还有一个更为专业的名字，叫作：rootfs（根文件系统）。 所以，一个最常见的 rootfs，或者说容器镜像，会包括如下所示的一些目录和文件，比如 /bin，/etc，/proc 等等： 12$ ls /bin dev etc home lib lib64 mnt opt proc root run sbin sys tmp usr var 而你进入容器之后执行的 /bin/bash，就是 /bin 目录下的可执行文件，与宿主机的 /bin/bash 完全不同。 现在，你应该可以理解，对 Docker 项目来说，它最核心的原理实际上就是为待创建的用户进程： 启用 Linux Namespace 配置； 设置指定的 Cgroups 参数； 切换进程的根目录（Change Root）。 这样，一个完整的容器就诞生了。不过，Docker 项目在最后一步的切换上会优先使用 pivot_root 系统调用，如果系统不支持，才会使用 chroot。这两个系统调用虽然功能类似，但是也有细微的区别。 另外，需要明确的是，rootfs 只是一个操作系统所包含的文件、配置和目录，并不包括操作系统内核。在 Linux 操作系统中，这两部分是分开存放的，操作系统只有在开机启动时才会加载指定版本的内核镜像。 所以说，rootfs 只包括了操作系统的“躯壳”，并没有包括操作系统的“灵魂”。 那么，对于容器来说，这个操作系统的“灵魂”又在哪里呢？ 实际上，同一台机器上的所有容器，都共享宿主机操作系统的内核。 这就意味着，如果你的应用程序需要配置内核参数、加载额外的内核模块，以及跟内核进行直接的交互，你就需要注意了：这些操作和依赖的对象，都是宿主机操作系统的内核，它对于该机器上的所有容器来说是一个“全局变量”，牵一发而动全身。 这也是容器相比于虚拟机的主要缺陷之一：毕竟后者不仅有模拟出来的硬件机器充当沙盒，而且每个沙盒里还运行着一个完整的 Guest OS 给应用随便折腾。 不过，正是由于 rootfs 的存在，容器才有了一个被反复宣传至今的重要特性：一致性。 什么是容器的“一致性”呢？ 由于云端与本地服务器环境不同，应用的打包过程，一直是使用 PaaS 时最“痛苦”的一个步骤。 但有了容器之后，更准确地说，有了容器镜像（即 rootfs）之后，这个问题被非常优雅地解决了。 由于 rootfs 里打包的不只是应用，而是整个操作系统的文件和目录，也就意味着，应用以及它运行所需要的所有依赖，都被封装在了一起。 事实上，对于大多数开发者而言，他们对应用依赖的理解，一直局限在编程语言层面。比如 Golang 的 Godeps.json。但实际上，一个一直以来很容易被忽视的事实是，对一个应用来说，操作系统本身才是它运行所需要的最完整的“依赖库”。 有了容器镜像“打包操作系统”的能力，这个最基础的依赖环境也终于变成了应用沙盒的一部分。这就赋予了容器所谓的一致性：无论在本地、云端，还是在一台任何地方的机器上，用户只需要解压打包好的容器镜像，那么这个应用运行所需要的完整的执行环境就被重现出来了。 这种深入到操作系统级别的运行环境一致性，打通了应用在本地开发和远端执行环境之间难以逾越的鸿沟。 不过，这时你可能已经发现了另一个非常棘手的问题：难道我每开发一个应用，或者升级一下现有的应用，都要重复制作一次 rootfs 吗？ 比如，我现在用 Ubuntu 操作系统的 ISO 做了一个 rootfs，然后又在里面安装了 Java 环境，用来部署我的 Java 应用。那么，我的另一个同事在发布他的 Java 应用时，显然希望能够直接使用我安装过 Java 环境的 rootfs，而不是重复这个流程。 一种比较直观的解决办法是，我在制作 rootfs 的时候，每做一步“有意义”的操作，就保存一个 rootfs 出来，这样其他同事就可以按需求去用他需要的 rootfs 了。 但是，这个解决办法并不具备推广性。原因在于，一旦你的同事们修改了这个 rootfs，新旧两个 rootfs 之间就没有任何关系了。这样做的结果就是极度的碎片化。 那么，既然这些修改都基于一个旧的 rootfs，我们能不能以增量的方式去做这些修改呢？这样做的好处是，所有人都只需要维护相对于 base rootfs 修改的增量内容，而不是每次修改都制造一个“fork”。 答案当然是肯定的。 这也正是为何，Docker 公司在实现 Docker 镜像时并没有沿用以前制作 rootfs 的标准流程，而是做了一个小小的创新： Docker 在镜像的设计中，引入了层（layer）的概念。也就是说，用户制作镜像的每一步操作，都会生成一个层，也就是一个增量 rootfs。 当然，这个想法不是凭空臆造出来的，而是用到了一种叫作联合文件系统（Union File System）的能力。 Union File System 也叫 UnionFS，最主要的功能是将多个不同位置的目录联合挂载（union mount）到同一个目录下。比如，我现在有两个目录 A 和 B，它们分别有两个文件： 12345678$ tree.├── A│ ├── a│ └── x└── B ├── b └── x 然后，我使用联合挂载的方式，将这两个目录挂载到一个公共的目录 C 上： 12$ mkdir C$ mount -t aufs -o dirs=./A:./B none ./C 这时，我再查看目录 C 的内容，就能看到目录 A 和 B 下的文件被合并到了一起： 12345$ tree ./C./C├── a├── b└── x 可以看到，在这个合并后的目录 C 里，有 a、b、x 三个文件，并且 x 文件只有一份。这，就是“合并”的含义。此外，如果你在目录 C 里对 a、b、x 文件做修改，这些修改也会在对应的目录 A、B 中生效。 那么，在 Docker 项目中，又是如何使用这种 Union File System 的呢？ 我的环境是 Ubuntu 16.04 和 Docker CE 18.05，这对组合默认使用的是 AuFS 这个联合文件系统的实现。你可以通过 docker info 命令，查看到这个信息。 AuFS 的全称是 Another UnionFS，后改名为 Alternative UnionFS，再后来干脆改名叫作 Advance UnionFS，它是对 Linux 原生 UnionFS 的重写和改进。 对于 AuFS 来说，它最关键的目录结构在 /var/lib/docker 路径下的 diff 目录： 1/var/lib/docker/aufs/diff/&lt;layer_id&gt; 而这个目录的作用，我们不妨通过一个具体例子来看一下。 现在，我们启动一个容器，比如： 1$ docker run -d ubuntu:latest sleep 3600 这时候，Docker 就会从 Docker Hub 上拉取一个 Ubuntu 镜像到本地。 这个所谓的“镜像”，实际上就是一个 Ubuntu 操作系统的 rootfs，它的内容是 Ubuntu 操作系统的所有文件和目录。不过，与之前我们讲述的 rootfs 稍微不同的是，Docker 镜像使用的 rootfs，往往由多个“层”组成： 123456789101112$ docker image inspect ubuntu:latest... &quot;RootFS&quot;: &#123; &quot;Type&quot;: &quot;layers&quot;, &quot;Layers&quot;: [ &quot;sha256:f49017d4d5ce9c0f544c...&quot;, &quot;sha256:8f2b771487e9d6354080...&quot;, &quot;sha256:ccd4d61916aaa2159429...&quot;, &quot;sha256:c01d74f99de40e097c73...&quot;, &quot;sha256:268a067217b5fe78e000...&quot; ] &#125; 可以看到，这个 Ubuntu 镜像，实际上由五个层组成。这五个层就是五个增量 rootfs，每一层都是 Ubuntu 操作系统文件与目录的一部分；而在使用镜像时，Docker 会把这些增量联合挂载在一个统一的挂载点上（等价于前面例子里的“/C”目录）。 这个挂载点就是 /var/lib/docker/aufs/mnt/，比如： 1/var/lib/docker/aufs/mnt/6e3be5d2ecccae7cc0fcfa2a2f5c89dc21ee30e166be823ceaeba15dce645b3e 不出意外的，这个目录里面正是一个完整的 Ubuntu 操作系统： 12$ ls /var/lib/docker/aufs/mnt/6e3be5d2ecccae7cc0fcfa2a2f5c89dc21ee30e166be823ceaeba15dce645b3ebin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var 那么，前面提到的五个镜像层，又是如何被联合挂载成这样一个完整的 Ubuntu 文件系统的呢？ 这个信息记录在 AuFS 的系统目录 /sys/fs/aufs 下面。 首先，通过查看 AuFS 的挂载信息，我们可以找到这个目录对应的 AuFS 的内部 ID（也叫：si）： 12$ cat /proc/mounts| grep aufsnone /var/lib/docker/aufs/mnt/6e3be5d2ecccae7cc0fc... aufs rw,relatime,si=972c6d361e6b32ba,dio,dirperm1 0 0 即，si=972c6d361e6b32ba。 然后使用这个 ID，你就可以在 /sys/fs/aufs 下查看被联合挂载在一起的各个层的信息： 12345678$ cat /sys/fs/aufs/si_972c6d361e6b32ba/br[0-9]*/var/lib/docker/aufs/diff/6e3be5d2ecccae7cc...=rw/var/lib/docker/aufs/diff/6e3be5d2ecccae7cc...-init=ro+wh/var/lib/docker/aufs/diff/32e8e20064858c0f2...=ro+wh/var/lib/docker/aufs/diff/2b8858809bce62e62...=ro+wh/var/lib/docker/aufs/diff/20707dce8efc0d267...=ro+wh/var/lib/docker/aufs/diff/72b0744e06247c7d0...=ro+wh/var/lib/docker/aufs/diff/a524a729adadedb90...=ro+wh 从这些信息里，我们可以看到，镜像的层都放置在 /var/lib/docker/aufs/diff 目录下，然后被联合挂载在 /var/lib/docker/aufs/mnt 里面。 而且，从这个结构可以看出来，这个容器的 rootfs 由如下图所示的三部分组成： 第一部分，只读层。 它是这个容器的 rootfs 最下面的五层，对应的正是 ubuntu:latest 镜像的五层。可以看到，它们的挂载方式都是只读的（ro+wh，即 readonly+whiteout，至于什么是 whiteout，我下面马上会讲到）。 这时，我们可以分别查看一下这些层的内容： 123456$ ls /var/lib/docker/aufs/diff/72b0744e06247c7d0...etc sbin usr var$ ls /var/lib/docker/aufs/diff/32e8e20064858c0f2...run$ ls /var/lib/docker/aufs/diff/a524a729adadedb900...bin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var 可以看到，这些层，都以增量的方式分别包含了 Ubuntu 操作系统的一部分。 第二部分，可读写层。 它是这个容器的 rootfs 最上面的一层（6e3be5d2ecccae7cc），它的挂载方式为：rw，即 read write。在没有写入文件之前，这个目录是空的。而一旦在容器里做了写操作，你修改产生的内容就会以增量的方式出现在这个层中。 可是，你有没有想到这样一个问题：如果我现在要做的，是删除只读层里的一个文件呢？ 为了实现这样的删除操作，AuFS 会在可读写层创建一个 whiteout 文件，把只读层里的文件“遮挡”起来。 比如，你要删除只读层里一个名叫 foo 的文件，那么这个删除操作实际上是在可读写层创建了一个名叫.wh.foo 的文件。这样，当这两个层被联合挂载之后，foo 文件就会被.wh.foo 文件“遮挡”起来，“消失”了。这个功能，就是“ro+wh”的挂载方式，即只读 +whiteout 的含义。我喜欢把 whiteout 形象地翻译为：“白障”。 所以，最上面这个可读写层的作用，就是专门用来存放你修改 rootfs 后产生的增量，无论是增、删、改，都发生在这里。而当我们使用完了这个被修改过的容器之后，还可以使用 docker commit 和 push 指令，保存这个被修改过的可读写层，并上传到 Docker Hub 上，供其他人使用；而与此同时，原先的只读层里的内容则不会有任何变化。这，就是增量 rootfs 的好处。 第三部分，Init 层。 它是一个以“-init”结尾的层，夹在只读层和读写层之间。Init 层是 Docker 项目单独生成的一个内部层，专门用来存放 /etc/hosts、/etc/resolv.conf 等信息。 需要这样一层的原因是，这些文件本来属于只读的 Ubuntu 镜像的一部分，但是用户往往需要在启动容器时写入一些指定的值比如 hostname，所以就需要在可读写层对它们进行修改。 可是，这些修改往往只对当前的容器有效，我们并不希望执行 docker commit 时，把这些信息连同可读写层一起提交掉。 所以，Docker 做法是，在修改了这些文件之后，以一个单独的层挂载了出来。而用户执行 docker commit 只会提交可读写层，所以是不包含这些内容的。 最终，这 7 个层都被联合挂载到 /var/lib/docker/aufs/mnt 目录下，表现为一个完整的 Ubuntu 操作系统供容器使用。 总结： 我们经常提到的容器镜像，也叫作：rootfs。它只是一个操作系统的所有文件和目录，并不包含内核，最多也就几百兆。而相比之下，传统虚拟机的镜像大多是一个磁盘的“快照”，磁盘有多大，镜像就至少有多大。 通过结合使用 Mount Namespace 和 rootfs，容器就能够为进程构建出一个完善的文件系统隔离环境。当然，这个功能的实现还必须感谢 chroot 和 pivot_root 这两个系统调用切换进程根目录的能力。 而在 rootfs 的基础上，Docker 公司创新性地提出了使用多个增量 rootfs 联合挂载一个完整 rootfs 的方案，这就是容器镜像中“层”的概念。 通过“分层镜像”的设计，以 Docker 镜像为核心，来自不同公司、不同团队的技术人员被紧密地联系在了一起。而且，由于容器镜像的操作是增量式的，这样每次镜像拉取、推送的内容，比原本多个完整的操作系统的大小要小得多；而共享层的存在，可以使得所有这些容器镜像需要的总空间，也比每个镜像的总和要小。这样就使得基于容器镜像的团队协作，要比基于动则几个 GB 的虚拟机磁盘镜像的协作要敏捷得多。 更重要的是，一旦这个镜像被发布，那么你在全世界的任何一个地方下载这个镜像，得到的内容都完全一致，可以完全复现这个镜像制作者当初的完整环境。这，就是容器技术“强一致性”的重要体现。 而这种价值正是支撑 Docker 公司在 2014~2016 年间迅猛发展的核心动力。容器镜像的发明，不仅打通了“开发 - 测试 - 部署”流程的每一个环节，更重要的是： 容器镜像将会成为未来软件的主流发布方式。 问题：既然容器的 rootfs（比如，Ubuntu 镜像），是以只读方式挂载的，那么又如何在容器里修改 Ubuntu 镜像的内容呢？ 简单地说，修改一个镜像里的文件的时候，联合文件系统首先会从上到下在各个层中查找有没有目标文件。如果找到，就把这个文件复制到可读写层进行修改。这个修改的结果会屏蔽掉下层的文件，这种方式就被称为 copy-on-write。 重新认识Docker容器这一次，我要用 Docker 部署一个用 Python 编写的 Web 应用。这个应用的代码部分非常简单： 1234567891011121314from flask import Flaskimport socketimport os app = Flask(__name__) @app.route(&#x27;/&#x27;)def hello(): html = &quot;&lt;h3&gt;Hello &#123;name&#125;!&lt;/h3&gt;&quot; \\ &quot;&lt;b&gt;Hostname:&lt;/b&gt; &#123;hostname&#125;&lt;br/&gt;&quot; return html.format(name=os.getenv(&quot;NAME&quot;, &quot;world&quot;), hostname=socket.gethostname()) if __name__ == &quot;__main__&quot;: app.run(host=&#x27;0.0.0.0&#x27;, port=80) 在这段代码中，我使用 Flask 框架启动了一个 Web 服务器，而它唯一的功能是：如果当前环境中有“NAME”这个环境变量，就把它打印在“Hello”后，否则就打印“Hello world”，最后再打印出当前环境的 hostname。 这个应用的依赖，则被定义在了同目录下的 requirements.txt 文件里，内容如下所示： 12$ cat requirements.txtFlask 而将这样一个应用容器化的第一步，是制作容器镜像。 不过，相较于我之前介绍的制作 rootfs 的过程，Docker 为你提供了一种更便捷的方式，叫作 Dockerfile，如下所示。 1234567891011121314151617181920# 使用官方提供的 Python 开发镜像作为基础镜像FROM python:2.7-slim # 将工作目录切换为 /appWORKDIR /app # 将当前目录下的所有内容复制到 /app 下ADD . /app # 使用 pip 命令安装这个应用所需要的依赖RUN pip install --trusted-host pypi.python.org -r requirements.txt # 允许外界访问容器的 80 端口EXPOSE 80 # 设置环境变量ENV NAME World # 设置容器进程为：python app.py，即：这个 Python 应用的启动命令CMD [&quot;python&quot;, &quot;app.py&quot;] 通过这个文件的内容，你可以看到Dockerfile 的设计思想，是使用一些标准的原语（即大写高亮的词语），描述我们所要构建的 Docker 镜像。并且这些原语，都是按顺序处理的。 比如 FROM 原语，指定了“python:2.7-slim”这个官方维护的基础镜像，从而免去了安装 Python 等语言环境的操作。否则，这一段我们就得这么写了： 123FROM ubuntu:latestRUN apt-get update -yRUN apt-get install -y python-pip python-dev build-essential... 其中，RUN 原语就是在容器里执行 shell 命令的意思。 而 WORKDIR，意思是在这一句之后，Dockerfile 后面的操作都以这一句指定的 /app 目录作为当前目录。 所以，到了最后的 CMD，意思是 Dockerfile 指定 python app.py 为这个容器的进程。这里，app.py 的实际路径是 /app/app.py。所以，CMD [“python”, “app.py”] 等价于 “docker run python app.py”。 另外，在使用 Dockerfile 时，你可能还会看到一个叫作 ENTRYPOINT 的原语。实际上，它和 CMD 都是 Docker 容器进程启动所必需的参数，完整执行格式是：“ENTRYPOINT CMD”。 但是，默认情况下，Docker 会为你提供一个隐含的 ENTRYPOINT，即：/bin/sh -c。所以，在不指定 ENTRYPOINT 时，比如在我们这个例子里，实际上运行在容器里的完整进程是：/bin/sh -c “python app.py”，即 CMD 的内容就是 ENTRYPOINT 的参数。 备注：基于以上原因，我们后面会统一称 Docker 容器的启动进程为 ENTRYPOINT，而不是 CMD。 需要注意的是，Dockerfile 里的原语并不都是指对容器内部的操作。就比如 ADD，它指的是把当前目录（即 Dockerfile 所在的目录）里的文件，复制到指定容器内的目录当中。 读懂这个 Dockerfile 之后，我再把上述内容，保存到当前目录里一个名叫“Dockerfile”的文件中： 12$ lsDockerfile app.py requirements.txt 接下来，我就可以让 Docker 制作这个镜像了，在当前目录执行： 1$ docker build -t helloworld . 其中，-t 的作用是给这个镜像加一个 Tag，即：起一个好听的名字。docker build 会自动加载当前目录下的 Dockerfile 文件，然后按照顺序，执行文件中的原语。而这个过程，实际上可以等同于 Docker 使用基础镜像启动了一个容器，然后在容器中依次执行 Dockerfile 中的原语。 需要注意的是，Dockerfile 中的每个原语执行后，都会生成一个对应的镜像层。即使原语本身并没有明显地修改文件的操作（比如，ENV 原语），它对应的层也会存在。只不过在外界看来，这个层是空的。 docker build 操作完成后，我可以通过 docker images 命令查看结果： 1234$ docker image ls REPOSITORY TAG IMAGE IDhelloworld latest 653287cdf998 通过这个镜像 ID，就可以查看这些新增的层在 AuFS 路径下对应的文件和目录了。 接下来，我使用这个镜像，通过 docker run 命令启动容器： 1$ docker run -p 4000:80 helloworld 在这一句命令中，镜像名 helloworld 后面，我什么都不用写，因为在 Dockerfile 中已经指定了 CMD。否则，我就得把进程的启动命令加在后面： 1$ docker run -p 4000:80 helloworld python app.py 容器启动之后，我可以使用 docker ps 命令看到： 123$ docker psCONTAINER ID IMAGE COMMAND CREATED4ddf4638572d helloworld &quot;python app.py&quot; 10 seconds ago 同时，我已经通过 -p 4000:80 告诉了 Docker，请把容器内的 80 端口映射在宿主机的 4000 端口上。 这样做的目的是，只要访问宿主机的 4000 端口，我就可以看到容器里应用返回的结果： 12$ curl http://localhost:4000&lt;h3&gt;Hello World!&lt;/h3&gt;&lt;b&gt;Hostname:&lt;/b&gt; 4ddf4638572d&lt;br/&gt; 否则，我就得先用 docker inspect 命令查看容器的 IP 地址，然后访问“http://&lt; 容器 IP 地址 &gt;:80”才可以看到容器内应用的返回。 至此，我已经使用容器完成了一个应用的开发与测试，如果现在想要把这个容器的镜像上传到 DockerHub 上分享给更多的人，我要怎么做呢？ 为了能够上传镜像，我首先需要注册一个 Docker Hub 账号，然后使用 docker login 命令登录。 接下来，我要用 docker tag 命令给容器镜像起一个完整的名字： 1$ docker tag helloworld geektime/helloworld:v1 其中，geektime 是我在 Docker Hub 上的用户名，它的“学名”叫镜像仓库（Repository）；“/”后面的 helloworld 是这个镜像的名字，而“v1”则是我给这个镜像分配的版本号。 然后，我执行 docker push： 1$ docker push geektime/helloworld:v1 这样，我就可以把这个镜像上传到 Docker Hub 上了。 此外，我还可以使用 docker commit 指令，把一个正在运行的容器，直接提交为一个镜像。一般来说，需要这么操作原因是：这个容器运行起来后，我又在里面做了一些操作，并且要把操作结果保存到镜像里，比如： 1234567$ docker exec -it 4ddf4638572d /bin/sh# 在容器内部新建了一个文件root@4ddf4638572d:/app# touch test.txtroot@4ddf4638572d:/app# exit # 将这个新建的文件提交到镜像中保存$ docker commit 4ddf4638572d geektime/helloworld:v2 这里，我使用了 docker exec 命令进入到了容器当中。在了解了 Linux Namespace 的隔离机制后，你应该会很自然地想到一个问题：docker exec 是怎么做到进入容器里的呢？ 实际上，Linux Namespace 创建的隔离空间虽然看不见摸不着，但一个进程的 Namespace 信息在宿主机上是确确实实存在的，并且是以一个文件的方式存在。 比如，通过如下指令，你可以看到当前正在运行的 Docker 容器的进程号（PID）是 25686： 12$ docker inspect --format &#x27;&#123;&#123; .State.Pid &#125;&#125;&#x27; 4ddf4638572d25686 这时，你可以通过查看宿主机的 proc 文件，看到这个 25686 进程的所有 Namespace 对应的文件： 12345678910$ ls -l /proc/25686/nstotal 0lrwxrwxrwx 1 root root 0 Aug 13 14:05 cgroup -&gt; cgroup:[4026531835]lrwxrwxrwx 1 root root 0 Aug 13 14:05 ipc -&gt; ipc:[4026532278]lrwxrwxrwx 1 root root 0 Aug 13 14:05 mnt -&gt; mnt:[4026532276]lrwxrwxrwx 1 root root 0 Aug 13 14:05 net -&gt; net:[4026532281]lrwxrwxrwx 1 root root 0 Aug 13 14:05 pid -&gt; pid:[4026532279]lrwxrwxrwx 1 root root 0 Aug 13 14:05 pid_for_children -&gt; pid:[4026532279]lrwxrwxrwx 1 root root 0 Aug 13 14:05 user -&gt; user:[4026531837]lrwxrwxrwx 1 root root 0 Aug 13 14:05 uts -&gt; uts:[4026532277] 可以看到，一个进程的每种 Linux Namespace，都在它对应的 /proc/[进程号]/ns 下有一个对应的虚拟文件，并且链接到一个真实的 Namespace 文件上。 有了这样一个可以“hold 住”所有 Linux Namespace 的文件，我们就可以对 Namespace 做一些很有意义事情了，比如：加入到一个已经存在的 Namespace 当中。 这也就意味着：一个进程，可以选择加入到某个进程已有的 Namespace 当中，从而达到“进入”这个进程所在容器的目的，这正是 docker exec 的实现原理。 而这个操作所依赖的，乃是一个名叫 setns() 的 Linux 系统调用。它的调用方法，我可以用如下一段小程序为你说明： 12345678910111213141516171819#define _GNU_SOURCE#include &lt;fcntl.h&gt;#include &lt;sched.h&gt;#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt; #define errExit(msg) do &#123; perror(msg); exit(EXIT_FAILURE);&#125; while (0) int main(int argc, char *argv[]) &#123; int fd; fd = open(argv[1], O_RDONLY); if (setns(fd, 0) == -1) &#123; errExit(&quot;setns&quot;); &#125; execvp(argv[2], &amp;argv[2]); errExit(&quot;execvp&quot;);&#125; 这段代码功能非常简单：它一共接收两个参数，第一个参数是 argv[1]，即当前进程要加入的 Namespace 文件的路径，比如 /proc/25686/ns/net；而第二个参数，则是你要在这个 Namespace 里运行的进程，比如 /bin/bash。 这段代码的的核心操作，则是通过 open() 系统调用打开了指定的 Namespace 文件，并把这个文件的描述符 fd 交给 setns() 使用。在 setns() 执行后，当前进程就加入了这个文件对应的 Linux Namespace 当中了。 现在，你可以编译执行一下这个程序，加入到容器进程（PID=25686）的 Network Namespace 中： 1234567891011121314151617181920$ gcc -o set_ns set_ns.c $ ./set_ns /proc/25686/ns/net /bin/bash $ ifconfigeth0 Link encap:Ethernet HWaddr 02:42:ac:11:00:02 inet addr:172.17.0.2 Bcast:0.0.0.0 Mask:255.255.0.0 inet6 addr: fe80::42:acff:fe11:2/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:12 errors:0 dropped:0 overruns:0 frame:0 TX packets:10 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:976 (976.0 B) TX bytes:796 (796.0 B) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) 正如上所示，当我们执行 ifconfig 命令查看网络设备时，我会发现能看到的网卡“变少”了：只有两个。而我的宿主机则至少有四个网卡。这是怎么回事呢？ 实际上，在 setns() 之后我看到的这两个网卡，正是我在前面启动的 Docker 容器里的网卡。也就是说，我新创建的这个 /bin/bash 进程，由于加入了该容器进程（PID=25686）的 Network Namepace，它看到的网络设备与这个容器里是一样的，即：/bin/bash 进程的网络设备视图，也被修改了。 而一旦一个进程加入到了另一个 Namespace 当中，在宿主机的 Namespace 文件上，也会有所体现。 在宿主机上，你可以用 ps 指令找到这个 set_ns 程序执行的 /bin/bash 进程，其真实的 PID 是 28499： 123# 在宿主机上ps aux | grep /bin/bashroot 28499 0.0 0.0 19944 3612 pts/0 S 14:15 0:00 /bin/bash 这时，如果按照前面介绍过的方法，查看一下这个 PID=28499 的进程的 Namespace，你就会发现这样一个事实： 12345$ ls -l /proc/28499/ns/netlrwxrwxrwx 1 root root 0 Aug 13 14:18 /proc/28499/ns/net -&gt; net:[4026532281] $ ls -l /proc/25686/ns/netlrwxrwxrwx 1 root root 0 Aug 13 14:05 /proc/25686/ns/net -&gt; net:[4026532281] 在 /proc/[PID]/ns/net 目录下，这个 PID=28499 进程，与我们前面的 Docker 容器进程（PID=25686）指向的 Network Namespace 文件完全一样。这说明这两个进程，共享了这个名叫 net:[4026532281] 的 Network Namespace。 此外，Docker 还专门提供了一个参数，可以让你启动一个容器并“加入”到另一个容器的 Network Namespace 里，这个参数就是 -net，比如: 1$ docker run -it --net container:4ddf4638572d busybox ifconfig 这样，我们新启动的这个容器，就会直接加入到 ID=4ddf4638572d 的容器，也就是我们前面的创建的 Python 应用容器（PID=25686）的 Network Namespace 中。所以，这里 ifconfig 返回的网卡信息，跟我前面那个小程序返回的结果一模一样，你也可以尝试一下。 而如果我指定–net=host，就意味着这个容器不会为进程启用 Network Namespace。这就意味着，这个容器拆除了 Network Namespace 的“隔离墙”，所以，它会和宿主机上的其他普通进程一样，直接共享宿主机的网络栈。这就为容器直接操作和使用宿主机网络提供了一个渠道。 转了一个大圈子，我其实是为你详细解读了 docker exec 这个操作背后，Linux Namespace 更具体的工作原理。 这种通过操作系统进程相关的知识，逐步剖析 Docker 容器的方法，是理解容器的一个关键思路，希望你一定要掌握。 现在，我们再一起回到前面提交镜像的操作 docker commit 上来吧。 docker commit，实际上就是在容器运行起来后，把最上层的“可读写层”，加上原先容器镜像的只读层，打包组成了一个新的镜像。当然，下面这些只读层在宿主机上是共享的，不会占用额外的空间。 而由于使用了联合文件系统，你在容器里对镜像 rootfs 所做的任何修改，都会被操作系统先复制到这个可读写层，然后再修改。这就是所谓的：Copy-on-Write。 而正如前所说，Init 层的存在，就是为了避免你执行 docker commit 时，把 Docker 自己对 /etc/hosts 等文件做的修改，也一起提交掉。 有了新的镜像，我们就可以把它推送到 Docker Hub 上了： 1$ docker push geektime/helloworld:v2 你可能还会有这样的问题：我在企业内部，能不能也搭建一个跟 Docker Hub 类似的镜像上传系统呢？ 当然可以，这个统一存放镜像的系统，就叫作 Docker Registry。感兴趣的话，你可以查看Docker 的官方文档，以及VMware 的 Harbor 项目。 最后，我再来讲解一下 Docker 项目另一个重要的内容：Volume（数据卷）。 前面我已经介绍过，容器技术使用了 rootfs 机制和 Mount Namespace，构建出了一个同宿主机完全隔离开的文件系统环境。这时候，我们就需要考虑这样两个问题： 容器里进程新建的文件，怎么才能让宿主机获取到？ 宿主机上的文件和目录，怎么才能让容器里的进程访问到？ 这正是 Docker Volume 要解决的问题：Volume 机制，允许你将宿主机上指定的目录或者文件，挂载到容器里面进行读取和修改操作。 在 Docker 项目里，它支持两种 Volume 声明方式，可以把宿主机目录挂载进容器的 /test 目录当中： 12$ docker run -v /test ...$ docker run -v /home:/test ... 而这两种声明方式的本质，实际上是相同的：都是把一个宿主机的目录挂载进了容器的 /test 目录。 只不过，在第一种情况下，由于你并没有显示声明宿主机目录，那么 Docker 就会默认在宿主机上创建一个临时目录 /var/lib/docker/volumes/[VOLUME_ID]/_data，然后把它挂载到容器的 /test 目录上。而在第二种情况下，Docker 就直接把宿主机的 /home 目录挂载到容器的 /test 目录上。 那么，Docker 又是如何做到把一个宿主机上的目录或者文件，挂载到容器里面去呢？难道又是 Mount Namespace 的黑科技吗？ 实际上，并不需要这么麻烦。 我已经介绍过，当容器进程被创建之后，尽管开启了 Mount Namespace，但是在它执行 chroot（或者 pivot_root）之前，容器进程一直可以看到宿主机上的整个文件系统。 而宿主机上的文件系统，也自然包括了我们要使用的容器镜像。这个镜像的各个层，保存在 /var/lib/docker/aufs/diff 目录下，在容器进程启动后，它们会被联合挂载在 /var/lib/docker/aufs/mnt/ 目录中，这样容器所需的 rootfs 就准备好了。 所以，我们只需要在 rootfs 准备好之后，在执行 chroot 之前，把 Volume 指定的宿主机目录（比如 /home 目录），挂载到指定的容器目录（比如 /test 目录）在宿主机上对应的目录（即 /var/lib/docker/aufs/mnt/[可读写层 ID]/test）上，这个 Volume 的挂载工作就完成了。 更重要的是，由于执行这个挂载操作时，“容器进程”已经创建了，也就意味着此时 Mount Namespace 已经开启了。所以，这个挂载事件只在这个容器里可见。你在宿主机上，是看不见容器内部的这个挂载点的。这就保证了容器的隔离性不会被 Volume 打破。 注意：这里提到的 “ 容器进程 “，是 Docker 创建的一个容器初始化进程 (dockerinit)，而不是应用进程 (ENTRYPOINT + CMD)。dockerinit 会负责完成根目录的准备、挂载设备和目录、配置 hostname 等一系列需要在容器内进行的初始化操作。最后，它通过 execv() 系统调用，让应用进程取代自己，成为容器里的 PID=1 的进程。 而这里要使用到的挂载技术，就是 Linux 的绑定挂载（bind mount）机制。它的主要作用就是，允许你将一个目录或者文件，而不是整个设备，挂载到一个指定的目录上。并且，这时你在该挂载点上进行的任何操作，只是发生在被挂载的目录或者文件上，而原挂载点的内容则会被隐藏起来且不受影响。 其实，如果你了解 Linux 内核的话，就会明白，绑定挂载实际上是一个 inode 替换的过程。在 Linux 操作系统中，inode 可以理解为存放文件内容的“对象”，而 dentry，也叫目录项，就是访问这个 inode 所使用的“指针”。 正如上图所示，mount —bind /home /test，会将 /home 挂载到 /test 上。其实相当于将 /test 的 dentry，重定向到了 /home 的 inode。这样当我们修改 /test 目录时，实际修改的是 /home 目录的 inode。这也就是为何，一旦执行 umount 命令，/test 目录原先的内容就会恢复：因为修改真正发生在的，是 /home 目录里。 所以，在一个正确的时机，进行一次绑定挂载，Docker 就可以成功地将一个宿主机上的目录或文件，不动声色地挂载到容器中。 这样，进程在容器里对这个 /test 目录进行的所有操作，都实际发生在宿主机的对应目录（比如，/home，或者 /var/lib/docker/volumes/[VOLUME_ID]/_data）里，而不会影响容器镜像的内容。 那么，这个 /test 目录里的内容，既然挂载在容器 rootfs 的可读写层，它会不会被 docker commit 提交掉呢？ 也不会。 这个原因其实我们前面已经提到过。容器的镜像操作，比如 docker commit，都是发生在宿主机空间的。而由于 Mount Namespace 的隔离作用，宿主机并不知道这个绑定挂载的存在。所以，在宿主机看来，容器中可读写层的 /test 目录（/var/lib/docker/aufs/mnt/[可读写层 ID]/test），始终是空的。 不过，由于 Docker 一开始还是要创建 /test 这个目录作为挂载点，所以执行了 docker commit 之后，你会发现新产生的镜像里，会多出来一个空的 /test 目录。毕竟，新建目录操作，又不是挂载操作，Mount Namespace 对它可起不到“障眼法”的作用。 结合以上的讲解，我们现在来亲自验证一下： 首先，启动一个 helloworld 容器，给它声明一个 Volume，挂载在容器里的 /test 目录上： 12$ docker run -d -v /test helloworldcf53b766fa6f 容器启动之后，我们来查看一下这个 Volume 的 ID： 123$ docker volume lsDRIVER VOLUME NAMElocal cb1c2f7221fa9b0971cc35f68aa1034824755ac44a034c0c0a1dd318838d3a6d 然后，使用这个 ID，可以找到它在 Docker 工作目录下的 volumes 路径： 1$ ls /var/lib/docker/volumes/cb1c2f7221fa/_data/ 这个 _data 文件夹，就是这个容器的 Volume 在宿主机上对应的临时目录了。 接下来，我们在容器的 Volume 里，添加一个文件 text.txt： 123$ docker exec -it cf53b766fa6f /bin/shcd test/touch text.txt 这时，我们再回到宿主机，就会发现 text.txt 已经出现在了宿主机上对应的临时目录里： 12$ ls /var/lib/docker/volumes/cb1c2f7221fa/_data/text.txt 可是，如果你在宿主机上查看该容器的可读写层，虽然可以看到这个 /test 目录，但其内容是空的： 1$ ls /var/lib/docker/aufs/mnt/6780d0778b8a/test 可以确认，容器 Volume 里的信息，并不会被 docker commit 提交掉；但这个挂载点目录 /test 本身，则会出现在新的镜像当中。 以上内容，就是 Docker Volume 的核心原理了。 Docker 容器，我们实际上就可以用下面这个“全景图”描述出来： 这个容器进程“python app.py”，运行在由 Linux Namespace 和 Cgroups 构成的隔离环境里；而它运行所需要的各种文件，比如 python，app.py，以及整个操作系统文件，则由多个联合挂载在一起的 rootfs 层提供。 这些 rootfs 层的最下层，是来自 Docker 镜像的只读层。 在只读层之上，是 Docker 自己添加的 Init 层，用来存放被临时修改过的 /etc/hosts 等文件。 而 rootfs 的最上层是一个可读写层，它以 Copy-on-Write 的方式存放任何对只读层的修改，容器声明的 Volume 的挂载点，也出现在这一层。 问题：你在查看 Docker 容器的 Namespace 时，是否注意到有一个叫 cgroup 的 Namespace？它是 Linux 4.6 之后新增加的一个 Namespace，你知道它的作用吗？ Linux 内核从 4.6 开始，支持了一个新的 Namespace 叫作：Cgroup Namespace。 我们知道，正常情况下，在一个容器里查看 /proc/$PID/cgroup，是会看到整个宿主机的 cgroup 信息的。而有了 Cgroup Namespace 后，每个容器里的进程都会有自己 Cgroup Namespace，从而获得一个属于自己的 Cgroups 文件目录视图。也就是说，Cgroups 文件系统也可以被 Namespace 隔离起来了。 Kubernetes的本质一个“容器”，实际上是一个由 Linux Namespace、Linux Cgroups 和 rootfs 三种技术构建出来的进程的隔离环境。 从这个结构中我们不难看出，一个正在运行的 Linux 容器，其实可以被“一分为二”地看待： 一组联合挂载在 /var/lib/docker/aufs/mnt 上的 rootfs，这一部分我们称为“容器镜像”（Container Image），是容器的静态视图； 一个由 Namespace+Cgroups 构成的隔离环境，这一部分我们称为“容器运行时”（Container Runtime），是容器的动态视图。 更进一步地说，作为一名开发者，我并不关心容器运行时的差异。因为，在整个“开发 - 测试 - 发布”的流程中，真正承载着容器信息进行传递的，是容器镜像，而不是容器运行时。 这个重要假设，正是容器技术圈在 Docker 项目成功后不久，就迅速走向了“容器编排”这个“上层建筑”的主要原因：作为一家云服务商或者基础设施提供商，我只要能够将用户提交的 Docker 镜像以容器的方式运行起来，就能成为这个非常热闹的容器生态图上的一个承载点，从而将整个容器技术栈上的价值，沉淀在我的这个节点上。 更重要的是，只要从我这个承载点向 Docker 镜像制作者和使用者方向回溯，整条路径上的各个服务节点，比如 CI/CD、监控、安全、网络、存储等等，都有我可以发挥和盈利的余地。这个逻辑，正是所有云计算提供商如此热衷于容器技术的重要原因：通过容器镜像，它们可以和潜在用户（即，开发者）直接关联起来。 从一个开发者和单一的容器镜像，到无数开发者和庞大的容器集群，容器技术实现了从“容器”到“容器云”的飞跃，标志着它真正得到了市场和生态的认可。 这样，容器就从一个开发者手里的小工具，一跃成为了云计算领域的绝对主角；而能够定义容器组织和管理规范的“容器编排”技术，则当仁不让地坐上了容器技术领域的“头把交椅”。 这其中，最具代表性的容器编排工具，当属 Docker 公司的 Compose+Swarm 组合，以及 Google 与 RedHat 公司共同主导的 Kubernetes 项目。 跟很多基础设施领域先有工程实践、后有方法论的发展路线不同，Kubernetes 项目的理论基础则要比工程实践走得靠前得多，这当然要归功于 Google 公司在 2015 年 4 月发布的 Borg 论文了。 Borg 系统，一直以来都被誉为 Google 公司内部最强大的“秘密武器”。虽然略显夸张，但这个说法倒不算是吹牛。 因为，相比于 Spanner、BigTable 等相对上层的项目，Borg 要承担的责任，是承载 Google 公司整个基础设施的核心依赖。在 Google 公司已经公开发表的基础设施体系论文中，Borg 项目当仁不让地位居整个基础设施技术栈的最底层。 正是由于这样的定位，Borg 可以说是 Google 最不可能开源的一个项目。而幸运地是，得益于 Docker 项目和容器技术的风靡，它却终于得以以另一种方式与开源社区见面，这个方式就是 Kubernetes 项目。 所以，相比于“小打小闹”的 Docker 公司、“旧瓶装新酒”的 Mesos 社区，Kubernetes 项目从一开始就比较幸运地站上了一个他人难以企及的高度：在它的成长阶段，这个项目每一个核心特性的提出，几乎都脱胎于 Borg/Omega 系统的设计与经验。更重要的是，这些特性在开源社区落地的过程中，又在整个社区的合力之下得到了极大的改进，修复了很多当年遗留在 Borg 体系中的缺陷和问题。 所以，尽管在发布之初被批评是“曲高和寡”，但是在逐渐觉察到 Docker 技术栈的“稚嫩”和 Mesos 社区的“老迈”之后，这个社区很快就明白了：Kubernetes 项目在 Borg 体系的指导下，体现出了一种独有的“先进性”与“完备性”，而这些特质才是一个基础设施领域开源项目赖以生存的核心价值。 为了更好地理解这两种特质，我们不妨从 Kubernetes 的顶层设计说起。 首先，Kubernetes 项目要解决的问题是什么？ 编排？调度？容器云？还是集群管理？ 实际上，这个问题到目前为止都没有固定的答案。因为在不同的发展阶段，Kubernetes 需要着重解决的问题是不同的。 但是，对于大多数用户来说，他们希望 Kubernetes 项目带来的体验是确定的：现在我有了应用的容器镜像，请帮我在一个给定的集群上把这个应用运行起来。 更进一步地说，我还希望 Kubernetes 能给我提供路由网关、水平扩展、监控、备份、灾难恢复等一系列运维能力。 等一下，这些功能听起来好像有些耳熟？这不就是经典 PaaS（比如，Cloud Foundry）项目的能力吗？ 而且，有了 Docker 之后，我根本不需要什么 Kubernetes、PaaS，只要使用 Docker 公司的 Compose+Swarm 项目，就完全可以很方便地 DIY 出这些功能了！ 所以说，如果 Kubernetes 项目只是停留在拉取用户镜像、运行容器，以及提供常见的运维功能的话，那么别说跟“原生”的 Docker Swarm 项目竞争了，哪怕跟经典的 PaaS 项目相比也难有什么优势可言。 而实际上，在定义核心功能的过程中，Kubernetes 项目正是依托着 Borg 项目的理论优势，才在短短几个月内迅速站稳了脚跟，进而确定了一个如下图所示的全局架构： 我们可以看到，Kubernetes 项目的架构，跟它的原型项目 Borg 非常类似，都由 Master 和 Node 两种节点组成，而这两种角色分别对应着控制节点和计算节点。 其中，控制节点，即 Master 节点，由三个紧密协作的独立组件组合而成，它们分别是负责 API 服务的 kube-apiserver、负责调度的 kube-scheduler，以及负责容器编排的 kube-controller-manager。整个集群的持久化数据，则由 kube-apiserver 处理后保存在 Etcd 中。 而计算节点上最核心的部分，则是一个叫作 kubelet 的组件。 在 Kubernetes 项目中，kubelet 主要负责同容器运行时（比如 Docker 项目）打交道。而这个交互所依赖的，是一个称作 CRI（Container Runtime Interface）的远程调用接口，这个接口定义了容器运行时的各项核心操作，比如：启动一个容器需要的所有参数。 这也是为何，Kubernetes 项目并不关心你部署的是什么容器运行时、使用的什么技术实现，只要你的这个容器运行时能够运行标准的容器镜像，它就可以通过实现 CRI 接入到 Kubernetes 项目当中。 而具体的容器运行时，比如 Docker 项目，则一般通过 OCI 这个容器运行时规范同底层的 Linux 操作系统进行交互，即：把 CRI 请求翻译成对 Linux 操作系统的调用（操作 Linux Namespace 和 Cgroups 等）。 此外，kubelet 还通过 gRPC 协议同一个叫作 Device Plugin 的插件进行交互。这个插件，是 Kubernetes 项目用来管理 GPU 等宿主机物理设备的主要组件，也是基于 Kubernetes 项目进行机器学习训练、高性能作业支持等工作必须关注的功能。 而kubelet 的另一个重要功能，则是调用网络插件和存储插件为容器配置网络和持久化存储。这两个插件与 kubelet 进行交互的接口，分别是 CNI（Container Networking Interface）和 CSI（Container Storage Interface）。 实际上，kubelet 这个奇怪的名字，来自于 Borg 项目里的同源组件 Borglet。不过，如果你浏览过 Borg 论文的话，就会发现，这个命名方式可能是 kubelet 组件与 Borglet 组件的唯一相似之处。因为 Borg 项目，并不支持我们这里所讲的容器技术，而只是简单地使用了 Linux Cgroups 对进程进行限制。 这就意味着，像 Docker 这样的“容器镜像”在 Borg 中是不存在的，Borglet 组件也自然不需要像 kubelet 这样考虑如何同 Docker 进行交互、如何对容器镜像进行管理的问题，也不需要支持 CRI、CNI、CSI 等诸多容器技术接口。 可以说，kubelet 完全就是为了实现 Kubernetes 项目对容器的管理能力而重新实现的一个组件，与 Borg 之间并没有直接的传承关系。 备注：虽然不使用 Docker，但 Google 内部确实在使用一个包管理工具，名叫 Midas Package Manager (MPM)，其实它可以部分取代 Docker 镜像的角色。 那么，Borg 对于 Kubernetes 项目的指导作用又体现在哪里呢？ 答案是，Master 节点。 虽然在 Master 节点的实现细节上 Borg 项目与 Kubernetes 项目不尽相同，但它们的出发点却高度一致，即：如何编排、管理、调度用户提交的作业？ 所以，Borg 项目完全可以把 Docker 镜像看做是一种新的应用打包方式。这样，Borg 团队过去在大规模作业管理与编排上的经验就可以直接“套”在 Kubernetes 项目上了。 这些经验最主要的表现就是，从一开始，Kubernetes 项目就没有像同时期的各种“容器云”项目那样，把 Docker 作为整个架构的核心，而仅仅把它作为最底层的一个容器运行时实现。 而 Kubernetes 项目要着重解决的问题，则来自于 Borg 的研究人员在论文中提到的一个非常重要的观点： 运行在大规模集群中的各种任务之间，实际上存在着各种各样的关系。这些关系的处理，才是作业编排和管理系统最困难的地方。 事实也正是如此。 其实，这种任务与任务之间的关系，在我们平常的各种技术场景中随处可见。比如，一个 Web 应用与数据库之间的访问关系，一个负载均衡器和它的后端服务之间的代理关系，一个门户应用与授权组件之间的调用关系。 更进一步地说，同属于一个服务单位的不同功能之间，也完全可能存在这样的关系。比如，一个 Web 应用与日志搜集组件之间的文件交换关系。 而在容器技术普及之前，传统虚拟机环境对这种关系的处理方法都是比较“粗粒度”的。你会经常发现很多功能并不相关的应用被一股脑儿地部署在同一台虚拟机中，只是因为它们之间偶尔会互相发起几个 HTTP 请求。 更常见的情况则是，一个应用被部署在虚拟机里之后，你还得手动维护很多跟它协作的守护进程（Daemon），用来处理它的日志搜集、灾难恢复、数据备份等辅助工作。 但容器技术出现以后，你就不难发现，在“功能单位”的划分上，容器有着独一无二的“细粒度”优势：毕竟容器的本质，只是一个进程而已。 也就是说，只要你愿意，那些原先拥挤在同一个虚拟机里的各个应用、组件、守护进程，都可以被分别做成镜像，然后运行在一个个专属的容器中。它们之间互不干涉，拥有各自的资源配额，可以被调度在整个集群里的任何一台机器上。而这，正是一个 PaaS 系统最理想的工作状态，也是所谓“微服务”思想得以落地的先决条件。 当然，如果只做到“封装微服务、调度单容器”这一层次，Docker Swarm 项目就已经绰绰有余了。如果再加上 Compose 项目，你甚至还具备了处理一些简单依赖关系的能力，比如：一个“Web 容器”和它要访问的数据库“DB 容器”。 在 Compose 项目中，你可以为这样的两个容器定义一个“link”，而 Docker 项目则会负责维护这个“link”关系，其具体做法是：Docker 会在 Web 容器中，将 DB 容器的 IP 地址、端口等信息以环境变量的方式注入进去，供应用进程使用，比如： 123456DB_NAME=/web/db DB_PORT=tcp://172.17.0.5:5432 DB_PORT_5432_TCP=tcp://172.17.0.5:5432 DB_PORT_5432_TCP_PROTO=tcp DB_PORT_5432_TCP_PORT=5432 DB_PORT_5432_TCP_ADDR=172.17.0.5 而当 DB 容器发生变化时（比如，镜像更新，被迁移到其他宿主机上等等），这些环境变量的值会由 Docker 项目自动更新。这就是平台项目自动地处理容器间关系的典型例子。 可是，如果我们现在的需求是，要求这个项目能够处理前面提到的所有类型的关系，甚至还要能够支持未来可能出现的更多种类的关系呢？ 这时，“link”这种单独针对一种案例设计的解决方案就太过简单了。如果你做过架构方面的工作，就会深有感触：一旦要追求项目的普适性，那就一定要从顶层开始做好设计。 所以，Kubernetes 项目最主要的设计思想是，从更宏观的角度，以统一的方式来定义任务之间的各种关系，并且为将来支持更多种类的关系留有余地。 比如，Kubernetes 项目对容器间的“访问”进行了分类，首先总结出了一类非常常见的“紧密交互”的关系，即：这些应用之间需要非常频繁的交互和访问；又或者，它们会直接通过本地文件进行信息交换。 在常规环境下，这些应用往往会被直接部署在同一台机器上，通过 Localhost 通信，通过本地磁盘目录交换文件。而在 Kubernetes 项目中，这些容器则会被划分为一个“Pod”，Pod 里的容器共享同一个 Network Namespace、同一组数据卷，从而达到高效率交换信息的目的。 Pod 是 Kubernetes 项目中最基础的一个对象，源自于 Google Borg 论文中一个名叫 Alloc 的设计。 而对于另外一种更为常见的需求，比如 Web 应用与数据库之间的访问关系，Kubernetes 项目则提供了一种叫作“Service”的服务。像这样的两个应用，往往故意不部署在同一台机器上，这样即使 Web 应用所在的机器宕机了，数据库也完全不受影响。可是，我们知道，对于一个容器来说，它的 IP 地址等信息不是固定的，那么 Web 应用又怎么找到数据库容器的 Pod 呢？ 所以，Kubernetes 项目的做法是给 Pod 绑定一个 Service 服务，而 Service 服务声明的 IP 地址等信息是“终生不变”的。这个Service 服务的主要作用，就是作为 Pod 的代理入口（Portal），从而代替 Pod 对外暴露一个固定的网络地址。 这样，对于 Web 应用的 Pod 来说，它需要关心的就是数据库 Pod 的 Service 信息。不难想象，Service 后端真正代理的 Pod 的 IP 地址、端口等信息的自动更新、维护，则是 Kubernetes 项目的职责。 像这样，围绕着容器和 Pod 不断向真实的技术场景扩展，我们就能够摸索出一幅如下所示的 Kubernetes 项目核心功能的“全景图”。 按照这幅图的线索，我们从容器这个最基础的概念出发，首先遇到了容器间“紧密协作”关系的难题，于是就扩展到了 Pod；有了 Pod 之后，我们希望能一次启动多个应用的实例，这样就需要 Deployment 这个 Pod 的多实例管理器；而有了这样一组相同的 Pod 后，我们又需要通过一个固定的 IP 地址和端口以负载均衡的方式访问它，于是就有了 Service。 可是，如果现在两个不同 Pod 之间不仅有“访问关系”，还要求在发起时加上授权信息。最典型的例子就是 Web 应用对数据库访问时需要 Credential（数据库的用户名和密码）信息。那么，在 Kubernetes 中这样的关系又如何处理呢？ Kubernetes 项目提供了一种叫作 Secret 的对象，它其实是一个保存在 Etcd 里的键值对数据。这样，你把 Credential 信息以 Secret 的方式存在 Etcd 里，Kubernetes 就会在你指定的 Pod（比如，Web 应用的 Pod）启动时，自动把 Secret 里的数据以 Volume 的方式挂载到容器里。这样，这个 Web 应用就可以访问数据库了。 除了应用与应用之间的关系外，应用运行的形态是影响“如何容器化这个应用”的第二个重要因素。 为此，Kubernetes 定义了新的、基于 Pod 改进后的对象。比如 Job，用来描述一次性运行的 Pod（比如，大数据任务）；再比如 DaemonSet，用来描述每个宿主机上必须且只能运行一个副本的守护进程服务；又比如 CronJob，则用于描述定时任务等等。 如此种种，正是 Kubernetes 项目定义容器间关系和形态的主要方法。 可以看到，Kubernetes 项目并没有像其他项目那样，为每一个管理功能创建一个指令，然后在项目中实现其中的逻辑。这种做法，的确可以解决当前的问题，但是在更多的问题来临之后，往往会力不从心。 相比之下，在 Kubernetes 项目中，我们所推崇的使用方法是： 首先，通过一个“编排对象”，比如 Pod、Job、CronJob 等，来描述你试图管理的应用； 然后，再为它定义一些“服务对象”，比如 Service、Secret、Horizontal Pod Autoscaler（自动水平扩展器）等。这些对象，会负责具体的平台级功能。 这种使用方法，就是所谓的“声明式 API”。这种 API 对应的“编排对象”和“服务对象”，都是 Kubernetes 项目中的 API 对象（API Object）。 这就是 Kubernetes 最核心的设计理念，也是接下来我会重点剖析的关键技术点。 最后，我来回答一个更直接的问题：Kubernetes 项目如何启动一个容器化任务呢？ 比如，我现在已经制作好了一个 Nginx 容器镜像，希望让平台帮我启动这个镜像。并且，我要求平台帮我运行两个完全相同的 Nginx 副本，以负载均衡的方式共同对外提供服务。 如果是自己 DIY 的话，可能需要启动两台虚拟机，分别安装两个 Nginx，然后使用 keepalived 为这两个虚拟机做一个虚拟 IP。 而如果使用 Kubernetes 项目呢？你需要做的则是编写如下这样一个 YAML 文件（比如名叫 nginx-deployment.yaml）： 123456789101112131415161718192021apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deployment labels: app: nginxspec: replicas: 2 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 在上面这个 YAML 文件中，我们定义了一个 Deployment 对象，它的主体部分（spec.template 部分）是一个使用 Nginx 镜像的 Pod，而这个 Pod 的副本数是 2（replicas=2）。 然后执行： 1$ kubectl create -f nginx-deployment.yaml 这样，两个完全相同的 Nginx 容器副本就被启动了。 实际上，过去很多的集群管理项目（比如 Yarn、Mesos，以及 Swarm）所擅长的，都是把一个容器，按照某种规则，放置在某个最佳节点上运行起来。这种功能，我们称为“调度”。 而 Kubernetes 项目所擅长的，是按照用户的意愿和整个系统的规则，完全自动化地处理好容器之间的各种关系。这种功能，就是我们经常听到的一个概念：编排。 所以说，Kubernetes 项目的本质，是为用户提供一个具有普遍意义的容器编排工具。 不过，更重要的是，Kubernetes 项目为用户提供的不仅限于一个工具。它真正的价值，乃在于提供了一套基于容器构建分布式系统的基础依赖。 参考链接：https://time.geekbang.org/column/intro/100015201","categories":[{"name":"云原生","slug":"云原生","permalink":"http://wht6.github.io/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://wht6.github.io/tags/Docker/"},{"name":"容器","slug":"容器","permalink":"http://wht6.github.io/tags/%E5%AE%B9%E5%99%A8/"}]},{"title":"Shell脚本复习","slug":"shell脚本复习","date":"2022-03-23T08:00:00.000Z","updated":"2022-03-28T00:40:19.663Z","comments":true,"path":"posts/a2bb.html","link":"","permalink":"http://wht6.github.io/posts/a2bb.html","excerpt":"","text":"基础复习代码规范 脚本第一行 123456#!/usr/bin/env bash # 通过/usr/bin/env运行程序，用户不需要去寻找程序在系统中的位置,，只要程序在你的$PATH中；#!/usr/bin/bash# 指定程序在系统中的具体位置的方式usr/bin/bash，在某些情况下更安全，因为它限制了代码注入的可能；#!/bin/bash# 在一些系统上/usr/bin/bash可能没有，而/bin/bash则一定存在的，所以/bin/bash是显示指定的优先选择。 基本信息描述 12345# Author：作者# Desc：描述# Usage：用法# Update：更新时间# Release：发布版本 基本数据类型Bash中基本数据类型只有字符串类型，连数值类型都没有(declare -i可强制声明数值类型)。 变量赋值和引用变量12345a=3echo $aa=&#x27;hello world&#x27;echo $a 变量替换和命令替换12a=&quot;hello&quot;echo $a world 取得变量a的值hello，并将它替换到命令行的$a处. 12echo `id root`echo $(id root) 命令的输出结果替换到$()或反引号位置处。 算术运算$[]或$(())或let命令可以做算术运算。 let是单独的命令，不能写在其它命令行中。 123a=3let a=a+1echo $a $[]和$(())可以写在命令行内部，Shell在解析命令行的时候，会对它们做算术运算，然后将运算结果替换到命令行中。 1234567a=33echo $[a+3]echo $((a+3))a=333echo $[$a+3]echo $(($a+3)) 退出状态码每个命令执行后都会有对应的进程退出状态码，用来表示该进程是否是正常退出。 所以，在命令行中，在Shell脚本中，经常会使用特殊变量$?判断最近一个前台命令是否正常退出。 通常情况下，如果$?的值： 为0，表示进程成功执行，即正常退出 非0，表示进程未成功执行，即非正常退出 但非0退出状态码并不一定表示错误，也可能是正常逻辑的退出 另外，在Shell脚本中，所有条件判断(比如if语句、while语句)都以0退出状态码表示True，以非0退出状态码为False。 重定向在Linux系统中，每个程序默认都会打开三个文件描述符(file descriptor,fd)： fd=0：标准输入，表示程序默认从哪里读取数据 fd=1：标准输出，表示程序默认将数据输出到哪里 fd=2：标准错误，表示程序默认将错误信息输出到哪里 文件描述符，说白了就是系统为了跟踪打开的文件而分配给它的一个数字，这个数字和文件有对应关系：从文件描述符读取数据，即表示从对应的文件中读取数据，向文件描述符写数据，即表示向对应文件中写入数据。 Linux中万物皆文件，文件描述符也是文件。默认： fd=0的标准输入是/dev/stdin文件 fd=1的标准输出是/dev/stdout文件 fd=2的标准错误是/dev/stderr文件 这些文件默认又是各个终端的软链接文件： 12345678910$ ls -l /dev/std*lrwxrwxrwx 1 root root 15 Jan 8 20:26 /dev/stderr -&gt; /proc/self/fd/2lrwxrwxrwx 1 root root 15 Jan 8 20:26 /dev/stdin -&gt; /proc/self/fd/0lrwxrwxrwx 1 root root 15 Jan 8 20:26 /dev/stdout -&gt; /proc/self/fd/1$ ls -l /proc/self/fd/lrwx------ 1 root root 64 Jan 16 10:40 0 -&gt; /dev/pts/0lrwx------ 1 root root 64 Jan 16 10:40 1 -&gt; /dev/pts/0lrwx------ 1 root root 64 Jan 16 10:40 2 -&gt; /dev/pts/0lr-x------ 1 root root 64 Jan 16 10:40 3 -&gt; /proc/75220/fd 所以，默认情况下读写数据都是终端。 改变文件描述符对应的目标，可以改变数据的流向。比如标准输出fd=1默认流向是终端设备，若将其改为/tmp/a.log，便能让数据写入/tmp/a.log文件中而不再是终端设备中。 在Shell中，这种改变文件描述符目标的行为称为重定向，即重新确定数据的流向。 其实，文件描述符有很多类操作，包括fd的重定向、fd的分配(open，即打开文件)、fd复制(duplicate)、fd的移动(move)、fd的关闭(close)。现在只介绍基础重定向操作。 Shell中，基础重定向操作有以下几种方式： [n]&gt;file：覆盖式输出重定向，输出到fd=n的数据改变流向输出到file文件中，file不存在则创建，file存在则先清空再写入数据 省略n时&gt;file，等价于1&gt;file，即标准输出覆盖重定向到file文件中 [n]&gt;&gt;file：追加式输出重定向，输出到fd=n的数据改变流向输出到file文件的尾部，file不存在则创建，file存在则直接追加在文件尾部 省略n时&gt;&gt;file，等价于1&gt;&gt;file，即标准输出追加重定向到file文件中 [n]&lt;file：输入重定向，以读取模式打开file文件并分配fd=n，file不存在则报错 省略n时&lt;file，等价于0&lt;file，即直接从file中读数据 通常程序都只从fd=0中读数据，所以当n不等于0时，需要多做一步操作3&lt;file &lt;&amp;3 &amp;&gt;file：这是特殊的重定向方式，表示将标准错误和标准输出都重定向到file文件中，等价于&gt;file 2&gt;&amp;1 &amp;&gt;&gt;file：这是特殊的重定向方式，表示将标准错误和标准输出都追加到file文件中，等价于&gt;&gt;file 2&gt;&amp;1另外，经常用于输出的一个特殊目标文件是/dev/null，它是空设备，可以直接丢掉所有写入它的数据。 一个经常用的技巧是清空文件的方式： 12$ cat /dev/null &gt;file$ &gt;file cat1cat -n /etc/fstab cat命令开始执行后，会识别-n选项，该选项会让cat输出时同时输出行号，cat同时还会识别/etc/fstab参数，cat会读取参数指定的文件然后输出。 如果没有指定cat的文件参数，则cat默认会从标准输入中读取数据。默认的标准输入是终端，所以在没有改变标准输入的流向时，会从终端读取数据，也就是用户输入什么字符，就读取什么字符，然后输出什么字符： 123456$ cathello # 在终端输入hello # 在终端输出world # 在终端输入world # 在终端输出^C 但用户可以改变标准输入的来源。比如： 1$ cat &lt;/etc/fstab 表示将标准输入来源改为/etc/fstab文件，于是cat会从/etc/fstab中读取数据。 cat与重定向结合使用可以将将stdin标准输入的内容重定向到指定的文件(若文件不存在，则创建)，且当stdin中含有EOF时完成写入。 1234567891011cat &lt;&lt; EOF &gt; cattest.txthelloEOF# 等价于cat &gt; cattest.txt &lt;&lt; EOFhelloEOF# 也可以使用追加cat &gt;&gt; cattest.txt &lt;&lt;EOFworldEOF read命令read命令是bash内置命令，用来从标准输入中读取数据。比如可以交互式读取用户在终端的输入，读取管道数据，读取标准输入重定向数据，等等。 读取文件中数据的方式： 按字符数读取 按分隔符读取 按行读取 一次性读完所有数据 按字节数读取(read命令不支持) 1234567891011121314151617181920212223242526272829read [-a aname] [-d delim] [-n nchars] [-N nchars] [-p prompt] [-t timeout] [-u fd] [name …]-a arr读取数据保存到数组arr中，arr数组已存在则先清空-d delim指定读取数据时的分隔符，不指定时默认为换行符。当指定为空字符串时，则默认为\\0。当指定为文件中不存在的符号，则直接读整个文件-n X每次读取X个字符，但如果读满X字符前遇到了分隔符，则也停止本次读取-N X每次读取X个字符，即使遇到了分隔符也不停止-p prompt交互式提示用户在终端输入的信息，默认不输出换行符-s用户在终端中的输入不会显示出来。在提示用户输入密码时应设置该选项-r使得读取到的反斜线不进行转义，而是作为一个普通反斜线字符 -t timeout超时时间，如果在超时时间内还未读满数据，则读取失败，可指定为小数时间-u fd从文件描述符中读取数据 例子： 1234567891011#!/usr/bin/bashclearread -p &quot;Login: &quot; accecho -n -e &quot;Password： &quot;read -s -t50 -n6 pwechoecho &quot;account: $acc password: $pw &quot; 注意：如果没有提供变量名，那么读取的数据将存放到环境变量 REPLY 中。 变量分类 本地变量：用户私有变量，只有本用户可以使用，保存在家目录的.bash_profile、.bashrc文件中。 全局变量：所有用户都可以使用，保存在/etc/profile、/etc/bashrc文件中。定义全局变量加export。 用户自定义变量：用户自定义，比如脚本中的变量。 普通数组普通数组：只能使用整数作为数组索引(元素的索引)定义方式： 1数组名称=(元素1 元素2 元素3 ...) 读出方式： 1$&#123;数组名[索引]&#125; 赋值方式： 一次赋一个值 1234变量名=变量值array[0]=v1array[1]=v2array[3]=v3 一次附多个值 12345array=(var1 var2 var3 var4)array1=(`cat /etc/passwd`) # 将文件中每一行赋值给array1数组array2=(`ls /root`)array3=(harry amy jack &quot;Miss zhang&quot;)array4=(1 2 3 4 &quot;hello world&quot; [10]=linux) 访问数组元素1234567$&#123;array[i]&#125; i表示元素的索引# 使用@ 或 * 可以获取数组中的所有元素：echo $&#123;array[*]&#125; # 获取数组里的所有元素echo $&#123;#array[*]&#125; # 获取数组里所有元素个数echo $&#123;!array[@]&#125; # 获取数组元素的索引索引echo $&#123;array[@]:1:2&#125; # 访问指定的元素；1代表从索引为1的元素开始获取；2代表获取后面几个元素 关联数组关联数组使用首先需要申明该数组为关联数组，声明方式： declare -A 数组名称 赋值方式： 一次赋一个值 12asso_array1[linux]=oneasso_array1[java]=two 一次附多个值 1asso_array2=([name1]=harry [name2]=jack [name3]=amy [name4]=&quot;Miss zhang&quot;) 查看关联数组 1$ declare -A bash debug 使用bash的-x选项 1$ bash -x example_script.sh 调试部份的脚本，调用set -x，结束的时候调用set +x。 12345#!/bin/bashecho &quot;Hello $USER,&quot;set -xecho &quot;Today is $(date %Y-%m-%d)&quot;set +x 判断 文件存在与否 12345678-e 是否存在 不管是文件还是目录，只要存在，条件就成立-f 是否为普通文件-d 是否为目录-S socket-p pipe-c character-b block-L 软link 例子：(创建文件夹) 123456if [ ! -d /tmp/abc ] then mkdir -v /tmp/abc echo &quot;123&quot; echo &quot;create /tmp/abc ok &quot;fi 文件权限 123456-r 当前用户对其是否可读-w 当前用户对其是否可写-x 当前用户对其是否可执行-u 是否有suid-g 是否sgid-k 是否有t位 两个文件比较 123file1 -nt file2 比较file1是否比file2新 file1 -ot file2 比较file1是否比file2旧file1 -ef file2 比较是否为同一个文件，或者用于判断硬连接，是否指向同一个inode 字符串比较 1234-z 是否为空字符串 字符串长度为0，就成立-n 是否为非空字符串 只要字符串非空，就是成立string1 == string2 是否相等string1 != string2 不等 if语句1234if [ condition ] 假如 条件为真 then 那么 commands 执行commands代码块fi 结束 123456if [ condition ] then 条件为真 commands1 真 要执行代码块else 条件为假 commands2 假 要执行的代码块fi 结束 1234567891011if [ condition 1 ] 满足第一个条件 then 真 command1 执行command1代码块elif [ condition 2 ] 满足第二个条件 then 真 commands2 执行command2代码块 .......else 如果条件都不满足 commandsX 执行commandX代码块fi 结束判断 高级用法 12345678910111213141516# 条件符号使用双圆括号，可以在条件中植入数学表达式 if (())if (( (5+5-5)*5/5 &gt; 10 )) then echo &quot;yes&quot;else echo &quot;no&quot;fi# 使用双方括号,可以在条件中使用通配符for var in ab ac rx bx rvv vt do if [[ &quot;$var&quot; == r* ]] then echo &quot;$var&quot; fidone for循环123456789101112for variable_name in &#123;list&#125; do command command … done或者for variable in a b c do command command done c风格 123456789101112for(( expr1;expr2;expr3 )) do command command … done for (( i=1;i&lt;=5;i++)) do echo $i done break [n]，退出整个循环，包括for、while、until和select语句。其中数值n表示退出的循环层次。 continue [n]，退出当前循环进入下一次循环。n表示继续执行向外退出n层的循环。默认n=1，表示继续当前层的下一循环，n=2表示继续上一层的下一循环。 while循环1234while [ 表达式 ] # 条件为真就进入循环；条件为假就退出循环 do command... done case语句1234567891011121314case $var in 定义变量;var代表是变量名pattern 1) 模式1;用 | 分割多个模式，相当于or command1 需要执行的语句 ;; 两个分号代表命令结束pattern 2) command2 ;;pattern 3) command3 ;;*) default，不满足以上模式，默认执行*)下面的语句 command4 ;;esac esac表示case语句结束 函数12345678910111213141516171819语法一:函数名 () &#123; 代码块 return N &#125;语法二：function 函数名 &#123; 代码块 return N &#125; 函数中return说明：1.return可以结束一个函数，类似于循环控制语句break(结束当前循环，执行循环体后面的代码)2.return默认返回函数中最后一个命令的退出状态，也可以给定参数值，该参数值的范围是0-256之间。3.如果没有return命令，函数将返回最后一个Shell的退出值。shell的函数一般都不写return。 文件操作sedsed是linux中提供的一个外部命令,它是一个行(流)编辑器，非交互式的对文件内容进行增删改查的操作。 文本编辑器: 编辑对象是文件；行编辑器：编辑对象是文件中的行。前者一次处理一个文本，而后者是一次处理一个文本中的一行。 sed 命令语法： sed [options] ‘{command}[flags]’ [filename] 123456789101112131415161718192021222324252627282930#命令选项-e script 将脚本中指定的命令添加到处理输入时执行的命令中 多条件，一行中要有多个操作-f script 将文件中指定的命令添加到处理输入时执行的命令中-n 抑制自动输出-i 编辑文件内容-i.bak 修改时同时创建.bak备份文件。-r 使用扩展的正则表达式! 取反 （跟在模式条件后与shell有所区别）#command 对文件干什么sed 常用内部命令a 在匹配后面添加i 在匹配前面添加d 删除s 查找替换 字符串c 更改y 转换 N D P p 打印#flags数字 表示新文本替换的模式g： 表示用新文本替换现有文本的全部实例p： 表示打印原始的内容w filename: 将替换的结果写入文件 命令： 123456789101112131415161718192021222324252627282930313233sed &#x27;a\\append data &quot;haha&quot;&#x27; data1 # 在data1的每行后追加一行新数据内容: append data &quot;haha&quot;sed &#x27;2a\\append data &quot;haha&quot;&#x27; data1# 在第二行后新开一行追加数据: append data &quot;haha&quot;sed &#x27;/3 the/a\\append data &quot;haha&quot;&#x27; data1# 找到包含&quot;3 the&quot;的行，在其后新开一行追加内容: append data &quot;haha&quot;# //开启匹配模式 /要匹配的字符串/ 更常用sed &#x27;2,4i\\insert data &quot;haha&quot;&#x27; data1# 在第二到四行每行前新开一行插入数据: insert data &quot;haha&quot;sed &#x27;/3 the/i\\insert data &quot;haha&quot;&#x27; data1# 找到包含&quot;3 the&quot;的行，在其前新开一行插入内容: insert data &quot;haha&quot;sed &#x27;/3 the/d&#x27; data1# 删除文件data1中包含字符串&quot;3 the&quot;的行sed &#x27;2s/dog/cat/&#x27; data1# 将data1中第二行的dog替换为catsed &#x27;/3 the/s/dog/cat/&#x27; data1# 将包含字符串&quot;3 the&quot;的行中的dog替换为catsed &#x27;2c\\change data &quot;haha&quot;&#x27; data1# 将data1文件第二行的内容更改为: change data &quot;haha&quot;sed &#x27;2,4c\\change data &quot;haha&quot;&#x27; data1# 将data1文件中的第二、三、四行的内容删除，更改为一行：change data &quot;haha&quot;sed &#x27;/3 the/c\\change data &quot;data&quot;&#x27; data1# 将data1文件中包含&quot;3 the&quot;的行内容更改为: change data &quot;haha&quot;sed &#x27;y/abc/ABC/&#x27; data1# 将data1中的a b c字符转换为对应的 A B C字符sed &#x27;2,4p&#x27; data1# 打印data1文件第二、三、四行内容 标志位 123456789101112sed &#x27;s/dog/cat/2&#x27; data2# 替换一行中的第二处dog为catsed &#x27;s/dog/cat/g&#x27; data2# 将data1文件中的所有dog替换为catsed &#x27;3s/dog/cat/w text&#x27; data2# 将修改的内容存入text文件中sed &#x27;w data2.bak&#x27; data2# 备份data2的数据sed &#x27;3s/dog/cat/p&#x27; data2# 打印文本内容，类似于-p命令选项 选项 12345678910111213141516171819202122232425sed -n &#x27;2,$p&#x27; data1 # 打印data1文件的第二行到最后一行内容 $是最后的意思sed -r &#x27;/(^#|#|^$)/d&#x27; nginx.conf # 删除所有注释和空行sed -n -r &#x27;/^(root)(.*)(bash)$/p&#x27; /etc/password# 打印root开头，bash结尾，中间任意的行sed -e &#x27;s/brown/green/;s/dog/cat/&#x27; data1# 将brown替换为green dog替换为cat# 在命令行中使用多个命令 用-evim abc ### abc的内容# s/brown/green/ # s/dog/cat/# s/fox/elephant/###sed -f abc data1 # 从文件读取编辑器命令 用-f ，适用于日常重复执行的场景# 如果需要修改文件内容可以直接使用-i命令选项sed -i.bak &#x27;s/brown/green/&#x27; data1# -i是一个不可逆的操作，一旦修改，如果想复原就很困难，几乎不可能，所以建议大家在操作的时候可以备份一下源文件。 其他： 12345# 配合管道echo &quot;xxx is yyy&quot; | sed &#x27;s/yyy/zzz/&#x27;# 统计行数sed -n &#x27;$=&#x27; data1 awkawk可以对数据进行筛选和处理。awk是一种可以处理数据、产生格式化报表的语言，功能十分强大。awk 认为文件中的每一行是一条记录 记录与记录的分隔符为换行符,每一列是一个字段 字段与字段的分隔符默认是一个或多个空格或tab制表符。 awk的工作方式是读取数据，将每一行数据视为一条记录（record）每条记录以字段分隔符分成若干字段，然后输出各个字段的值。 awk语法 awk [options] ‘[BEGIN]{program}[END]’ [FILENAME] 12345678910111213常用命令选项-F fs 指定描绘一行中数据字段的文件分隔符 默认为空格-f file 指定读取程序的文件名-v var=value 定义awk程序中使用的变量和默认值注意：awk 程序由左大括号和右大括号定义。 程序命令必须放置在两个大括号之间。由于awk命令行假定程序是单文本字符串，所以必须将程序包括在单引号内。1）程序必须放在大括号内2）程序必须要用单引号引起来awk程序运行优先级是: 1)BEGIN: 在开始处理数据流之前执行，可选项 2)program: 如何处理数据流，必选项 3)END: 处理完数据流后执行，可选项 基本用法 awk对字段(列)的提取 字段提取:提取一个文本中的一列数据并打印输出 字段相关内置变量 $0 表示整行文本 $1 表示文本行中的第一个数据字段 $2 表示文本行中的第二个数据字段 $N 表示文本行中的第N个数据字段 $NF 表示文本行中的最后一个数据字段 123456awk &#x27;&#123;print $0&#125;&#x27; test # 读入test每行数据并把每行数据打印出来awk &#x27;&#123;print $6&#125;&#x27; test# 打印test第六个字段（列）awk &#x27;&#123;print $NF&#125;&#x27; test# 打印test最后一列 awk对记录(行)的提取 记录提取：提取一个文本中的一行并打印输出 记录的提取方法有两种：a、通过行号 b、通过正则匹配 NR: 指定行号 number row 1234awk &#x27;NR==3&#123;print $0&#125;&#x27; test # 提取test第三行数据 指定行号为3awk &#x27;$1==&quot;3&quot;&#123;print $0&#125;&#x27; test# 指定行的第一个字段精确匹配字符串为3 选项 -F: 指定字段与字段的分隔符 12awk -F &#x27;:&#x27; &#x27;&#123;print $1,$3,$NF&#125;&#x27; /etc/passwdawk -F &#x27;:&#x27; &#x27;&#123;print &quot;Account: &quot; $1,&quot;UID: &quot; $3,&quot;DESC: &quot; $5&#125;&#x27; /etc/passwd #可以加入字符串 awk的优先级 关于awk程序的执行优先级，BEGIN是优先级最高的代码块，是在执行PROGRAM之前执行的，不需要提供数据源，因为不涉及到任何数据的处理，也不依赖与PROGRAM代码块；PROGRAM是对数据流干什么，是必选代码块，也是默认代码块。所以在执行时必须提供数据源；END是处理完数据流后的操作，如果需要执行END代码块，就必须需要PROGRAM的支持，单个无法执行。 BEGIN：处理数据源之前干什么 不需要数据源就可以执行 PROGRAM： 对数据源干什么 【默认必须有】 需要数据源 END：处理完数据源后干什么 需要program 需要数据源 12345678awk &#x27;BEGIN&#123;print &quot;hello&quot;&#125;&#123;print $0&#125;END&#123;print &quot;bye&quot;&#125;&#x27; test# 不需要数据源，可以直接执行awk &#x27;BEGIN&#123;print &quot;hello world&quot;&#125;&#x27;# 没有提供数据流，所以无法执行成功# awk &#x27;&#123;print &quot;hello world&quot;&#125;&#x27;# awk &#x27;END&#123;print &quot;hello world&quot;&#125;&#x27; 高级用法awk还可以定义变量，定义数组，运算和流程控制。 计算内存使用率 1head -2 /proc/meminfo | awk &#x27;NR==1&#123;t=$2&#125;NR==2&#123;f=$2;print (t-f)*100/t &quot;%&quot;&#125;&#x27; 变量和数组 123awk &#x27;BEGIN&#123;name=&quot;xxx&quot;;print name&#125;&#x27;awk &#x27;BEGIN&#123;array[0]=100;array[1]=200;print array[0],array[1]&#125;&#x27; 运算 1234awk &#x27;BEGIN&#123;print &quot;a&quot; &gt;= &quot;b&quot; &#125;&#x27;awk &#x27;BEGIN&#123;print 100/3 &#125;&#x27;awk &#x27;BEGIN&#123;print 100&gt;=2 &amp;&amp; 100&gt;=3 &#125;&#x27;awk -v &#x27;count=0&#x27; &#x27;BEGIN&#123;count++;print count&#125;&#x27; 匹配 12awk -F: &#x27;$1=&quot;root&quot; &#123;print $0&#125;&#x27; /etc/passwd # 精确匹配awk -F: &#x27;$1 ~ &quot;^ro&quot; &#123;print $0&#125;&#x27; /etc/passwd # 模糊匹配 awk环境变量 变量 描述 FIELDWIDTHS 以空格分隔的数字列表，用空格定义每个数据字段的精确宽度 FS 输入字段分隔符号 数据源的字段分隔符 -F OFS 输出字段分隔符号 RS 输入记录分隔符 ORS 输出记录分隔符号 1234567891011121314# FIELDWIDTHS:重定义列宽并打印，注意不可以使用$0打印所有，因为$0是打印本行全内容，不会打印你定义的字段awk &#x27;BEGIN&#123;FIELDWIDTHS=&quot;5 2 8&quot;&#125;NR==1&#123;print $1,$2,$3&#125;&#x27; /etc/passwd# FS:指定数据源中字段分隔符，类似命令选项-Fawk &#x27;BEGIN&#123;FS=&quot;:&quot;&#125;NR==1&#123;print $1,$3,$NF&#125;&#x27; /etc/passwd# OFS:指定输出到屏幕后字段的分隔符awk &#x27;BEGIN&#123;FS=&quot;:&quot;;OFS=&quot;-&quot;&#125;NR==1&#123;print $1,$3,$NF&#125;&#x27; /etc/passwd# RS:指定记录(行)的分隔符awk &#x27;BEGIN&#123;RS=&quot;&quot;&#125;&#123;print $1,$2,$3&#125;&#x27; test# ORS:输出到屏幕后记录的分隔符，默认为回车awk &#x27;BEGIN&#123;RS=&quot;&quot;;ORS=&quot;*&quot;&#125;&#123;print $1,$2,$3&#125;&#x27; test 流程控制 1234567891011121314151617181920awk &#x27;&#123;if($1&gt;5)print $0&#125;&#x27; num# 单if语句 打印$1大于5的行awk &#x27;&#123;if($1&gt;5)print $1/2;else print $1*2&#125;&#x27; num# if...else语句 假如$1大于5则除以2输出，否则乘以2输出awk &#x27;&#123;sum=0;for (i=1;i&lt;4;i++)&#123;sum+=$i&#125;print sum&#125;&#x27; num2# for循环 将一行中的数据都加起来 $1+$2+$3# 如果看的不明白可以看下面格式awk &#x27;&#123;&gt; sum=0&gt; for (i=1;i&lt;4;i++) &#123;&gt; sum+=$i&gt; &#125;&gt; print sum&gt; &#125;&#x27; num2awk &#x27;&#123;sum=0;i=1;while(i&lt;4)&#123;sum+=$i;i++&#125;print sum&#125;&#x27; num2# while循环 将文件中的每行的数值累加# do while和break也可以使用 小技巧 12345678# 打印test文本中的行数awk &#x27;END&#123;print NR&#125;&#x27; test# 打印test文本最后一行的内容awk &#x27;END&#123;print $0&#125;&#x27; test# 打印test文本中的列数awk &#x27;END&#123;print NF&#125;&#x27; test 常用命令wcwc命令用于计算字数。 -c或—bytes或—chars 只显示Bytes数。 -l或—lines 显示行数。 -w或—words 只显示字数。 常用工具lsoflsof 是 List Open File 的缩写, 它主要用来获取被进程打开文件的信息，我们都知道，在Linux中，一切皆文件，lsof命令可以查看所有已经打开了的文件，比如: 普通文件，目录，特殊的块文件，管道，socket套接字，设备，Unix域套接字等等，同时，它还可以结合 grep 以及 ps 命令进行更多的高级搜索。 不带任何参数执行 lsof 命令会输出当前所有活跃进程打开的所有文件 -u，列出指定用户已经打开的文件 -i，列出所有打开了的网络文件 -i 4，列出所有已经打开了的 ipv4 网络文件 -i 6，列出所有已经打开了的 ipv6 网络文件 -i:端口号，获得所有在指定端口号上打开的文件 -i TCP/UDP 列出使用了TCP 或 UDP 协议的文件 -p，列出指定进程ID打开的文件 curlcurl 是一个工具，利用URL规则在命令行下工作的文件传输工具，可以说是一款很强大的http命令行工具。它支持文件的上传和下载，是综合传输工具，但按传统，习惯称url为下载工具。可支持的协议有（DICT、FILE、FTP、FTPS、GOPHER、HTTP、HTTPS、IMAP、IMAPS、LDAP、LDAPS、POP3、POP3S、RTMP、RTSP、SCP、SFTP、SMTP、SMTPS、TELNET和TFTP）。 1234567891011121314curl http://www.linux.com# 直接下载html页面，内容会直接显示在终端curl http://www.linux.com &gt;&gt; linux.html# 将内容重定向到文件中curl -o linux.html http://www.linux.com# 或者使用-o 输出到文件中curl -O http://www.linux.com/hello.sh# -O 要注意这里后面的url要具体到某个文件，不然抓不下来-s # 静默模式，不输出任何东西-S # 当与 -s 一起使用时，如果curl失败，curl将显示一条错误消息-i # 在输出的内容中包含HTTP 头信息-I # (HTTP/FTP/FILE)只获取HTTP头文件;在FTP或FILE 文件上使用时，curl只显示文件大小和最后修改时间-# # 将curl进度显示为一个简单的进度条；而不是标准的、具有更多信息的进度表 其他库函数库函数就是/etc/rc.d/init.d/functions文件中定义的系统函数（/etc/init.d/是/etc/rc.d/init.d的软链接）。 显示函数 success：显示绿色的OK，表示成功 failure：显示红色的FAILED，表示失败 passed：显示黄色的PASSED，表示pass该任务 warning：显示黄色的warning，表示警告 confirm：提示(Y)es/(N)o/(C)ontinue? [Y]并判断、传递输入的值 is_true：$1的布尔值代表为真时，返回状态码0，否则返回1；包括t/y/yes/true，不区分大小写 is_false：$1的布尔值代表为假时，返回状态码0，否则返回1；包括f/n/no/false，不区分大小写 action：根据进程退出状态码自行判断是执行success还是failure 进程函数 checkpid：检查/proc下是否有给定pid对应的目录，给定多个pid时，只要存在一个目录都返回状态码0 __pids_var_run：检查pid是否存在，并保存到变量pid中，同时返回几种进程状态码 __pids_pidof：获取进程pid pidfileofproc：获取进程pid，但只能获取/var/run下的pid文件中的值 pidofproc：获取进程pid，可获取任意给定pidfile或默认/var/run下pidfile中的值 status：检查给定进程的运行状态 daemon：启动一个服务程序，启动前还检查进程是否已在运行 killproc：杀掉给定的服务进程 在脚本中使用引入库函数的方式是在脚本中加入. /etc/rc.d/init.d/functions或. /etc/init.d/functions 正则表达式正则表达式是一种文本匹配模式，提供一些特殊字符生成匹配字符串的公式来从文本中匹配出想要的数据。 Linux中支持正则表达式的工具：locate |find| vim| grep| sed |awk。 定位符使用技巧：同时锚定开头和结尾，做精确匹配；单一锚定开头或结尾或者不锚定的，做模糊匹配。 定位符 说明 ^ 锚定开头 ^a 以a开头 默认锚定一个字符 $ 锚定结尾 a$ 以a结尾 默认锚定一个字符 grep -e或egrep，表示支持正则表达式（默认不支持）。 123$ egrep &quot;^ac$&quot; file # 匹配a开头且c结尾的串 精确匹配$ egrep &quot;^a&quot; file # 匹配a开头的串 模糊匹配$ egrep &quot;c$&quot; file # 匹配c结尾的串 模糊匹配 匹配符 说明 . 匹配除回车以外的任意一个字符 ( ) 字符串分组 [ ] 定义字符类，匹配括号中的一个字符 [ ^ ] 表示否定括号中出现字符类中的字符,取反。 \\ 转义字符 \\ 或 123$ egrep &quot;^a[a-z0-9]c$&quot; file # 以a开头c结尾 中间是a-z,0-9 长度为三个字节的字符串$ egrep &quot;^a[^a-z0-9]c$&quot; file # 以a开头c结尾 中间不包含a-z,0-9 长度为三个字节的字符串$ egrep &quot;^a.(b|c)$&quot; file # 以a开头b或c结尾 中间是任意 长度为三个字节的字符串 限定符 说明 * 某个字符之后加星号表示该字符不出现或出现多次 a (ab) ？ 与星号相似，但略有变化，表示该字符出现一次或不出现 + 与星号相似，表示其前面字符出现一次或多次，但必须出现一次 {n,m} 某个字符之后出现，表示该字符最少n次，最多m次 {m} 正好出现了m次 12345$ egrep &quot;^ab*c$&quot; file # 以a开头 c结尾 中间是有b或者没有b 长度不限的字符串$ egrep &quot;^ab?c$&quot; file # 以a开头 c结尾 中间只出现一次b或者没有b的字符串$ egrep &quot;^ab+c$&quot; file # 以a开头 c结尾 中间是有b且至少出现一次 长度不限的字符串$ egrep &quot;^ab&#123;2,4&#125;c$&quot; file # 以a开头 c结尾 中间是有b且至少出现两次最多出现四次 长度不限的字符串$ egrep &quot;^ab&#123;3&#125;c$&quot; file # 以a开头 c结尾 中间是有b且正好出现三次的字符串 posix字符 posix字符一次只匹配一个范围中的一个字节 POSIX字符 说明 [:alnum:] 匹配任意字母字符0-9 a-z A-Z [:alpha:] 匹配任意字母，大写或小写 [:digit:] 数字 0-9 [:graph:] 非空字符( 非空格控制字符) [:lower:] 小写字符a-z [:upper:] 大写字符A-Z [:cntrl:] 控制字符 [:print:] 非空字符( 包括空格) [:punct:] 标点符号 [:blank:] 空格和TAB字符 [:xdigit:] 16 进制数字 [:space:] 所有空白字符( 新行、空格、制表符) 注意[[ ]]双中括号的意思: 第一个中括号是匹配符[]匹配中括号中的任意一个字符，第二个[]是格式 如[:digit:]。 12$ egrep &quot;^a[[:alnum:]]c$&quot; file # 以a开头c结尾 中间a-zA-Z0-9任意字符 长度为三个字节的字符串$ egrep &quot;^a[[:blank:]]c$&quot; file # 以a开头c结尾 中间是空格或者TAB符字符 长度为三个字节的字符串 案例：ip匹配 1egrep &#x27;(^([1-9]|1[0-9]|1[1-9]&#123;2&#125;|2[0-4][0-9]|25[0-5])\\.)(([0-9]|1[0-9]|1[1-9]&#123;2&#125;|2[0-4][0-9]|25[0-5])\\.)&#123;2&#125;([1-9]|1[0-9]|1[1-9]&#123;2&#125;|2[0-5][0-9]|25[0-4])$&#x27; -- color ip.txt","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"http://wht6.github.io/tags/Shell/"}]},{"title":"理解Docker的文件系统","slug":"理解Docker的文件系统","date":"2022-03-20T08:00:00.000Z","updated":"2022-03-26T13:10:00.419Z","comments":true,"path":"posts/6635.html","link":"","permalink":"http://wht6.github.io/posts/6635.html","excerpt":"","text":"01|Docker存储镜像存储UnionFS（联合文件系统）是一种分层、轻量级并且高性能的文件系统，它支持将对文件系统的修改作为一次提交操作来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下。overlay2 是目前 Docker 默认的存储驱动，Docker支持选择其他的存储驱动。 文件系统在linux主机上只有两层，一个目录在下层，用来保存镜像（docker），另外一个目录在上层，用来存储容器信息。 镜像不包含任何动态数据，其内容在构建之后也不会被改变。Docker 镜像层次结构： base image：基础镜像 image：固化了一个标准运行环境，镜像本身的功能-封装一组功能性的文件，通过统一的方式，文件格式提供出来（只读） container：容器层（读写） 分层结构是 docker 镜像如此轻量的重要原因。当需要修改容器镜像内的某个文件时，只对处于最上方的读写层（容器层）进行变动，不覆写下层已有文件系统的内容，已有文件在只读层中的原始版本仍然存在，但会被读写层中的新版本所隐藏。当使用 docker commit 提交这个修改过的容器文件系统为一个新的镜像时，保存的内容仅为最上层读写文件系统中被更新过的文件。分层达到了在不的容器同镜像之间共享镜像层的效果。 Dockerfile是由一组指令组成的文件 基础镜像信息（指定操作系统镜像是什么镜像、什么版本) 维护者信息(可选填) 镜像操作指令 容器启动时执行指令（启动容器的时候，执行的脚本/命令参数等等) Dockerfile中的每一条指令都会对应于Docker镜像中的每一层。 如下面的Dockerfile： 1234FROM ubuntu:15.04COPY . /appRUN make /appCMD python /app/app.py 该Dockerfile包含四个命令，每个命令创建一个层。FROM语句是从Ubuntu：15.04镜像开始创建第一个层，COPY命令是从Docker客户端的当前目录添加一些文件，RUN命令使用make命令来构建应用程序，最后一层指定要在容器中运行的命令。 可以使用docker history redis命令查看镜像的所有层，从下往上看是生成的顺序。 镜像为容器提供基础文件系统，容器运行时需要依赖镜像中的内容，一般不允许删除正在已存在容器的底层镜像，除非强制删除。 通过docker image inspect nginx查看镜像的详细内容，里面有一个GraphDriver的关键字指示了镜像是在宿主机上存储的路径。通过docker inspect nginxtest查看容器的详细内容，里面的GraphDriver的关键字指示了容器是在宿主机上存储的路径。 1、rootfs： 基础镜像 2、lower： 下层信息（为镜像层，可读） 3、upper： 上层目录（容器信息,可写） 4、merged： “视图层”（容器视图）（镜像基础文件与容器的修改变化的合并的抽象视图） 5、worker： 运行的工作目录 nginx的LowerDir包含四个目录（diff表示只存储不同），生成顺序也是从下往上，最下面的目录就是nginx的底层linux系统根目录，我们进入该目录，通过ls -i查看文件的inode，然后我们用这个nginx镜像以交互的形式启动一个容器，然后再通过ls -i查看文件的inode，会发现inode一模一样，说明是同一个文件，因为容器的基础文件系统就是镜像提供的。通过docker ps -s可以查看容器实际占用的存储，如果是刚启动的容器，其自身并不占用多少存储空间，因为容器用的是镜像的文件。 virtual size：容器使用的用于只读镜像数据的数据量加上容器的可写镜像层大小。 如果容器要对镜像文件进行修改，该如何进行？这就用到了Docker的Copy on Write（写时复制）。 docker 镜像使用了写时复制(copy-on-write)的策略，在多个容器之间共享镜像，每个容器在启动的时候并不需要单独复制一份镜像文件，而是将所有镜像层以只读的方式挂载到一个挂载点，再在上面覆盖一个可读写的容器层。在未更改文件内容时，所有容器共享同一份数据，只有在 docker 容器运行过程中文件系统发生变化时，才会把变化的文件内容写到可读写层，并隐藏只读层中的老版本文件。写时复制配合分层机制减少了镜像对磁盘空间的占用和容器启动时间。 容器挂载容器挂载的原因：比如，在容器中运行着一个MySQL数据库，由于容器中的数据是动态的，当容器损坏，容器中的数据也会随之丢失，这样就保证不了数据的可靠性。容器挂载可以将容器中的文件挂载到主机上的某个目录，当容器损坏，数据将不受影响。 Docker提供三种方式将数据从宿主机挂载到容器中 volumes：Docker管理宿主机文件系统的一部分（/var/lib/docker/volumes） 保存数据的最佳方式 bind mounts：将宿主机上的任意位置的文件或者目录挂载到容器中， 就像软连接一样 tmpfs：挂载存储在主机系统的内存中，而不会写入主机的文件系统（不常用） 区别： volume ： 是docker的宿主机文件系统一部分，只有docker可以进行更改，其他进程不能修改 bind mounts ： 是挂载在宿主机文件系统的任意位置，除了docker所有进程都可以进行修改 管理卷 123456789docker volume create nginx-vol # 创建一个数据卷 nginx-voldocker volume ls # 查看宿主机数据卷信息 docker volume inspect nginx-vol # 查看 nginx-vol 这个数据卷详细信息ls /var/lib/docker/volumes/nginx-vol/_data # 详细信息中会显示 nginx-vol 这个卷实际在宿主机位置docker rm -f $(docker ps -a |awk &#x27;&#123;print $1&#125;&#x27;) # 删除所有容器 bind mounts手动挂载： -v 宿主机绝对路径:容器目录 1234docker run -d -P --name some-nginx -v /some/content:/usr/share/nginx/html:ro --restart=always nginx# 以只读的方式将容器的/usr/share/nginx/html目录挂载到宿主机的/some/content目录（默认是rw读写）# 使用这种方式需要首先在目录中准备好文件，否则可能会出现空挂载问题，挂载的目录为空，没有程序所必须的文件--restart=always #当Docker重启时，容器自动启动。 volumes自动挂载 -v 卷名称:容器目录 （创建一个匿名卷：-v 容器目录） 12docker run -d -P --name some-nginx -v html:/usr/share/nginx/html:ro --restart=always nginx# 以只读的方式将容器的/usr/share/nginx/html目录自动挂载到宿主机上 怎么查看olumes自动挂载的位置，使用docker inspect命令查看mounts字段。 12# 同时挂载配置文件和html页面docker run -d -P -v nginxconf:/etc/nginx/ -v nginxpage:/usr/share/nginx/html --restart=always nginx","categories":[{"name":"云原生","slug":"云原生","permalink":"http://wht6.github.io/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://wht6.github.io/tags/Docker/"},{"name":"容器","slug":"容器","permalink":"http://wht6.github.io/tags/%E5%AE%B9%E5%99%A8/"}]},{"title":"LVS+Keepalived架构理解","slug":"LVS-Keepalived架构理解","date":"2022-03-19T12:00:00.000Z","updated":"2022-03-20T02:02:34.814Z","comments":true,"path":"posts/8db7.html","link":"","permalink":"http://wht6.github.io/posts/8db7.html","excerpt":"","text":"架构简介在LVS+Keepalived架构中，LVS起到负载均衡的作用，Keepalived保证服务的高可用。LVS按照一定的调度算法，把不同客户端请求转发到不同的后端真实的服务器（RS，Real Server），平衡各个后端服务器的负载。keepalived 为LVS中负载均衡器（LB，LoadBalancer）提供一个冗余备份，当主LB故障时，随时切换到从LB。keepalived 还会对RS做健康检查，发现不健康的 RS，就把它从LVS集群中剔除。&nbsp; Keepalived在此之前，先理解什么是虚拟IP（VIP）。&nbsp; 虚拟IP虚拟IP，就是一个未分配给真实主机的IP，也就是说对外提供服务器的主机除了有一个真实IP外还有一个虚IP，使用这两个IP中的任意一个都可以连接到这台主机。虚拟IP一般用作达到HA(High Availability)的目的,比如让所有项目中数据库链接一项配置的都是这个虚IP，当主服务器发生故障无法对外提供服务时，动态将这个虚IP切换到备用服务器。&nbsp;因为ip地址只是一个逻辑地址，在以太网中MAC地址才是真正用来进行数据传输的物理地址，每台主机中都有一个ARP高速缓存，存储同一个网络内的IP地址与MAC地址的对应关 系，以太网中的主机发送数据时会先从这个缓存中查询目标IP对应的MAC地址，会向这个MAC地址发送数据。操作系统会自动维护这个缓存。&nbsp;虚拟IP实际上就是临时绑定在物理网卡上的别名，如eth0:x ，x为0-255的任意数字，你可以在一块网卡上绑定多个别名。这个VIP可以看作是你上网的QQ网名、昵称、外号等。在实际生产环境中，需要在DNS配置中把网站域名地址解析到这个VIP地址，由这个VIP对用户提供服务。这样做的好处就是当提供服务的服务器宕机以后，在接管的服务器上会直接自动配置上同样的VIP提供服务。&nbsp;Linux系统给网卡配置VIP的方法常见的有两种，即别名IP（alias ip）以及辅助IP（secondary ip address）。ip alias 和 secondary ip address 是两种不同的实现方式，用来在 Linux 系统中给同一个物理网卡增加多个ip地址。提示： heartbeat 和 keepalived 在启动时就是分别利用上面命令来配置VIP的。在停止时利用下面的命令来删除VIP。以上两种方式配置VIP，在高可用环境中的作用是一样的，没什么区别，只是由于当时的系统环境等历史原因，选择的配置命令方式不同。heartbeat3 版本起，不在使用别名，而是使用辅助IP提供服务，而 keepalived 软件一直都是使用的辅助IP技术。注意：别名IP将被遗弃，用辅助IP替代&nbsp; Keepalived原理Keepalived是基于VRRP协议的一款高可用软件。Keepailived有一台主服务器和多台备份服务器，在主服务器和备份服务器上面部署相同的服务配置，使用一个虚拟IP地址对外提供服务，当主服务器出现故障时，虚拟IP地址会自动漂移到备份服务器。&nbsp;VRRP（Virtual Router Redundancy Protocol，虚拟路由器冗余协议），VRRP是为了解决静态路由的高可用。VRRP的基本架构虚拟路由器由多个路由器组成，每个路由器都有各自的IP和共同的VRID(0-255)，其中一个VRRP路由器通过竞选成为MASTER，占有VIP，对外提供路由服务，其他成为BACKUP，MASTER以IP组播（组播地址：224.0.0.18）形式发送VRRP协议包，与BACKUP保持心跳连接，若MASTER不可用（或BACKUP接收不到VRRP协议包），则BACKUP通过竞选产生新的MASTER并继续对外提供路由服务，从而实现高可用。&nbsp;Keepalived起初就是为LVS设计的，因此通常搭配LVS实现高可用。Keepalived的实现就是它自身启动为一个服务，工作在多个LVS主机节点上，当前活动的节点叫做Master，备用节点叫做Backup，Master会不停的向Backup节点通告自己的心跳，这种通告是基于VRRP协议的。Backup节点一旦接收不到Master的通告信息，从Backup中选择一个新的Master，将LVS的VIP和ipvs的规则在该节点上生效，从而替代Master节点。&nbsp;Keepalived启动后以后会有一个主进程Master，它会生成还有2个子进程，一个是VRRP Stack负责VRRP（也就是VRRP协议的实现）、一个是Checkers负责IPVS的后端的应用服务器的健康检查，当检测失败就会调用IPVS规则删除后端服务器的IP地址，检测成功了再加回来。当检测后端有失败的情况可以使用SMTP通知管理员。另外VRRP如果检测到另外一个Keepalive失败也可以通过SMTP通知管理员。&nbsp; LVSLVS概念LVS（Linux Virtual Server）即Linux虚拟服务器，是一个负载均衡项目，目前LVS已被集成到Linux内核模块中，因此性能较高。&nbsp;LVS属于四层负载均衡，不支持七层规则修改，机制庞大，不适合小规模应用。&nbsp;优势：高并发连接：LVS基于内核工作，有超强的承载能力和并发处理能力。单台LVS负载均衡器，可支持上万并发连接。稳定性强：是工作在网络4层之上仅作分发之用，这个特点也决定了它在负载均衡软件里的性能最强，稳定性最好，对内存和cpu资源消耗极低。成本低廉：硬件负载均衡器少则十几万，多则几十万上百万，LVS只需一台服务器和就能免费部署使用，性价比极高。配置简单：LVS配置非常简单，仅需几行命令即可完成配置，也可写成脚本进行管理。支持多种算法：支持多种论调算法，可根据业务场景灵活调配进行使用。支持多种工作模型：可根据业务场景，使用不同的工作模式来解决生产环境请求处理问题。应用范围广：因为LVS工作在4层，所以它几乎可以对所有应用做负载均衡，包括http、数据库、DNS、ftp服务等等。&nbsp;LVS核心组件：管理工具ipvsadm：用户空间的命令行工具，用于管理集群服务及集群服务上的RS等；内核模块ipvs：工作于内核上的程序，可根据用户定义的集群实现请求转发；&nbsp;IPVS是LVS项目重要组成部分，是一款运行在Linux kernel当中的4层负载均衡器，性能异常优秀。IPVS依赖于netfilter框架，位于内核源码的net/netfilter/ipvs目录下。k8s引入了IPVS模式，IPVS模式与iptables同样基于Netfilter，但是采用的hash表，因此当service数量达到一定规模时，hash查表的速度优势就会显现出来，从而提高service的服务性能。&nbsp; LVS的转发模式NAT模式(NAT)：进站和出站的数据流量都要经过负载均衡器。负载均衡器（也叫Director Server）具有公网IP和内网IP，真实服务器只有内网IP。接收到目的地址为VIP的数据包，根据调度算法从后端群集中选择一个RS（real server），将数据包的目标IP地址重写为所选RS的IP地址，然后将数据包转发到RS。当RS处理完请求之后，会把回复数据包返回给LB，此时LB会将数据包的源IP地址重写为自己的IP地址，然后发送给客户端。 RS 应该使用私有地址，RS 的网关必须指向负载均衡器。 优点：集群中的物理服务器可以使用任何支持TCP/IP操作系统，只有负载均衡器需要一个合法的IP地址，并且支持端口映射，可修改请求报文的端口。NAT 模式的优势在于配置及管理简单，由于了使用 NAT 技术，LVS 调度器及应用服务器可以在不同网段中，网络架构更灵活，应用服务器只需要进行简单的网络设定即可加入集群。 缺点：扩展性有限。当服务器节点（普通PC服务器）增长过多时,负载均衡器将成为整个系统的瓶颈。因为所有的请求包和应答包的流向都经过负载均衡器。当服务器节点过多时大量的数据包都交汇在负载均衡器那，速度就会变慢！ &nbsp;直接路由模式(DR) ：只有进站的数据流量经过负载均衡器。LB（LoadBalancer）接收到目的地址为VIP的数据包，根据调度算法从后端群集中选择一个RS（real server），将所选RS的MAC地址封装到数据包上，将数据包转发给RS。当RS处理完请求之后，会直接发送给客户端。这里LB和RS都使用同一个VIP对外服务但只有LB对ARP请求进行响应，网关会把对这个VIP的请求全部定向给LB，LB再将请求分发给RS。处理完成之后，由于IP一致，则等于直接从客户端收到这个数据包无异，可以直接将数据返给客户。限制：由于负载均衡器要对二层包头进行改换,所以负载均衡器和RS之间必须在一个广播域，也可以简单的理解为在同一台交换机上。 保证前端路由将目标地址为 VIP 报文统统发给LB，而不是 RS。实现方案：修改 RS 上内核参数（arp_ignore 和 arp_announce）将 RS 上的 VIP 配置在 lo 接口的别名上，并限制其不能响应对 VIP 地址解析请求。 RS 可以使用私有地址；也可以是公网地址，如果使用公网地址，此时可以通过互联网对 RIP 进行直接访问。 RS 的网关绝不允许指向LB。 优点：和TUN（隧道模式）一样，负载均衡器也只是分发请求，应答包通过单独的路由方法返回给客户端，但是与TUN相比，DR这种实现方式不需要隧道结构，因此可以使用大多数操作系统做为物理服务器。 缺点：RS节点需要合法IP，要求负载均衡器的网卡必须与物理网卡在一个物理段上。 &nbsp;隧道模式(TUN)：只有进站的数据流量经过负载均衡器。接收到目的地址为VIP的数据包，根据调度算法从后端群集中选择一个RS（real server），将所选RS的IP地址封装到数据包上，将数据包转发给RS。RS收到后，先把数据包的头解开，还原数据包，处理后，会直接发送给客户端。注意，由于RS需要对负载均衡器发过来的数据包进行还原,所以说必须支持IPTUNNEL协议，所以,在RS的内核中,必须编译支持IPTUNNEL这个选项。 后端服务器地址、网关地址、负载均衡器地址全是公网地址。 RS 的网关不会也不可能指向LB 优点：负载均衡器只负责将请求包分发给后端节点服务器，而RS将应答包直接发给用户。所以，减少了负载均衡器的大量数据流动，负载均衡器不再是系统的瓶颈，就能处理很巨大的请求量。这种方式，一台负载均衡器能够为很多RS进行分发。而且跑在公网上就能进行不同地域的分发。 缺点：隧道模式的RS节点需要合法IP，需要所有的服务器支持”IP Tunneling”(IP Encapsulation)协议，服务器可能只局限在部分Linux系统上。","categories":[{"name":"运维","slug":"运维","permalink":"http://wht6.github.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"负载均衡","slug":"负载均衡","permalink":"http://wht6.github.io/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"name":"高可用","slug":"高可用","permalink":"http://wht6.github.io/tags/%E9%AB%98%E5%8F%AF%E7%94%A8/"}]},{"title":"程序性能分析基础","slug":"程序性能分析基础","date":"2022-03-19T02:00:00.000Z","updated":"2022-03-20T02:02:26.382Z","comments":true,"path":"posts/bb96.html","link":"","permalink":"http://wht6.github.io/posts/bb96.html","excerpt":"","text":"Go 语言为程序开发者们提供了丰富的性能分析 API，和非常好用的标准工具。这些 API 主要存在于： runtime/pprof； net/http/pprof； runtime/trace； 这三个代码包中。 &nbsp; 另外，runtime代码包中还包含了一些更底层的 API。它们可以被用来收集或输出 Go 程序运行过程中的一些关键指标，并帮助我们生成相应的概要文件以供后续分析时使用。&nbsp;至于标准工具，主要有go tool pprof和go tool trace这两个。它们可以解析概要文件中的信息，并以人类易读的方式把这些信息展示出来。&nbsp;此外，go test命令也可以在程序测试完成后生成概要文件。如此一来，我们就可以很方便地使用前面那两个工具读取概要文件，并对被测程序的性能加以分析。这无疑会让程序性能测试的一手资料更加丰富，结果更加精确和可信。&nbsp;在 Go 语言中，用于分析程序性能的概要文件有三种，分别是：CPU 概要文件（CPU Profile）、内存概要文件（Mem Profile）和阻塞概要文件（Block Profile）。&nbsp;这些概要文件中包含的都是：在某一段时间内，对 Go 程序的相关指标进行多次采样后得到的概要信息。&nbsp;对于 CPU 概要文件来说，其中的每一段独立的概要信息都记录着，在进行某一次采样的那个时刻，CPU 上正在执行的 Go 代码。&nbsp;而对于内存概要文件，其中的每一段概要信息都记载着，在某个采样时刻，正在执行的 Go 代码以及堆内存的使用情况，这里包含已分配和已释放的字节数量和对象数量。至于阻塞概要文件，其中的每一段概要信息，都代表着 Go 程序中的一个 goroutine 阻塞事件。&nbsp;注意，在默认情况下，这些概要文件中的信息并不是普通的文本，它们都是以二进制的形式展现的。如果你使用一个常规的文本编辑器查看它们的话，那么肯定会看到一堆“乱码”。&nbsp;这时就可以显现出go tool pprof这个工具的作用了。我们可以通过它进入一个基于命令行的交互式界面，并对指定的概要文件进行查阅。就像下面这样： 123456$ go tool pprof cpuprofile.outType: cpuTime: Nov 9, 2018 at 4:31pm (CST)Duration: 7.96s, Total samples = 6.88s (86.38%)Entering interactive mode (type &quot;help&quot; for commands, &quot;o&quot; for options)(pprof) 关于这个工具的具体用法，我就不在这里赘述了。在进入这个工具的交互式界面之后，我们只要输入指令help并按下回车键，就可以看到很详细的帮助文档。&nbsp;我们现在来说说怎样生成概要文件。&nbsp;你可能会问，既然在概要文件中的信息不是普通的文本，那么它们到底是什么格式的呢？一个对广大的程序开发者而言，并不那么重要的事实是，它们是通过 protocol buffers 生成的二进制数据流，或者说字节流。&nbsp;概括来讲，protocol buffers 是一种数据序列化协议，同时也是一个序列化工具。它可以把一个值，比如一个结构体或者一个字典，转换成一段字节流。&nbsp;也可以反过来，把经过它生成的字节流反向转换为程序中的一个值。前者就被叫做序列化，而后者则被称为反序列化。&nbsp;换句话说，protocol buffers 定义和实现了一种“可以让数据在结构形态和扁平形态之间互相转换”的方式。&nbsp;Protocol buffers 的优势有不少。比如，它可以在序列化数据的同时对数据进行压缩，所以它生成的字节流，通常都要比相同数据的其他格式（例如 XML 和 JSON）占用的空间明显小很多。&nbsp;又比如，它既能让我们自己去定义数据序列化和结构化的格式，也允许我们在保证向后兼容的前提下去更新这种格式。&nbsp;正因为这些优势，Go 语言从 1.8 版本开始，把所有 profile 相关的信息生成工作都交给 protocol buffers 来做了。这也是我们在上述概要文件中，看不到普通文本的根本原因了。&nbsp;Protocol buffers 的用途非常广泛，并且在诸如数据存储、数据传输等任务中有着很高的使用率。&nbsp;怎样让程序对 CPU 概要信息进行采样？&nbsp;这需要用到runtime/pprof包中的 API。更具体地说，在我们想让程序开始对 CPU 概要信息进行采样的时候，需要调用这个代码包中的StartCPUProfile函数，而在停止采样的时候则需要调用该包中的StopCPUProfile函数。&nbsp;runtime/pprof.StartCPUProfile函数（以下简称StartCPUProfile函数）在被调用的时候，先会去设定 CPU 概要信息的采样频率，并会在单独的 goroutine 中进行 CPU 概要信息的收集和输出。&nbsp;注意，StartCPUProfile函数设定的采样频率总是固定的，即：100赫兹。也就是说，每秒采样100次，或者说每10毫秒采样一次。&nbsp;赫兹，也称 Hz，是从英文单词“Hertz”（一个英文姓氏）音译过来的一个中文词。它是 CPU 主频的基本单位。&nbsp;CPU 的主频指的是，CPU 内核工作的时钟频率，也常被称为 CPU clock speed。这个时钟频率的倒数即为时钟周期（clock cycle），也就是一个 CPU 内核执行一条运算指令所需的时间，单位是秒。&nbsp;例如，主频为1000Hz 的 CPU，它的单个内核执行一条运算指令所需的时间为0.001秒，即1毫秒。又例如，我们现在常用的3.2GHz 的多核 CPU，其单个内核在1个纳秒的时间里就可以至少执行三条运算指令。&nbsp;StartCPUProfile函数设定的 CPU 概要信息采样频率，相对于现代的 CPU 主频来说是非常低的。这主要有两个方面的原因。&nbsp;一方面，过高的采样频率会对 Go 程序的运行效率造成很明显的负面影响。因此，runtime包中SetCPUProfileRate函数在被调用的时候，会保证采样频率不超过1MHz（兆赫），也就是说，它只允许每1微秒最多采样一次。StartCPUProfile函数正是通过调用这个函数来设定 CPU 概要信息的采样频率的。&nbsp;另一方面，经过大量的实验，Go 语言团队发现100Hz 是一个比较合适的设定。因为这样做既可以得到足够多、足够有用的概要信息，又不至于让程序的运行出现停滞。另外，操作系统对高频采样的处理能力也是有限的，一般情况下，超过500Hz 就很可能得不到及时的响应了。&nbsp;在StartCPUProfile函数执行之后，一个新启用的 goroutine 将会负责执行 CPU 概要信息的收集和输出，直到runtime/pprof包中的StopCPUProfile函数被成功调用。&nbsp;StopCPUProfile函数也会调用runtime.SetCPUProfileRate函数，并把参数值（也就是采样频率）设为0。这会让针对 CPU 概要信息的采样工作停止。&nbsp;同时，它也会给负责收集 CPU 概要信息的代码一个“信号”，以告知收集工作也需要停止了。&nbsp;在接到这样的“信号”之后，那部分程序将会把这段时间内收集到的所有 CPU 概要信息，全部写入到我们在调用StartCPUProfile函数的时候指定的写入器中。只有在上述操作全部完成之后，StopCPUProfile函数才会返回。&nbsp;怎样设定内存概要信息的采样频率？&nbsp;针对内存概要信息的采样会按照一定比例收集 Go 程序在运行期间的堆内存使用情况。设定内存概要信息采样频率的方法很简单，只要为runtime.MemProfileRate变量赋值即可。&nbsp;这个变量的含义是，平均每分配多少个字节，就对堆内存的使用情况进行一次采样。如果把该变量的值设为0，那么，Go 语言运行时系统就会完全停止对内存概要信息的采样。该变量的缺省值是512 KB，也就是512千字节。&nbsp;注意，如果你要设定这个采样频率，那么越早设定越好，并且只应该设定一次，否则就可能会对 Go 语言运行时系统的采样工作，造成不良影响。比如，只在main函数的开始处设定一次。&nbsp;在这之后，当我们想获取内存概要信息的时候，还需要调用runtime/pprof包中的WriteHeapProfile函数。该函数会把收集好的内存概要信息，写到我们指定的写入器中。&nbsp;注意，我们通过WriteHeapProfile函数得到的内存概要信息并不是实时的，它是一个快照，是在最近一次的内存垃圾收集工作完成时产生的。如果你想要实时的信息，那么可以调用runtime.ReadMemStats函数。不过要特别注意，该函数会引起 Go 语言调度器的短暂停顿。&nbsp;怎样获取到阻塞概要信息？&nbsp;我们调用runtime包中的SetBlockProfileRate函数，即可对阻塞概要信息的采样频率进行设定。该函数有一个名叫rate的参数，它是int类型的。&nbsp;这个参数的含义是，只要发现一个阻塞事件的持续时间达到了多少个纳秒，就可以对其进行采样。如果这个参数的值小于或等于0，那么就意味着 Go 语言运行时系统将会完全停止对阻塞概要信息的采样。&nbsp;在runtime包中，还有一个名叫blockprofilerate的包级私有变量，它是uint64类型的。这个变量的含义是，只要发现一个阻塞事件的持续时间跨越了多少个 CPU 时钟周期，就可以对其进行采样。它的含义与我们刚刚提到的rate参数的含义非常相似，不是吗？&nbsp;实际上，这两者的区别仅仅在于单位不同。runtime.SetBlockProfileRate函数会先对参数rate的值进行单位换算和必要的类型转换，然后，它会把换算结果用原子操作赋给blockprofilerate变量。由于此变量的缺省值是0，所以 Go 语言运行时系统在默认情况下并不会记录任何在程序中发生的阻塞事件。&nbsp;另一方面，当我们需要获取阻塞概要信息的时候，需要先调用runtime/pprof包中的Lookup函数并传入参数值&quot;block&quot;，从而得到一个*runtime/pprof.Profile类型的值（以下简称Profile值）。在这之后，我们还需要调用这个Profile值的WriteTo方法，以驱使它把概要信息写进我们指定的写入器中。&nbsp;这个WriteTo方法有两个参数，一个参数就是我们刚刚提到的写入器，它是io.Writer类型的。而另一个参数则是代表了概要信息详细程度的int类型参数debug。&nbsp;debug参数主要的可选值有两个，即：0和1。当debug的值为0时，通过WriteTo方法写进写入器的概要信息仅会包含go tool pprof工具所需的内存地址，这些内存地址会以十六进制的形式展现出来。&nbsp;当该值为1时，相应的包名、函数名、源码文件路径、代码行号等信息就都会作为注释被加入进去。另外，debug为0时的概要信息，会经由 protocol buffers 转换为字节流。而在debug为1的时候，WriteTo方法输出的这些概要信息就是我们可以读懂的普通文本了。&nbsp;除此之外，debug的值也可以是2。这时，被输出的概要信息也会是普通的文本，并且通常会包含更多的细节。至于这些细节都包含了哪些内容，那就要看我们调用runtime/pprof.Lookup函数的时候传入的是什么样的参数值了。&nbsp;runtime/pprof.Lookup函数的正确调用方式是什么？&nbsp;runtime/pprof.Lookup函数（以下简称Lookup函数）的功能是，提供与给定的名称相对应的概要信息。这个概要信息会由一个Profile值代表。如果该函数返回了一个nil，那么就说明不存在与给定名称对应的概要信息。&nbsp;runtime/pprof包已经为我们预先定义了 6 个概要名称。它们对应的概要信息收集方法和输出方法也都已经准备好了。我们直接拿来使用就可以了。它们是：goroutine、heap、allocs、threadcreate、block和mutex。&nbsp;当我们把&quot;goroutine&quot;传入Lookup函数的时候，该函数会利用相应的方法，收集到当前正在使用的所有 goroutine 的堆栈跟踪信息。注意，这样的收集会引起 Go 语言调度器的短暂停顿。&nbsp;当调用该函数返回的Profile值的WriteTo方法时，如果参数debug的值大于或等于2，那么该方法就会输出所有 goroutine 的堆栈跟踪信息。这些信息可能会非常多。如果它们占用的空间超过了64 MB（也就是64兆字节），那么相应的方法就会将超出的部分截掉。&nbsp;如果Lookup函数接到的参数值是&quot;heap&quot;，那么它就会收集与堆内存的分配和释放有关的采样信息。这实际上就是我们在前面讨论过的内存概要信息。在我们传入&quot;allocs&quot;的时候，后续的操作会与之非常的相似。&nbsp;在这两种情况下，Lookup函数返回的Profile值也会极其相像。只不过，在这两种Profile值的WriteTo方法被调用时，它们输出的概要信息会有细微的差别，而且这仅仅体现在参数debug等于0的时候。&nbsp;&quot;heap&quot;会使得被输出的内存概要信息默认以“在用空间”（inuse_space）的视角呈现，而&quot;allocs&quot;对应的默认视角则是“已分配空间”（alloc_space）。&nbsp;“在用空间”是指，已经被分配但还未被释放的内存空间。在这个视角下，go tool pprof工具并不会去理会与已释放空间有关的那部分信息。而在“已分配空间”的视角下，所有的内存分配信息都会被展现出来，无论这些内存空间在采样时是否已被释放。&nbsp;此外，无论是&quot;heap&quot;还是&quot;allocs&quot;，在我们调用Profile值的WriteTo方法的时候，只要赋予debug参数的值大于0，那么该方法输出内容的规格就会是相同的。&nbsp;参数值&quot;threadcreate&quot;会使Lookup函数去收集一些堆栈跟踪信息。这些堆栈跟踪信息中的每一个都会描绘出一个代码调用链，这些调用链上的代码都导致新的操作系统线程产生。这样的Profile值的输出规格也只有两种，取决于我们传给其WriteTo方法的参数值是否大于0。&nbsp;再说&quot;block&quot;和&quot;mutex&quot;。&quot;block&quot;代表的是，因争用同步原语而被阻塞的那些代码的堆栈跟踪信息。还记得吗？这就是我们在前面讲过的阻塞概要信息。&nbsp;与之相对应，&quot;mutex&quot;代表的是，曾经作为同步原语持有者的那些代码，它们的堆栈跟踪信息。它们的输出规格也都只有两种，取决于debug是否大于0。&nbsp;这里所说的同步原语，指的是存在于 Go 语言运行时系统内部的一种底层的同步工具，或者说一种同步机制。&nbsp;它是直接面向内存地址的，并以异步信号量和原子操作作为实现手段。我们已经熟知的通道、互斥锁、条件变量、WaitGroup，以及 Go 语言运行时系统本身，都会利用它来实现自己的功能。 如何为基于 HTTP 协议的网络服务添加性能分析接口？&nbsp;这个问题说起来还是很简单的。这是因为我们在一般情况下只要在程序中导入net/http/pprof代码包就可以了，就像这样： 1import _ &quot;net/http/pprof&quot; 然后，启动网络服务并开始监听，比如： 1log.Println(http.ListenAndServe(&quot;localhost:8082&quot;, nil)) 在运行这个程序之后，我们就可以通过在网络浏览器中访问http://localhost:8082/debug/pprof这个地址看到一个简约的网页。如果你认真地看了上一个问题的话，那么肯定可以快速搞明白这个网页中各个部分的含义。&nbsp;在/debug/pprof/这个 URL 路径下还有很多可用的子路径，这一点你通过点选网页中的链接就可以了解到。像allocs、block、goroutine、heap、mutex、threadcreate这 6 个子路径，在底层其实都是通过Lookup函数来处理的。关于这个函数，你应该已经很熟悉了。&nbsp;这些子路径都可以接受查询参数debug。它用于控制概要信息的格式和详细程度。至于它的可选值，我就不再赘述了。它的缺省值是0。另外，还有一个名叫gc的查询参数。它用于控制是否在获取概要信息之前强制地执行一次垃圾回收。只要它的值大于0，程序就会这样做。不过，这个参数仅在/debug/pprof/heap路径下有效。&nbsp;一旦/debug/pprof/profile路径被访问，程序就会去执行对 CPU 概要信息的采样。它接受一个名为seconds的查询参数。该参数的含义是，采样工作需要持续多少秒。如果这个参数未被显式地指定，那么采样工作会持续30秒。注意，在这个路径下，程序只会响应经 protocol buffers 转换的字节流。我们可以通过go tool pprof工具直接读取这样的 HTTP 响应，例如： 1go tool pprof http://localhost:6060/debug/pprof/profile?seconds=60 除此之外，还有一个值得我们关注的路径，即：/debug/pprof/trace。在这个路径下，程序主要会利用runtime/trace代码包中的 API 来处理我们的请求。&nbsp;更具体地说，程序会先调用trace.Start函数，然后在查询参数seconds指定的持续时间之后再调用trace.Stop函数。这里的seconds的缺省值是1秒。&nbsp;前面说的这些 URL 路径都是固定不变的。这是默认情况下的访问规则。我们还可以对它们进行定制，就像这样： 1234567891011121314151617181920mux := http.NewServeMux()pathPrefix := &quot;/d/pprof/&quot;mux.HandleFunc(pathPrefix, func(w http.ResponseWriter, r *http.Request) &#123; name := strings.TrimPrefix(r.URL.Path, pathPrefix) if name != &quot;&quot; &#123; pprof.Handler(name).ServeHTTP(w, r) return &#125; pprof.Index(w, r) &#125;)mux.HandleFunc(pathPrefix+&quot;cmdline&quot;, pprof.Cmdline)mux.HandleFunc(pathPrefix+&quot;profile&quot;, pprof.Profile)mux.HandleFunc(pathPrefix+&quot;symbol&quot;, pprof.Symbol)mux.HandleFunc(pathPrefix+&quot;trace&quot;, pprof.Trace) server := http.Server&#123; Addr: &quot;localhost:8083&quot;, Handler: mux,&#125; 可以看到，我们几乎只使用了net/http/pprof代码包中的几个程序实体，就完成了这样的定制。这在我们使用第三方的网络服务开发框架时尤其有用。&nbsp;我们自定义的 HTTP 请求多路复用器mux所包含的访问规则与默认的规则很相似，只不过 URL 路径的前缀更短了一些而已。&nbsp;我们定制mux的过程与net/http/pprof包中的init函数所做的事情也是类似的。这个init函数的存在，其实就是我们在前面仅仅导入net/http/pprof代码包就能够访问相关路径的原因。&nbsp;在我们编写网络服务程序的时候，使用net/http/pprof包要比直接使用runtime/pprof包方便和实用很多。通过合理运用，这个代码包可以为网络服务的监测提供有力的支撑。&nbsp;runtime/trace代码包的功用是什么？&nbsp;简单来说，这个代码包是用来帮助 Go 程序实现内部跟踪操作的。其中的程序实体可以帮助我们记录程序中各个 goroutine 的状态、各种系统调用的状态，与 GC 有关的各种事件，以及内存相关和 CPU 相关的变化，等等。&nbsp;通过它们生成的跟踪记录可以通过go tool trace命令来查看。更具体的说明可以参看runtime/trace代码包的文档。&nbsp;有了runtime/trace代码包，我们就可以为 Go 程序加装上可以满足个性化需求的跟踪器了。Go 语言标准库中有的代码包正是通过使用该包实现了自身的功能，例如net/http/pprof包。&nbsp; &nbsp;参考链接：https://time.geekbang.org/column/intro/112","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Go语言","slug":"Go语言","permalink":"http://wht6.github.io/tags/Go%E8%AF%AD%E8%A8%80/"}]},{"title":"访问网络服务","slug":"访问网络服务","date":"2022-03-18T10:00:00.000Z","updated":"2022-03-20T02:01:58.390Z","comments":true,"path":"posts/235e.html","link":"","permalink":"http://wht6.github.io/posts/235e.html","excerpt":"","text":"socket 与 IPC人们常常会使用 Go 语言去编写网络程序（当然了，这方面也是 Go 语言最为擅长的事情）。说到网络编程，我们就不得不提及 socket。 &nbsp; socket，常被翻译为套接字，它应该算是网络编程世界中最为核心的知识之一了。关于 socket，我们可以讨论的东西太多了，因此，在这里只围绕着 Go 语言向你介绍一些关于它的基础知识。&nbsp;所谓 socket，是一种 IPC 方法。IPC 是 Inter-Process Communication 的缩写，可以被翻译为进程间通信。顾名思义，IPC 这个概念（或者说规范）主要定义的是多个进程之间，相互通信的方法。&nbsp;这些方法主要包括：系统信号（signal）、管道（pipe）、套接字 （socket）、文件锁（file lock）、消息队列（message queue）、信号灯（semaphore，有的地方也称之为信号量）等。现存的主流操作系统大都对 IPC 提供了强有力的支持，尤其是 socket。&nbsp;你可能已经知道，Go 语言对 IPC 也提供了一定的支持。&nbsp;比如，在os代码包和os/signal代码包中就有针对系统信号的 API。&nbsp;又比如，os.Pipe函数可以创建命名管道，而os/exec代码包则对另一类管道（匿名管道）提供了支持。对于 socket，Go 语言与之相应的程序实体都在其标准库的net代码包中。&nbsp;毫不夸张地说，在众多的 IPC 方法中，socket 是最为通用和灵活的一种。与其他的 IPC 方法不同，利用 socket 进行通信的进程，可以不局限在同一台计算机当中。&nbsp;实际上，通信的双方无论存在于世界上的哪个角落，只要能够通过计算机的网卡端口以及网络进行互联，就可以使用 socket。&nbsp;支持 socket 的操作系统一般都会对外提供一套 API。跑在它们之上的应用程序利用这套 API，就可以与互联网上的另一台计算机中的程序、同一台计算机中的其他程序，甚至同一个程序中的其他线程进行通信。&nbsp;例如，在 Linux 操作系统中，用于创建 socket 实例的 API，就是由一个名为socket的系统调用代表的。这个系统调用是 Linux 内核的一部分。 所谓的系统调用，你可以理解为特殊的 C 语言函数。它们是连接应用程序和操作系统内核的桥梁，也是应用程序使用操作系统功能的唯一渠道。 &nbsp;在 Go 语言标准库的syscall代码包中，有一个与这个socket系统调用相对应的函数。这两者的函数签名是基本一致的，它们都会接受三个int类型的参数，并会返回一个可以代表文件描述符的结果。&nbsp;但不同的是，syscall包中的Socket函数本身是平台不相关的。在其底层，Go 语言为它支持的每个操作系统都做了适配，这才使得这个函数无论在哪个平台上，总是有效的。&nbsp;Go 语言的net代码包中的很多程序实体，都会直接或间接地使用到syscall.Socket函数。&nbsp;比如，我们在调用net.Dial函数的时候，会为它的两个参数设定值。其中的第一个参数名为network，它决定着 Go 程序在底层会创建什么样的 socket 实例，并使用什么样的协议与其他程序通信。&nbsp;net.Dial函数的第一个参数network有哪些可选值？&nbsp;net.Dial函数会接受两个参数，分别名为network和address，都是string类型的。&nbsp;参数network常用的可选值一共有 9 个。这些值分别代表了程序底层创建的 socket 实例可使用的不同通信协议，罗列如下。 &quot;tcp&quot;：代表 TCP 协议，其基于的 IP 协议的版本根据参数address的值自适应。 &quot;tcp4&quot;：代表基于 IP 协议第四版的 TCP 协议。 &quot;tcp6&quot;：代表基于 IP 协议第六版的 TCP 协议。 &quot;udp&quot;：代表 UDP 协议，其基于的 IP 协议的版本根据参数address的值自适应。 &quot;udp4&quot;：代表基于 IP 协议第四版的 UDP 协议。 &quot;udp6&quot;：代表基于 IP 协议第六版的 UDP 协议。 &quot;unix&quot;：代表 Unix 通信域下的一种内部 socket 协议，以 SOCK_STREAM 为 socket 类型。 &quot;unixgram&quot;：代表 Unix 通信域下的一种内部 socket 协议，以 SOCK_DGRAM 为 socket 类型。 &quot;unixpacket&quot;：代表 Unix 通信域下的一种内部 socket 协议，以 SOCK_SEQPACKET 为 socket 类型。 为了更好地理解这些可选值的深层含义，我们需要了解一下syscall.Socket函数接受的那三个参数。&nbsp;我在前面说了，这个函数接受的三个参数都是int类型的。这些参数所代表的分别是想要创建的 socket 实例通信域、类型以及使用的协议。&nbsp;Socket 的通信域主要有这样几个可选项：IPv4 域、IPv6 域和 Unix 域。&nbsp;Unix 域，指的是一种类 Unix 操作系统中特有的通信域。在装有此类操作系统的同一台计算机中，应用程序可以基于此域建立 socket 连接。&nbsp;以上三种通信域分别可以由syscall代码包中的常量AF_INET、AF_INET6和AF_UNIX表示。&nbsp;Socket 的类型一共有 4 种，分别是：SOCK_DGRAM、SOCK_STREAM、SOCK_SEQPACKET以及SOCK_RAW。syscall代码包中也都有同名的常量与之对应。前两者更加常用一些。&nbsp;SOCK_DGRAM中的“DGRAM”代表的是 datagram，即数据报文。它是一种有消息边界，但没有逻辑连接的非可靠 socket 类型，我们熟知的基于 UDP 协议的网络通信就属于此类。&nbsp;有消息边界的意思是，与 socket 相关的操作系统内核中的程序（以下简称内核程序）在发送或接收数据的时候是以消息为单位的。&nbsp;你可以把消息理解为带有固定边界的一段数据。内核程序可以自动地识别和维护这种边界，并在必要的时候，把数据切割成一个一个的消息，或者把多个消息串接成连续的数据。如此一来，应用程序只需要面向消息进行处理就可以了。&nbsp;所谓的有逻辑连接是指，通信双方在收发数据之前必须先建立网络连接。待连接建立好之后，双方就可以一对一地进行数据传输了。显然，基于 UDP 协议的网络通信并不需要这样，它是没有逻辑连接的。&nbsp;只要应用程序指定好对方的网络地址，内核程序就可以立即把数据报文发送出去。这有优势，也有劣势。&nbsp;优势是发送速度快，不长期占用网络资源，并且每次发送都可以指定不同的网络地址。但是，无法保证传输的可靠性，不能实现数据的有序性，以及数据只能单向进行传输。&nbsp;而SOCK_STREAM这个 socket 类型，恰恰与SOCK_DGRAM相反。它没有消息边界，但有逻辑连接，能够保证传输的可靠性和数据的有序性，同时还可以实现数据的双向传输。众所周知的基于 TCP 协议的网络通信就属于此类。 这样的网络通信传输数据的形式是字节流，而不是数据报文。字节流是以字节为单位的。内核程序无法感知一段字节流中包含了多少个消息，以及这些消息是否完整，这完全需要应用程序自己去把控。 不过，此类网络通信中的一端，总是会忠实地按照另一端发送数据时的字节排列顺序，接收和缓存它们。所以，应用程序需要根据双方的约定去数据中查找消息边界，并按照边界切割数据，仅此而已。 &nbsp;syscall.Socket函数的第三个参数用于表示 socket 实例所使用的协议。&nbsp;通常，只要明确指定了前两个参数的值，我们就无需再去确定第三个参数值了，一般把它置为0就可以了。这时，内核程序会自行选择最合适的协议。&nbsp;比如，当前两个参数值分别为syscall.AF_INET和syscall.SOCK_DGRAM的时候，内核程序会选择 UDP 作为协议。&nbsp;又比如，在前两个参数值分别为syscall.AF_INET6和syscall.SOCK_STREAM时，内核程序可能会选择 TCP 作为协议。 不过，你也看到了，在使用net包中的高层次 API 的时候，我们连那前两个参数值都无需给定，只需要把前面罗列的那些字符串字面量的其中一个，作为network参数的值就好了。&nbsp;调用net.DialTimeout函数时给定的超时时间意味着什么？&nbsp;简单来说，这里的超时时间，代表着函数为网络连接建立完成而等待的最长时间。这是一个相对的时间。它会由这个函数的参数timeout的值表示。&nbsp;开始的时间点几乎是我们调用net.DialTimeout函数的那一刻。在这之后，时间会主要花费在“解析参数network和address的值”，以及“创建 socket 实例并建立网络连接”这两件事情上。&nbsp;不论执行到哪一步，只要在绝对的超时时间达到的那一刻，网络连接还没有建立完成，该函数就会返回一个代表了 I/O 操作超时的错误值。&nbsp;值得注意的是，在解析address的值的时候，函数会确定网络服务的 IP 地址、端口号等必要信息，并在需要时访问 DNS 服务。&nbsp;另外，如果解析出的 IP 地址有多个，那么函数会串行或并发地尝试建立连接。但无论用什么样的方式尝试，函数总会以最先建立成功的那个连接为准。&nbsp;同时，它还会根据超时前的剩余时间，去设定针对每次连接尝试的超时时间，以便让它们都有适当的时间执行。&nbsp;再多说一点。在net包中还有一个名为Dialer的结构体类型。该类型有一个名叫Timeout的字段，它与上述的timeout参数的含义是完全一致的。实际上，net.DialTimeout函数正是利用了这个类型的值才得以实现功能的。&nbsp;net.Dialer类型值得你好好学习一下，尤其是它的每个字段的功用以及它的DialContext方法。&nbsp;在你调用了net.Dial等函数之后，如果成功就会得到一个代表了网络连接的net.Conn接口类型的值。&nbsp;怎样在net.Conn类型的值上正确地设定针对读操作和写操作的超时时间？&nbsp;net.Conn类型有 3 个可用于设置超时时间的方法，分别是：SetDeadline、SetReadDeadline和SetWriteDeadline。&nbsp;这三个方法的签名是一模一样的，只是名称不同罢了。它们都接受一个time.Time类型的参数，并都会返回一个error类型的结果。其中的SetDeadline方法是用来同时设置读操作超时和写操作超时的。&nbsp;有一点需要特别注意，这三个方法都会针对任何正在进行以及未来将要进行的相应操作进行超时设定。&nbsp;因此，如果你要在一个循环中进行读操作或写操作的话，最好在每次迭代中都进行一次超时设定。&nbsp;否则，靠后的操作就有可能因触达超时时间而直接失败。另外，如果有必要，你应该再次调用它们并传入time.Time类型的零值来表达不再限定超时时间。&nbsp; HTTP协议通信用net.Dial或net.DialTimeout函数来访问基于 HTTP 协议的网络服务是完全没有问题的，因为HTTP 协议是基于 TCP/IP 协议栈的，并且它也是一个面向普通文本的协议。&nbsp;原则上，我们使用任何一个文本编辑器，都可以轻易地写出一个完整的 HTTP 请求报文。只要你搞清楚了请求报文的头部（header）和主体（body）应该包含的内容，这样做就会很容易。所以，在这种情况下，即便直接使用net.Dial函数，你应该也不会感觉到困难。&nbsp;不过，不困难并不意味着很方便。如果我们只是访问基于 HTTP 协议的网络服务的话，那么使用net/http代码包中的程序实体来做，显然会更加便捷。&nbsp;其中，最便捷的是使用http.Get函数。我们在调用它的时候只需要传给它一个 URL 就可以了，比如像下面这样：&nbsp;123456789url1 := &quot;http://google.cn&quot;fmt.Printf(&quot;Send request to %q with method GET ...\\n&quot;, url1)resp1, err := http.Get(url1)if err != nil &#123; fmt.Printf(&quot;request sending error: %v\\n&quot;, err)&#125;defer resp1.Body.Close()line1 := resp1.Proto + &quot; &quot; + resp1.Statusfmt.Printf(&quot;The first line of response:\\n%s\\n&quot;, line1)&nbsp; http.Get函数会返回两个结果值。第一个结果值的类型是*http.Response，它是网络服务给我们传回来的响应内容的结构化表示。 &nbsp;第二个结果值是error类型的，它代表了在创建和发送 HTTP 请求，以及接收和解析 HTTP 响应的过程中可能发生的错误。&nbsp;http.Get函数会在内部使用缺省的 HTTP 客户端，并且调用它的Get方法以完成功能。这个缺省的 HTTP 客户端是由net/http包中的公开变量DefaultClient代表的，其类型是*http.Client。它的基本类型也是可以被拿来使用的，甚至它还是开箱即用的。下面的这两行代码：&nbsp;12var httpClient1 http.Clientresp2, err := httpClient1.Get(url1)&nbsp; 与前面的这一行代码resp1, err := http.Get(url1)是等价的。 &nbsp;http.Client是一个结构体类型，并且它包含的字段都是公开的。之所以该类型的零值仍然可用，是因为它的这些字段要么存在着相应的缺省值，要么其零值直接就可以使用，且代表着特定的含义。&nbsp;http.Client类型中的Transport字段代表着什么？&nbsp;http.Client类型中的Transport字段代表着：向网络服务发送 HTTP 请求，并从网络服务接收 HTTP 响应的操作过程。也就是说，该字段的方法RoundTrip应该实现单次 HTTP 事务（或者说基于 HTTP 协议的单次交互）需要的所有步骤。&nbsp;这个字段是http.RoundTripper接口类型的，它有一个由http.DefaultTransport变量代表的缺省值（以下简称DefaultTransport）。当我们在初始化一个http.Client类型的值（以下简称Client值）的时候，如果没有显式地为该字段赋值，那么这个Client值就会直接使用DefaultTransport。&nbsp;顺便说一下，http.Client类型的Timeout字段，代表的正是前面所说的单次 HTTP 事务的超时时间，它是time.Duration类型的。它的零值是可用的，用于表示没有设置超时时间。&nbsp;下面，我们再通过该字段的缺省值DefaultTransport，来深入地了解一下这个Transport字段。&nbsp;DefaultTransport的实际类型是*http.Transport，后者即为http.RoundTripper接口的默认实现。这个类型是可以被复用的，也推荐被复用，同时，它也是并发安全的。正因为如此，http.Client类型也拥有着同样的特质。&nbsp;http.Transport类型，会在内部使用一个net.Dialer类型的值（以下简称Dialer值），并且，它会把该值的Timeout字段的值，设定为30秒。&nbsp;也就是说，这个Dialer值如果在 30 秒内还没有建立好网络连接，那么就会被判定为操作超时。在DefaultTransport的值被初始化的时候，这样的Dialer值的DialContext方法会被赋给前者的DialContext字段。&nbsp;http.Transport类型还包含了很多其他的字段，其中有一些字段是关于操作超时的。 IdleConnTimeout：含义是空闲的连接在多久之后就应该被关闭。 DefaultTransport会把该字段的值设定为90秒。如果该值为0，那么就表示不关闭空闲的连接。注意，这样很可能会造成资源的泄露。 ResponseHeaderTimeout：含义是，从客户端把请求完全递交给操作系统到从操作系统那里接收到响应报文头的最大时长。DefaultTransport并没有设定该字段的值。 ExpectContinueTimeout：含义是，在客户端递交了请求报文头之后，等待接收第一个响应报文头的最长时间。在客户端想要使用 HTTP 的“POST”方法把一个很大的报文体发送给服务端的时候，它可以先通过发送一个包含了“Expect: 100-continue”的请求报文头，来询问服务端是否愿意接收这个大报文体。这个字段就是用于设定在这种情况下的超时时间的。注意，如果该字段的值不大于0，那么无论多大的请求报文体都将会被立即发送出去。这样可能会造成网络资源的浪费。DefaultTransport把该字段的值设定为了1秒。 TLSHandshakeTimeout：TLS 是 Transport Layer Security 的缩写，可以被翻译为传输层安全。这个字段代表了基于 TLS 协议的连接在被建立时的握手阶段的超时时间。若该值为0，则表示对这个时间不设限。DefaultTransport把该字段的值设定为了10秒。 &nbsp;此外，还有一些与IdleConnTimeout相关的字段值得我们关注，即：MaxIdleConns、MaxIdleConnsPerHost以及MaxConnsPerHost。&nbsp;无论当前的http.Transport类型的值（以下简称Transport值）访问了多少个网络服务，MaxIdleConns字段都只会对空闲连接的总数做出限定。而MaxIdleConnsPerHost字段限定的则是，该Transport值访问的每一个网络服务的最大空闲连接数。&nbsp;每一个网络服务都会有自己的网络地址，可能会使用不同的网络协议，对于一些 HTTP 请求也可能会用到代理。Transport值正是通过这三个方面的具体情况，来鉴别不同的网络服务的。&nbsp;MaxIdleConnsPerHost字段的缺省值，由http.DefaultMaxIdleConnsPerHost变量代表，值为2。也就是说，在默认情况下，对于某一个Transport值访问的每一个网络服务，它的空闲连接数都最多只能有两个。&nbsp;与MaxIdleConnsPerHost字段的含义相似的，是MaxConnsPerHost字段。不过，后者限制的是，针对某一个Transport值访问的每一个网络服务的最大连接数，不论这些连接是否是空闲的。并且，该字段没有相应的缺省值，它的零值表示不对此设限。&nbsp;DefaultTransport并没有显式地为MaxIdleConnsPerHost和MaxConnsPerHost这两个字段赋值，但是它却把MaxIdleConns字段的值设定为了100。&nbsp;换句话说，在默认情况下，空闲连接的总数最大为100，而针对每个网络服务的最大空闲连接数为2。注意，上述两个与空闲连接数有关的字段的值应该是联动的，所以，你有时候需要根据实际情况来定制它们。&nbsp;当然了，这首先需要我们在初始化Client值的时候，定制它的Transport字段的值。定制这个值的方式，可以参看DefaultTransport变量的声明。&nbsp;最后，我简单说一下为什么会出现空闲的连接。我们都知道，HTTP 协议有一个请求报文头叫做“Connection”。在 HTTP 协议的 1.1 版本中，这个报文头的值默认是“keep-alive”。&nbsp;在这种情况下的网络连接都是持久连接，它们会在当前的 HTTP 事务完成后仍然保持着连通性，因此是可以被复用的。&nbsp;既然连接可以被复用，那么就会有两种可能。一种可能是，针对于同一个网络服务，有新的 HTTP 请求被递交，该连接被再次使用。另一种可能是，不再有对该网络服务的 HTTP 请求，该连接被闲置。&nbsp;显然，后一种可能就产生了空闲的连接。另外，如果分配给某一个网络服务的连接过多的话，也可能会导致空闲连接的产生，因为每一个新递交的 HTTP 请求，都只会征用一个空闲的连接。所以，为空闲连接设定限制，在大多数情况下都是很有必要的，也是需要斟酌的。&nbsp;如果我们想彻底地杜绝空闲连接的产生，那么可以在初始化Transport值的时候把它的DisableKeepAlives字段的值设定为true。这时，HTTP 请求的“Connection”报文头的值就会被设置为“close”。这会告诉网络服务，这个网络连接不必保持，当前的 HTTP 事务完成后就可以断开它了。&nbsp;如此一来，每当一个 HTTP 请求被递交时，就都会产生一个新的网络连接。这样做会明显地加重网络服务以及客户端的负载，并会让每个 HTTP 事务都耗费更多的时间。所以，在一般情况下，我们都不要去设置这个DisableKeepAlives字段。&nbsp;顺便说一句，在net.Dialer类型中，也有一个看起来很相似的字段KeepAlive。不过，它与前面所说的 HTTP 持久连接并不是一个概念，KeepAlive是直接作用在底层的 socket 上的。&nbsp;它的背后是一种针对网络连接（更确切地说，是 TCP 连接）的存活探测机制。它的值用于表示每间隔多长时间发送一次探测包。当该值不大于0时，则表示不开启这种机制。DefaultTransport会把这个字段的值设定为30秒。&nbsp;好了，以上这些内容阐述的就是，http.Client类型中的Transport字段的含义，以及它的值的定制方式。这涉及了http.RoundTripper接口、http.DefaultTransport变量、http.Transport类型，以及net.Dialer类型。&nbsp;http.Server类型的ListenAndServe方法都做了哪些事情？&nbsp;http.Server类型与http.Client是相对应的。http.Server代表的是基于 HTTP 协议的服务端，或者说网络服务。&nbsp;http.Server类型的ListenAndServe方法的功能是：监听一个基于 TCP 协议的网络地址，并对接收到的 HTTP 请求进行处理。这个方法会默认开启针对网络连接的存活探测机制，以保证连接是持久的。同时，该方法会一直执行，直到有严重的错误发生或者被外界关掉。当被外界关掉时，它会返回一个由http.ErrServerClosed变量代表的错误值。&nbsp;这个ListenAndServe方法主要会做下面这几件事情。 检查当前的http.Server类型的值（以下简称当前值）的Addr字段。该字段的值代表了当前的网络服务需要使用的网络地址，即：IP 地址和端口号。如果这个字段的值为空字符串，那么就用&quot;:http&quot;代替。也就是说，使用任何可以代表本机的域名和 IP 地址，并且端口号为80。 通过调用net.Listen函数在已确定的网络地址上启动基于 TCP 协议的监听。 检查net.Listen函数返回的错误值。如果该错误值不为nil，那么就直接返回该值。否则，通过调用当前值的Serve方法准备接受和处理将要到来的 HTTP 请求。 &nbsp;可以从当前问题直接衍生出的问题一般有两个，一个是“net.Listen函数都做了哪些事情”，另一个是“http.Server类型的Serve方法是怎样接受和处理 HTTP 请求的”。&nbsp;对于第一个直接的衍生问题，如果概括地说，回答可以是： 解析参数值中包含的网络地址隐含的 IP 地址和端口号； 根据给定的网络协议，确定监听的方法，并开始进行监听。 &nbsp;从这里的第二个步骤出发，我们还可以继续提出一些间接的衍生问题。这往往会涉及net.socket函数以及相关的 socket 知识。&nbsp;对于第二个直接的衍生问题，我们可以这样回答：&nbsp;在一个for循环中，网络监听器的Accept方法会被不断地调用，该方法会返回两个结果值；第一个结果值是net.Conn类型的，它会代表包含了新到来的 HTTP 请求的网络连接；第二个结果值是代表了可能发生的错误的error类型值。&nbsp;如果这个错误值不为nil，除非它代表了一个暂时性的错误，否则循环都会被终止。如果是暂时性的错误，那么循环的下一次迭代将会在一段时间之后开始执行。&nbsp;如果这里的Accept方法没有返回非nil的错误值，那么这里的程序将会先把它的第一个结果值包装成一个*http.conn类型的值（以下简称conn值），然后通过在新的 goroutine 中调用这个conn值的serve方法，来对当前的 HTTP 请求进行处理。&nbsp;这个处理的细节还是很多的，所以我们依然可以找出不少的间接的衍生问题。比如，这个conn值的状态有几种，分别代表着处理的哪个阶段？又比如，处理过程中会用到哪些读取器和写入器，它们的作用分别是什么？再比如，这里的程序是怎样调用我们自定义的处理函数的，等等。&nbsp;怎样优雅地停止基于 HTTP 协议的网络服务程序？&nbsp;net/http.Server类型有一个名为Shutdown的指针方法可以实现“优雅的停止”。也就是说，它可以在不中断任何正处在活动状态的连接的情况下平滑地关闭当前的服务器。&nbsp;它会先关闭所有的空闲连接，并一直等待。只有活动的连接变为空闲之后，它才会关闭它们。当所有的连接都被平滑地关闭之后，它会关闭当前的服务器并返回。当有错误发生时，它还会把相应的错误值返回。&nbsp;另外，你还可以通过调用Server值的RegisterOnShutdown方法来注册可以在服务器即将关闭时被自动调用的函数。&nbsp;更确切地说，当前服务器的Shutdown方法会以异步的方式调用如此注册的所有函数。我们可以利用这样的函数来通知长连接的客户端“连接即将关闭”。&nbsp; &nbsp;参考链接：https://time.geekbang.org/column/intro/112","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Go语言","slug":"Go语言","permalink":"http://wht6.github.io/tags/Go%E8%AF%AD%E8%A8%80/"}]},{"title":"使用os包中的API","slug":"使用os包中的API","date":"2022-03-18T03:00:00.000Z","updated":"2022-03-20T02:01:42.708Z","comments":true,"path":"posts/a29a.html","link":"","permalink":"http://wht6.github.io/posts/a29a.html","excerpt":"","text":"&nbsp; os 包中的 API&nbsp;这个代码包提供的都是平台不相关的 API。那么说，什么叫平台不相关的 API 呢？&nbsp;它的意思是：这些 API 基于（或者说抽象自）操作系统，为我们使用操作系统的功能提供高层次的支持，但是，它们并不依赖于具体的操作系统。&nbsp;不论是 Linux、macOS、Windows，还是 FreeBSD、OpenBSD、Plan9，os代码包都可以为之提供统一的使用接口。这使得我们可以用同样的方式，来操纵不同的操作系统，并得到相似的结果。&nbsp;os包中的 API 主要可以帮助我们使用操作系统中的文件系统、权限系统、环境变量、系统进程以及系统信号。&nbsp;其中，操纵文件系统的 API 最为丰富。我们不但可以利用这些 API 创建和删除文件以及目录，还可以获取到它们的各种信息、修改它们的内容、改变它们的访问权限，等等。&nbsp;说到这里，就不得不提及一个非常常用的数据类型：os.File。&nbsp;从字面上来看，os.File类型代表了操作系统中的文件。但实际上，它可以代表的远不止于此。或许你已经知道，对于类 Unix 的操作系统（包括 Linux、macOS、FreeBSD 等），其中的一切都可以被看做是文件。&nbsp;除了文本文件、二进制文件、压缩文件、目录这些常见的形式之外，还有符号链接、各种物理设备（包括内置或外接的面向块或者字符的设备）、命名管道，以及套接字（也就是 socket），等等。&nbsp;因此，可以说，我们能够利用os.File类型操纵的东西太多了。不过，为了聚焦于os.File本身，同时也为了让本文讲述的内容更加通用，我们在这里主要把os.File类型应用于常规的文件。&nbsp;os.File类型都实现了哪些io包中的接口？&nbsp;os.File类型拥有的都是指针方法，所以除了空接口之外，它本身没有实现任何接口。而它的指针类型则实现了很多io代码包中的接口。&nbsp;首先，对于io包中最核心的 3 个简单接口io.Reader、io.Writer和io.Closer，*os.File类型都实现了它们。&nbsp;其次，该类型还实现了另外的 3 个简单接口，即：io.ReaderAt、io.Seeker和io.WriterAt。&nbsp;正是因为*os.File类型实现了这些简单接口，所以它也顺便实现了io包的 9 个扩展接口中的 7 个。&nbsp;然而，由于它并没有实现简单接口io.ByteReader和io.RuneReader，所以它没有实现分别作为这两者的扩展接口的io.ByteScanner和io.RuneScanner。&nbsp;总之，os.File类型及其指针类型的值，不但可以通过各种方式读取和写入某个文件中的内容，还可以寻找并设定下一次读取或写入时的起始索引位置，另外还可以随时对文件进行关闭。&nbsp;但是，它们并不能专门地读取文件中的下一个字节，或者下一个 Unicode 字符，也不能进行任何的读回退操作。&nbsp;不过，单独读取下一个字节或字符的功能也可以通过其他方式来实现，比如，调用它的Read方法并传入适当的参数值就可以做到这一点。&nbsp;怎样才能获得一个os.File类型的指针值（以下简称File值）。&nbsp;在os包中，有这样几个函数，即：Create、NewFile、Open和OpenFile。&nbsp;os.Create函数用于根据给定的路径创建一个新的文件。 它会返回一个File值和一个错误值。我们可以在该函数返回的File值之上，对相应的文件进行读操作和写操作。&nbsp;不但如此，我们使用这个函数创建的文件，对于操作系统中的所有用户来说，都是可以读和写的。&nbsp;换句话说，一旦这样的文件被创建出来，任何能够登录其所属的操作系统的用户，都可以在任意时刻读取该文件中的内容，或者向该文件写入内容。&nbsp;注意，如果在我们给予os.Create函数的路径之上，已经存在了一个文件，那么该函数会先清空现有文件中的全部内容，然后再把它作为第一个结果值返回。&nbsp;另外，os.Create函数是有可能返回非nil的错误值的。&nbsp;比如，如果我们给定的路径上的某一级父目录并不存在，那么该函数就会返回一个*os.PathError类型的错误值，以表示“不存在的文件或目录”。&nbsp;再来看os.NewFile函数。 该函数在被调用的时候，需要接受一个代表文件描述符的、uintptr类型的值，以及一个用于表示文件名的字符串值。&nbsp;如果我们给定的文件描述符并不是有效的，那么这个函数将会返回nil，否则，它将会返回一个代表了相应文件的File值。&nbsp;注意，不要被这个函数的名称误导了，它的功能并不是创建一个新的文件，而是依据一个已经存在的文件的描述符，来新建一个包装了该文件的File值。&nbsp;例如，我们可以像这样拿到一个包装了标准错误输出的File值：&nbsp;1file3 := os.NewFile(uintptr(syscall.Stderr), &quot;/dev/stderr&quot;)&nbsp; 然后，通过这个File值向标准错误输出上写入一些内容： &nbsp;12345if file3 != nil &#123; defer file3.Close() file3.WriteString( &quot;The Go language program writes the contents into stderr.\\n&quot;)&#125;&nbsp; os.Open函数会打开一个文件并返回包装了该文件的File值。 然而，该函数只能以只读模式打开文件。换句话说，我们只能从该函数返回的File值中读取内容，而不能向它写入任何内容。 &nbsp;如果我们调用了这个File值的任何一个写入方法，那么都将会得到一个表示了“坏的文件描述符”的错误值。实际上，我们刚刚说的只读模式，正是应用在File值所持有的文件描述符之上的。&nbsp;所谓的文件描述符，是由通常很小的非负整数代表的。它一般会由 I/O 相关的系统调用返回，并作为某个文件的一个标识存在。&nbsp;从操作系统的层面看，针对任何文件的 I/O 操作都需要用到这个文件描述符。只不过，Go 语言中的一些数据类型，为我们隐匿掉了这个描述符，如此一来我们就无需时刻关注和辨别它了（就像os.File类型这样）。&nbsp;实际上，我们在调用前文所述的os.Create函数、os.Open函数以及将会提到的os.OpenFile函数的时候，它们都会执行同一个系统调用，并且在成功之后得到这样一个文件描述符。这个文件描述符将会被储存在它们返回的File值中。&nbsp;os.File类型有一个指针方法，名叫Fd。它在被调用之后将会返回一个uintptr类型的值。这个值就代表了当前的File值所持有的那个文件描述符。&nbsp;不过，在os包中，除了NewFile函数需要用到它，它也没有什么别的用武之地了。所以，如果你操作的只是常规的文件或者目录，那么就无需特别地在意它了。&nbsp;最后，再说一下os.OpenFile函数。 这个函数其实是os.Create函数和os.Open函数的底层支持，它最为灵活。&nbsp;这个函数有 3 个参数，分别名为name、flag和perm。其中的name指代的就是文件的路径。而flag参数指的则是需要施加在文件描述符之上的模式，我在前面提到的只读模式就是这里的一个可选项。&nbsp;在 Go 语言中，这个只读模式由常量os.O_RDONLY代表，它是int类型的。当然了，这里除了只读模式之外，还有几个别的模式可选，我们稍后再细说。&nbsp;os.OpenFile函数的参数perm代表的也是模式，它的类型是os.FileMode，此类型是一个基于uint32类型的再定义类型。&nbsp;为了加以区别，我们把参数flag指代的模式叫做操作模式，而把参数perm指代的模式叫做权限模式。可以这么说，操作模式限定了操作文件的方式，而权限模式则可以控制文件的访问权限。 到这里，你需要记住的是，通过os.File类型的值，我们不但可以对文件进行读取、写入、关闭等操作，还可以设定下一次读取或写入时的起始索引位置。&nbsp;此外，os包中还有用于创建全新文件的Create函数，用于包装现存文件的NewFile函数，以及可被用来打开已存在的文件的Open函数和OpenFile函数。&nbsp; 操作模式和访问权限&nbsp;可应用于File值的操作模式都有哪些？&nbsp;针对File值的操作模式主要有只读模式、只写模式和读写模式。&nbsp;这些模式分别由常量os.O_RDONLY、os.O_WRONLY和os.O_RDWR代表。在我们新建或打开一个文件的时候，必须把这三个模式中的一个设定为此文件的操作模式。&nbsp;除此之外，我们还可以为这里的文件设置额外的操作模式，可选项如下所示。 os.O_APPEND：当向文件中写入内容时，把新内容追加到现有内容的后边。 os.O_CREATE：当给定路径上的文件不存在时，创建一个新文件。 os.O_EXCL：需要与os.O_CREATE一同使用，表示在给定的路径上不能有已存在的文件。 os.O_SYNC：在打开的文件之上实施同步 I/O。它会保证读写的内容总会与硬盘上的数据保持同步。 os.O_TRUNC：如果文件已存在，并且是常规的文件，那么就先清空其中已经存在的任何内容。 对于以上操作模式的使用，os.Create函数和os.Open函数都是现成的例子。&nbsp;123func Create(name string) (*File, error) &#123; return OpenFile(name, O_RDWR|O_CREATE|O_TRUNC, 0666)&#125;&nbsp; os.Create函数在调用os.OpenFile函数的时候，给予的操作模式是os.O_RDWR、os.O_CREATE和os.O_TRUNC的组合。 &nbsp;这就基本上决定了前者的行为，即：如果参数name代表路径之上的文件不存在，那么就新建一个，否则，先清空现存文件中的全部内容。&nbsp;并且，它返回的File值的读取方法和写入方法都是可用的。这里需要注意，多个操作模式是通过按位或操作符|组合起来的。&nbsp;123func Open(name string) (*File, error) &#123; return OpenFile(name, O_RDONLY, 0)&#125;&nbsp; 我在前面说过，os.Open函数的功能是：以只读模式打开已经存在的文件。其根源就是它在调用os.OpenFile函数的时候，只提供了一个单一的操作模式os.O_RDONLY。 &nbsp;以上，就是我对可应用于File值的操作模式的简单解释。&nbsp;怎样设定常规文件的访问权限？&nbsp;我们已经知道，os.OpenFile函数的第三个参数perm代表的是权限模式，其类型是os.FileMode。但实际上，os.FileMode类型能够代表的，可远不只权限模式，它还可以代表文件模式（也可以称之为文件种类）。&nbsp;由于os.FileMode是基于uint32类型的再定义类型，所以它的每个值都包含了 32 个比特位。在这 32 个比特位当中，每个比特位都有其特定的含义。&nbsp;比如，如果在其最高比特位上的二进制数是1，那么该值表示的文件模式就等同于os.ModeDir，也就是说，相应的文件代表的是一个目录。&nbsp;又比如，如果其中的第 26 个比特位上的是1，那么相应的值表示的文件模式就等同于os.ModeNamedPipe，也就是说，那个文件代表的是一个命名管道。&nbsp;实际上，在一个os.FileMode类型的值（以下简称FileMode值）中，只有最低的 9 个比特位才用于表示文件的权限。当我们拿到一个此类型的值时，可以把它和os.ModePerm常量的值做按位与操作。&nbsp;这个常量的值是0777，是一个八进制的无符号整数，其最低的 9 个比特位上都是1，而更高的 23 个比特位上都是0。&nbsp;所以，经过这样的按位与操作之后，我们即可得到这个FileMode值中所有用于表示文件权限的比特位，也就是该值所表示的权限模式。这将会与我们调用FileMode值的Perm方法所得到的结果值是一致。&nbsp;在这 9 个用于表示文件权限的比特位中，每 3 个比特位为一组，共可分为 3 组。&nbsp;从高到低，这 3 组分别表示的是文件所有者（也就是创建这个文件的那个用户）、文件所有者所属的用户组，以及其他用户对该文件的访问权限。而对于每个组，其中的 3 个比特位从高到低分别表示读权限、写权限和执行权限。&nbsp;如果在其中的某个比特位上的是1，那么就意味着相应的权限开启，否则，就表示相应的权限关闭。&nbsp;因此，八进制整数0777就表示：操作系统中的所有用户都对当前的文件有读、写和执行的权限，而八进制整数0666则表示：所有用户都对当前文件有读和写的权限，但都没有执行的权限。&nbsp;我们在调用os.OpenFile函数的时候，可以根据以上说明设置它的第三个参数。但要注意，只有在新建文件的时候，这里的第三个参数值才是有效的。在其他情况下，即使我们设置了此参数，也不会对目标文件产生任何的影响。&nbsp;扩展：怎样通过os包中的 API 创建和操纵一个系统进程？&nbsp;可以从os包的FindProcess函数和StartProcess函数开始。前者用于通过进程 ID（pid）查找进程，后者用来基于某个程序启动一个进程。&nbsp;这两者都会返回一个*os.Process类型的值。该类型提供了一些方法，比如，用于杀掉当前进程的Kill方法，又比如，可以给当前进程发送系统信号的Signal方法，以及会等待当前进程结束的Wait方法。&nbsp;与此相关的还有os.ProcAttr类型、os.ProcessState类型、os.Signal类型，等等。&nbsp; &nbsp;参考链接：https://time.geekbang.org/column/intro/112","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Go语言","slug":"Go语言","permalink":"http://wht6.github.io/tags/Go%E8%AF%AD%E8%A8%80/"}]},{"title":"bufio包中的数据类型","slug":"bufio包中的数据类型","date":"2022-03-17T12:00:00.000Z","updated":"2022-03-20T02:01:26.495Z","comments":true,"path":"posts/b456.html","link":"","permalink":"http://wht6.github.io/posts/b456.html","excerpt":"","text":"bufio是“buffered I/O”的缩写。顾名思义，这个代码包中的程序实体实现的 I/O 操作都内置了缓冲区。 &nbsp; bufio包中的数据类型主要有：&nbsp; Reader； Scanner； Writer和ReadWriter。 &nbsp;与io包中的数据类型类似，这些类型的值也都需要在初始化的时候，包装一个或多个简单 I/O 接口类型的值。&nbsp;（这里的简单 I/O 接口类型指的就是io包中的那些简单接口。）&nbsp;bufio.Reader类型值中的缓冲区起着怎样的作用？&nbsp;bufio.Reader类型的值（以下简称Reader值）内的缓冲区，其实就是一个数据存储中介，它介于底层读取器与读取方法及其调用方之间。所谓的底层读取器，就是在初始化此类值的时候传入的io.Reader类型的参数值。&nbsp;Reader值的读取方法一般都会先从其所属值的缓冲区中读取数据。同时，在必要的时候，它们还会预先从底层读取器那里读出一部分数据，并暂存于缓冲区之中以备后用。&nbsp;有这样一个缓冲区的好处是，可以在大多数的时候降低读取方法的执行时间。虽然，读取方法有时还要负责填充缓冲区，但从总体来看，读取方法的平均执行时间一般都会因此有大幅度的缩短。&nbsp;bufio.Reader类型并不是开箱即用的，因为它包含了一些需要显式初始化的字段。为了让你能在后面更好地理解它的读取方法的内部流程，我先在这里简要地解释一下这些字段，如下所示。&nbsp; buf：[]byte类型的字段，即字节切片，代表缓冲区。虽然它是切片类型的，但是其长度却会在初始化的时候指定，并在之后保持不变。 rd：io.Reader类型的字段，代表底层读取器。缓冲区中的数据就是从这里拷贝来的。 r：int类型的字段，代表对缓冲区进行下一次读取时的开始索引。我们可以称它为已读计数。 w：int类型的字段，代表对缓冲区进行下一次写入时的开始索引。我们可以称之为已写计数。 err：error类型的字段。它的值用于表示在从底层读取器获得数据时发生的错误。这里的值在被读取或忽略之后，该字段会被置为nil。 lastByte：int类型的字段，用于记录缓冲区中最后一个被读取的字节。读回退时会用到它的值。 lastRuneSize：int类型的字段，用于记录缓冲区中最后一个被读取的 Unicode 字符所占用的字节数。读回退的时候会用到它的值。这个字段只会在其所属值的ReadRune方法中才会被赋予有意义的值。在其他情况下，它都会被置为-1。 &nbsp;bufio包为我们提供了两个用于初始化Reader值的函数，分别叫：&nbsp; NewReader； NewReaderSize； &nbsp;它们都会返回一个*bufio.Reader类型的值。&nbsp;NewReader函数初始化的Reader值会拥有一个默认尺寸的缓冲区。这个默认尺寸是 4096 个字节，即：4 KB。而NewReaderSize函数则将缓冲区尺寸的决定权抛给了使用方。&nbsp;由于这里的缓冲区在一个Reader值的生命周期内其尺寸不可变，所以在有些时候是需要做一些权衡的。NewReaderSize函数就提供了这样一个途径。&nbsp;在bufio.Reader类型拥有的读取方法中，Peek方法和ReadSlice方法都会调用该类型一个名为fill的包级私有方法。fill方法的作用是填充内部缓冲区。我们在这里就先重点说说它。&nbsp;fill方法会先检查其所属值的已读计数。如果这个计数不大于0，那么有两种可能。&nbsp;一种可能是其缓冲区中的字节都是全新的，也就是说它们都没有被读取过，另一种可能是缓冲区刚被压缩过。&nbsp;对缓冲区的压缩包括两个步骤。第一步，把缓冲区中在[已读计数, 已写计数)范围之内的所有元素值（或者说字节）都依次拷贝到缓冲区的头部。&nbsp;比如，把缓冲区中与已读计数代表的索引对应字节拷贝到索引0的位置，并把紧挨在它后边的字节拷贝到索引1的位置，以此类推。&nbsp;这一步之所以不会有任何副作用，是因为它基于两个事实。&nbsp;第一事实，已读计数之前的字节都已经被读取过，并且肯定不会再被读取了，因此把它们覆盖掉是安全的。&nbsp;第二个事实，在压缩缓冲区之后，已写计数之后的字节只可能是已被读取过的字节，或者是已被拷贝到缓冲区头部的未读字节，又或者是代表未曾被填入数据的零值0x00。所以，后续的新字节是可以被写到这些位置上的。&nbsp;在压缩缓冲区的第二步中，fill方法会把已写计数的新值设定为原已写计数与原已读计数的差。这个差所代表的索引，就是压缩后第一次写入字节时的开始索引。&nbsp;另外，该方法还会把已读计数的值置为0。显而易见，在压缩之后，再读取字节就肯定要从缓冲区的头部开始读了。 实际上，fill方法只要在开始时发现其所属值的已读计数大于0，就会对缓冲区进行一次压缩。之后，如果缓冲区中还有可写的位置，那么该方法就会对其进行填充。&nbsp;在填充缓冲区的时候，fill方法会试图从底层读取器那里，读取足够多的字节，并尽量把从已写计数代表的索引位置到缓冲区末尾之间的空间都填满。&nbsp;在这个过程中，fill方法会及时地更新已写计数，以保证填充的正确性和顺序性。另外，它还会判断从底层读取器读取数据的时候，是否有错误发生。如果有，那么它就会把错误值赋给其所属值的err字段，并终止填充流程。&nbsp;bufio.Writer类型值中缓冲的数据什么时候会被写到它的底层写入器？&nbsp;我们先来看一下bufio.Writer类型都有哪些字段： err：error类型的字段。它的值用于表示在向底层写入器写数据时发生的错误。 buf：[]byte类型的字段，代表缓冲区。在初始化之后，它的长度会保持不变。 n：int类型的字段，代表对缓冲区进行下一次写入时的开始索引。我们可以称之为已写计数。 wr：io.Writer类型的字段，代表底层写入器。 bufio.Writer类型有一个名为Flush的方法，它的主要功能是把相应缓冲区中暂存的所有数据，都写到底层写入器中。数据一旦被写进底层写入器，该方法就会把它们从缓冲区中删除掉。&nbsp;不过，这里的删除有时候只是逻辑上的删除而已。不论是否成功地写入了所有的暂存数据，Flush方法都会妥当处置，并保证不会出现重写和漏写的情况。该类型的字段n在此会起到很重要的作用。&nbsp;bufio.Writer类型值（以下简称Writer值）拥有的所有数据写入方法都会在必要的时候调用它的Flush方法。&nbsp;比如，Write方法有时候会在把数据写进缓冲区之后，调用Flush方法，以便为后续的新数据腾出空间。WriteString方法的行为与之类似。&nbsp;又比如，WriteByte方法和WriteRune方法，都会在发现缓冲区中的可写空间不足以容纳新的字节，或 Unicode 字符的时候，调用Flush方法。&nbsp;此外，如果Write方法发现需要写入的字节太多，同时缓冲区已空，那么它就会跨过缓冲区，并直接把这些数据写到底层写入器中。&nbsp;而ReadFrom方法，则会在发现底层写入器的类型是io.ReaderFrom接口的实现之后，直接调用其ReadFrom方法把参数值持有的数据写进去。&nbsp;总之，在通常情况下，只要缓冲区中的可写空间无法容纳需要写入的新数据，Flush方法就一定会被调用。并且，bufio.Writer类型的一些方法有时候还会试图走捷径，跨过缓冲区而直接对接数据供需的双方。&nbsp;你可以在理解了这些内部机制之后，有的放矢地编写你的代码。不过，在你把所有的数据都写入Writer值之后，再调用一下它的Flush方法，显然是最稳妥的。&nbsp;bufio.Reader类型读取方法有哪些不同？&nbsp;bufio.Reader类型拥有很多用于读取数据的指针方法，这里面有 4 个方法可以作为不同读取流程的代表，它们是：Peek、Read、ReadSlice和ReadBytes。&nbsp;Reader值的Peek方法的功能是：读取并返回其缓冲区中的n个未读字节，并且它会从已读计数代表的索引位置开始读。&nbsp;在缓冲区未被填满，并且其中的未读字节的数量小于n的时候，该方法就会调用fill方法，以启动缓冲区填充流程。但是，如果它发现上次填充缓冲区的时候有错误，那就不会再次填充。&nbsp;如果调用方给定的n比缓冲区的长度还要大，或者缓冲区中未读字节的数量小于n，那么Peek方法就会把“所有未读字节组成的序列”作为第一个结果值返回。&nbsp;同时，它通常还把“bufio.ErrBufferFull变量的值（以下简称缓冲区已满的错误）”作为第二个结果值返回，用来表示：虽然缓冲区被压缩和填满了，但是仍然满足不了要求。&nbsp;只有在上述的情况都没有出现时，Peek方法才能返回：“以已读计数为起始的n个字节”和“表示未发生任何错误的nil”。&nbsp;bufio.Reader类型的 Peek 方法有一个鲜明的特点，那就是：即使它读取了缓冲区中的数据，也不会更改已读计数的值。&nbsp;这个类型的其他读取方法并不是这样。就拿该类型的Read方法来说，它有时会把缓冲区中的未读字节，依次拷贝到其参数p代表的字节切片中，并立即根据实际拷贝的字节数增加已读计数的值。 在缓冲区中还有未读字节的情况下，该方法的做法就是如此。不过，在另一些时候，其所属值的已读计数会等于已写计数，这表明：此时的缓冲区中已经没有任何未读的字节了。 当缓冲区中已无未读字节时，Read方法会先检查参数p的长度是否大于或等于缓冲区的长度。如果是，那么Read方法会索性放弃向缓冲区中填充数据，转而直接从其底层读取器中读出数据并拷贝到p中。这意味着它完全跨过了缓冲区，并直连了数据供需的双方。 &nbsp;需要注意的是，Peek方法在遇到类似情况时的做法与这里的区别（这两种做法孰优孰劣还要看具体的使用场景）。&nbsp;Peek方法会在条件满足时填充缓冲区，并在发现参数n的值比缓冲区的长度更大时，直接返回缓冲区中的所有未读字节。&nbsp;如果我们当初设定的缓冲区长度很大，那么在这种情况下的方法执行耗时，就有可能会比较长。最主要的原因是填充缓冲区需要花费较长的时间。&nbsp;由fill方法执行的流程可知，它会尽量填满缓冲区中的可写空间。然而，Read方法在大多数的情况下，是不会向缓冲区中写入数据的，尤其是在前面描述的那种情况下，即：缓冲区中已无未读字节，且参数p的长度大于或等于缓冲区的长度。&nbsp;此时，该方法会直接从底层读取器那里读出数据，所以数据的读出速度就成为了这种情况下方法执行耗时的决定性因素。&nbsp;当然了，我在这里说的只是耗时操作在某些情况下更可能出现在哪里，一切的结论还是要以性能测试的客观结果为准。&nbsp;说回Read方法的内部流程。如果缓冲区中已无未读字节，但其长度比参数p的长度更大，那么该方法会先把已读计数和已写计数的值都重置为0，然后再尝试着使用从底层读取器那里获取的数据，对缓冲区进行一次从头至尾的填充。&nbsp;不过要注意，这里的尝试只会进行一次。无论在这一时刻是否能够获取到数据，也无论获取时是否有错误发生，都会是如此。而fill方法的做法与此不同，只要没有发生错误，它就会进行多次尝试，因此它真正获取到一些数据的可能性更大。&nbsp;不过，这两个方法有一点是相同，那就是：只要它们把获取到的数据写入缓冲区，就会及时地更新已写计数的值。&nbsp;再来说ReadSlice方法和ReadBytes方法。 这两个方法的功能总体上来说，都是持续地读取数据，直至遇到调用方给定的分隔符为止。&nbsp;ReadSlice方法会先在其缓冲区的未读部分中寻找分隔符。如果未能找到，并且缓冲区未满，那么该方法会先通过调用fill方法对缓冲区进行填充，然后再次寻找，如此往复。&nbsp;如果在填充的过程中发生了错误，那么它会把缓冲区中的未读部分作为结果返回，同时返回相应的错误值。&nbsp;注意，在这个过程中有可能会出现虽然缓冲区已被填满，但仍然没能找到分隔符的情况。&nbsp;这时，ReadSlice方法会把整个缓冲区（也就是buf字段代表的字节切片）作为第一个结果值，并把缓冲区已满的错误（即bufio.ErrBufferFull变量的值）作为第二个结果值。&nbsp;经过fill方法填满的缓冲区肯定从头至尾都只包含了未读的字节，所以这样做是合理的。&nbsp;当然了，一旦ReadSlice方法找到了分隔符，它就会在缓冲区上切出相应的、包含分隔符的字节切片，并把该切片作为结果值返回。无论分隔符找到与否，该方法都会正确地设置已读计数的值。&nbsp;比如，在返回缓冲区中的所有未读字节，或者代表全部缓冲区的字节切片之前，它会把已写计数的值赋给已读计数，以表明缓冲区中已无未读字节。&nbsp;如果说ReadSlice是一个容易半途而废的方法的话，那么可以说ReadBytes方法算得上是相当的执着。&nbsp;ReadBytes方法会通过调用ReadSlice方法一次又一次地从缓冲区中读取数据，直至找到分隔符为止。&nbsp;在这个过程中，ReadSlice方法可能会因缓冲区已满而返回所有已读到的字节和相应的错误值，但ReadBytes方法总是会忽略掉这样的错误，并再次调用ReadSlice方法，这使得后者会继续填充缓冲区并在其中寻找分隔符。&nbsp;除非ReadSlice方法返回的错误值并不代表缓冲区已满的错误，或者它找到了分隔符，否则这一过程永远不会结束。&nbsp;如果寻找的过程结束了，不管是不是因为找到了分隔符，ReadBytes方法都会把在这个过程中读到的所有字节，按照读取的先后顺序组装成一个字节切片，并把它作为第一个结果值。如果过程结束是因为出现错误，那么它还会把拿到的错误值作为第二个结果值。&nbsp;在bufio.Reader类型的众多读取方法中，依赖ReadSlice方法的除了ReadBytes方法，还有ReadLine方法。不过后者在读取流程上并没有什么特别之处，我就不在这里赘述了。&nbsp;另外，该类型的ReadString方法完全依赖于ReadBytes方法，前者只是在后者返回的结果值之上做了一个简单的类型转换而已。&nbsp;最后，我还要提醒你一下，有个安全性方面的问题需要你注意。bufio.Reader类型的Peek方法、ReadSlice方法和ReadLine方法都有可能会造成内容泄露。&nbsp;这主要是因为它们在正常的情况下都会返回直接基于缓冲区的字节切片。&nbsp;调用方可以通过这些方法返回的结果值访问到缓冲区的其他部分，甚至修改缓冲区中的内容。这通常都是很危险的。&nbsp;bufio.Scanner类型的主要功用是什么？它有哪些特点？&nbsp;bufio.Scanner类型俗称带缓存的扫描器。它的功能还是比较强大的。&nbsp;比如，我们可以自定义每次扫描的边界，或者说内容的分段方法。我们在调用它的Scan方法对目标进行扫描之前，可以先调用其Split方法并传入一个函数来自定义分段方法。&nbsp;在默认情况下，扫描器会以行为单位对目标内容进行扫描。bufio代码包提供了一些现成的分段方法。实际上，扫描器在默认情况下会使用bufio.ScanLines函数作为分段方法。&nbsp;又比如，我们还可以在扫描之前自定义缓存的载体和缓存的最大容量，这需要调用它的Buffer方法。在默认情况下，扫描器内部设定的最大缓存容量是64K个字节。&nbsp;换句话说，目标内容中的每一段都不能超过64K个字节。否则，扫描器就会使它的Scan方法返回false，并通过其Err方法给予我们一个表示“token too long”的错误值。这里的“token”代表的就是一段内容。&nbsp;&nbsp; 参考链接：https://time.geekbang.org/column/intro/112","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Go语言","slug":"Go语言","permalink":"http://wht6.github.io/tags/Go%E8%AF%AD%E8%A8%80/"}]},{"title":"io包中的接口和工具","slug":"io包中的接口和工具","date":"2022-03-16T12:00:00.000Z","updated":"2022-03-20T02:01:12.614Z","comments":true,"path":"posts/6c1c.html","link":"","permalink":"http://wht6.github.io/posts/6c1c.html","excerpt":"","text":"先来看一下strings.Builder、strings.Reader和bytes.Buffer这三个数据类型实现了哪些接口。 &nbsp; strings.Builder类型主要用于构建字符串，它的指针类型实现的接口有io.Writer、io.ByteWriter和fmt.Stringer。另外，它其实还实现了一个io包的包级私有接口io.StringWriter&nbsp;strings.Reader类型主要用于读取字符串，它的指针类型实现的接口比较多，包括：&nbsp; io.Reader； io.ReaderAt； io.ByteReader； io.RuneReader； io.Seeker； io.ByteScanner； io.RuneScanner； io.WriterTo； &nbsp;共有 8 个，它们都是io包中的接口。其中，io.ByteScanner是io.ByteReader的扩展接口，而io.RuneScanner又是io.RuneReader的扩展接口。&nbsp;bytes.Buffer是集读、写功能于一身的数据类型，它非常适合作为字节序列的缓冲区。 它的指针类型实现的接口就更多了。更具体地说，该指针类型实现的读取相关的接口有下面几个。&nbsp; io.Reader； io.ByteReader； io.RuneReader； io.ByteScanner； io.RuneScanner； io.WriterTo；&nbsp; 共有 6 个。而其实现的写入相关的接口则有这些。&nbsp; io.Writer； io.ByteWriter； io.stringWriter； io.ReaderFrom； &nbsp;共 4 个。此外，它还实现了导出相关的接口fmt.Stringer。&nbsp; io 包中接口的好处与优势&nbsp;那么，这些类型实现了这么多的接口，其动机（或者说目的）究竟是什么呢？&nbsp;简单地说，这是为了提高不同程序实体之间的互操作性。远的不说，我们就以io包中的一些函数为例。&nbsp;在io包中，有这样几个用于拷贝数据的函数，它们是：&nbsp; io.Copy； io.CopyBuffer； io.CopyN。 &nbsp;虽然这几个函数在功能上都略有差别，但是它们都首先会接受两个参数，即：用于代表数据目的地、io.Writer类型的参数dst，以及用于代表数据来源的、io.Reader类型的参数src。这些函数的功能大致上都是把数据从src拷贝到dst。&nbsp;不论我们给予它们的第一个参数值是什么类型的，只要这个类型实现了io.Writer接口即可。&nbsp;同样的，无论我们传给它们的第二个参数值的实际类型是什么，只要该类型实现了io.Reader接口就行。&nbsp;一旦我们满足了这两个条件，这些函数几乎就可以正常地执行了。当然了，函数中还会对必要的参数值进行有效性的检查，如果检查不通过，它的执行也是不能够成功结束的。&nbsp;下面来看一段示例代码：&nbsp;1234567891011src := strings.NewReader( &quot;CopyN copies n bytes (or until an error) from src to dst. &quot; + &quot;It returns the number of bytes copied and &quot; + &quot;the earliest error encountered while copying.&quot;)dst := new(strings.Builder)written, err := io.CopyN(dst, src, 58)if err != nil &#123; fmt.Printf(&quot;error: %v\\n&quot;, err)&#125; else &#123; fmt.Printf(&quot;Written(%d): %q\\n&quot;, written, dst.String())&#125;&nbsp; 我先使用strings.NewReader创建了一个字符串读取器，并把它赋给了变量src，然后我又new了一个字符串构建器，并将其赋予了变量dst。 &nbsp;之后，我在调用io.CopyN函数的时候，把这两个变量的值都传了进去，同时把给这个函数的第三个参数值设定为了58。也就是说，我想从src中拷贝前58个字节到dst那里。&nbsp;虽然，变量src和dst的类型分别是strings.Reader和strings.Builder，但是当它们被传到io.CopyN函数的时候，就已经分别被包装成了io.Reader类型和io.Writer类型的值。io.CopyN函数也根本不会去在意，它们的实际类型到底是什么。&nbsp;为了优化的目的，io.CopyN函数中的代码会对参数值进行再包装，也会检测这些参数值是否还实现了别的接口，甚至还会去探求某个参数值被包装后的实际类型，是否为某个特殊的类型。&nbsp;但是，从总体上来看，这些代码都是面向参数声明中的接口来做的。io.CopyN函数的作者通过面向接口编程，极大地拓展了它的适用范围和应用场景。&nbsp;换个角度看，正因为strings.Reader类型和strings.Builder类型都实现了不少接口，所以它们的值才能够被使用在更广阔的场景中。&nbsp;换句话说，如此一来，Go 语言的各种库中，能够操作它们的函数和数据类型明显多了很多。&nbsp;这就是我想要告诉你的，strings包和bytes包中的数据类型在实现了若干接口之后得到的最大好处。&nbsp;也可以说，这就是面向接口编程带来的最大优势。这些数据类型和函数的做法，也是非常值得我们在编程的过程中去效仿的。&nbsp;可以看到，前文所述的几个类型实现的大都是io代码包中的接口。实际上，io包中的接口，对于 Go 语言的标准库和很多第三方库而言，都起着举足轻重的作用。它们非常基础也非常重要。&nbsp;就拿io.Reader和io.Writer这两个最核心的接口来说，它们是很多接口的扩展对象和设计源泉。同时，单从 Go 语言的标准库中统计，实现了它们的数据类型都（各自）有上百个，而引用它们的代码更是都（各自）有 400 多处。&nbsp;很多数据类型实现了io.Reader接口，是因为它们提供了从某处读取数据的功能。类似的，许多能够把数据写入某处的数据类型，也都会去实现io.Writer接口。&nbsp;其实，有不少类型的设计初衷都是：实现这两个核心接口的某个，或某些扩展接口，以提供比单纯的字节序列读取或写入，更加丰富的功能，就像前面讲到的那几个strings包和bytes包中的数据类型那样。&nbsp;在 Go 语言中，对接口的扩展是通过接口类型之间的嵌入来实现的，这也常被叫做接口的组合。&nbsp;Go 语言提倡使用小接口加接口组合的方式，来扩展程序的行为以及增加程序的灵活性。io代码包恰恰就可以作为这样的一个标杆，它可以成为我们运用这种技巧时的一个参考标准。&nbsp;在io包中，io.Reader的扩展接口和实现类型都有哪些？它们分别都有什么功用？&nbsp;在io包中，io.Reader的扩展接口有下面几种。&nbsp; io.ReadWriter：此接口既是io.Reader的扩展接口，也是io.Writer的扩展接口。换句话说，该接口定义了一组行为，包含且仅包含了基本的字节序列读取方法Read，和字节序列写入方法Write。 io.ReadCloser：此接口除了包含基本的字节序列读取方法之外，还拥有一个基本的关闭方法Close。后者一般用于关闭数据读写的通路。这个接口其实是io.Reader接口和io.Closer接口的组合。 io.ReadWriteCloser：很明显，此接口是io.Reader、io.Writer和io.Closer这三个接口的组合。 io.ReadSeeker：此接口的特点是拥有一个用于寻找读写位置的基本方法Seek。更具体地说，该方法可以根据给定的偏移量基于数据的起始位置、末尾位置，或者当前读写位置去寻找新的读写位置。这个新的读写位置用于表明下一次读或写时的起始索引。Seek是io.Seeker接口唯一拥有的方法。 io.ReadWriteSeeker：显然，此接口是另一个三合一的扩展接口，它是io.Reader、io.Writer和io.Seeker的组合。 &nbsp;再来说说io包中的io.Reader接口的实现类型，它们包括下面几项内容。&nbsp; *io.LimitedReader：此类型的基本类型会包装io.Reader类型的值，并提供一个额外的受限读取的功能。所谓的受限读取指的是，此类型的读取方法Read返回的总数据量会受到限制，无论该方法被调用多少次。这个限制由该类型的字段N指明，单位是字节。 *io.SectionReader：此类型的基本类型可以包装io.ReaderAt类型的值，并且会限制它的Read方法，只能够读取原始数据中的某一个部分（或者说某一段）。 这个数据段的起始位置和末尾位置，需要在它被初始化的时候就指明，并且之后无法变更。该类型值的行为与切片有些类似，它只会对外暴露在其窗口之中的那些数据。 *io.teeReader：此类型是一个包级私有的数据类型，也是io.TeeReader函数结果值的实际类型。这个函数接受两个参数r和w，类型分别是io.Reader和io.Writer。 其结果值的Read方法会把r中的数据经过作为方法参数的字节切片p写入到w。可以说，这个值就是r和w之间的数据桥梁，而那个参数p就是这座桥上的数据搬运者。 io.multiReader：此类型也是一个包级私有的数据类型。类似的，io包中有一个名为MultiReader的函数，它可以接受若干个io.Reader类型的参数值，并返回一个实际类型为io.multiReader的结果值。 当这个结果值的Read方法被调用时，它会顺序地从前面那些io.Reader类型的参数值中读取数据。因此，我们也可以称之为多对象读取器。 io.pipe：此类型为一个包级私有的数据类型，它比上述类型都要复杂得多。它不但实现了io.Reader接口，而且还实现了io.Writer接口。 实际上，io.PipeReader类型和io.PipeWriter类型拥有的所有指针方法都是以它为基础的。这些方法都只是代理了io.pipe类型值所拥有的某一个方法而已。 又因为io.Pipe函数会返回这两个类型的指针值并分别把它们作为其生成的同步内存管道的两端，所以可以说，*io.pipe类型就是io包提供的同步内存管道的核心实现。 io.PipeReader：此类型可以被视为io.pipe类型的代理类型。它代理了后者的一部分功能，并基于后者实现了io.ReadCloser接口。同时，它还定义了同步内存管道的读取端。 &nbsp;注意，我在这里忽略掉了测试源码文件中的实现类型，以及不会以任何形式直接对外暴露的那些实现类型。&nbsp;这个代码包是 Go 语言标准库中所有 I/O 相关 API 的根基，所以，我们必须对其中的每一个程序实体都有所了解。&nbsp;然而，由于该包包含的内容众多，因此这里的问题是以io.Reader接口作为切入点的。通过io.Reader接口，我们应该能够梳理出基于它的类型树，并知晓其中每一个类型的功用。&nbsp;io.Reader可谓是io包乃至是整个 Go 语言标准库中的核心接口，所以我们可以从它那里牵扯出很多扩展接口和实现类型。&nbsp;这些类型中的每一个都值得你认真去理解，尤其是那几个实现了io.Reader接口的类型。它们实现的功能在细节上都各有不同。&nbsp;在很多时候，我们可以根据实际需求将它们搭配起来使用。&nbsp;例如，对施加在原始数据之上的（由Read方法提供的）读取功能进行多层次的包装（比如受限读取和多对象读取等），以满足较为复杂的读取需求。&nbsp;在实际的面试中，只要应聘者能够从某一个方面出发，说出io.Reader的扩展接口及其存在意义，或者说清楚该接口的三五个实现类型，那么就可以算是基本回答正确了。&nbsp;比如，从读取、写入、关闭这一些列的基本功能出发，描述清楚：&nbsp; io.ReadWriter； io.ReadCloser； io.ReadWriteCloser； &nbsp;这几个接口。&nbsp;又比如，说明白io.LimitedReader和io.SectionReader这两个类型之间的异同点。&nbsp;再比如，阐述*io.SectionReader类型实现io.ReadSeeker接口的具体方式，等等。不过，这只是合格的门槛，应聘者回答得越全面越好。&nbsp;io包中的接口都有哪些？它们之间都有着怎样的关系？&nbsp;我们可以把没有嵌入其他接口并且只定义了一个方法的接口叫做简单接口。在io包中，这样的接口一共有 11 个。&nbsp;在它们之中，有的接口有着众多的扩展接口和实现类型，我们可以称之为核心接口。io包中的核心接口只有 3 个，它们是：io.Reader、io.Writer和io.Closer。&nbsp;我们还可以把io包中的简单接口分为四大类。这四大类接口分别针对于四种操作，即：读取、写入、关闭和读写位置设定。前三种操作属于基本的 I/O 操作。&nbsp;关于读取操作，我们在前面已经重点讨论过核心接口io.Reader。它在io包中有 5 个扩展接口，并有 6 个实现类型。除了它，这个包中针对读取操作的接口还有不少。我们下面就来梳理一下。&nbsp;首先来看io.ByteReader和io.RuneReader这两个简单接口。它们分别定义了一个读取方法，即：ReadByte和ReadRune。&nbsp;但与io.Reader接口中Read方法不同的是，这两个读取方法分别只能够读取下一个单一的字节和 Unicode 字符。&nbsp;我们之前讲过的数据类型strings.Reader和bytes.Buffer都是io.ByteReader和io.RuneReader的实现类型。&nbsp;不仅如此，这两个类型还都实现了io.ByteScanner接口和io.RuneScanner接口。&nbsp;io.ByteScanner接口内嵌了简单接口io.ByteReader，并定义了额外的UnreadByte方法。如此一来，它就抽象出了一个能够读取和读回退单个字节的功能集。&nbsp;与之类似，io.RuneScanner内嵌了简单接口io.RuneReader，并定义了额外的UnreadRune方法。它抽象的是可以读取和读回退单个 Unicode 字符的功能集。&nbsp;再来看io.ReaderAt接口。它也是一个简单接口，其中只定义了一个方法ReadAt。与我们在前面说过的读取方法都不同，ReadAt是一个纯粹的只读方法。&nbsp;它只去读取其所属值中包含的字节，而不对这个值进行任何的改动，比如，它绝对不能去修改已读计数的值。这也是io.ReaderAt接口与其实现类型之间最重要的一个约定。&nbsp;因此，如果仅仅并发地调用某一个值的ReadAt方法，那么安全性应该是可以得到保障的。&nbsp;另外，还有一个读取操作相关的接口我们没有介绍过，它就是io.WriterTo。这个接口定义了一个名为WriteTo的方法。&nbsp;千万不要被它的名字迷惑，这个WriteTo方法其实是一个读取方法。它会接受一个io.Writer类型的参数值，并会把其所属值中的数据读出并写入到这个参数值中。&nbsp;与之相对应的是io.ReaderFrom接口。它定义了一个名叫ReadFrom的写入方法。该方法会接受一个io.Reader类型的参数值，并会从该参数值中读出数据, 并写入到其所属值中。&nbsp;值得一提的是，我们在前面用到过的io.CopyN函数，在复制数据的时候会先检测其参数src的值，是否实现了io.WriterTo接口。如果是，那么它就直接利用该值的WriteTo方法，把其中的数据拷贝给参数dst代表的值。&nbsp;类似的，这个函数还会检测dst的值是否实现了io.ReaderFrom接口。如果是，那么它就会利用这个值的ReadFrom方法，直接从src那里把数据拷贝进该值。&nbsp;实际上，对于io.Copy函数和io.CopyBuffer函数来说也是如此，因为它们在内部做数据复制的时候用的都是同一套代码。&nbsp;你也看到了，io.ReaderFrom接口与io.WriterTo接口对应得很规整。实际上，在io包中，与写入操作有关的接口都与读取操作的相关接口有着一定的对应关系。下面，我们就来说说写入操作相关的接口。&nbsp;首先当然是核心接口io.Writer。基于它的扩展接口除了有我们已知的io.ReadWriter、io.ReadWriteCloser和io.ReadWriteSeeker之外，还有io.WriteCloser和io.WriteSeeker。&nbsp;我们之前提及的*io.pipe就是io.ReadWriter接口的实现类型。然而，在io包中并没有io.ReadWriteCloser接口的实现，它的实现类型主要集中在net包中。&nbsp;除此之外，写入操作相关的简单接口还有io.ByteWriter和io.WriterAt。可惜，io包中也没有它们的实现类型。不过，有一个数据类型值得在这里提一句，那就是*os.File。&nbsp;这个类型不但是io.WriterAt接口的实现类型，还同时实现了io.ReadWriteCloser接口和io.ReadWriteSeeker接口。也就是说，该类型支持的 I/O 操作非常的丰富。&nbsp;io.Seeker接口作为一个读写位置设定相关的简单接口，也仅仅定义了一个方法，名叫Seek。&nbsp;我在讲strings.Reader类型的时候还专门说过这个Seek方法，当时还给出了一个与已读计数估算有关的例子。该方法主要用于寻找并设定下一次读取或写入时的起始索引位置。&nbsp;io包中有几个基于io.Seeker的扩展接口，包括前面讲过的io.ReadSeeker和io.ReadWriteSeeker，以及还未曾提过的io.WriteSeeker。io.WriteSeeker是基于io.Writer和io.Seeker的扩展接口。&nbsp;我们之前多次提到的两个指针类型strings.Reader和io.SectionReader都实现了io.Seeker接口。顺便说一句，这两个类型也都是io.ReaderAt接口的实现类型。&nbsp;最后，关闭操作相关的接口io.Closer非常通用，它的扩展接口和实现类型都不少。我们单从名称上就能够一眼看出io包中的哪些接口是它的扩展接口。至于它的实现类型，io包中只有io.PipeReader和io.PipeWriter。 &nbsp;&nbsp; 参考链接：https://time.geekbang.org/column/intro/112","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Go语言","slug":"Go语言","permalink":"http://wht6.github.io/tags/Go%E8%AF%AD%E8%A8%80/"}]},{"title":"Docker的基本概念和命令","slug":"Docker的基本概念和命令","date":"2022-03-15T03:00:00.000Z","updated":"2022-03-26T02:44:34.486Z","comments":true,"path":"posts/865e.html","link":"","permalink":"http://wht6.github.io/posts/865e.html","excerpt":"","text":"01|基本概念1、Docker架构&nbsp;&nbsp; Client： 客户端；操作docker服务器的客户端（命令行或者界面） Docker_Host：Docker主机；安装Docker服务的主机 Docker_Daemon：后台进程；运行在Docker服务器的后台进程 Containers：容器；在Docker服务器中的容器（一个容器一般是一个应用实例，容器间互相隔离） Images：镜像、映像、程序包；Image是只读模板，其中包含创建Docker容器的说明。容器是由Image运行而来，Image固定不变。 Registries：仓库；存储Docker Image的地方。官方远程仓库地址： https://hub.docker.com/search &nbsp; Docker用Go编程语言编写，并利用Linux内核的多种功能来交付其功能。 Docker使用一种称为命名空间的技术来提供容器的隔离工作区。 运行容器时，Docker会为该容器创建一组命名空间。 这些命名空间提供了一层隔离。 容器的每个方面都在单独的命名空间中运行，并且对其的访问仅限于该命名空间。 &nbsp; 镜像和容器的关系（一个类可以创建多个实例）（镜像和容器也可以比作软件安装包和软件，一个安装包可以在多个机器上安装多个软件）&nbsp; Docker 面向对象 镜像（Image） 类 容器（Container） 对象（实例） &nbsp;容器与虚拟机&nbsp; &nbsp; 2、Docker隔离原理&nbsp;namespace 6项隔离 （资源隔离）&nbsp; namespace 系统调用参数 隔离内容 UTS CLONE_NEWUTS 主机和域名 IPC CLONE_NEWIPC 信号量、消息队列和共享内存 PID CLONE_NEWPID 进程编号 Network CLONE_NEWNET 网络设备、网络栈、端口等 Mount CLONE_NEWNS 挂载点(文件系统) User CLONE_NEWUSER 用户和用户组 &nbsp;cgroups资源限制 （资源限制）&nbsp;cgroup提供的主要功能如下：&nbsp; 资源限制：限制任务使用的资源总额，并在超过这个 配额 时发出提示 优先级分配：分配CPU时间片数量及磁盘IO带宽大小、控制任务运行的优先级 资源统计：统计系统资源使用量，如CPU使用时长、内存用量等 任务控制：对任务执行挂起、恢复等操作 &nbsp;cgroup资源控制系统，每种子系统独立地控制一种资源。功能如下：&nbsp; 子系统 功能 cpu 使用调度程序控制任务对CPU的使用。 cpuacct(CPU Accounting) 自动生成cgroup中任务对CPU资源使用情况的报告。 cpuset 为cgroup中的任务分配独立的CPU(多处理器系统时)和内存。 devices 开启或关闭cgroup中任务对设备的访问 freezer 挂起或恢复cgroup中的任务 memory 设定cgroup中任务对内存使用量的限定，并生成这些任务对内存资源使用 情况的报告 perf_event(Linux CPU性能探测器) 使cgroup中的任务可以进行统一的性能测试 net_cls(Docker未使 用) 通过等级识别符标记网络数据包，从而允许Linux流量监控程序(Trawic Controller)识别从具体cgroup中生成的数据包 &nbsp; 3、Docker安装&nbsp; 以下以centos为例；更多其他安装方式，详细参照文档： https://docs.docker.com/engine/install/centos/ &nbsp; 1、移除旧版本&nbsp;1sudo yum remove docker*&nbsp; 2、设置docker yum源&nbsp;1234sudo yum install -y yum-utilssudo yum-config-manager \\--add-repo \\https://download.docker.com/linux/centos/docker-ce.repo&nbsp; 3、安装最新docker engine&nbsp;1sudo yum install docker-ce docker-ce-cli containerd.io&nbsp; 4、安装指定版本docker engine&nbsp; 1、在线安装&nbsp;123456789#找到所有可用docker版本列表yum list docker-ce --showduplicates | sort -r# 安装指定版本，用上面的版本号替换&lt;VERSION_STRING&gt;sudo yum install docker-ce-&lt;VERSION_STRING&gt;.x86_64 docker-ce-cli-&lt;VERSION_STRING&gt;.x86_64 containerd.io#例如：#yum install docker-ce-3:20.10.5-3.el7.x86_64 docker-ce-cli-3:20.10.5-3.el7.x86_64 containerd.io#注意加上 .x86_64 大版本号&nbsp; 2、离线安装&nbsp;https://download.docker.com/linux/centos/7/x86_64/stable/Packages/&nbsp;123rpm -ivh xxx.rpm# 可以下载 tar# 解压启动即可&nbsp; https://docs.docker.com/engine/install/binaries/#install-daemon-and-client-binaries-on-linux &nbsp; 5、启动服务&nbsp;123systemctl start dockersystemctl enable dockerdocker version # 查看Docker的版本&nbsp; 6、镜像加速&nbsp;123456789sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-&#x27;EOF&#x27;&#123;&quot;registry-mirrors&quot;: [&quot;https://82m9ar63.mirror.aliyuncs.com&quot;]&#125; EOFsudo systemctl daemon-reloadsudo systemctl restart docker#以后docker下载直接从阿里云拉取相关镜像&nbsp; /etc/docker/daemon.json 是Docker的核心配置文件。 &nbsp; 7、可视化界面-Portainer&nbsp; 1、什么是Portainer&nbsp;https://documentation.portainer.io/&nbsp;Portainer社区版2.0拥有超过50万的普通用户，是功能强大的开源工具集，可让您轻松地在Docker，Swarm，Kubernetes和Azure ACI中构建和管理容器。 Portainer的工作原理是在易于使用的GUI后面隐藏使管理容器变得困难的复杂性。通过消除用户使用CLI，编写YAML或理解清单的需求，Portainer使部署应用程序和解决问题变得如此简单，任何人都可以做到。 Portainer开发团队在这里为您的Docker之旅提供帮助；&nbsp; 2、安装&nbsp;123456789# 服务端部署docker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v/var/run/docker.sock:/var/run/docker.sock -v portainer_data:/dataportainer/portainer-ce# 访问 9000 端口即可#agent端部署docker run -d -p 9001:9001 --name portainer_agent --restart=always -v/var/run/docker.sock:/var/run/docker.sock -v/var/lib/docker/volumes:/var/lib/docker/volumes portainer/agent&nbsp; 02|Docker命令1、常见命令&nbsp;所有Docker命令手册https://docs.docker.com/engine/reference/commandline/docker/&nbsp; 命令 作用 attach 绑定到运行中容器的 标准输入, 输出,以及错误流（这样似乎也能进入容器内容，但是 一定小心，他们操作的就是控制台，控制台的退出命令会生效，比如redis,nginx…） build 从一个 Dockerfile 文件构建镜像 commit 把容器的改变 提交创建一个新的镜像 cp 容器和本地文件系统间 复制 文件/文件夹 create 创建新容器，但并不启动（注意与docker run 的区分）需要手动启动。start\\stop diff 检查容器里文件系统结构的更改【A：添加文件或目录 D：文件或者目录删除 C：文件或者目录更改】 events 获取服务器的实时事件 exec 在运行时的容器内运行命令 export 导出容器的文件系统为一个tar文件。commit是直接提交成镜像，export是导出成文件方便在本地移动。 history 显示镜像的历史 images 列出所有镜像 import 导入tar的内容创建一个镜像，但是导入进来的镜像无法直接启动容器。必须使用导出之前镜像的完整启动命令去启动它。用docker ps --no-trunc查看完整启动命令。 info 显示系统信息 inspect 获取docker对象的底层信息 kill 杀死一个或者多个容器 load 从 tar 文件加载镜像 login 登录Docker registry logout 退出Docker registry logs 获取容器日志 pause 暂停一个或者多个容器 port 列出容器的端口映射 ps 列出所有容器 pull 从registry下载一个image 或者repository push 给registry推送一个image或者repository rename 重命名一个容器 restart 重启一个或者多个容器 rm 移除一个或者多个容器 rmi 移除一个或者多个镜像 run 创建并启动容器 save 把一个或者多个镜像保存为tar文件 search 去docker hub寻找镜像 start 启动一个或者多个容器 stats 显示容器资源的实时使用状态 stop 停止一个或者多个容器 tag 给源镜像创建一个新的标签，变成新的镜像 top 显示正在运行容器的进程 unpause pause的反操作 update 更新一个或者多个docker容器配置 version Show the Docker version information container 管理容器 image 管理镜像 network 管理网络 volume 管理卷 &nbsp;Docker命令的关系图&nbsp;&nbsp;根据正在运行的容器制作出相关的镜像：反向&nbsp;根据镜像启动一个容器：正向&nbsp;下载镜像并启动一个容器：&nbsp;1、先去软件市场搜镜像：docker hub 2、下载镜像 docker pull xxx 3、启动软件 docker run 镜像名；&nbsp;通过命令docker image --help 查看镜像的所有管理操作。&nbsp;123456789101112131415161718192021222324252627282930313233docker pull redis == docker pull redis:latest（最新版）# 阿里云的镜像是从docker hub来的，我们配置了加速，默认是从阿里云（缓存）下载docker images # 查看本地所有镜像docker rmi 镜像名 # 删除某个镜像 （-f为强制删除）docker rm 容器id # 删除某个容器docker ps # 列出所有容器 （-a则会将已经停止的容器也列出）docker rmi -f $(docker images -aq) #删除全部镜像docker rm -f $(docker ps -aq) # 删除所有容器docker image prune #移除游离镜像 dangling：游离镜像（没有镜像名字的）docker tag 原镜像:标签 新镜像名:标签 #起别名docker kill 容器名 # 是强制kill -9（直接拔电源）；docker stop 容器名 # 可以允许优雅停机(当前正在运行中的程序处理完所有事情后再停止)docker logs mynginx # -d运行前台没有输出，通过logs命令查看日志(可以加-f来持续追踪日志)docker attach # 绑定的是控制台. 可能导致容器停止，所有一般不用这个命令，而用execdocker container inspect 容器名 = docker inspect 容器名 # 查看容器的详细信息docker inspect image /network/volume ....docker cp index.html mynginx:/usr/share/nginx/html # 复制文件docker cp mynginx:/etc/nginx/nginx.conf nginx.confdocker diff 容器名 # 检查容器里文件系统结构的更改,即容器的改变docker commit -a 作者名 -m &quot;信息&quot; mynginx4 mynginx:v4 # mynginx:v4是给镜像起的名字docker save -o busybox.tar busybox:latest # 把busybox镜像保存成tar文件docker load -i busybox.tar # 把压缩包里面的内容直接导成镜像&nbsp; 容器的状态 &nbsp; Created（新建）、Up（运行中）、Pause（暂停）、Exited（退出）&nbsp;docker hub的一个镜像的完整路径&nbsp; 对于官方镜像：docker.io/library/仓库名/标签 对于非官方镜像：docker.io/仓库名/标签 &nbsp;推送镜像的过程：&nbsp; 注册docker hub并登录 可以创建一个仓库，选为public 登录远程docker仓库 ，docker login，输入用户名和密码。（判断是否登录cat ~/.docker/config.json 有 auth的值说明登录了 ） 给需要上传的镜像改名为：你的用户名/镜像名/标签，即docker tag 镜像名/标签 你的用户名/镜像名/标签 docker push docker.io/带用户名的镜像名/标签（docker.io/可以省略） &nbsp;制作镜像的过程：&nbsp; 新建Dockerfile文件 编写docker file中的内容 docker build构建镜像 &nbsp;例如：&nbsp;Dockerfile的内容：&nbsp;12FROM busyboxping baidu.com&nbsp; 构建镜像的命令： &nbsp;1docker build -t mybusy66:v6 -f Dockerfile ./&nbsp; 2、典型命令&nbsp; 1、docker run&nbsp;常用关键参数 OPTIONS 说明：&nbsp; -d: 后台运行容器，并返回容器ID； -i: 以交互模式运行容器，通常与 -t 同时使用； -P: 随机端口映射，容器内部端口随机映射到主机的端口 -p:指定端口映射，格式为：主机(宿主)端口:容器端口 -t: 为容器重新分配一个伪输入终端，通常与 -i 同时使用 --name=&quot;nginx-lb&quot;:为容器指定一个名称； --dns 8.8.8.8: 指定容器使用的DNS服务器，默认和宿主一致； --dns-search example.com: 指定容器DNS搜索域名，默认和宿主一致； -h &quot;mars&quot;: 指定容器的hostname； -e username=&quot;ritchie&quot;: 设置环境变量； --env-file=[]: 从指定文件读入环境变量； --cpuset=&quot;0-2&quot; or --cpuset=&quot;0,1,2&quot;: 绑定容器到指定CPU运行； -m:设置容器使用内存最大值； --net=&quot;bridge&quot;: 指定容器的网络连接类型，支持 bridge/host/none/container: 四种类型； --link=[]: 添加链接到另一个容器； --expose=[]: 开放一个端口或一组端口； --restart, 指定重启策略，可以写—restart=awlays 总是故障重启 --volume , -v: 绑定一个卷。一般格式 主机文件或文件夹:虚拟机文件或文件夹 &nbsp;使用Docker部署组件的步骤：&nbsp; 1、先去找组件的镜像 2、查看镜像文档，了解组件的可配置内容 3、docker run进行部署 &nbsp;12docker run --name myredis2 -p 6379:6379 -p 8888:6379 redis -d # 虚拟机的很多端口绑定容器的一个端口是允许的，虚拟机的一个端口绑定容器的多个端口是行不通的，因为从主机端口来的数据它不知道给谁。默认是前台启动的，一般加上-d 让他后台悄悄启动docker run -d == docker create + docker start&nbsp; 注意：直接用docker run busybox这个命令并不能启动busybox，这是因为busybox运行后没有阻塞进程的命令，启动后直接就退出了，也就是容器中没有人干活。docker run -it busybox（交互模式），docker run -d busybox ping baidu.com（启动后开启ping程序），这些命令才能运行。 &nbsp; 1、部署Nginx&nbsp;12345# 注意 外部的/nginx/conf下面的内容必须存在，否则挂载会覆盖docker run --name nginx-app \\-v /app/nginx/html:/usr/share/nginx/html:ro \\-v /app/nginx/conf:/etc/nginx-d nginx&nbsp; 2、部署MySQL&nbsp;12345678910111213141516# 5.7版本docker run -p 3306:3306 --name mysql57-app \\-v /app/mysql/log:/var/log/mysql \\-v /app/mysql/data:/var/lib/mysql \\-v /app/mysql/conf:/etc/mysql/conf.d \\-e MYSQL_ROOT_PASSWORD=123456 \\-d mysql:5.7#8.x版本,引入了 secure-file-priv 机制，磁盘挂载将没有权限读写data数据，所以需要将权限透传，或者chmod -R 777 /app/mysql/data# --privileged 特权容器，容器内使用真正的root用户docker run -p 3306:3306 --name mysql8-app \\-v /app/mysql/conf:/etc/mysql/conf.d \\-v /app/mysql/log:/var/log/mysql \\-v /app/mysql/data:/var/lib/mysql \\-e MYSQL_ROOT_PASSWORD=123456 \\--privileged \\-d mysql&nbsp; 3、部署Redis&nbsp;123456789# 提前准备好redis.conf文件，创建好相应的文件夹。如：port 6379appendonly yes#更多配置参照 https://raw.githubusercontent.com/redis/redis/6.0/redis.confdocker run -p 6379:6379 --name redis \\-v /app/redis/redis.conf:/etc/redis/redis.conf \\-v /app/redis/data:/data \\-d redis:6.2.1-alpine3.13 \\redis-server /etc/redis/redis.conf --appendonly yes&nbsp; 4、部署ElasticSearch&nbsp;123456789101112#准备文件和文件夹，并chmod -R 777 xxx#配置文件内容，参照https://www.elastic.co/guide/en/elasticsearch/reference/7.5/node.name.html 搜索相关配置# 考虑为什么挂载使用esconfig ...docker run --name=elasticsearch -p 9200:9200 -p 9300:9300 \\-e &quot;discovery.type=single-node&quot; \\-e ES_JAVA_OPTS=&quot;-Xms300m -Xmx300m&quot; \\-v /app/es/data:/usr/share/elasticsearch/data \\-v /app/es/plugins:/usr/shrae/elasticsearch/plugins \\-v esconfig:/usr/share/elasticsearch/config \\-d elasticsearch:7.12.0&nbsp; 5、部署Tomcat&nbsp;12345# 考虑，如果我们每次 -v 都是指定磁盘路径，是不是很麻烦？docker run --name tomcat-app -p 8080:8080 \\-v tomcatconf:/usr/local/tomcat/conf \\-v tomcatwebapp:/usr/local/tomcat/webapps \\-d tomcat:jdk8-openjdk-slim-buster&nbsp; 6、重启策略&nbsp; no，默认策略，在容器退出时不重启容器 on-failure，在容器非正常退出时（退出状态非0），才会重启容器 on-failure:3，在容器非正常退出时重启容器，最多重启3次 always，在容器退出时总是重启容器 unless-stopped，在容器退出时总是重启容器，但是不考虑在Docker守护进程启动时就已经停止了的容器 &nbsp; 2、docker exec&nbsp;1docker exec -it -u 0:0 mynginx4 /bin/bash # -i表示交互模式，-t表示新的终端 -u 0:0表示用户的属主和属组（换成--privileged表示以root身份进入容器），/bin/bash是控制台程序（可以通过exit退出bash终端）&nbsp; 3、docker create&nbsp;123456docker create [OPTIONS] IMAGE [COMMAND] [ARG...]docker create [设置项] 镜像名 [启动命令] [启动参数...]docker create redis # 按照redis:latest镜像启动一个容器docker create --name myredis -p 6379（主机的端口）:6379（容器的端口） redis # --name表示给容器起名，-p是端口绑定 （-p port1:port2） port1到port2是主机端口到容器端口的映射。docker start myredis # 创建之后启动容器 &nbsp;","categories":[{"name":"云原生","slug":"云原生","permalink":"http://wht6.github.io/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://wht6.github.io/tags/Docker/"},{"name":"容器","slug":"容器","permalink":"http://wht6.github.io/tags/%E5%AE%B9%E5%99%A8/"}]},{"title":"bytes包与字节串操作","slug":"bytes包与字节串操作","date":"2022-03-13T02:00:00.000Z","updated":"2022-03-20T01:59:53.491Z","comments":true,"path":"posts/b956.html","link":"","permalink":"http://wht6.github.io/posts/b956.html","excerpt":"","text":"bytes.Buffer基础知识&nbsp; strings包和bytes包可以说是一对孪生兄弟，它们在 API 方面非常的相似。单从它们提供的函数的数量和功能上讲，差别可以说是微乎其微。&nbsp;只不过，strings包主要面向的是 Unicode 字符和经过 UTF-8 编码的字符串，而bytes包面对的则主要是字节和字节切片。&nbsp;bytes.Buffer类型的用途主要是作为字节序列的缓冲区。与strings.Builder类型一样，bytes.Buffer也是开箱即用的。&nbsp;但不同的是，strings.Builder只能拼接和导出字符串，而bytes.Buffer不但可以拼接、截断其中的字节序列，以各种形式导出其中的内容，还可以顺序地读取其中的子序列。&nbsp;可以说，bytes.Buffer是集读、写功能于一身的数据类型。当然了，这些也基本上都是作为一个缓冲区应该拥有的功能。&nbsp;在内部，bytes.Buffer类型同样是使用字节切片作为内容容器的。并且，与strings.Reader类型类似，bytes.Buffer有一个int类型的字段，用于代表已读字节的计数，可以简称为已读计数。&nbsp;不过，这里的已读计数就无法通过bytes.Buffer提供的方法计算出来了。&nbsp;123456var buffer1 bytes.Buffercontents := &quot;Simple byte buffer for marshaling data.&quot;fmt.Printf(&quot;Writing contents %q ...\\n&quot;, contents)buffer1.WriteString(contents)fmt.Printf(&quot;The length of buffer: %d\\n&quot;, buffer1.Len())fmt.Printf(&quot;The capacity of buffer: %d\\n&quot;, buffer1.Cap())&nbsp; 我先声明了一个bytes.Buffer类型的变量buffer1，并写入了一个字符串。然后，我想打印出这个bytes.Buffer类型的值（以下简称Buffer值）的长度和容量。在运行这段代码之后，我们将会看到如下的输出： &nbsp;123Writing contents &quot;Simple byte buffer for marshaling data.&quot; ...The length of buffer: 39The capacity of buffer: 64&nbsp; 乍一看这没什么问题。长度39和容量64的含义看起来与我们已知的概念是一致的。我向缓冲区中写入了一个长度为39的字符串，所以buffer1的长度就是39。 &nbsp;根据切片的自动扩容策略，64这个数字也是合理的。另外，可以想象，这时的已读计数的值应该是0，这是因为我还没有调用任何用于读取其中内容的方法。&nbsp;可实际上，与strings.Reader类型的Len方法一样，buffer1的Len方法返回的也是内容容器中未被读取部分的长度，而不是其中已存内容的总长度（以下简称内容长度）。示例如下：&nbsp;12345p1 := make([]byte, 7)n, _ := buffer1.Read(p1)fmt.Printf(&quot;%d bytes were read. (call Read)\\n&quot;, n)fmt.Printf(&quot;The length of buffer: %d\\n&quot;, buffer1.Len())fmt.Printf(&quot;The capacity of buffer: %d\\n&quot;, buffer1.Cap())&nbsp; 当我从buffer1中读取一部分内容，并用它们填满长度为7的字节切片p1之后，buffer1的Len方法返回的结果值也会随即发生变化。如果运行这段代码，我们会发现，这个缓冲区的长度已经变为了32。 &nbsp;另外，因为我们并没有再向该缓冲区中写入任何内容，所以它的容量会保持不变，仍是64。&nbsp;总之，在这里，你需要记住的是，Buffer值的长度是未读内容的长度，而不是已存内容的总长度。 它与在当前值之上的读操作和写操作都有关系，并会随着这两种操作的进行而改变，它可能会变得更小，也可能会变得更大。&nbsp;而Buffer值的容量指的是它的内容容器（也就是那个字节切片）的容量，它只与在当前值之上的写操作有关，并会随着内容的写入而不断增长。&nbsp;再说已读计数。由于strings.Reader还有一个Size方法可以给出内容长度的值，所以我们用内容长度减去未读部分的长度，就可以很方便地得到它的已读计数。&nbsp;然而，bytes.Buffer类型却没有这样一个方法，它只有Cap方法。可是Cap方法提供的是内容容器的容量，也不是内容长度。&nbsp;并且，这里的内容容器容量在很多时候都与内容长度不相同。因此，没有了现成的计算公式，只要遇到稍微复杂些的情况，我们就很难估算出Buffer值的已读计数。&nbsp;一旦理解了已读计数这个概念，并且能够在读写的过程中，实时地获得已读计数和内容长度的值，我们就可以很直观地了解到当前Buffer值各种方法的行为了。不过，很可惜，这两个数字我们都无法直接拿到。&nbsp;虽然，我们无法直接得到一个Buffer值的已读计数，并且有时候也很难估算它，但是我们绝对不能就此作罢，而应该通过研读bytes.Buffer和文档和源码，去探究已读计数在其中起到的关键作用。&nbsp;否则，我们想用好bytes.Buffer的意愿，恐怕就不会那么容易实现了。&nbsp;下面的这个问题，如果你认真地阅读了bytes.Buffer的源码之后，就可以很好地回答出来。&nbsp;bytes.Buffer类型的值记录的已读计数，在其中起到了怎样的作用？&nbsp;bytes.Buffer中的已读计数的大致功用如下所示。&nbsp; 读取内容时，相应方法会依据已读计数找到未读部分，并在读取后更新计数。 写入内容时，如需扩容，相应方法会根据已读计数实现扩容策略。 截断内容时，相应方法截掉的是已读计数代表索引之后的未读部分。 读回退时，相应方法需要用已读计数记录回退点。 重置内容时，相应方法会把已读计数置为0。 导出内容时，相应方法只会导出已读计数代表的索引之后的未读部分。 获取长度时，相应方法会依据已读计数和内容容器的长度，计算未读部分的长度并返回。 &nbsp;通过上面的典型回答，我们已经能够体会到已读计数在bytes.Buffer类型，及其方法中的重要性了。没错，bytes.Buffer的绝大多数方法都用到了已读计数，而且都是非用不可。&nbsp;在读取内容的时候，相应方法会先根据已读计数，判断一下内容容器中是否还有未读的内容。如果有，那么它就会从已读计数代表的索引处开始读取。&nbsp;在读取完成后，它还会及时地更新已读计数。也就是说，它会记录一下又有多少个字节被读取了。这里所说的相应方法包括了所有名称以Read开头的方法，以及Next方法和WriteTo方法。&nbsp;在写入内容的时候，绝大多数的相应方法都会先检查当前的内容容器，是否有足够的容量容纳新的内容。如果没有，那么它们就会对内容容器进行扩容。&nbsp;在扩容的时候，方法会在必要时，依据已读计数找到未读部分，并把其中的内容拷贝到扩容后内容容器的头部位置。&nbsp;然后，方法将会把已读计数的值置为0，以表示下一次读取需要从内容容器的第一个字节开始。用于写入内容的相应方法，包括了所有名称以Write开头的方法，以及ReadFrom方法。&nbsp;用于截断内容的方法Truncate，会让很多对bytes.Buffer不太了解的程序开发者迷惑。 它会接受一个int类型的参数，这个参数的值代表了：在截断时需要保留头部的多少个字节。&nbsp;不过，需要注意的是，这里说的头部指的并不是内容容器的头部，而是其中的未读部分的头部。头部的起始索引正是由已读计数的值表示的。因此，在这种情况下，已读计数的值再加上参数值后得到的和，就是内容容器新的总长度。&nbsp;在bytes.Buffer中，用于读回退的方法有UnreadByte和UnreadRune。 这两个方法分别用于回退一个字节和回退一个 Unicode 字符。调用它们一般都是为了退回在上一次被读取内容末尾的那个分隔符，或者为重新读取前一个字节或字符做准备。&nbsp;不过，退回的前提是，在调用它们之前的那一个操作必须是“读取”，并且是成功的读取，否则这些方法就只能忽略后续操作并返回一个非nil的错误值。&nbsp;UnreadByte方法的做法比较简单，把已读计数的值减1就好了。而UnreadRune方法需要从已读计数中减去的，是上一次被读取的 Unicode 字符所占用的字节数。&nbsp;这个字节数由bytes.Buffer的另一个字段负责存储，它在这里的有效取值范围是 [1, 4]。只有ReadRune方法才会把这个字段的值设定在此范围之内。&nbsp;由此可见，只有紧接在调用ReadRune方法之后，对UnreadRune方法的调用才能够成功完成。该方法明显比UnreadByte方法的适用面更窄。&nbsp;我在前面说过，bytes.Buffer的Len方法返回的是内容容器中未读部分的长度，而不是其中已存内容的总长度（即：内容长度）。&nbsp;而该类型的Bytes方法和String方法的行为，与Len方法是保持一致的。前两个方法只会去访问未读部分中的内容，并返回相应的结果值。&nbsp;在我们剖析了所有的相关方法之后，可以这样来总结：在已读计数代表的索引之前的那些内容，永远都是已经被读过的，它们几乎没有机会再次被读取。&nbsp;不过，这些已读内容所在的内存空间可能会被存入新的内容。这一般都是由于重置或者扩充内容容器导致的。这时，已读计数一定会被置为0，从而再次指向内容容器中的第一个字节。这有时候也是为了避免内存分配和重用内存空间。&nbsp;bytes.Buffer的扩容策略是怎样的？&nbsp;Buffer值既可以被手动扩容，也可以进行自动扩容。并且，这两种扩容方式的策略是基本一致的。所以，除非我们完全确定后续内容所需的字节数，否则让Buffer值自动去扩容就好了。&nbsp;在扩容的时候，Buffer值中相应的代码（以下简称扩容代码）会先判断内容容器的剩余容量，是否可以满足调用方的要求，或者是否足够容纳新的内容。&nbsp;如果可以，那么扩容代码会在当前的内容容器之上，进行长度扩充。&nbsp;更具体地说，如果内容容器的容量与其长度的差，大于或等于另需的字节数，那么扩容代码就会通过切片操作对原有的内容容器的长度进行扩充，就像下面这样：&nbsp;1b.buf = b.buf[:length+need]&nbsp; 反之，如果内容容器的剩余容量不够了，那么扩容代码可能就会用新的内容容器去替代原有的内容容器，从而实现扩容。 &nbsp;不过，这里还有一步优化。&nbsp;如果当前内容容器的容量的一半，仍然大于或等于其现有长度再加上另需的字节数的和，即：&nbsp;1cap(b.buf)/2 &gt;= len(b.buf)+need&nbsp; 那么，扩容代码就会复用现有的内容容器，并把容器中的未读内容拷贝到它的头部位置。 &nbsp;这也意味着其中的已读内容，将会全部被未读内容和之后的新内容覆盖掉。&nbsp;这样的复用预计可以至少节省掉一次后续的扩容所带来的内存分配，以及若干字节的拷贝。&nbsp;若这一步优化未能达成，也就是说，当前内容容器的容量小于新长度的二倍。&nbsp;那么，扩容代码就只能再创建一个新的内容容器，并把原有容器中的未读内容拷贝进去，最后再用新的容器替换掉原有的容器。这个新容器的容量将会等于原有容量的二倍再加上另需字节数的和。&nbsp; 新容器的容量 =2* 原有容量 + 所需字节数 &nbsp;通过上面这些步骤，对内容容器的扩充基本上就完成了。不过，为了内部数据的一致性，以及避免原有的已读内容可能造成的数据混乱，扩容代码还会把已读计数置为0，并再对内容容器做一下切片操作，以掩盖掉原有的已读内容。&nbsp;顺便说一下，对于处在零值状态的Buffer值来说，如果第一次扩容时的另需字节数不大于64，那么该值就会基于一个预先定义好的、长度为64的字节数组来创建内容容器。&nbsp;在这种情况下，这个内容容器的容量就是64。这样做的目的是为了让Buffer值在刚被真正使用的时候就可以快速地做好准备。&nbsp;bytes.Buffer中的哪些方法可能会造成内容的泄露？&nbsp;首先明确一点，什么叫内容泄露？这里所说的内容泄露是指，使用Buffer值的一方通过某种非标准的（或者说不正式的）方式，得到了本不该得到的内容。&nbsp;比如说，我通过调用Buffer值的某个用于读取内容的方法，得到了一部分未读内容。我应该，也只应该通过这个方法的结果值，拿到在那一时刻Buffer值中的未读内容。&nbsp;但是，在这个Buffer值又有了一些新内容之后，我却可以通过当时得到的结果值，直接获得新的内容，而不需要再次调用相应的方法。&nbsp;这就是典型的非标准读取方式。这种读取方式是不应该存在的，即使存在，我们也不应该使用。因为它是在无意中（或者说一不小心）暴露出来的，其行为很可能是不稳定的。&nbsp;在bytes.Buffer中，Bytes方法和Next方法都可能会造成内容的泄露。原因在于，它们都把基于内容容器的切片直接返回给了方法的调用方。&nbsp;我们都知道，通过切片，我们可以直接访问和操纵它的底层数组。不论这个切片是基于某个数组得来的，还是通过对另一个切片做切片操作获得的，都是如此。&nbsp;在这里，Bytes方法和Next方法返回的字节切片，都是通过对内容容器做切片操作得到的。也就是说，它们与内容容器共用了同一个底层数组，起码在一段时期之内是这样的。&nbsp;以Bytes方法为例。它会返回在调用那一刻其所属值中的所有未读内容。示例代码如下：&nbsp; 123456contents := &quot;ab&quot;buffer1 := bytes.NewBufferString(contents)fmt.Printf(&quot;The capacity of new buffer with contents %q: %d\\n&quot;, contents, buffer1.Cap()) // 内容容器的容量为：8。unreadBytes := buffer1.Bytes()fmt.Printf(&quot;The unread bytes of the buffer: %v\\n&quot;, unreadBytes) // 未读内容为：[97 98]。 &nbsp; 我用字符串值&quot;ab&quot;初始化了一个Buffer值，由变量buffer1代表，并打印了当时该值的一些状态。 &nbsp;你可能会有疑惑，我只在这个Buffer值中放入了一个长度为2的字符串值，但为什么该值的容量却变为了8。&nbsp;虽然这与我们当前的主题无关，但是我可以提示你一下：你可以去阅读runtime包中一个名叫stringtoslicebyte的函数，答案就在其中。&nbsp;接着说buffer1。我又向该值写入了字符串值&quot;cdefg&quot;，此时，其容量仍然是8。我在前面通过调用buffer1的Bytes方法得到的结果值unreadBytes，包含了在那时其中的所有未读内容。&nbsp;但是，由于这个结果值与buffer1的内容容器在此时还共用着同一个底层数组，所以，我只需通过简单的再切片操作，就可以利用这个结果值拿到buffer1在此时的所有未读内容。如此一来，buffer1的新内容就被泄露出来了。&nbsp;1234buffer1.WriteString(&quot;cdefg&quot;)fmt.Printf(&quot;The capacity of buffer: %d\\n&quot;, buffer1.Cap()) // 内容容器的容量仍为：8。unreadBytes = unreadBytes[:cap(unreadBytes)]fmt.Printf(&quot;The unread bytes of the buffer: %v\\n&quot;, unreadBytes) // 基于前面获取到的结果值可得，未读内容为：[97 98 99 100 101 102 103 0]。&nbsp; 如果我当时把unreadBytes的值传到了外界，那么外界就可以通过该值操纵buffer1的内容了，就像下面这样： &nbsp;12unreadBytes[len(unreadBytes)-2] = byte(&#x27;X&#x27;) // &#x27;X&#x27;的 ASCII 编码为 88。fmt.Printf(&quot;The unread bytes of the buffer: %v\\n&quot;, buffer1.Bytes()) // 未读内容变为了：[97 98 99 100 101 102 88]。&nbsp; 现在，你应该能够体会到，这里的内容泄露可能造成的严重后果了吧？对于Buffer值的Next方法，也存在相同的问题。 &nbsp;不过，如果经过扩容，Buffer值的内容容器或者它的底层数组被重新设定了，那么之前的内容泄露问题就无法再进一步发展了。&nbsp;&nbsp; 参考链接：https://time.geekbang.org/column/intro/112","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Go语言","slug":"Go语言","permalink":"http://wht6.github.io/tags/Go%E8%AF%AD%E8%A8%80/"}]},{"title":"深入类和对象","slug":"深入类和对象","date":"2022-03-12T02:00:00.000Z","updated":"2022-03-20T01:59:38.267Z","comments":true,"path":"posts/9a3b.html","link":"","permalink":"http://wht6.github.io/posts/9a3b.html","excerpt":"","text":"鸭子类型：当看到一只鸟走起来像鸭子、游泳起来像鸭子、叫起来也像鸭子，那么这只鸟就可以被称为鸭子。 &nbsp; Java中实现多态的方式是定义一个父类，再定义一些子类，然后在这些子类中重写父类的方法。我们可以定义一个父类类型的变量并用子类来实例化它。&nbsp;1234567891011121314151617181920212223242526class Animal&#123; void say()&#123; System.out.println(&quot;i am a animal&quot;); &#125;&#125;class Cat extends Animal&#123; void say()&#123; System.out.println(&quot;i am a cat&quot;); &#125;&#125;class Dog extends Animal&#123; void say()&#123; System.out.println(&quot;i am a dog&quot;); &#125;&#125;class Duck extends Animal&#123; void say()&#123; System.out.println(&quot;i am a duck&quot;); &#125;&#125;Animal an = new Cat();an.say();&nbsp; 在Python中实现同样的效果，则不需要继承。下面是Python中的实现代码。 &nbsp;1234567891011121314class Cat(object): def say(self): print(&quot;i am a cat&quot;)class Dog(object): def say(self): print(&quot;i am a fish&quot;) class Duck(object): def say(self): print(&quot;i am a duck&quot;)animal = Catanimal().say()&nbsp; 在Python中animal就是一个动态类型，可以将任意的对象赋值给它。这样我们只需要在每个类中定义相同名称的方法，就可以轻松的实现多态。 &nbsp;123animal_list = [Cat, Dog, Duck]for animal in animal_list: animal().say()&nbsp; 这些实现同样方法的类的集合就可以划分成同一类型，这就是鸭子类型。 &nbsp;12345678910a = [&quot;bobby1&quot;, &quot;bobby2&quot;]b = [&quot;bobby2&quot;, &quot;bobby&quot;]name_tuple = (&quot;bobby3&quot;, &quot;bobby4&quot;)name_set = set()name_set.add(&quot;bobby5&quot;)name_set.add(&quot;bobby6&quot;)a.extend(b)a.extend(name_tuple)a.extend(name_set)&nbsp; 这里的extend()方法可以接收list、tuple、set，并没有限定一个特定的类型，只要是可迭代的类型都可以传进来，这个可迭代类型就是一个鸭子类型。结合魔法函数，我们可以自定义一个可迭代的类型，那么这个类型就也能够作为extend()方法的参数。 &nbsp;抽象基类又称为abc（abstract base class）模块。抽象基类类似于Java中的接口，都是不能实例化的。&nbsp;变量在Python中只是一个符号，它可以指向任意类型的对象，也就是变量本身的动态类型的属性就包含了多态。&nbsp;第一，抽象基类预先定义一些方法，所有继承抽象基类的子类都需要覆盖这些方法；第二，抽象基类无法被实例化。&nbsp; 抽象基类的作用&nbsp;用抽象基类去检查某个类是否具有某种方法，或者是否属于某种类型。&nbsp;12345678910class Company(object): def __init__(self, employee_list): self.employee = employee_list def __len__(self): return len(self.employee)com = Company([&quot;bobby1&quot;,&quot;bobby2&quot;])print(hasattr(com, &quot;__len__&quot;))&nbsp; 上面这种方法用到的是hasattr方法，其实我们更习惯的是判断Company是否是可测量长度的类型（Sized），就用到了抽象基类。Sized在collections.abc这个包当中，这个包主要是用来判断某个类型是否是具有某种属性的，里边除了用到了抽象基类，还用到了__subclasshook__这个魔法函数。 &nbsp;12from collections.abc import Sizedisinstance(com, Sized)&nbsp; 用抽象基类去强制某个子类必须实现某些方法。 &nbsp;比如，需要自定义一个web框架，但是为了保证后期的可扩展性和灵活性，我们想只定义方法而不实现方法的内容，让其子类去实现方法的内容，就可以用到抽象基类来解决。&nbsp;下面模拟一个抽象基类：&nbsp;1234567891011class CacheBase(): def get(self, key): raise NotImplementedError def set(self, key, value): raise NotImplementedError class RedisCache(CacheBase): passredis_cache = RedisCache()redis_cache.set(&quot;key&quot;, &quot;value&quot;)&nbsp; 当我们的子类中没有实现父类中的相关方法，而去调用该方法的时候就会抛出异常：NotImplementedError。 &nbsp;123456789101112class CacheBase(): def get(self, key): raise NotImplementedError def set(self, key, value): raise NotImplementedError class RedisCache(CacheBase): def set(self, key, value): passredis_cache = RedisCache()redis_cache.set(&quot;key&quot;, &quot;value&quot;)&nbsp; 当我们的子类中实现了父类中的相关方法，再去调用就不会抛异常。 &nbsp;这里只是在调用某个方法的时候才抛异常，我们更希望在初始化的时候就抛出异常。同时上面的方法也不能保证子类方法的全覆盖。&nbsp; 抽象基类的使用&nbsp;首先需要引用全局的abc包，然后继承元类abc.ABCMeta。这里的@abc.abstractmethod是装饰器。&nbsp;123456789101112131415import abcclass CacheBase(metaclass=abc.ABCMeta): @abc.abstractmethod def get(self, key): pass @abc.abstractmethod def set(self, key, value): pass class RedisCache(CacheBase): passredis_cache = RedisCache()&nbsp; 这段代码因为定义了抽象基类，所有在初始化的时候就会抛异常。 &nbsp;123class RedisCache(CacheBase): def set(self, key, value): pass&nbsp; 如果我们只实现了set方法，而没有实现get方法，那么在初始化的时候同样会抛异常。所有子类中必须实现继承的抽象基类中的所有方法。 &nbsp; isinstance和type&nbsp;123456789101112class A: passclass B(A): passb = B()print(isinstance(b, B))print(isinstance(b, A))print(type(b) is B)print(type(b) is A)&nbsp; 这段代码的输出结果是： &nbsp;1234TrueTrueTrueFalse&nbsp; isinstance可以去查找对象的继承链获取继承关系，而type查找的只是对象本身的类型而已。 &nbsp; 类变量和实例变量&nbsp;12345678class A: aa = 1 def __init__(self, x, y): self.x = x self.y = ya = A(2,3)print(a.x, a.y, a.aa)&nbsp; 这里边x和y都是实例变量（类里边的self代表的是一个实例），而aa是类变量。 &nbsp;如果我们打印A.aa也是卡可以的，但是如果我们打印A.x或A.y就会抛异常。我们在使用a.aa的时候，解释器会先去实例a里边查找，如果找不到，则会向上去它的类A里边查找。&nbsp;123A.aa = 11print(a.x, a.y, a.aa)print(A.a)&nbsp; 输出结果是： &nbsp;122 3 1111&nbsp; 如果我们改变了类变量的值，当我们再次通过实例来获取该值的时候，值也会改变，因为本质上还是查找到类变量。 &nbsp;123a.aa = 100print(a.x, a.y, a.aa)print(A.a)&nbsp; 输出结果是： &nbsp;122 3 10011&nbsp; 当我们给a.aa赋值的时候，实际上是在实例中新建了一个新的属性aa并赋值100。再去通过实例获取该值的时候，因为先去实例中查找，所以找到的就是100。当我们通过类去获取aa的值的时候还是11，实例的变化并不会影响到类。 &nbsp;在单继承的类里边，直接安装自下而上的顺序查找，对于包含多继承的继承链，查找顺序就是安装MRO算法来查找。Python中的MRO（方法查询顺序）算法用的是C3算法。最早用的是深度优先算法，后来改为广度优先算法，但是这两张方法都有问题，现在用的是比较复杂的C3算法。&nbsp;我们并不需要知道C3算法去推算方法查找的顺序，我们可以直接调用魔法函数__mro__来获取方法查找顺序。&nbsp; 类方法、静态方法和实例方法&nbsp;123456789101112131415161718class Date: #构造函数 def __init__(self, year, month, day): self.year = year self.month = month self.day = day def tomorrow(self): self.day += 1 def __str__(self): return &quot;&#123;year&#125;/&#123;month&#125;/&#123;day&#125;&quot;.format(year=self.year, month=self.month, day=self.day) if __name__ == &quot;__main__&quot;: new_day = Date(2022, 3, 12) new_day.tomorrow() print(new_day)&nbsp; self关键字代表的就是实例，而对应的方法就是实例方法。我们在调用实例方法的时候不用将实例作为参数进行传递，Python解释器会自动的帮我们完成。 &nbsp;如果我们想在初始化的时候传递一个字符串进去，就可以加入一个静态方法。&nbsp;1234567891011121314151617181920212223class Date: #构造函数 def __init__(self, year, month, day): self.year = year self.month = month self.day = day def tomorrow(self): self.day += 1 @staticmethod def parse_from_string(date_str): year, month, day = tuple(date_str.split(&quot;-&quot;)) return Date(int(year), int(month), int(day)) def __str__(self): return &quot;&#123;year&#125;/&#123;month&#125;/&#123;day&#125;&quot;.format(year=self.year, month=self.month, day=self.day) if __name__ == &quot;__main__&quot;: date_str = &quot;2018-12-31&quot; new_day = Date.parse_from_string(date_str) print (new_day)&nbsp; 静态方法的参数列表中，既没有代表实例的self，也没有类本身。但是我们在调用的时候要从类里边调用，因为它属于类的命名空间。但是静态方法如果用到了类本身，比如上面代码中的parse_from_string方法在返回值的地方用到了类本身Date，当我们更改类名称的时候，方法里边的类名称也要修改。所以如果方法中涉及到类本身，最好使用类方法。 &nbsp;1234567891011121314151617181920212223class Date: #构造函数 def __init__(self, year, month, day): self.year = year self.month = month self.day = day def tomorrow(self): self.day += 1 @classmethod def from_string(cls, date_str): year, month, day = tuple(date_str.split(&quot;-&quot;)) return cls(int(year), int(month), int(day)) def __str__(self): return &quot;&#123;year&#125;/&#123;month&#125;/&#123;day&#125;&quot;.format(year=self.year, month=self.month, day=self.day) if __name__ == &quot;__main__&quot;: date_str = &quot;2018-12-31&quot; new_day = Date.from_string(date_str) print (new_day)&nbsp; 这里的from_string就是一个类方法，cls代表的是类本身。当我们不涉及类本身的使用的时候就可以用静态方法。 &nbsp;1234567@staticmethod def valid_str(date_str): year, month, day = tuple(date_str.split(&quot;-&quot;)) if int(year)&gt;0 and (int(month) &gt;0 and int(month)&lt;=12) and (int(day) &gt;0 and int(day)&lt;=31): return True else: return False&nbsp; 类方法前边必须加装饰器@classmethod，静态方法前边必须加装饰器@staticmethod，实例方法不用加装饰器。 &nbsp;Python中没有private和protected关键字，那么它是如何实现私有属性的呢？&nbsp;1234567891011121314from chapter04.class_method import Dateclass User: def __init__(self, birthday): self.__birthday = birthday def get_age(self): #返回年龄 return 2018 - self.__birthday.yearif __name__ == &quot;__main__&quot;: user = User(Date(1990,2,1)) # print(user.__birthday) # 这么调用会报错 print(user.get_age())&nbsp; 通过在变量名的前边加上双下划线来表明该变量是私有变量，只能在定义它的类的内部使用。实际上的内部实现是把变量变成_class_attribute的形式，这里我们通过访问user._User__birthday还是可以访问的，所以Python的私有属性只是在形式上的私有，并非强制的私有。另外，私有方法也是在方法名的前边加上双下划线。 &nbsp;123456789101112131415class Person: &quot;&quot;&quot; 人 &quot;&quot;&quot; name = &quot;user&quot;class Student(Person): def __init__(self, scool_name): self.scool_name = scool_nameif __name__ == &quot;__main__&quot;: user = Student(&quot;慕课网&quot;) #通过__dict__查询属性 print(user.__dict__) print(user.name)&nbsp; 这段代码的输出结果是： &nbsp;12&#123;&#39;scool_name&#39;: &#39;慕课网&#39;&#125;user&nbsp; __dict__是用来查询对象的属性的，包括部分的隐藏的属性。通过__dict__方法无法查询到name属性，因为name属性并不在实例user里边，但是我们在使用user.name的时候，根据MRO算法会向上查询到它的父类，进而查询到该属性。 &nbsp;如果我们查询类Person的属性，就会发现更为的丰富，因为类是一种特殊的对象，并且包含了更多的隐藏的属性。如果打印Person.__dict__，输出如下：&nbsp;1&#123;&#39;__module__&#39;: &#39;__main__&#39;, &#39;__doc__&#39;: &#39;\\n 人\\n &#39;, &#39;name&#39;: &#39;user&#39;, &#39;__dict__&#39;: &lt;attribute &#39;__dict__&#39; of &#39;Person&#39; objects&gt;, &#39;__weakref__&#39;: &lt;attribute &#39;__weakref__&#39; of &#39;Person&#39; objects&gt;&#125;&nbsp; 并且我们还能够直接使用__dict__方法来更改属性。比如： &nbsp;12user.__dict__[&quot;school_addr&quot;] = &quot;北京市&quot;print(user.school_addr)&nbsp; 我们添加了一个新的属性school_addr并打印了它的值。 &nbsp;Python还提供了一个全局的方法dir(a)用于查询对象的所有属性，包括所有隐藏的属性。&nbsp;Python中我们如何调用父类的方法呢？这里就要用到super()方法。&nbsp;1234567891011class A: def __init__(self): print (&quot;A&quot;)class B(A): def __init__(self): print (&quot;B&quot;) super().__init__()if __name__ == &quot;__main__&quot;: b = B()&nbsp; 再来看一段代码，这段代码中包含了多继承。 &nbsp;123456789101112131415161718192021class A: def __init__(self): print (&quot;A&quot;)class B(A): def __init__(self): print (&quot;B&quot;) super().__init__()class C(A): def __init__(self): print (&quot;C&quot;) super().__init__() class D(B, C): def __init__(self): print (&quot;D&quot;) super(D, self).__init__()if __name__ == &quot;__main__&quot;: d = D()&nbsp; super()并不是调用它父类中的方法，而是调用MRO算法查找到的下一个类的方法。所有上面这段代码的输出结果是： &nbsp;1234DBCA&nbsp; 我们可以通过打印D.__mro__来验证。 &nbsp;我们在使用Python的过程中并不推荐使用多继承，因为这样可能会导致继承关系的混乱，还有可能出现一些意想不到的问题。但是这并不意味着多继承就不能用了，如果能提前设计好框架，提前做好预防，还是可以使用的，比如Python中的一种混合模式mixin。&nbsp;mixin模式会定义许多mixin类，每一个类只包含单一的功能，我们通过继承这些类来直接使用mixin类的功能。并且mixin类中都不会包含super方法。&nbsp; 上下文管理器&nbsp;123456789101112131415161718def exe_try(): try: print (&quot;code started&quot;) raise KeyError return 1 except KeyError as e: print (&quot;key error&quot;) return 2 else: print (&quot;other error&quot;) return 3 finally: print (&quot;finally&quot;) return 4if __name__ == &quot;__main__&quot;: result = exe_try() print (result)&nbsp; 首先正常的try语句的执行顺序是先执行try里面的代码，如果抛出异常，就进而去执行except中捕获异常的代码，如果没有抛出异常，就执行else中的代码，然后不管怎样finally中的代码都会在最后执行。所有我们通常会在try里面获取资源，在finally中释放资源。 &nbsp;那么为什么这段代码中的print (result)的结果是4呢？这是因为在执行到except中时，会把return的返回值压入栈中，到了finally中又把return的返回值压入栈中，最后从栈顶获取一个返回值，就是4。&nbsp;上下文管理器就是Python设计用来简化try结构的。&nbsp;1234567891011121314# 上下文管理器class Sample: def __enter__(self): print (&quot;enter&quot;) #获取资源 return self def __exit__(self, exc_type, exc_val, exc_tb): #释放资源 print (&quot;exit&quot;) def do_something(self): print (&quot;doing something&quot;) with Sample() as sample: sample.do_something() &nbsp; 这段代码的输出结果如下： &nbsp;123enterdoing somethingexit&nbsp; 当我们定义了__enter__和__exit__这两个魔法函数的时候，就可以使用with语句来实例化这个类，并且在进入with语句的时候会去自动执行__enter__方法，退出with语句的时候会去自动执行__exit__方法。 &nbsp;利用Python提供的contextlib包还能够进一步简化上下文管理器。通过使用装饰器@contextlib.contextmanager我们可以直接把一个函数变成一个上下文管理器。&nbsp;12345678910import contextlib@contextlib.contextmanagerdef file_open(file_name): print (&quot;file open&quot;) yield &#123;&#125; print (&quot;file end&quot;)with file_open(&quot;bobby.txt&quot;) as f_opened: print (&quot;file processing&quot;)&nbsp; yield &#123;&#125;是一个生成器，它之前的代码就相当于__enter__方法中的代码，它之后的代码就相当于__exit__方法中的代码。","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Python语言","slug":"Python语言","permalink":"http://wht6.github.io/tags/Python%E8%AF%AD%E8%A8%80/"}]},{"title":"strings包与字符串操作","slug":"strings包与字符串操作","date":"2022-03-11T02:00:00.000Z","updated":"2022-03-20T01:59:09.527Z","comments":true,"path":"posts/d8b5.html","link":"","permalink":"http://wht6.github.io/posts/d8b5.html","excerpt":"","text":"标准库中的strings代码包用到了不少unicode包和unicode/utf8包中的程序实体。比如，strings.Builder类型的WriteRune方法、strings.Reader类型的ReadRune方法，等等。 &nbsp; 与string值相比，strings.Builder类型的值有哪些优势？&nbsp;strings.Builder类型的值（以下简称Builder值）的优势有下面的三种：&nbsp; 已存在的内容不可变，但可以拼接更多的内容； 减少了内存分配和内容拷贝的次数； 可将内容重置，可重用值。 &nbsp;先来说说string类型。 我们都知道，在 Go 语言中，string类型的值是不可变的。 如果我们想获得一个不一样的字符串，那么就只能基于原字符串进行裁剪、拼接等操作，从而生成一个新的字符串。&nbsp; 裁剪操作可以使用切片表达式； 拼接操作可以用操作符+实现。 &nbsp;在底层，一个string值的内容会被存储到一块连续的内存空间中。同时，这块内存容纳的字节数量也会被记录下来，并用于表示该string值的长度。&nbsp;你可以把这块内存的内容看成一个字节数组，而相应的string值则包含了指向字节数组头部的指针值。如此一来，我们在一个string值上应用切片表达式，就相当于在对其底层的字节数组做切片。&nbsp;另外，我们在进行字符串拼接的时候，Go 语言会把所有被拼接的字符串依次拷贝到一个崭新且足够大的连续内存空间中，并把持有相应指针值的string值作为结果返回。&nbsp;显然，当程序中存在过多的字符串拼接操作的时候，会对内存的分配产生非常大的压力。&nbsp;注意，虽然string值在内部持有一个指针值，但其类型仍然属于值类型。不过，由于string值的不可变，其中的指针值也为内存空间的节省做出了贡献。&nbsp;更具体地说，一个string值会在底层与它的所有副本共用同一个字节数组。由于这里的字节数组永远不会被改变，所以这样做是绝对安全的。&nbsp;与string值相比，Builder值的优势其实主要体现在字符串拼接方面。&nbsp;Builder值中有一个用于承载内容的容器（以下简称内容容器）。它是一个以byte为元素类型的切片（以下简称字节切片）。&nbsp;由于这样的字节切片的底层数组就是一个字节数组，所以我们可以说它与string值存储内容的方式是一样的。&nbsp;实际上，它们都是通过一个unsafe.Pointer类型的字段来持有那个指向了底层字节数组的指针值的。&nbsp;正是因为这样的内部构造，Builder值同样拥有高效利用内存的前提条件。虽然，对于字节切片本身来说，它包含的任何元素值都可以被修改，但是Builder值并不允许这样做，其中的内容只能够被拼接或者完全重置。&nbsp;这就意味着，已存在于Builder值中的内容是不可变的。因此，我们可以利用Builder值提供的方法拼接更多的内容，而丝毫不用担心这些方法会影响到已存在的内容。&nbsp; 这里所说的方法指的是，Builder值拥有的一系列指针方法，包括：Write、WriteByte、WriteRune和WriteString。我们可以把它们统称为拼接方法。 &nbsp;我们可以通过调用上述方法把新的内容拼接到已存在的内容的尾部（也就是右边）。这时，如有必要，Builder值会自动地对自身的内容容器进行扩容。这里的自动扩容策略与切片的扩容策略一致。&nbsp;换句话说，我们在向Builder值拼接内容的时候并不一定会引起扩容。只要内容容器的容量够用，扩容就不会进行，针对于此的内存分配也不会发生。同时，只要没有扩容，Builder值中已存在的内容就不会再被拷贝。&nbsp;除了Builder值的自动扩容，我们还可以选择手动扩容，这通过调用Builder值的Grow方法就可以做到。Grow方法也可以被称为扩容方法，它接受一个int类型的参数n，该参数用于代表将要扩充的字节数量。&nbsp;如有必要，Grow方法会把其所属值中内容容器的容量增加n个字节。更具体地讲，它会生成一个字节切片作为新的内容容器，该切片的容量会是原容器容量的二倍再加上n。之后，它会把原容器中的所有字节全部拷贝到新容器中。&nbsp;12345var builder1 strings.Builder// 省略若干代码。fmt.Println(&quot;Grow the builder ...&quot;)builder1.Grow(10)fmt.Printf(&quot;The length of contents in the builder is %d.\\n&quot;, builder1.Len())&nbsp; 当然，Grow方法还可能什么都不做。这种情况的前提条件是：当前的内容容器中的未用容量已经够用了，即：未用容量大于或等于n。这里的前提条件与前面提到的自动扩容策略中的前提条件是类似的。 &nbsp;123fmt.Println(&quot;Reset the builder ...&quot;)builder1.Reset()fmt.Printf(&quot;The third output(%d):\\n%q\\n&quot;, builder1.Len(), builder1.String())&nbsp; 最后，Builder值是可以被重用的。通过调用它的Reset方法，我们可以让Builder值重新回到零值状态，就像它从未被使用过那样。 &nbsp;一旦被重用，Builder值中原有的内容容器会被直接丢弃。之后，它和其中的所有内容，将会被 Go 语言的垃圾回收器标记并回收掉。&nbsp;strings.Builder类型在使用上有约束吗？有约束，概括如下：&nbsp; 在已被真正使用后就不可再被复制； 由于其内容不是完全不可变的，所以需要使用方自行解决操作冲突和并发安全问题。 &nbsp;我们只要调用了Builder值的拼接方法或扩容方法，就意味着开始真正使用它了。显而易见，这些方法都会改变其所属值中的内容容器的状态。&nbsp;一旦调用了它们，我们就不能再以任何的方式对其所属值进行复制了。否则，只要在任何副本上调用上述方法就都会引发 panic。&nbsp;这种 panic 会告诉我们，这样的使用方式是并不合法的，因为这里的Builder值是副本而不是原值。顺便说一句，这里所说的复制方式，包括但不限于在函数间传递值、通过通道传递值、把值赋予变量等等。&nbsp;12345var builder1 strings.Builderbuilder1.Grow(1)builder3 := builder1//builder3.Grow(1) // 这里会引发 panic。_ = builder3&nbsp; 虽然这个约束非常严格，但是如果我们仔细思考一下的话，就会发现它还是有好处的。 &nbsp;正是由于已使用的Builder值不能再被复制，所以肯定不会出现多个Builder值中的内容容器（也就是那个字节切片）共用一个底层字节数组的情况。这样也就避免了多个同源的Builder值在拼接内容时可能产生的冲突问题。&nbsp;不过，虽然已使用的Builder值不能再被复制，但是它的指针值却可以。无论什么时候，我们都可以通过任何方式复制这样的指针值。注意，这样的指针值指向的都会是同一个Builder值。&nbsp; 1234567f2 := func(bp *strings.Builder) &#123; (*bp).Grow(1) // 这里虽然不会引发 panic，但不是并发安全的。 builder4 := *bp //builder4.Grow(1) // 这里会引发 panic。 _ = builder4&#125;f2(&amp;builder1) &nbsp; 正因为如此，这里就产生了一个问题，即：如果Builder值被多方同时操作，那么其中的内容就很可能会产生混乱。这就是我们所说的操作冲突和并发安全问题。 &nbsp;Builder值自己是无法解决这些问题的。所以，我们在通过传递其指针值共享Builder值的时候，一定要确保各方对它的使用是正确、有序的，并且是并发安全的；而最彻底的解决方案是，绝不共享Builder值以及它的指针值。&nbsp;我们可以在各处分别声明一个Builder值来使用，也可以先声明一个Builder值，然后在真正使用它之前，便将它的副本传到各处。另外，我们还可以先使用再传递，只要在传递之前调用它的Reset方法即可。&nbsp; 123builder1.Reset()builder5 := builder1builder5.Grow(1) // 这里不会引发 panic。 &nbsp; 总之，关于复制Builder值的约束是有意义的，也是很有必要的。虽然我们仍然可以通过某些方式共享Builder值，但最好还是不要以身犯险，“各自为政”是最好的解决方案。不过，对于处在零值状态的Builder值，复制不会有任何问题。 &nbsp;为什么说strings.Reader类型的值可以高效地读取字符串？&nbsp;与strings.Builder类型恰恰相反，strings.Reader类型是为了高效读取字符串而存在的。后者的高效主要体现在它对字符串的读取机制上，它封装了很多用于在string值上读取内容的最佳实践。&nbsp;strings.Reader类型的值（以下简称Reader值）可以让我们很方便地读取一个字符串中的内容。在读取的过程中，Reader值会保存已读取的字节的计数（以下简称已读计数）。&nbsp;已读计数也代表着下一次读取的起始索引位置。Reader值正是依靠这样一个计数，以及针对字符串值的切片表达式，从而实现快速读取。&nbsp;此外，这个已读计数也是读取回退和位置设定时的重要依据。虽然它属于Reader值的内部结构，但我们还是可以通过该值的Len方法和Size把它计算出来的。代码如下：&nbsp; 123var reader1 strings.Reader// 省略若干代码。readingIndex := reader1.Size() - int64(reader1.Len()) // 计算出的已读计数。 &nbsp; Reader值拥有的大部分用于读取的方法都会及时地更新已读计数。比如，ReadByte方法会在读取成功后将这个计数的值加1。 &nbsp;又比如，ReadRune方法在读取成功之后，会把被读取的字符所占用的字节数作为计数的增量。&nbsp;不过，ReadAt方法算是一个例外。它既不会依据已读计数进行读取，也不会在读取后更新它。正因为如此，这个方法可以自由地读取其所属的Reader值中的任何内容。&nbsp;除此之外，Reader值的Seek方法也会更新该值的已读计数。实际上，这个Seek方法的主要作用正是设定下一次读取的起始索引位置。&nbsp;另外，如果我们把常量io.SeekCurrent的值作为第二个参数值传给该方法，那么它还会依据当前的已读计数，以及第一个参数offset的值来计算新的计数值。&nbsp;由于Seek方法会返回新的计数值，所以我们可以很容易地验证这一点。比如像下面这样：&nbsp; 123456offset2 := int64(17)expectedIndex := reader1.Size() - int64(reader1.Len()) + offset2fmt.Printf(&quot;Seek with offset %d and whence %d ...\\n&quot;, offset2, io.SeekCurrent)readingIndex, _ := reader1.Seek(offset2, io.SeekCurrent)fmt.Printf(&quot;The reading index in reader: %d (returned by Seek)\\n&quot;, readingIndex)fmt.Printf(&quot;The reading index in reader: %d (computed by me)\\n&quot;, expectedIndex) &nbsp; 综上所述，Reader值实现高效读取的关键就在于它内部的已读计数。计数的值就代表着下一次读取的起始索引位置。它可以很容易地被计算出来。Reader值的Seek方法可以直接设定该值中的已读计数值。 &nbsp;&nbsp; 参考链接：https://time.geekbang.org/column/intro/112","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Go语言","slug":"Go语言","permalink":"http://wht6.github.io/tags/Go%E8%AF%AD%E8%A8%80/"}]},{"title":"魔法函数","slug":"魔法函数","date":"2022-03-10T02:00:00.000Z","updated":"2022-03-20T01:59:23.483Z","comments":true,"path":"posts/bc85.html","link":"","permalink":"http://wht6.github.io/posts/bc85.html","excerpt":"","text":"&nbsp; Python里面的魔法函数，是以双下划线开头和结尾的函数。魔法函数是Python预定义好的一些函数接口，我们可以根据这些接口来定制类的一些属性。&nbsp;12345678class Company(object): def __init__(self, employee_list): self.employee = employee_listcompany = Company([&quot;tom&quot;, &quot;bob&quot;, &quot;jane&quot;])for em in company.employee: print(em)&nbsp; 这里的__init__就是一个魔法函数，是专门用于对象初始化操作的。 &nbsp;12345678910class Company(object): def __init__(self, employee_list): self.employee = employee_list def __getitem__(self, item): return self.employee[item]company = Company([&quot;tom&quot;, &quot;bob&quot;, &quot;jane&quot;])for em in company: print(em)&nbsp; 当我们定义了__getitem__这个函数之后，对象company就变成了可迭代的类型。我们并没有显式的调用__getitem__方法，但是在我们用for语句对它进行遍历的时候，解释器会自动的调用它。 &nbsp;魔法函数是Python的数据模型，一个主要的特征是对方法的隐式调用。它既不属于定义它的类，也不属于它所继承的类，可以理解为对类型的增强，就如同Python的内置类型一样，我们在使用内置类型的时候也没有方法的调用。或者可以说这些魔法函数的使用使得该类可以像内置类型一样使用。&nbsp;还是接着上面的代码：&nbsp;123company1= company[:2]print(company)print(len(company))&nbsp; 定义了__getitem__这个函数之后，我们就可以像使用list一样使用Company。 &nbsp;我们也可以不定义__getitem__方法来定义__len__方法来获取对象的长度。在使用len(company)来获取对象长度的时候，Python的解释器会先去找__len__方法，如果__len__没有，会去找__getitem__方法，如果__getitem__也没有，就去找其他可以获取长度的方法，如果都没有，程序就会崩溃报错。&nbsp;下面再举几个例子：&nbsp;123456class Company(object): def __init__(self, employee_list): self.employee = employee_listcompany = Company([&quot;tom&quot;, &quot;bob&quot;, &quot;jane&quot;])print(company) &nbsp; 这里只会打印company的地址。 &nbsp;123456789class Company(object): def __init__(self, employee_list): self.employee = employee_list def __str__(self): return &quot;,&quot;.join(self.employee)company = Company([&quot;tom&quot;, &quot;bob&quot;, &quot;jane&quot;])print(company)&nbsp; 这段代码打印的结果是：tom,bob,jane。 &nbsp;12345678910111213class MyVector(object): def __init__(self, x, y): self.x = x self.y = y def __add__(self, other): re_vector = MyVector(self.x+other.x, self.y+other.y) return re_vector def __str__(self): return &quot;x:&#123;x&#125;, y:&#123;y&#125;&quot;.format(x=self.x, y=self.y)vec1 = MyVector(1, 2)vec2 = MyVector(2, 3)print(vec1+vec2)&nbsp; 这段代码打印的结果是：x:3, y:5。","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Python语言","slug":"Python语言","permalink":"http://wht6.github.io/tags/Python%E8%AF%AD%E8%A8%80/"}]},{"title":"unicode与字符编码","slug":"unicode与字符编码","date":"2022-03-09T09:00:00.000Z","updated":"2022-03-20T01:58:55.122Z","comments":true,"path":"posts/2b2.html","link":"","permalink":"http://wht6.github.io/posts/2b2.html","excerpt":"","text":"Go语言字符编码&nbsp; 首先，让我们来关注字符编码方面的问题。这应该是在计算机软件领域中非常基础的一个问题了。&nbsp;我在前面说过，Go 语言中的标识符可以包含“任何 Unicode 编码可以表示的字母字符”。我还说过，虽然我们可以直接把一个整数值转换为一个string类型的值。&nbsp;但是，被转换的整数值应该可以代表一个有效的 Unicode 代码点，否则转换的结果就将会是&quot;�&quot;，即：一个仅由高亮的问号组成的字符串值。&nbsp;另外，当一个string类型的值被转换为[]rune类型值的时候，其中的字符串会被拆分成一个一个的 Unicode 字符。&nbsp;显然，Go 语言采用的字符编码方案从属于 Unicode 编码规范。更确切地说，Go 语言的代码正是由 Unicode 字符组成的。Go 语言的所有源代码，都必须按照 Unicode 编码规范中的 UTF-8 编码格式进行编码。&nbsp;换句话说，Go 语言的源码文件必须使用 UTF-8 编码格式进行存储。如果源码文件中出现了非 UTF-8 编码的字符，那么在构建、安装以及运行的时候，go 命令就会报告错误“illegal UTF-8 encoding”。&nbsp;在这里，我们首先要对 Unicode 编码规范有所了解。不过，在讲述它之前，我先来简要地介绍一下 ASCII 编码。&nbsp; ASCII编码&nbsp;ASCII 是英文“American Standard Code for Information Interchange”的缩写，中文译为美国信息交换标准代码。它是由美国国家标准学会（ANSI）制定的单字节字符编码方案，可用于基于文本的数据交换。&nbsp;它最初是美国的国家标准，后又被国际标准化组织（ISO）定为国际标准，称为 ISO 646 标准，并适用于所有的拉丁文字字母。&nbsp;ASCII 编码方案使用单个字节（byte）的二进制数来编码一个字符。标准的 ASCII 编码用一个字节的最高比特（bit）位作为奇偶校验位，而扩展的 ASCII 编码则将此位也用于表示字符。ASCII 编码支持的可打印字符和控制字符的集合也被叫做 ASCII 编码集。&nbsp;我们所说的 Unicode 编码规范，实际上是另一个更加通用的、针对书面字符和文本的字符编码标准。它为世界上现存的所有自然语言中的每一个字符，都设定了一个唯一的二进制编码。&nbsp;它定义了不同自然语言的文本数据在国际间交换的统一方式，并为全球化软件创建了一个重要的基础。&nbsp;Unicode 编码规范以 ASCII 编码集为出发点，并突破了 ASCII 只能对拉丁字母进行编码的限制。它不但提供了可以对世界上超过百万的字符进行编码的能力，还支持所有已知的转义序列和控制代码。&nbsp;我们都知道，在计算机系统的内部，抽象的字符会被编码为整数。这些整数的范围被称为代码空间。在代码空间之内，每一个特定的整数都被称为一个代码点。&nbsp;一个受支持的抽象字符会被映射并分配给某个特定的代码点，反过来讲，一个代码点总是可以被看成一个被编码的字符。&nbsp;Unicode 编码规范通常使用十六进制表示法来表示 Unicode 代码点的整数值，并使用“U+”作为前缀。比如，英文字母字符“a”的 Unicode 代码点是 U+0061。在 Unicode 编码规范中，一个字符能且只能由与它对应的那个代码点表示。&nbsp;Unicode 编码规范提供了三种不同的编码格式，即：UTF-8、UTF-16 和 UTF-32。其中的 UTF 是 UCS Transformation Format 的缩写。而 UCS 又是 Universal Character Set 的缩写，但也可以代表 Unicode Character Set。所以，UTF 也可以被翻译为 Unicode 转换格式。它代表的是字符与字节序列之间的转换方式。&nbsp;在这几种编码格式的名称中，“-”右边的整数的含义是，以多少个比特位作为一个编码单元。以 UTF-8 为例，它会以 8 个比特，也就是一个字节，作为一个编码单元。并且，它与标准的 ASCII 编码是完全兼容的。也就是说，在 [0x00, 0x7F] 的范围内，这两种编码表示的字符都是相同的。这也是 UTF-8 编码格式的一个巨大优势。&nbsp;UTF-8 是一种可变宽的编码方案。换句话说，它会用一个或多个字节的二进制数来表示某个字符，最多使用四个字节。比如，对于一个英文字符，它仅用一个字节的二进制数就可以表示，而对于一个中文字符，它需要使用三个字节才能够表示。不论怎样，一个受支持的字符总是可以由 UTF-8 编码为一个字节序列。以下会简称后者为 UTF-8 编码值。&nbsp;一个string类型的值在底层是怎样被表达的？&nbsp;在底层，一个string类型的值是由一系列相对应的 Unicode 代码点的 UTF-8 编码值来表达的。&nbsp;在 Go 语言中，一个string类型的值既可以被拆分为一个包含多个字符的序列，也可以被拆分为一个包含多个字节的序列。&nbsp;前者可以由一个以rune为元素类型的切片来表示，而后者则可以由一个以byte为元素类型的切片代表。&nbsp;rune是 Go 语言特有的一个基本数据类型，它的一个值就代表一个字符，即：一个 Unicode 字符。&nbsp;比如，&#39;G&#39;、&#39;o&#39;、&#39;爱&#39;、&#39;好&#39;、&#39;者&#39;代表的就都是一个 Unicode 字符。&nbsp;我们已经知道，UTF-8 编码方案会把一个 Unicode 字符编码为一个长度在 [1, 4] 范围内的字节序列。所以，一个rune类型的值也可以由一个或多个字节来代表。&nbsp;1type rune = int32&nbsp; 根据rune类型的声明可知，它实际上就是int32类型的一个别名类型。也就是说，一个rune类型的值会由四个字节宽度的空间来存储。它的存储空间总是能够存下一个 UTF-8 编码值。 &nbsp;一个rune类型的值在底层其实就是一个 UTF-8 编码值。前者是（便于我们人类理解的）外部展现，后者是（便于计算机系统理解的）内在表达。&nbsp;12345str := &quot;Go 爱好者 &quot;fmt.Printf(&quot;The string: %q\\n&quot;, str)fmt.Printf(&quot; =&gt; runes(char): %q\\n&quot;, []rune(str))fmt.Printf(&quot; =&gt; runes(hex): %x\\n&quot;, []rune(str))fmt.Printf(&quot; =&gt; bytes(hex): [% x]\\n&quot;, []byte(str))&nbsp; 字符串值&quot;Go爱好者&quot;如果被转换为[]rune类型的值的话，其中的每一个字符（不论是英文字符还是中文字符）就都会独立成为一个rune类型的元素值。因此，这段代码打印出的第二行内容就会如下所示： &nbsp;1&#x3D;&gt; runes(char): [&#39;G&#39; &#39;o&#39; &#39;爱&#39; &#39;好&#39; &#39;者&#39;]&nbsp; 又由于，每个rune类型的值在底层都是由一个 UTF-8 编码值来表达的，所以我们可以换一种方式来展现这个字符序列： &nbsp;1&#x3D;&gt; runes(hex): [47 6f 7231 597d 8005]&nbsp; 可以看到，五个十六进制数与五个字符相对应。很明显，前两个十六进制数47和6f代表的整数都比较小，它们分别表示字符&#39;G&#39;和&#39;o&#39;。 &nbsp;因为它们都是英文字符，所以对应的 UTF-8 编码值用一个字节表达就足够了。一个字节的编码值被转换为整数之后，不会大到哪里去。&nbsp;而后三个十六进制数7231、597d和8005都相对较大，它们分别表示中文字符&#39;爱&#39;、&#39;好&#39;和&#39;者&#39;。&nbsp;这些中文字符对应的 UTF-8 编码值，都需要使用三个字节来表达。所以，这三个数就是把对应的三个字节的编码值，转换为整数后得到的结果。&nbsp;我们还可以进一步地拆分，把每个字符的 UTF-8 编码值都拆成相应的字节序列。上述代码中的第五行就是这么做的。它会得到如下的输出：&nbsp;1&#x3D;&gt; bytes(hex): [47 6f e7 88 b1 e5 a5 bd e8 80 85]&nbsp; 这里得到的字节切片比前面的字符切片明显长了很多。这正是因为一个中文字符的 UTF-8 编码值需要用三个字节来表达。 &nbsp;这个字节切片的前两个元素值与字符切片的前两个元素值是一致的，而在这之后，前者的每三个元素值才对应字符切片中的一个元素值。&nbsp;注意，对于一个多字节的 UTF-8 编码值来说，我们可以把它当做一个整体转换为单一的整数，也可以先把它拆成字节序列，再把每个字节分别转换为一个整数，从而得到多个整数。&nbsp;这两种表示法展现出来的内容往往会很不一样。比如，对于中文字符&#39;爱&#39;来说，它的 UTF-8 编码值可以展现为单一的整数7231，也可以展现为三个整数，即：e7、88和b1。&nbsp;&nbsp;总之，一个string类型的值会由若干个 Unicode 字符组成，每个 Unicode 字符都可以由一个rune类型的值来承载。&nbsp;这些字符在底层都会被转换为 UTF-8 编码值，而这些 UTF-8 编码值又会以字节序列的形式表达和存储。因此，一个string类型的值在底层就是一个能够表达若干个 UTF-8 编码值的字节序列。&nbsp;使用带有range子句的for语句遍历字符串值的时候应该注意什么？&nbsp;带有range子句的for语句会先把被遍历的字符串值拆成一个字节序列，然后再试图找出这个字节序列中包含的每一个 UTF-8 编码值，或者说每一个 Unicode 字符。&nbsp;这样的for语句可以为两个迭代变量赋值。如果存在两个迭代变量，那么赋给第一个变量的值，就将会是当前字节序列中的某个 UTF-8 编码值的第一个字节所对应的那个索引值。&nbsp;而赋给第二个变量的值，则是这个 UTF-8 编码值代表的那个 Unicode 字符，其类型会是rune。&nbsp;1234str := &quot;Go 爱好者 &quot;for i, c := range str &#123; fmt.Printf(&quot;%d: %q [% x]\\n&quot;, i, c, []byte(string(c)))&#125;&nbsp; 这里被遍历的字符串值是&quot;Go爱好者&quot;。在每次迭代的时候，这段代码都会打印出两个迭代变量的值，以及第二个值的字节序列形式。完整的打印内容如下： &nbsp;123450: &#39;G&#39; [47]1: &#39;o&#39; [6f]2: &#39;爱&#39; [e7 88 b1]5: &#39;好&#39; [e5 a5 bd]8: &#39;者&#39; [e8 80 85]&nbsp; 第一行内容中的关键信息有0、&#39;G&#39;和[47]。这是由于这个字符串值中的第一个 Unicode 字符是&#39;G&#39;。该字符是一个单字节字符，并且由相应的字节序列中的第一个字节表达。这个字节的十六进制表示为47。 &nbsp;第二行展示的内容与之类似，即：第二个 Unicode 字符是&#39;o&#39;，由字节序列中的第二个字节表达，其十六进制表示为6f。&nbsp;再往下看，第三行展示的是&#39;爱&#39;，也是第三个 Unicode 字符。因为它是一个中文字符，所以由字节序列中的第三、四、五个字节共同表达，其十六进制表示也不再是单一的整数，而是e7、88和b1组成的序列。&nbsp;下面要注意了，正是因为&#39;爱&#39;是由三个字节共同表达的，所以第四个 Unicode 字符&#39;好&#39;对应的索引值并不是3，而是2加3后得到的5。&nbsp;这里的2代表的是&#39;爱&#39;对应的索引值，而3代表的则是&#39;爱&#39;对应的 UTF-8 编码值的宽度。对于这个字符串值中的最后一个字符&#39;者&#39;来说也是类似的，因此，它对应的索引值是8。&nbsp;由此可以看出，这样的for语句可以逐一地迭代出字符串值里的每个 Unicode 字符。但是，相邻的 Unicode 字符的索引值并不一定是连续的。这取决于前一个 Unicode 字符是否为单字节字符。&nbsp;正因为如此，如果我们想得到其中某个 Unicode 字符对应的 UTF-8 编码值的宽度，就可以用下一个字符的索引值减去当前字符的索引值。&nbsp;&nbsp; 参考链接：https://time.geekbang.org/column/intro/112","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Go语言","slug":"Go语言","permalink":"http://wht6.github.io/tags/Go%E8%AF%AD%E8%A8%80/"}]},{"title":"一切皆对象","slug":"一切皆对象","date":"2022-03-09T02:00:00.000Z","updated":"2022-03-20T01:58:40.060Z","comments":true,"path":"posts/d24b.html","link":"","permalink":"http://wht6.github.io/posts/d24b.html","excerpt":"","text":"一切皆对象&nbsp; Python的设计理念是“一切皆对象”，例如在元类编程和猴子补丁中就很好的贯彻了这一思想。&nbsp;Java中对象（object）是类（class）的一个实例，而python的面向对象更彻底，Python中类和函数也是对象，代码和模块也是对象。&nbsp;Python的类和函数具有以下特性：&nbsp; 可以赋值给一个变量 可以添加到集合对象中 可以作为参数传递给函数 可以当做函数的返回值 &nbsp; type、object和class的关系&nbsp;下面看一个例子：&nbsp;123456a=1b=&quot;abc&quot;print(type(1))print(type(int))print(type(b))print(type(str))&nbsp; 这段代码的输出： &nbsp;1234&lt;class &#39;int&#39;&gt;&lt;class &#39;type&#39;&gt;&lt;class &#39;str&#39;&gt;&lt;class &#39;type&#39;&gt;&nbsp;1是int类实例化的对象，而int是type类实例化的对象。同样，&quot;abc&quot;是str类实例化的对象，str是type类实例化的对象。 &nbsp;1234567class Student: passstu = Student()print(type(stu))print(type(Student))print(Student.__bases__)&nbsp; 这段代码的输出： &nbsp;123&lt;class &#39;__main__.Student&#39;&gt;&lt;class &#39;type&#39;&gt;(&lt;class &#39;object&#39;&gt;,)&nbsp; stu是Student类实例化的对象，而Student是type类实例化的对象。可以看出type类是用来生成类的。 &nbsp;object类是所有类都要继承的一个基础类，它是最顶层基类。由于Student类没有指名继承的类，那么默认继承object类。&nbsp;123print(type.__bases__)print(object.__bases__)print(type(object))&nbsp; 这段代码的输出： &nbsp;123(&lt;class &#39;object&#39;&gt;,)()&lt;class &#39;type&#39;&gt;&nbsp; type的基类是object，object的基类为空，object的类型为type。 &nbsp;&nbsp;可以看到list、str、dict、tuple、object这些对象都是由type创建出来的，同时这些对象又可以作为类来创建新的对象。type继承了object，同时object是type的一个实例，而type也是自身的一个实例。也就是说type可以把一切变成对象，包括它自己，这样就实现了”一切皆对象“。至于为什么type可以实例化自身，这和内部使用指针来实现有关，指针指向一块内存，同时指针也用一块内存来存储。&nbsp;因为Python中一切都是对象，所以一切都是可修改的。Java中类是不能修改的。&nbsp; Python中常见的内置类型&nbsp;对象的三个特征：身份、类型、值。对象的身份，就是就是对象的指针地址，可以通过id(a)来查看，其中a为任意对象。&nbsp;下面是常见的内置类型：&nbsp;None全局唯一。&nbsp;123a = Noneb = Noneprint(id(a) == id(b))&nbsp; 这段代码的输出结果是：Ture。说明a和b指向同一个对象None。 &nbsp;数值类型：int、float、complex、bool。&nbsp;迭代类型。&nbsp;序列类型：list、bytes、bytearray、memoryview、range、tuple、str、array。&nbsp;映射类型dict。&nbsp;集合：set、frozenset。&nbsp;上下文管理类型with。&nbsp;其他类型：模块类型、class和实例、函数类型、方法类型、代码类型、object对象、type类型、ellipsis类型、notimplemented类型。&nbsp;Python是动态语言，一切皆对象的设计理念使得Python使用起来更加的灵活方便，但是缺失了静态语言所具备的严谨性，比如Java、C++等在编译的时候就可以做一些类型检查，而Python没有编译过程，导致许多错误只能在代码运行起来之后才能发现。","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Python语言","slug":"Python语言","permalink":"http://wht6.github.io/tags/Python%E8%AF%AD%E8%A8%80/"}]},{"title":"并发安全字典","slug":"并发安全字典","date":"2022-03-08T10:00:00.000Z","updated":"2022-03-20T01:58:21.843Z","comments":true,"path":"posts/1e86.html","link":"","permalink":"http://wht6.github.io/posts/1e86.html","excerpt":"","text":"在sync包中提供了一个并发安全的高级数据结构sync.Map，而Go 语言自带的字典类型map并不是并发安全的。 &nbsp; 换句话说，在同一时间段内，让不同 goroutine 中的代码，对同一个字典进行读写操作是不安全的。字典值本身可能会因这些操作而产生混乱，相关的程序也可能会因此发生不可预知的问题。&nbsp;在sync.Map出现之前，我们如果要实现并发安全的字典，就只能自行构建。不过，这其实也不是什么麻烦事，使用 sync.Mutex或sync.RWMutex，再加上原生的map就可以轻松地做到。&nbsp;sync.Map这个字典类型提供了一些常用的键值存取操作方法，并保证了这些操作的并发安全。同时，它的存、取、删等操作都可以基本保证在常数时间内执行完毕。换句话说，它们的算法复杂度与map类型一样都是O(1)的。&nbsp;在有些时候，与单纯使用原生map和互斥锁的方案相比，使用sync.Map可以显著地减少锁的争用。sync.Map本身虽然也用到了锁，但是，它其实在尽可能地避免使用锁。&nbsp;我们都知道，使用锁就意味着要把一些并发的操作强制串行化。这往往会降低程序的性能，尤其是在计算机拥有多个 CPU 核心的情况下。&nbsp;因此，我们常说，能用原子操作就不要用锁，不过这很有局限性，毕竟原子只能对一些基本的数据类型提供支持。&nbsp;无论在何种场景下使用sync.Map，我们都需要注意，与原生map明显不同，它只是 Go 语言标准库中的一员，而不是语言层面的东西。也正因为这一点，Go 语言的编译器并不会对它的键和值，进行特殊的类型检查。&nbsp;如果你看过sync.Map的文档或者实际使用过它，那么就一定会知道，它所有的方法涉及的键和值的类型都是interface&#123;&#125;，也就是空接口，这意味着可以包罗万象。所以，我们必须在程序中自行保证它的键类型和值类型的正确性。&nbsp;键的实际类型不能是函数类型、字典类型和切片类型。&nbsp;Go 语言的原生字典的键类型不能是函数类型、字典类型和切片类型。由于并发安全字典内部使用的存储介质正是原生字典，又因为它使用的原生字典键类型也是可以包罗万象的interface&#123;&#125;；所以，我们绝对不能带着任何实际类型为函数类型、字典类型或切片类型的键值去操作并发安全字典。&nbsp;由于这些键值的实际类型只有在程序运行期间才能够确定，所以 Go 语言编译器是无法在编译期对它们进行检查的，不正确的键值实际类型肯定会引发 panic。&nbsp;因此，我们在这里首先要做的一件事就是：一定不要违反上述规则。我们应该在每次操作并发安全字典的时候，都去显式地检查键值的实际类型。无论是存、取还是删，都应该如此。&nbsp;当然，更好的做法是，把针对同一个并发安全字典的这几种操作都集中起来，然后统一地编写检查代码。除此之外，把并发安全字典封装在一个结构体类型中，往往是一个很好的选择。&nbsp;总之，我们必须保证键的类型是可比较的（或者说可判等的）。如果你实在拿不准，那么可以先通过调用reflect.TypeOf函数得到一个键值对应的反射类型值（即：reflect.Type类型的值），然后再调用这个值的Comparable方法，得到确切的判断结果。&nbsp;怎样保证并发安全字典中的键和值的类型正确性？&nbsp;第一种方案是，让并发安全字典只能存储某个特定类型的键。&nbsp;比如，指定这里的键只能是int类型的，或者只能是字符串，又或是某类结构体。一旦完全确定了键的类型，你就可以在进行存、取、删操作的时候，使用类型断言表达式去对键的类型做检查了。&nbsp;一般情况下，这种检查并不繁琐。而且，你要是把并发安全字典封装在一个结构体类型里面，那就更加方便了。你这时完全可以让 Go 语言编译器帮助你做类型检查。请看下面的代码：&nbsp;1234567891011121314151617181920212223242526272829303132type IntStrMap struct &#123; m sync.Map&#125; func (iMap *IntStrMap) Delete(key int) &#123; iMap.m.Delete(key)&#125; func (iMap *IntStrMap) Load(key int) (value string, ok bool) &#123; v, ok := iMap.m.Load(key) if v != nil &#123; value = v.(string) &#125; return&#125; func (iMap *IntStrMap) LoadOrStore(key int, value string) (actual string, loaded bool) &#123; a, loaded := iMap.m.LoadOrStore(key, value) actual = a.(string) return&#125; func (iMap *IntStrMap) Range(f func(key int, value string) bool) &#123; f1 := func(key, value interface&#123;&#125;) bool &#123; return f(key.(int), value.(string)) &#125; iMap.m.Range(f1)&#125; func (iMap *IntStrMap) Store(key int, value string) &#123; iMap.m.Store(key, value)&#125;&nbsp; 如上所示，我编写了一个名为IntStrMap的结构体类型，它代表了键类型为int、值类型为string的并发安全字典。在这个结构体类型中，只有一个sync.Map类型的字段m。并且，这个类型拥有的所有方法，都与sync.Map类型的方法非常类似。 &nbsp;两者对应的方法名称完全一致，方法签名也非常相似，只不过，与键和值相关的那些参数和结果的类型不同而已。在IntStrMap类型的方法签名中，明确了键的类型为int，且值的类型为string。&nbsp;显然，这些方法在接受键和值的时候，就不用再做类型检查了。另外，这些方法在从m中取出键和值的时候，完全不用担心它们的类型会不正确，因为它的正确性在当初存入的时候，就已经由 Go 语言编译器保证了。&nbsp;第一种方案适用于我们可以完全确定键和值的具体类型的情况。在这种情况下，我们可以利用 Go 语言编译器去做类型检查，并用类型断言表达式作为辅助，就像IntStrMap那样。&nbsp;这样做很方便，不是吗？不过，虽然方便，但是却让这样的字典类型缺少了一些灵活性。&nbsp;如果我们还需要一个键类型为uint32并发安全字典的话，那就不得不再如法炮制地写一遍代码了。因此，在需求多样化之后，工作量反而更大，甚至会产生很多雷同的代码。&nbsp;在第二种方案中，我们封装的结构体类型的所有方法，都可以与sync.Map类型的方法完全一致（包括方法名称和方法签名）。&nbsp;不过，在这些方法中，我们就需要添加一些做类型检查的代码了。另外，这样并发安全字典的键类型和值类型，必须在初始化的时候就完全确定。并且，这种情况下，我们必须先要保证键的类型是可比较的。&nbsp;所以在设计这样的结构体类型的时候，只包含sync.Map类型的字段就不够了。&nbsp;12345type ConcurrentMap struct &#123; m sync.Map keyType reflect.Type valueType reflect.Type&#125;&nbsp; 这里ConcurrentMap类型代表的是：可自定义键类型和值类型的并发安全字典。这个类型同样有一个sync.Map类型的字段m，代表着其内部使用的并发安全字典。 &nbsp;另外，它的字段keyType和valueType，分别用于保存键类型和值类型。这两个字段的类型都是reflect.Type，我们可称之为反射类型。&nbsp;这个类型可以代表 Go 语言的任何数据类型。并且，这个类型的值也非常容易获得：通过调用reflect.TypeOf函数并把某个样本值传入即可。&nbsp;调用表达式reflect.TypeOf(int(123))的结果值，就代表了int类型的反射类型值。&nbsp;我们现在来看一看ConcurrentMap类型方法应该怎么写。&nbsp;先说Load方法，这个方法接受一个interface&#123;&#125;类型的参数key，参数key代表了某个键的值。&nbsp;因此，当我们根据 ConcurrentMap 在m字段的值中查找键值对的时候，就必须保证 ConcurrentMap 的类型是正确的。由于反射类型值之间可以直接使用操作符==或!=进行判等，所以这里的类型检查代码非常简单。&nbsp;123456func (cMap *ConcurrentMap) Load(key interface&#123;&#125;) (value interface&#123;&#125;, ok bool) &#123; if reflect.TypeOf(key) != cMap.keyType &#123; return &#125; return cMap.m.Load(key)&#125;&nbsp; 我们把一个接口类型值传入reflect.TypeOf函数，就可以得到与这个值的实际类型对应的反射类型值。 &nbsp;因此，如果参数值的反射类型与keyType字段代表的反射类型不相等，那么我们就忽略后续操作，并直接返回。&nbsp;这时，Load方法的第一个结果value的值为nil，而第二个结果ok的值为false。这完全符合Load方法原本的含义。&nbsp;再来说Store方法。Store方法接受两个参数key和value，它们的类型也都是interface&#123;&#125;。因此，我们的类型检查应该针对它们来做。&nbsp;123456789func (cMap *ConcurrentMap) Store(key, value interface&#123;&#125;) &#123; if reflect.TypeOf(key) != cMap.keyType &#123; panic(fmt.Errorf(&quot;wrong key type: %v&quot;, reflect.TypeOf(key))) &#125; if reflect.TypeOf(value) != cMap.valueType &#123; panic(fmt.Errorf(&quot;wrong value type: %v&quot;, reflect.TypeOf(value))) &#125; cMap.m.Store(key, value)&#125;&nbsp; 这里的类型检查代码与Load方法中的代码很类似，不同的是对检查结果的处理措施。当参数key或value的实际类型不符合要求时，Store方法会立即引发 panic。 &nbsp;这主要是由于Store方法没有结果声明，所以在参数值有问题的时候，它无法通过比较平和的方式告知调用方。不过，这也是符合Store方法的原本含义的。&nbsp;如果你不想这么做，也是可以的，那么就需要为Store方法添加一个error类型的结果。&nbsp;并且，在发现参数值类型不正确的时候，让它直接返回相应的error类型值，而不是引发 panic。要知道，这里展示的只一个参考实现，你可以根据实际的应用场景去做优化和改进。&nbsp;至于与ConcurrentMap类型相关的其他方法和函数，我在这里就不展示了。&nbsp;并发安全字典如何做到尽量避免使用锁？&nbsp;与单纯使用原生字典和互斥锁的方案相比，使用sync.Map可以显著地减少锁的争用。sync.Map本身确实也用到了锁，但是，它会尽可能地避免使用锁。&nbsp;sync.Map类型在内部使用了大量的原子操作来存取键和值，并使用了两个原生的map作为存储介质。&nbsp;其中一个原生map被存在了sync.Map的read字段中，该字段是sync/atomic.Value类型的。 这个原生字典可以被看作一个快照，它总会在条件满足时，去重新保存所属的sync.Map值中包含的所有键值对。&nbsp;为了描述方便，我们在后面简称它为只读字典。不过，只读字典虽然不会增减其中的键，但却允许变更其中的键所对应的值。所以，它并不是传统意义上的快照，它的只读特性只是对于其中键的集合而言的。&nbsp;由read字段的类型可知，sync.Map在替换只读字典的时候根本用不着锁。另外，这个只读字典在存储键值对的时候，还在值之上封装了一层。&nbsp;它先把值转换为了unsafe.Pointer类型的值，然后再把后者封装，并储存在其中的原生字典中。如此一来，在变更某个键所对应的值的时候，就也可以使用原子操作了。&nbsp;sync.Map中的另一个原生字典由它的dirty字段代表。 它存储键值对的方式与read字段中的原生字典一致，它的键类型也是interface&#123;&#125;，并且同样是把值先做转换和封装后再进行储存的。我们暂且把它称为脏字典。&nbsp;注意，脏字典和只读字典如果都存有同一个键值对，那么这里的两个键指的肯定是同一个基本值，对于两个值来说也是如此。&nbsp;正如前文所述，这两个字典在存储键和值的时候都只会存入它们的某个指针，而不是基本值。&nbsp;sync.Map在查找指定的键所对应的值的时候，总会先去只读字典中寻找，并不需要锁定互斥锁。只有当确定“只读字典中没有，但脏字典中可能会有这个键”的时候，它才会在锁的保护下去访问脏字典。&nbsp;相对应的，sync.Map在存储键值对的时候，只要只读字典中已存有这个键，并且该键值对未被标记为“已删除”，就会把新值存到里面并直接返回，这种情况下也不需要用到锁。&nbsp;否则，它才会在锁的保护下把键值对存储到脏字典中。这个时候，该键值对的“已删除”标记会被抹去。&nbsp; &nbsp; 顺便说一句，只有当一个键值对应该被删除，但却仍然存在于只读字典中的时候，才会被用标记为“已删除”的方式进行逻辑删除，而不会直接被物理删除。&nbsp;这种情况会在重建脏字典以后的一段时间内出现。不过，过不了多久，它们就会被真正删除掉。在查找和遍历键值对的时候，已被逻辑删除的键值对永远会被无视。&nbsp;对于删除键值对，sync.Map会先去检查只读字典中是否有对应的键。如果没有，脏字典中可能有，那么它就会在锁的保护下，试图从脏字典中删掉该键值对。&nbsp;最后，sync.Map会把该键值对中指向值的那个指针置为nil，这是另一种逻辑删除的方式。&nbsp;除此之外，还有一个细节需要注意，只读字典和脏字典之间是会互相转换的。在脏字典中查找键值对次数足够多的时候，sync.Map会把脏字典直接作为只读字典，保存在它的read字段中，然后把代表脏字典的dirty字段的值置为nil。&nbsp;在这之后，一旦再有新的键值对存入，它就会依据只读字典去重建脏字典。这个时候，它会把只读字典中已被逻辑删除的键值对过滤掉。理所当然，这些转换操作肯定都需要在锁的保护下进行。&nbsp;&nbsp;综上所述，sync.Map的只读字典和脏字典中的键值对集合，并不是实时同步的，它们在某些时间段内可能会有不同。&nbsp;由于只读字典中键的集合不能被改变，所以其中的键值对有时候可能是不全的。相反，脏字典中的键值对集合总是完全的，并且其中不会包含已被逻辑删除的键值对。&nbsp;因此，可以看出，在读操作有很多但写操作却很少的情况下，并发安全字典的性能往往会更好。在几个写操作当中，新增键值对的操作对并发安全字典的性能影响是最大的，其次是删除操作，最后才是修改操作。&nbsp;如果被操作的键值对已经存在于sync.Map的只读字典中，并且没有被逻辑删除，那么修改它并不会使用到锁，对其性能的影响就会很小。&nbsp;&nbsp; 参考链接：https://time.geekbang.org/column/intro/112","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Go语言","slug":"Go语言","permalink":"http://wht6.github.io/tags/Go%E8%AF%AD%E8%A8%80/"}]},{"title":"临时对象池","slug":"临时对象池","date":"2022-03-08T02:00:00.000Z","updated":"2022-03-20T01:57:48.612Z","comments":true,"path":"posts/b82f.html","link":"","permalink":"http://wht6.github.io/posts/b82f.html","excerpt":"","text":"sync.Pool类型可以被称为临时对象池，它的值可以被用来存储临时的对象。与 Go 语言的很多同步工具一样，sync.Pool类型也属于结构体类型，它的值在被真正使用之后，就不应该再被复制了。 &nbsp; 这里的“临时对象”的意思是：不需要持久使用的某一类值。这类值对于程序来说可有可无，但如果有的话会明显更好。它们的创建和销毁可以在任何时候发生，并且完全不会影响到程序的功能。&nbsp;同时，它们也应该是无需被区分的，其中的任何一个值都可以代替另一个。如果你的某类值完全满足上述条件，那么你就可以把它们存储到临时对象池中。&nbsp;你可能已经想到了，我们可以把临时对象池当作针对某种数据的缓存来用。实际上，在我看来，临时对象池最主要的用途就在于此。&nbsp;sync.Pool类型只有两个方法——Put和Get。Put 用于在当前的池中存放临时对象，它接受一个interface&#123;&#125;类型的参数；而 Get 则被用于从当前的池中获取临时对象，它会返回一个interface&#123;&#125;类型的值。&nbsp;更具体地说，这个类型的Get方法可能会从当前的池中删除掉任何一个值，然后把这个值作为结果返回。如果此时当前的池中没有任何值，那么这个方法就会使用当前池的New字段创建一个新值，并直接将其返回。&nbsp;sync.Pool类型的New字段代表着创建临时对象的函数。它的类型是没有参数但有唯一结果的函数类型，即：func() interface&#123;&#125;。&nbsp;这个函数是Get方法最后的临时对象获取手段。Get方法如果到了最后，仍然无法获取到一个值，那么就会调用该函数。该函数的结果值并不会被存入当前的临时对象池中，而是直接返回给Get方法的调用方。&nbsp;这里的New字段的实际值需要我们在初始化临时对象池的时候就给定。否则，在我们调用它的Get方法的时候就有可能会得到nil。所以，sync.Pool类型并不是开箱即用的。不过，这个类型也就只有这么一个公开的字段，因此初始化起来也并不麻烦。&nbsp;举个例子。标准库代码包fmt就使用到了sync.Pool类型。这个包会创建一个用于缓存某类临时对象的sync.Pool类型值，并将这个值赋给一个名为ppFree的变量。这类临时对象可以识别、格式化和暂存需要打印的内容。&nbsp;123var ppFree = sync.Pool&#123; New: func() interface&#123;&#125; &#123; return new(pp) &#125;,&#125;&nbsp; 临时对象池ppFree的New字段在被调用的时候，总是会返回一个全新的pp类型值的指针（即临时对象）。这就保证了ppFree的Get方法总能返回一个可以包含需要打印内容的值。 &nbsp;pp类型是fmt包中的私有类型，它有很多实现了不同功能的方法。不过，这里的重点是，它的每一个值都是独立的、平等的和可重用的。&nbsp; 更具体地说，这些对象既互不干扰，又不会受到外部状态的影响。它们几乎只针对某个需要打印内容的缓冲区而已。由于fmt包中的代码在真正使用这些临时对象之前，总是会先对其进行重置，所以它们并不在意取到的是哪一个临时对象。这就是临时对象的平等性的具体体现。 &nbsp;另外，这些代码在使用完临时对象之后，都会先抹掉其中已缓冲的内容，然后再把它存放到ppFree中。这样就为重用这类临时对象做好了准备。&nbsp;众所周知的fmt.Println、fmt.Printf等打印函数都是如此使用ppFree，以及其中的临时对象的。因此，在程序同时执行很多的打印函数调用的时候，ppFree可以及时地把它缓存的临时对象提供给它们，以加快执行的速度。&nbsp;而当程序在一段时间内不再执行打印函数调用时，ppFree中的临时对象又能够被及时地清理掉，以节省内存空间。&nbsp;显然，在这个维度上，临时对象池可以帮助程序实现可伸缩性。这就是它的最大价值。&nbsp; 内部机制&nbsp;为什么说临时对象池中的值会被及时地清理掉？&nbsp;回答是：因为，Go 语言运行时系统中的垃圾回收器，所以在每次开始执行之前，都会对所有已创建的临时对象池中的值进行全面地清除。&nbsp;在前面已经向你讲述了临时对象会在什么时候被创建，下面我再来详细说说它会在什么时候被销毁。&nbsp;sync包在被初始化的时候，会向 Go 语言运行时系统注册一个函数，这个函数的功能就是清除所有已创建的临时对象池中的值。我们可以把它称为池清理函数。&nbsp;一旦池清理函数被注册到了 Go 语言运行时系统，后者在每次即将执行垃圾回收时就都会执行前者。&nbsp;另外，在sync包中还有一个包级私有的全局变量。这个变量代表了当前的程序中使用的所有临时对象池的汇总，它是元素类型为*sync.Pool的切片。我们可以称之为池汇总列表。&nbsp;通常，在一个临时对象池的Put方法或Get方法第一次被调用的时候，这个池就会被添加到池汇总列表中。正因为如此，池清理函数总是能访问到所有正在被真正使用的临时对象池。&nbsp;更具体地说，池清理函数会遍历池汇总列表。对于其中的每一个临时对象池，它都会先将池中所有的私有临时对象和共享临时对象列表都置为nil，然后再把这个池中的所有本地池列表都销毁掉。&nbsp;最后，池清理函数会把池汇总列表重置为空的切片。如此一来，这些池中存储的临时对象就全部被清除干净了。&nbsp;如果临时对象池以外的代码再无对它们的引用，那么在稍后的垃圾回收过程中，这些临时对象就会被当作垃圾销毁掉，它们占用的内存空间也会被回收以备他用。&nbsp;临时对象池存储值所用的数据结构是怎样的？&nbsp;在临时对象池中，有一个多层的数据结构。正因为有了它的存在，临时对象池才能够非常高效地存储大量的值。&nbsp;这个数据结构的顶层，我们可以称之为本地池列表，不过更确切地说，它是一个数组。这个列表的长度，总是与 Go 语言调度器中的 P 的数量相同。&nbsp;还记得吗？Go 语言调度器中的 P 是 processor 的缩写，它指的是一种可以承载若干个 G、且能够使这些 G 适时地与 M 进行对接，并得到真正运行的中介。&nbsp;这里的 G 正是 goroutine 的缩写，而 M 则是 machine 的缩写，后者指代的是系统级的线程。正因为有了 P 的存在，G 和 M 才能够进行灵活、高效的配对，从而实现强大的并发编程模型。&nbsp;P 存在的一个很重要的原因是为了分散并发程序的执行压力，而让临时对象池中的本地池列表的长度与 P 的数量相同的主要原因也是分散压力。这里所说的压力包括了存储和性能两个方面。在说明它们之前，我们先来探索一下临时对象池中的那个数据结构。&nbsp;在本地池列表中的每个本地池都包含了三个字段（或者说组件），它们是：存储私有临时对象的字段private、代表了共享临时对象列表的字段shared，以及一个sync.Mutex类型的嵌入字段。&nbsp;sync.Pool 中的本地池与各个 G 的对应关系如图所示。&nbsp;&nbsp;实际上，每个本地池都对应着一个 P。我们都知道，一个 goroutine 要想真正运行就必须先与某个 P 产生关联。也就是说，一个正在运行的 goroutine 必然会关联着某个 P。&nbsp;在程序调用临时对象池的Put方法或Get方法的时候，总会先试图从该临时对象池的本地池列表中，获取与之对应的本地池，依据的就是与当前的 goroutine 关联的那个 P 的 ID。&nbsp;换句话说，一个临时对象池的Put方法或Get方法会获取到哪一个本地池，完全取决于调用它的代码所在的 goroutine 关联的那个 P。&nbsp;临时对象池是怎样利用内部数据结构来存取值的？&nbsp;临时对象池的Put方法总会先试图把新的临时对象，存储到对应的本地池的private字段中，以便在后面获取临时对象的时候，可以快速地拿到一个可用的值。&nbsp;只有当这个private字段已经存有某个值时，该方法才会去访问本地池的shared字段。&nbsp;相应的，临时对象池的Get方法，总会先试图从对应的本地池的private字段处获取一个临时对象。只有当这个private字段的值为nil时，它才会去访问本地池的shared字段。&nbsp;一个本地池的shared字段原则上可以被任何 goroutine 中的代码访问到，不论这个 goroutine 关联的是哪一个 P。这也是我把它叫做共享临时对象列表的原因。&nbsp;相比之下，一个本地池的private字段，只可能被与之对应的那个 P 所关联的 goroutine 中的代码访问到，所以可以说，它是 P 级私有的。&nbsp;以临时对象池的Put方法为例，它一旦发现对应的本地池的private字段已存有值，就会去访问这个本地池的shared字段。当然，由于shared字段是共享的，所以此时必须受到互斥锁的保护。&nbsp;还记得本地池嵌入的那个sync.Mutex类型的字段吗？它就是这里用到的互斥锁，也就是说，本地池本身就拥有互斥锁的功能。Put方法会在互斥锁的保护下，把新的临时对象追加到共享临时对象列表的末尾。&nbsp;相应的，临时对象池的Get方法在发现对应本地池的private字段未存有值时，也会去访问后者的shared字段。它会在互斥锁的保护下，试图把该共享临时对象列表中的最后一个元素值取出并作为结果。&nbsp;不过，这里的共享临时对象列表也可能是空的，这可能是由于这个本地池中的所有临时对象都已经被取走了，也可能是当前的临时对象池刚被清理过。&nbsp;无论原因是什么，Get方法都会去访问当前的临时对象池中的所有本地池，它会去逐个搜索它们的共享临时对象列表。&nbsp;只要发现某个共享临时对象列表中包含元素值，它就会把该列表的最后一个元素值取出并作为结果返回。&nbsp;从 sync.Pool 中获取临时对象的步骤如图所示。&nbsp;&nbsp;当然了，即使这样也可能无法拿到一个可用的临时对象，比如，在所有的临时对象池都刚被大清洗的情况下就会是如此。&nbsp;这时，Get方法就会使出最后的手段——调用可创建临时对象的那个函数。还记得吗？这个函数是由临时对象池的New字段代表的，并且需要我们在初始化临时对象池的时候给定。如果这个字段的值是nil，那么Get方法此时也只能返回nil了。&nbsp;在临时对象池的内部，有一个多层的数据结构支撑着对临时对象的存储。它的顶层是本地池列表，其中包含了与某个 P 对应的那些本地池，并且其长度与 P 的数量总是相同的。&nbsp;在每个本地池中，都包含一个私有的临时对象和一个共享的临时对象列表。前者只能被其对应的 P 所关联的那个 goroutine 中的代码访问到，而后者却没有这个约束。从另一个角度讲，前者用于临时对象的快速存取，而后者则用于临时对象的池内共享。&nbsp;正因为有了这样的数据结构，临时对象池才能够有效地分散存储压力和性能压力。同时，又因为临时对象池的Get方法对这个数据结构的妙用，才使得其中的临时对象能够被高效地利用。比如，该方法有时候会从其他的本地池的共享临时对象列表中，“偷取”一个临时对象。&nbsp;这样的内部结构和存取方式，让临时对象池成为了一个特点鲜明的同步工具。它存储的临时对象都应该是拥有较长生命周期的值，并且，这些值不应该被某个 goroutine 中的代码长期的持有和使用。&nbsp;因此，临时对象池非常适合用作针对某种数据的缓存。从某种角度讲，临时对象池可以帮助程序实现可伸缩性，这也正是它的最大价值。&nbsp;怎样保证一个临时对象池中总有比较充足的临时对象？&nbsp;答：首先，我们应该事先向临时对象池中放入足够多的临时对象。其次，在用完临时对象之后，我们需要及时地把它归还给临时对象池。最后，我们应该保证它的New字段所代表的值是可用的。虽然New函数返回的临时对象并不会被放入池中，但是起码能够保证池的Get方法总能返回一个临时对象。&nbsp;&nbsp; 参考链接：https://time.geekbang.org/column/intro/112","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Go语言","slug":"Go语言","permalink":"http://wht6.github.io/tags/Go%E8%AF%AD%E8%A8%80/"}]},{"title":"实现一对多的goroutine协作流程","slug":"实现一对多的goroutine协作流程","date":"2022-03-07T10:00:00.000Z","updated":"2022-03-20T01:57:32.039Z","comments":true,"path":"posts/f871.html","link":"","permalink":"http://wht6.github.io/posts/f871.html","excerpt":"","text":"声明一个通道，使它的容量与我们手动启用的 goroutine 的数量相同，之后再利用这个通道，让主 goroutine 等待其他 goroutine 的运行结束。 &nbsp; 这一步更具体地说就是：让其他的 goroutine 在运行结束之前，都向这个通道发送一个元素值，并且，让主 goroutine 在最后从这个通道中接收元素值，接收的次数需要与其他的 goroutine 的数量相同。&nbsp;这就是下面的coordinateWithChan函数展示的多 goroutine 协作流程。&nbsp;1234567891011121314func coordinateWithChan() &#123; sign := make(chan struct&#123;&#125;, 2) num := int32(0) fmt.Printf(&quot;The number: %d [with chan struct&#123;&#125;]\\n&quot;, num) max := int32(10) go addNum(&amp;num, 1, max, func() &#123; sign &lt;- struct&#123;&#125;&#123;&#125; &#125;) go addNum(&amp;num, 2, max, func() &#123; sign &lt;- struct&#123;&#125;&#123;&#125; &#125;) &lt;-sign &lt;-sign&#125;&nbsp; addNum函数会把它接受的最后一个参数值作为其中的defer函数。 &nbsp;手动启用的两个 goroutine 都会调用addNum函数，而它们传给该函数的最后一个参数值（也就是那个既无参数声明，也无结果声明的函数）都只会做一件事情，那就是向通道sign发送一个元素值。&nbsp; sync包的WaitGroup类型&nbsp;其实，在这种应用场景下，我们可以选用另外一个同步工具，即：sync包的WaitGroup类型。它比通道更加适合实现这种一对多的 goroutine 协作流程。&nbsp;sync.WaitGroup类型（以下简称WaitGroup类型）是开箱即用的，也是并发安全的。同时，与我们前面讨论的几个同步工具一样，它一旦被真正使用就不能被复制了。&nbsp;WaitGroup类型拥有三个指针方法：Add、Done和Wait。你可以想象该类型中有一个计数器，它的默认值是0。我们可以通过调用该类型值的Add方法来增加，或者减少这个计数器的值。&nbsp;一般情况下，我会用这个方法来记录需要等待的 goroutine 的数量。相对应的，这个类型的Done方法，用于对其所属值中计数器的值进行减一操作。我们可以在需要等待的 goroutine 中，通过defer语句调用它。&nbsp;而此类型的Wait方法的功能是，阻塞当前的 goroutine，直到其所属值中的计数器归零。如果在该方法被调用的时候，那个计数器的值就是0，那么它将不会做任何事情。&nbsp;你可能已经看出来了，WaitGroup类型的值（以下简称WaitGroup值）完全可以被用来替换coordinateWithChan函数中的通道sign。下面的coordinateWithWaitGroup函数就是它的改造版本。&nbsp;12345678910func coordinateWithWaitGroup() &#123; var wg sync.WaitGroup wg.Add(2) num := int32(0) fmt.Printf(&quot;The number: %d [with sync.WaitGroup]\\n&quot;, num) max := int32(10) go addNum(&amp;num, 3, max, wg.Done) go addNum(&amp;num, 4, max, wg.Done) wg.Wait()&#125;&nbsp; 很明显，整体代码少了好几行，而且看起来也更加简洁了。这里我先声明了一个WaitGroup类型的变量wg。然后，我调用了它的Add方法并传入了2，因为我会在后面启用两个需要等待的 goroutine。 &nbsp;由于wg变量的Done方法本身就是一个既无参数声明，也无结果声明的函数，所以我在go语句中调用addNum函数的时候，可以直接把该方法作为最后一个参数值传进去。&nbsp;在coordinateWithWaitGroup函数的最后，我调用了wg的Wait方法。如此一来，该函数就可以等到那两个 goroutine 都运行结束之后，再结束执行了。&nbsp;以上就是WaitGroup类型最典型的应用场景了。不过不能止步于此，对于这个类型，我们还是有必要再深入了解一下的。我们一起看下面的问题。&nbsp;sync.WaitGroup类型值中计数器的值可以小于0吗？&nbsp;不可以。之所以说WaitGroup值中计数器的值不能小于0，是因为这样会引发一个 panic。 不适当地调用这类值的Done方法和Add方法都会如此。别忘了，我们在调用Add方法的时候是可以传入一个负数的。&nbsp;实际上，导致WaitGroup值的方法抛出 panic 的原因不只这一种。&nbsp;你需要知道，在我们声明了这样一个变量之后，应该首先根据需要等待的 goroutine，或者其他事件的数量，调用它的Add方法，以使计数器的值大于0。这是确保我们能在后面正常地使用这类值的前提。&nbsp;如果我们对它的Add方法的首次调用，与对它的Wait方法的调用是同时发起的，比如，在同时启用的两个 goroutine 中，分别调用这两个方法，那么就有可能会让这里的Add方法抛出一个 panic。&nbsp;这种情况不太容易复现，也正因为如此，我们更应该予以重视。所以，虽然WaitGroup值本身并不需要初始化，但是尽早地增加其计数器的值，还是非常有必要的。&nbsp;另外，你可能已经知道，WaitGroup值是可以被复用的，但需要保证其计数周期的完整性。这里的计数周期指的是这样一个过程：该值中的计数器值由0变为了某个正整数，而后又经过一系列的变化，最终由某个正整数又变回了0。&nbsp;也就是说，只要计数器的值始于0又归为0，就可以被视为一个计数周期。在一个此类值的生命周期中，它可以经历任意多个计数周期。但是，只有在它走完当前的计数周期之后，才能够开始下一个计数周期。&nbsp;&nbsp;因此，也可以说，如果一个此类值的Wait方法在它的某个计数周期中被调用，那么就会立即阻塞当前的 goroutine，直至这个计数周期完成。在这种情况下，该值的下一个计数周期，必须要等到这个Wait方法执行结束之后，才能够开始。&nbsp;如果在一个此类值的Wait方法被执行期间，跨越了两个计数周期，那么就会引发一个 panic。&nbsp;例如，在当前的 goroutine 因调用此类值的Wait方法，而被阻塞的时候，另一个 goroutine 调用了该值的Done方法，并使其计数器的值变为了0。&nbsp;这会唤醒当前的 goroutine，并使它试图继续执行Wait方法中其余的代码。但在这时，又有一个 goroutine 调用了它的Add方法，并让其计数器的值又从0变为了某个正整数。此时，这里的Wait方法就会立即抛出一个 panic。&nbsp;纵观上述会引发 panic 的后两种情况，我们可以总结出这样一条关于WaitGroup值的使用禁忌，即：不要把增加其计数器值的操作和调用其Wait方法的代码，放在不同的 goroutine 中执行。换句话说，要杜绝对同一个WaitGroup值的两种操作的并发执行。&nbsp;除了第一种情况外，我们通常需要反复地实验，才能够让WaitGroup值的方法抛出 panic。再次强调，虽然这不是每次都发生，但是在长期运行的程序中，这种情况发生的概率还是不小的，我们必须要重视它们。&nbsp;我们最好用“先统一Add，再并发Done，最后Wait”这种标准方式，来使用WaitGroup值。 尤其不要在调用Wait方法的同时，并发地通过调用Add方法去增加其计数器的值，因为这也有可能引发 panic。&nbsp; sync.Once类型&nbsp;sync.Once类型值的Do方法是怎么保证只执行参数函数一次的？&nbsp;与sync.WaitGroup类型一样，sync.Once类型（以下简称Once类型）也属于结构体类型，同样也是开箱即用和并发安全的。由于这个类型中包含了一个sync.Mutex类型的字段，所以，复制该类型的值也会导致功能的失效。&nbsp;Once类型的Do方法只接受一个参数，这个参数的类型必须是func()，即：无参数声明和结果声明的函数。&nbsp;该方法的功能并不是对每一种参数函数都只执行一次，而是只执行“首次被调用时传入的”那个函数，并且之后不会再执行任何参数函数。&nbsp;所以，如果你有多个只需要执行一次的函数，那么就应该为它们中的每一个都分配一个sync.Once类型的值（以下简称Once值）。&nbsp;Once类型中还有一个名叫done的uint32类型的字段。它的作用是记录其所属值的Do方法被调用的次数。不过，该字段的值只可能是0或者1。一旦Do方法的首次调用完成，它的值就会从0变为1。&nbsp;你可能会问，既然done字段的值不是0就是1，那为什么还要使用需要四个字节的uint32类型呢？&nbsp;原因很简单，因为对它的操作必须是“原子”的。Do方法在一开始就会通过调用atomic.LoadUint32函数来获取该字段的值，并且一旦发现该值为1，就会直接返回。这也初步保证了“Do方法，只会执行首次被调用时传入的函数”。&nbsp;不过，单凭这样一个判断的保证是不够的。因为，如果有两个 goroutine 都调用了同一个新的Once值的Do方法，并且几乎同时执行到了其中的这个条件判断代码，那么它们就都会因判断结果为false，而继续执行Do方法中剩余的代码。&nbsp;在这个条件判断之后，Do方法会立即锁定其所属值中的那个sync.Mutex类型的字段m。然后，它会在临界区中再次检查done字段的值，并且仅在条件满足时，才会去调用参数函数，以及用原子操作把done的值变为1。&nbsp;如果你熟悉 GoF 设计模式中的单例模式的话，那么肯定能看出来，这个Do方法的实现方式，与那个单例模式有很多相似之处。它们都会先在临界区之外，判断一次关键条件，若条件不满足则立即返回。这通常被称为 “快路径”，或者叫做“快速失败路径”。&nbsp;如果条件满足，那么到了临界区中还要再对关键条件进行一次判断，这主要是为了更加严谨。这两次条件判断常被统称为（跨临界区的）“双重检查”。&nbsp;由于进入临界区之前，肯定要锁定保护它的互斥锁m，显然会降低代码的执行速度，所以其中的第二次条件判断，以及后续的操作就被称为“慢路径”或者“常规路径”。&nbsp;别看Do方法中的代码不多，但它却应用了一个很经典的编程范式。我们在 Go 语言及其标准库中，还能看到不少这个经典范式及它衍生版本的应用案例。&nbsp;下面我再来说说这个Do方法在功能方面的两个特点。&nbsp;第一个特点，由于Do方法只会在参数函数执行结束之后把done字段的值变为1，因此，如果参数函数的执行需要很长时间或者根本就不会结束（比如执行一些守护任务），那么就有可能会导致相关 goroutine 的同时阻塞。&nbsp;例如，有多个 goroutine 并发地调用了同一个Once值的Do方法，并且传入的函数都会一直执行而不结束。那么，这些 goroutine 就都会因调用了这个Do方法而阻塞。因为，除了那个抢先执行了参数函数的 goroutine 之外，其他的 goroutine 都会被阻塞在锁定该Once值的互斥锁m的那行代码上。&nbsp;第二个特点，Do方法在参数函数执行结束后，对done字段的赋值用的是原子操作，并且，这一操作是被挂在defer语句中的。因此，不论参数函数的执行会以怎样的方式结束，done字段的值都会变为1。&nbsp;也就是说，即使这个参数函数没有执行成功（比如引发了一个 panic），我们也无法使用同一个Once值重新执行它了。所以，如果你需要为参数函数的执行设定重试机制，那么就要考虑Once值的适时替换问题。&nbsp;在很多时候，我们需要依据Do方法的这两个特点来设计与之相关的流程，以避免不必要的程序阻塞和功能缺失。&nbsp;如果我们不能在一开始就确定执行子任务的 goroutine 的数量，那么使用WaitGroup值来协调它们和分发子任务的 goroutine，就是有一定风险的。一个解决方案是：分批地启用执行子任务的 goroutine。&nbsp;我们都知道，WaitGroup值是可以被复用的，但需要保证其计数周期的完整性。尤其是涉及对其Wait方法调用的时候，它的下一个计数周期必须要等到，与当前计数周期对应的那个Wait方法调用完成之后，才能够开始。&nbsp;只要我们在严格遵循上述规则的前提下，分批地启用执行子任务的 goroutine，就肯定不会有问题。具体的实现方式有不少，其中最简单的方式就是使用for循环来作为辅助。这里的代码如下：&nbsp;123456789101112131415func coordinateWithWaitGroup() &#123; total := 12 stride := 3 var num int32 fmt.Printf(&quot;The number: %d [with sync.WaitGroup]\\n&quot;, num) var wg sync.WaitGroup for i := 1; i &lt;= total; i = i + stride &#123; wg.Add(stride) for j := 0; j &lt; stride; j++ &#123; go addNum(&amp;num, i+j, wg.Done) &#125; wg.Wait() &#125; fmt.Println(&quot;End.&quot;)&#125;&nbsp; 经过改造后的coordinateWithWaitGroup函数，循环地使用了由变量wg代表的WaitGroup值。它运用的依然是“先统一Add，再并发Done，最后Wait”的这种模式，只不过它利用for语句，对此进行了复用。 &nbsp; context包&nbsp;怎样使用context包中的程序实体，实现一对多的 goroutine 协作流程？&nbsp;123456789101112131415func coordinateWithContext() &#123; total := 12 var num int32 fmt.Printf(&quot;The number: %d [with context.Context]\\n&quot;, num) cxt, cancelFunc := context.WithCancel(context.Background()) for i := 1; i &lt;= total; i++ &#123; go addNum(&amp;num, i, func() &#123; if atomic.LoadInt32(&amp;num) == int32(total) &#123; cancelFunc() &#125; &#125;) &#125; &lt;-cxt.Done() fmt.Println(&quot;End.&quot;)&#125;&nbsp; 在这个函数体中，我先后调用了context.Background函数和context.WithCancel函数，并得到了一个可撤销的context.Context类型的值（由变量cxt代表），以及一个context.CancelFunc类型的撤销函数（由变量cancelFunc代表）。 &nbsp;在后面那条唯一的for语句中，我在每次迭代中都通过一条go语句，异步地调用addNum函数，调用的总次数只依据了total变量的值。&nbsp;请注意我给予addNum函数的最后一个参数值。它是一个匿名函数，其中只包含了一条if语句。这条if语句会“原子地”加载num变量的值，并判断它是否等于total变量的值。&nbsp;如果两个值相等，那么就调用cancelFunc函数。其含义是，如果所有的addNum函数都执行完毕，那么就立即通知分发子任务的 goroutine。&nbsp;这里分发子任务的 goroutine，即为执行coordinateWithContext函数的 goroutine。它在执行完for语句后，会立即调用cxt变量的Done函数，并试图针对该函数返回的通道，进行接收操作。&nbsp;由于一旦cancelFunc函数被调用，针对该通道的接收操作就会马上结束，所以，这样做就可以实现“等待所有的addNum函数都执行完毕”的功能。&nbsp;Context类型之所以受到了标准库中众多代码包的积极支持，主要是因为它是一种非常通用的同步工具。它的值不但可以被任意地扩散，而且还可以被用来传递额外的信息和信号。&nbsp;更具体地说，Context类型可以提供一类代表上下文的值。此类值是并发安全的，也就是说它可以被传播给多个 goroutine。&nbsp;由于Context类型实际上是一个接口类型，而context包中实现该接口的所有私有类型，都是基于某个数据类型的指针类型，所以，如此传播并不会影响该类型值的功能和安全。&nbsp;Context类型的值（以下简称Context值）是可以繁衍的，这意味着我们可以通过一个Context值产生出任意个子值。这些子值可以携带其父值的属性和数据，也可以响应我们通过其父值传达的信号。&nbsp;正因为如此，所有的Context值共同构成了一颗代表了上下文全貌的树形结构。这棵树的树根（或者称上下文根节点）是一个已经在context包中预定义好的Context值，它是全局唯一的。通过调用context.Background函数，我们就可以获取到它（我在coordinateWithContext函数中就是这么做的）。&nbsp;这里注意一下，这个上下文根节点仅仅是一个最基本的支点，它不提供任何额外的功能。也就是说，它既不可以被撤销（cancel），也不能携带任何数据。&nbsp;除此之外，context包中还包含了四个用于繁衍Context值的函数，即：WithCancel、WithDeadline、WithTimeout和WithValue。&nbsp;这些函数的第一个参数的类型都是context.Context，而名称都为parent。顾名思义，这个位置上的参数对应的都是它们将会产生的Context值的父值。&nbsp;WithCancel函数用于产生一个可撤销的parent的子值。在coordinateWithContext函数中，我通过调用该函数，获得了一个衍生自上下文根节点的Context值，和一个用于触发撤销信号的函数。&nbsp;而WithDeadline函数和WithTimeout函数则都可以被用来产生一个会定时撤销的parent的子值。至于WithValue函数，我们可以通过调用它，产生一个会携带额外数据的parent的子值。&nbsp;“可撤销的”在context包中代表着什么？“撤销”一个Context值又意味着什么？&nbsp;我相信很多初识context包的 Go 程序开发者，都会有这样的疑问。确实，“可撤销的”（cancelable）这个词在这里是比较抽象的，很容易让人迷惑。我这里再来解释一下。&nbsp;这需要从Context类型的声明讲起。这个接口中有两个方法与“撤销”息息相关。Done方法会返回一个元素类型为struct&#123;&#125;的接收通道。不过，这个接收通道的用途并不是传递元素值，而是让调用方去感知“撤销”当前Context值的那个信号。&nbsp;一旦当前的Context值被撤销，这里的接收通道就会被立即关闭。我们都知道，对于一个未包含任何元素值的通道来说，它的关闭会使任何针对它的接收操作立即结束。&nbsp;正因为如此，在coordinateWithContext函数中，基于调用表达式cxt.Done()的接收操作，才能够起到感知撤销信号的作用。&nbsp;除了让Context值的使用方感知到撤销信号，让它们得到“撤销”的具体原因，有时也是很有必要的。后者即是Context类型的Err方法的作用。该方法的结果是error类型的，并且其值只可能等于context.Canceled变量的值，或者context.DeadlineExceeded变量的值。&nbsp;前者用于表示手动撤销，而后者则代表：由于我们给定的过期时间已到，而导致的撤销。&nbsp;你可能已经感觉到了，对于Context值来说，“撤销”这个词如果当名词讲，指的其实就是被用来表达“撤销”状态的信号；如果当动词讲，指的就是对撤销信号的传达；而“可撤销的”指的则是具有传达这种撤销信号的能力。&nbsp;当我们通过调用context.WithCancel函数产生一个可撤销的Context值时，还会获得一个用于触发撤销信号的函数。&nbsp;通过调用这个函数，我们就可以触发针对这个Context值的撤销信号。一旦触发，撤销信号就会立即被传达给这个Context值，并由它的Done方法的结果值（一个接收通道）表达出来。&nbsp;撤销函数只负责触发信号，而对应的可撤销的Context值也只负责传达信号，它们都不会去管后边具体的“撤销”操作。实际上，我们的代码可以在感知到撤销信号之后，进行任意的操作，Context值对此并没有任何的约束。&nbsp;最后，若再深究的话，这里的“撤销”最原始的含义其实就是，终止程序针对某种请求（比如 HTTP 请求）的响应，或者取消对某种指令（比如 SQL 指令）的处理。这也是 Go 语言团队在创建context代码包，和Context类型时的初衷。&nbsp;撤销信号是如何在上下文树中传播的？&nbsp;context包中包含了四个用于繁衍Context值的函数。其中的WithCancel、WithDeadline和WithTimeout都是被用来基于给定的Context值产生可撤销的子值的。&nbsp;context包的WithCancel函数在被调用后会产生两个结果值。第一个结果值就是那个可撤销的Context值，而第二个结果值则是用于触发撤销信号的函数。&nbsp;在撤销函数被调用之后，对应的Context值会先关闭它内部的接收通道，也就是它的Done方法会返回的那个通道。&nbsp;然后，它会向它的所有子值（或者说子节点）传达撤销信号。这些子值会如法炮制，把撤销信号继续传播下去。最后，这个Context值会断开它与其父值之间的关联。&nbsp;&nbsp;我们通过调用context包的WithDeadline函数或者WithTimeout函数生成的Context值也是可撤销的。它们不但可以被手动撤销，还会依据在生成时被给定的过期时间，自动地进行定时撤销。这里定时撤销的功能是借助它们内部的计时器来实现的。&nbsp;当过期时间到达时，这两种Context值的行为与Context值被手动撤销时的行为是几乎一致的，只不过前者会在最后停止并释放掉其内部的计时器。&nbsp;最后要注意，通过调用context.WithValue函数得到的Context值是不可撤销的。撤销信号在被传播时，若遇到它们则会直接跨过，并试图将信号直接传给它们的子值。&nbsp;怎样通过Context值携带数据？怎样从中获取数据？&nbsp;既然谈到了context包的WithValue函数，我们就来说说Context值携带数据的方式。&nbsp;WithValue函数在产生新的Context值（以下简称含数据的Context值）的时候需要三个参数，即：父值、键和值。与“字典对于键的约束”类似，这里键的类型必须是可判等的。&nbsp;原因很简单，当我们从中获取数据的时候，它需要根据给定的键来查找对应的值。不过，这种Context值并不是用字典来存储键和值的，后两者只是被简单地存储在前者的相应字段中而已。&nbsp;Context类型的Value方法就是被用来获取数据的。在我们调用含数据的Context值的Value方法时，它会先判断给定的键，是否与当前值中存储的键相等，如果相等就把该值中存储的值直接返回，否则就到其父值中继续查找。&nbsp;如果其父值中仍然未存储相等的键，那么该方法就会沿着上下文根节点的方向一路查找下去。&nbsp;注意，除了含数据的Context值以外，其他几种Context值都是无法携带数据的。因此，Context值的Value方法在沿路查找的时候，会直接跨过那几种值。&nbsp;如果我们调用的Value方法的所属值本身就是不含数据的，那么实际调用的就将会是其父辈或祖辈的Value方法。这是由于这几种Context值的实际类型，都属于结构体类型，并且它们都是通过“将其父值嵌入到自身”，来表达父子关系的。&nbsp;最后，提醒一下，Context接口并没有提供改变数据的方法。因此，在通常情况下，我们只能通过在上下文树中添加含数据的Context值来存储新的数据，或者通过撤销此种值的父值丢弃掉相应的数据。如果你存储在这里的数据可以从外部改变，那么必须自行保证安全。&nbsp; &nbsp; 参考链接：https://time.geekbang.org/column/intro/112","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Go语言","slug":"Go语言","permalink":"http://wht6.github.io/tags/Go%E8%AF%AD%E8%A8%80/"}]},{"title":"原子操作","slug":"原子操作","date":"2022-03-06T11:00:00.000Z","updated":"2022-03-20T01:57:16.648Z","comments":true,"path":"posts/9000.html","link":"","permalink":"http://wht6.github.io/posts/9000.html","excerpt":"","text":"原子性执行和原子操作&nbsp; 我们已经知道，对于一个 Go 程序来说，Go 语言运行时系统中的调度器会恰当地安排其中所有的 goroutine 的运行。不过，在同一时刻，只可能有少数的 goroutine 真正地处于运行状态，并且这个数量只会与 M 的数量一致，而不会随着 G 的增多而增长。&nbsp;所以，为了公平起见，调度器总是会频繁地换上或换下这些 goroutine。换上的意思是，让一个 goroutine 由非运行状态转为运行状态，并促使其中的代码在某个 CPU 核心上执行。&nbsp;换下的意思正好相反，即：使一个 goroutine 中的代码中断执行，并让它由运行状态转为非运行状态。&nbsp;这个中断的时机有很多，任何两条语句执行的间隙，甚至在某条语句执行的过程中都是可以的。&nbsp;即使这些语句在临界区之内也是如此。所以，我们说，互斥锁虽然可以保证临界区中代码的串行执行，但却不能保证这些代码执行的原子性（atomicity）。&nbsp;在众多的同步工具中，真正能够保证原子性执行的只有原子操作（atomic operation）。原子操作在进行的过程中是不允许中断的。在底层，这会由 CPU 提供芯片级别的支持，所以绝对有效。即使在拥有多 CPU 核心，或者多 CPU 的计算机系统中，原子操作的保证也是不可撼动的。&nbsp;这使得原子操作可以完全地消除竞态条件，并能够绝对地保证并发安全性。并且，它的执行速度要比其他的同步工具快得多，通常会高出好几个数量级。不过，它的缺点也很明显。&nbsp;更具体地说，正是因为原子操作不能被中断，所以它需要足够简单，并且要求快速。&nbsp;你可以想象一下，如果原子操作迟迟不能完成，而它又不会被中断，那么将会给计算机执行指令的效率带来多么大的影响。因此，操作系统层面只对针对二进制位或整数的原子操作提供了支持。&nbsp;Go 语言的原子操作当然是基于 CPU 和操作系统的，所以它也只针对少数数据类型的值提供了原子操作函数。这些函数都存在于标准库代码包sync/atomic中。&nbsp; sync/atomic包的使用&nbsp;sync/atomic包中提供了几种原子操作？可操作的数据类型又有哪些？&nbsp;sync/atomic包中的函数可以做的原子操作有：加法（add）、比较并交换（compare and swap，简称 CAS）、加载（load）、存储（store）和交换（swap）。&nbsp;这些函数针对的数据类型并不多。但是，对这些类型中的每一个，sync/atomic包都会有一套函数给予支持。这些数据类型有：int32、int64、uint32、uint64、uintptr，以及unsafe包中的Pointer。不过，针对unsafe.Pointer类型，该包并未提供进行原子加法操作的函数。&nbsp;此外，sync/atomic包还提供了一个名为Value的类型，它可以被用来存储任意类型的值。&nbsp;我们都知道，传入这些原子操作函数的第一个参数值对应的都应该是那个被操作的值。比如，atomic.AddInt32函数的第一个参数，对应的一定是那个要被增大的整数。可是，这个参数的类型为什么不是int32而是*int32呢？&nbsp;回答是：因为原子操作函数需要的是被操作值的指针，而不是这个值本身；被传入函数的参数值都会被复制，像这种基本类型的值一旦被传入函数，就已经与函数外的那个值毫无关系了。&nbsp;所以，传入值本身没有任何意义。unsafe.Pointer类型虽然是指针类型，但是那些原子操作函数要操作的是这个指针值，而不是它指向的那个值，所以需要的仍然是指向这个指针值的指针。&nbsp;只要原子操作函数拿到了被操作值的指针，就可以定位到存储该值的内存地址。只有这样，它们才能够通过底层的指令，准确地操作这个内存地址上的数据。&nbsp;用于原子加法操作的函数可以做原子减法吗？比如，atomic.AddInt32函数可以用于减小那个被操作的整数值吗？&nbsp;回答是：当然是可以的。atomic.AddInt32函数的第二个参数代表差量，它的类型是int32，是有符号的。如果我们想做原子减法，那么把这个差量设置为负整数就可以了。&nbsp;对于atomic.AddInt64函数来说也是类似的。不过，要想用atomic.AddUint32和atomic.AddUint64函数做原子减法，就不能这么直接了，因为它们的第二个参数的类型分别是uint32和uint64，都是无符号的，不过，这也是可以做到的，就是稍微麻烦一些。&nbsp;例如，如果想对uint32类型的被操作值18做原子减法，比如说差量是-3，那么我们可以先把这个差量转换为有符号的int32类型的值，然后再把该值的类型转换为uint32，用表达式来描述就是uint32(int32(-3))。&nbsp;不过要注意，直接这样写会使 Go 语言的编译器报错，它会告诉你：“常量-3不在uint32类型可表示的范围内”，换句话说，这样做会让表达式的结果值溢出。&nbsp;不过，如果我们先把int32(-3)的结果值赋给变量delta，再把delta的值转换为uint32类型的值，就可以绕过编译器的检查并得到正确的结果了。&nbsp;最后，我们把这个结果作为atomic.AddUint32函数的第二个参数值，就可以达到对uint32类型的值做原子减法的目的了。&nbsp;还有一种更加直接的方式。我们可以依据下面这个表达式来给定atomic.AddUint32函数的第二个参数值：&nbsp; 1^uint32(-N-1)) &nbsp; 其中的N代表由负整数表示的差量。也就是说，我们先要把差量的绝对值减去1，然后再把得到的这个无类型的整数常量，转换为uint32类型的值，最后，在这个值之上做按位异或操作，就可以获得最终的参数值了。 &nbsp;这么做的原理也并不复杂。简单来说，此表达式的结果值的补码，与使用前一种方法得到的值的补码相同，所以这两种方式是等价的。我们都知道，整数在计算机中是以补码的形式存在的，所以在这里，结果值的补码相同就意味着表达式的等价。&nbsp;比较并交换操作与交换操作相比有什么不同？优势在哪里？&nbsp;回答是：比较并交换操作即 CAS 操作，是有条件的交换操作，只有在条件满足的情况下才会进行值的交换。&nbsp;所谓的交换指的是，把新值赋给变量，并返回变量的旧值。&nbsp;在进行 CAS 操作的时候，函数会先判断被操作变量的当前值，是否与我们预期的旧值相等。如果相等，它就把新值赋给该变量，并返回true以表明交换操作已进行；否则就忽略交换操作，并返回false。&nbsp;可以看到，CAS 操作并不是单一的操作，而是一种操作组合。这与其他的原子操作都不同。正因为如此，它的用途要更广泛一些。例如，我们将它与for语句联用就可以实现一种简易的自旋锁（spinlock）。&nbsp;1234567for &#123; if atomic.CompareAndSwapInt32(&amp;num2, 10, 0) &#123; fmt.Println(&quot;The second number has gone to zero.&quot;) break &#125; time.Sleep(time.Millisecond * 500)&#125;&nbsp; 在for语句中的 CAS 操作可以不停地检查某个需要满足的条件，一旦条件满足就退出for循环。这就相当于，只要条件未被满足，当前的流程就会被一直“阻塞”在这里。 &nbsp;这在效果上与互斥锁有些类似。不过，它们的适用场景是不同的。我们在使用互斥锁的时候，总是假设共享资源的状态会被其他的 goroutine 频繁地改变。&nbsp;而for语句加 CAS 操作的假设往往是：共享资源状态的改变并不频繁，或者，它的状态总会变成期望的那样。这是一种更加乐观，或者说更加宽松的做法。&nbsp;假设我已经保证了对一个变量的写操作都是原子操作，比如：加或减、存储、交换等等，那我对它进行读操作的时候，还有必要使用原子操作吗？&nbsp;回答是：很有必要。其中的道理你可以对照一下读写锁。为什么在读写锁保护下的写操作和读操作之间是互斥的？这是为了防止读操作读到没有被修改完的值，对吗？&nbsp;如果写操作还没有进行完，读操作就来读了，那么就只能读到仅修改了一部分的值。这显然破坏了值的完整性，读出来的值也是完全错误的。&nbsp;所以，一旦你决定了要对一个共享资源进行保护，那就要做到完全的保护。不完全的保护基本上与不保护没有什么区别。&nbsp;怎样用好sync/atomic.Value？&nbsp;此类型的值相当于一个容器，可以被用来“原子地”存储和加载任意的值。&nbsp;atomic.Value类型是开箱即用的，我们声明一个该类型的变量（以下简称原子变量）之后就可以直接使用了。这个类型使用起来很简单，它只有两个指针方法：Store和Load。不过，虽然简单，但还是有一些值得注意的地方的。&nbsp;首先一点，一旦atomic.Value类型的值（以下简称原子值）被真正使用，它就不应该再被复制了。什么叫做“真正使用”呢？&nbsp;我们只要用它来存储值了，就相当于开始真正使用了。atomic.Value类型属于结构体类型，而结构体类型属于值类型。&nbsp;所以，复制该类型的值会产生一个完全分离的新值。这个新值相当于被复制的那个值的一个快照。之后，不论后者存储的值怎样改变，都不会影响到前者，反之亦然。&nbsp;另外，关于用原子值来存储值，有两条强制性的使用规则。第一条规则，不能用原子值存储nil。&nbsp;也就是说，我们不能把nil作为参数值传入原子值的Store方法，否则就会引发一个 panic。&nbsp;这里要注意，如果有一个接口类型的变量，它的动态值是nil，但动态类型却不是nil，那么它的值就不等于nil。我在前面讲接口的时候和你说明过这个问题。正因为如此，这样一个变量的值是可以被存入原子值的。&nbsp;第二条规则，我们向原子值存储的第一个值，决定了它今后能且只能存储哪一个类型的值。&nbsp;例如，我第一次向一个原子值存储了一个string类型的值，那我在后面就只能用该原子值来存储字符串了。如果我又想用它存储结构体，那么在调用它的Store方法的时候就会引发一个 panic。这个 panic 会告诉我，这次存储的值的类型与之前的不一致。&nbsp;你可能会想：我先存储一个接口类型的值，然后再存储这个接口的某个实现类型的值，这样是不是可以呢？&nbsp;很可惜，这样是不可以的，同样会引发一个 panic。因为原子值内部是依据被存储值的实际类型来做判断的。所以，即使是实现了同一个接口的不同类型，它们的值也不能被先后存储到同一个原子值中。&nbsp;遗憾的是，我们无法通过某个方法获知一个原子值是否已经被真正使用，并且，也没有办法通过常规的途径得到一个原子值可以存储值的实际类型。这使得我们误用原子值的可能性大大增加，尤其是在多个地方使用同一个原子值的时候。&nbsp;下面，给你几条具体的使用建议。&nbsp; 不要把内部使用的原子值暴露给外界。比如，声明一个全局的原子变量并不是一个正确的做法。这个变量的访问权限最起码也应该是包级私有的。 如果不得不让包外，或模块外的代码使用你的原子值，那么可以声明一个包级私有的原子变量，然后再通过一个或多个公开的函数，让外界间接地使用到它。注意，这种情况下不要把原子值传递到外界，不论是传递原子值本身还是它的指针值。 如果通过某个函数可以向内部的原子值存储值的话，那么就应该在这个函数中先判断被存储值类型的合法性。若不合法，则应该直接返回对应的错误值，从而避免 panic 的发生。 如果可能的话，我们可以把原子值封装到一个数据类型中，比如一个结构体类型。这样，我们既可以通过该类型的方法更加安全地存储值，又可以在该类型中包含可存储值的合法类型信息。 &nbsp;除了上述使用建议之外，我还要再特别强调一点：尽量不要向原子值中存储引用类型的值。因为这很容易造成安全漏洞。请看下面的代码：&nbsp;1234var box6 atomic.Valuev6 := []int&#123;1, 2, 3&#125;box6.Store(v6)v6[1] = 4 // 注意，此处的操作不是并发安全的！&nbsp; 我把一个[]int类型的切片值v6, 存入了原子值box6。注意，切片类型属于引用类型。所以，我在外面改动这个切片值，就等于修改了box6中存储的那个值。这相当于绕过了原子值而进行了非并发安全的操作。那么，应该怎样修补这个漏洞呢？可以这样做： &nbsp;1234567store := func(v []int) &#123; replica := make([]int, len(v)) copy(replica, v) box6.Store(replica)&#125;store(v6)v6[2] = 5 // 此处的操作是安全的。&nbsp; 我先为切片值v6创建了一个完全的副本。这个副本涉及的数据已经与原值毫不相干了。然后，我再把这个副本存入box6。如此一来，无论我再对v6的值做怎样的修改，都不会破坏box6提供的安全保护。 &nbsp;&nbsp; 参考链接：https://time.geekbang.org/column/intro/112","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Go语言","slug":"Go语言","permalink":"http://wht6.github.io/tags/Go%E8%AF%AD%E8%A8%80/"}]},{"title":"标准库中的sync包","slug":"标准库中的sync包","date":"2022-03-06T03:00:00.000Z","updated":"2022-03-20T01:57:02.273Z","comments":true,"path":"posts/3ed6.html","link":"","permalink":"http://wht6.github.io/posts/3ed6.html","excerpt":"","text":"竞态条件、临界区和同步工具&nbsp; “sync”的中文意思是“同步”。&nbsp;相比于 Go 语言宣扬的“用通讯的方式共享数据”，通过共享数据的方式来传递信息和协调线程运行的做法其实更加主流，毕竟大多数的现代编程语言，都是用后一种方式作为并发编程的解决方案的。&nbsp;一旦数据被多个线程共享，那么就很可能会产生争用和冲突的情况。这种情况也被称为竞态条件（race condition），这往往会破坏共享数据的一致性。&nbsp;共享数据的一致性代表着某种约定，即：多个线程对共享数据的操作总是可以达到它们各自预期的效果。&nbsp;如果这个一致性得不到保证，那么将会影响到一些线程中代码和流程的正确执行，甚至会造成某种不可预知的错误。这种错误一般都很难发现和定位，排查起来的成本也是非常高的，所以一定要尽量避免。&nbsp;举个例子，同时有多个线程连续向同一个缓冲区写入数据块，如果没有一个机制去协调这些线程的写入操作的话，那么被写入的数据块就很可能会出现错乱。比如，在线程 A 还没有写完一个数据块的时候，线程 B 就开始写入另外一个数据块了。&nbsp;显然，这两个数据块中的数据会被混在一起，并且已经很难分清了。因此，在这种情况下，我们就需要采取一些措施来协调它们对缓冲区的修改。这通常就会涉及同步。&nbsp;概括来讲，同步的用途有两个，一个是避免多个线程在同一时刻操作同一个数据块，另一个是协调多个线程，以避免它们在同一时刻执行同一个代码块。&nbsp;由于这样的数据块和代码块的背后都隐含着一种或多种资源（比如存储资源、计算资源、I/O 资源、网络资源等等），所以我们可以把它们看做是共享资源，或者说共享资源的代表。我们所说的同步其实就是在控制多个线程对共享资源的访问。&nbsp;一个线程在想要访问某一个共享资源的时候，需要先申请对该资源的访问权限，并且只有在申请成功之后，访问才能真正开始。&nbsp;而当线程对共享资源的访问结束时，它还必须归还对该资源的访问权限，若要再次访问仍需申请。&nbsp;你可以把这里所说的访问权限想象成一块令牌，线程一旦拿到了令牌，就可以进入指定的区域，从而访问到资源，而一旦线程要离开这个区域了，就需要把令牌还回去，绝不能把令牌带走。&nbsp;如果针对某个共享资源的访问令牌只有一块，那么在同一时刻，就最多只能有一个线程进入到那个区域，并访问到该资源。&nbsp;这时，我们可以说，多个并发运行的线程对这个共享资源的访问是完全串行的。只要一个代码片段需要实现对共享资源的串行化访问，就可以被视为一个临界区（critical section），也就是我刚刚说的，由于要访问到资源而必须进入的那个区域。&nbsp;比如，在我前面举的那个例子中，实现了数据块写入操作的代码就共同组成了一个临界区。如果针对同一个共享资源，这样的代码片段有多个，那么它们就可以被称为相关临界区。&nbsp;它们可以是一个内含了共享数据的结构体及其方法，也可以是操作同一块共享数据的多个函数。临界区总是需要受到保护的，否则就会产生竞态条件。施加保护的重要手段之一，就是使用实现了某种同步机制的工具，也称为同步工具。&nbsp;&nbsp;在 Go 语言中，可供我们选择的同步工具并不少。其中，最重要且最常用的同步工具当属互斥量（mutual exclusion，简称 mutex）。sync包中的Mutex就是与其对应的类型，该类型的值可以被称为互斥量或者互斥锁。&nbsp; 互斥锁Mutex和读写锁RWMutex&nbsp;一个互斥锁可以被用来保护一个临界区或者一组相关临界区。我们可以通过它来保证，在同一时刻只有一个 goroutine 处于该临界区之内。&nbsp;为了兑现这个保证，每当有 goroutine 想进入临界区时，都需要先对它进行锁定，并且，每个 goroutine 离开临界区时，都要及时地对它进行解锁。&nbsp;锁定操作可以通过调用互斥锁的Lock方法实现，而解锁操作可以调用互斥锁的Unlock方法。&nbsp;123456mu.Lock()_, err := writer.Write([]byte(data))if err != nil &#123; log.Printf(&quot;error: %s [%d]&quot;, err, id)&#125;mu.Unlock()&nbsp; 我们使用互斥锁时有哪些注意事项？ &nbsp; 不要重复锁定互斥锁； 不要忘记解锁互斥锁，必要时使用defer语句； 不要对尚未锁定或者已解锁的互斥锁解锁； 不要在多个函数之间直接传递互斥锁。 &nbsp;首先，你还是要把互斥锁看作是针对某一个临界区或某一组相关临界区的唯一访问令牌。&nbsp;虽然没有任何强制规定来限制，你用同一个互斥锁保护多个无关的临界区，但是这样做，一定会让你的程序变得很复杂，并且也会明显地增加你的心智负担。&nbsp;你要知道，对一个已经被锁定的互斥锁进行锁定，是会立即阻塞当前的 goroutine 的。这个 goroutine 所执行的流程，会一直停滞在调用该互斥锁的Lock方法的那行代码上。&nbsp;直到该互斥锁的Unlock方法被调用，并且这里的锁定操作成功完成，后续的代码（也就是临界区中的代码）才会开始执行。这也正是互斥锁能够保护临界区的原因所在。&nbsp;一旦，你把一个互斥锁同时用在了多个地方，就必然会有更多的 goroutine 争用这把锁。这不但会让你的程序变慢，还会大大增加死锁（deadlock）的可能性。&nbsp;所谓的死锁，指的就是当前程序中的主 goroutine，以及我们启用的那些 goroutine 都已经被阻塞。这些 goroutine 可以被统称为用户级的 goroutine。这就相当于整个程序都已经停滞不前了。&nbsp;Go 语言运行时系统是不允许这种情况出现的，只要它发现所有的用户级 goroutine 都处于等待状态，就会自行抛出一个带有如下信息的 panic：&nbsp;1fatal error: all goroutines are asleep - deadlock!&nbsp; 注意，这种由 Go 语言运行时系统自行抛出的 panic 都属于致命错误，都是无法被恢复的，调用recover函数对它们起不到任何作用。也就是说，一旦产生死锁，程序必然崩溃。 &nbsp;因此，我们一定要尽量避免这种情况的发生。而最简单、有效的方式就是让每一个互斥锁都只保护一个临界区或一组相关临界区。&nbsp;在这个前提之下，我们还需要注意，对于同一个 goroutine 而言，既不要重复锁定一个互斥锁，也不要忘记对它进行解锁。&nbsp;一个 goroutine 对某一个互斥锁的重复锁定，就意味着它自己锁死了自己。先不说这种做法本身就是错误的，在这种情况下，想让其他的 goroutine 来帮它解锁是非常难以保证其正确性的。&nbsp;我以前就在团队代码库中见到过这样的代码。那个作者的本意是先让一个 goroutine 自己锁死自己，然后再让一个负责调度的 goroutine 定时地解锁那个互斥锁，从而让前一个 goroutine 周期性地去做一些事情，比如每分钟检查一次服务器状态，或者每天清理一次日志。&nbsp;这个想法本身是没有什么问题的，但却选错了实现的工具。对于互斥锁这种需要精细化控制的同步工具而言，这样的任务并不适合它。&nbsp;在这种情况下，即使选用通道或者time.Ticker类型，然后自行实现功能都是可以的，程序的复杂度和我们的心智负担也会小很多，更何况还有不少已经很完备的解决方案可供选择。&nbsp;话说回来，其实我们说“不要忘记解锁互斥锁”的一个很重要的原因就是：避免重复锁定。&nbsp;因为在一个 goroutine 执行的流程中，可能会出现诸如“锁定、解锁、再锁定、再解锁”的操作，所以如果我们忘记了中间的解锁操作，那就一定会造成重复锁定。&nbsp;除此之外，忘记解锁还会使其他的 goroutine 无法进入到该互斥锁保护的临界区，这轻则会导致一些程序功能的失效，重则会造成死锁和程序崩溃。&nbsp;在很多时候，一个函数执行的流程并不是单一的，流程中间可能会有分叉，也可能会被中断。&nbsp;如果一个流程在锁定了某个互斥锁之后分叉了，或者有被中断的可能，那么就应该使用defer语句来对它进行解锁，而且这样的defer语句应该紧跟在锁定操作之后。这是最保险的一种做法。&nbsp;忘记解锁导致的问题有时候是比较隐秘的，并不会那么快就暴露出来。这也是我们需要特别关注它的原因。相比之下，解锁未锁定的互斥锁会立即引发 panic。&nbsp;并且，与死锁导致的 panic 一样，它们是无法被恢复的。因此，我们总是应该保证，对于每一个锁定操作，都要有且只有一个对应的解锁操作。&nbsp;换句话说，我们应该让它们成对出现。这也算是互斥锁的一个很重要的使用原则了。在很多时候，利用defer语句进行解锁可以更容易做到这一点。&nbsp;&nbsp;最后，可能你已经知道，Go 语言中的互斥锁是开箱即用的。换句话说，一旦我们声明了一个sync.Mutex类型的变量，就可以直接使用它了。&nbsp;不过要注意，该类型是一个结构体类型，属于值类型中的一种。把它传给一个函数、将它从函数中返回、把它赋给其他变量、让它进入某个通道都会导致它的副本的产生。&nbsp;并且，原值和它的副本，以及多个副本之间都是完全独立的，它们都是不同的互斥锁。&nbsp;如果你把一个互斥锁作为参数值传给了一个函数，那么在这个函数中对传入的锁的所有操作，都不会对存在于该函数之外的那个原锁产生任何的影响。&nbsp;所以，你在这样做之前，一定要考虑清楚，这种结果是你想要的吗？我想，在大多数情况下应该都不是。即使你真的希望，在这个函数中使用另外一个互斥锁也不要这样做，这主要是为了避免歧义。&nbsp;读写锁与互斥锁有哪些异同？&nbsp; 读写锁是读 / 写互斥锁的简称。在 Go 语言中，读写锁由sync.RWMutex类型的值代表。与sync.Mutex类型一样，这个类型也是开箱即用的。&nbsp; 顾名思义，读写锁是把对共享资源的“读操作”和“写操作”区别对待了。它可以对这两种操作施加不同程度的保护。换句话说，相比于互斥锁，读写锁可以实现更加细腻的访问控制。&nbsp; 一个读写锁中实际上包含了两个锁，即：读锁和写锁。sync.RWMutex类型中的Lock方法和Unlock方法分别用于对写锁进行锁定和解锁，而它的RLock方法和RUnlock方法则分别用于对读锁进行锁定和解锁。&nbsp; 另外，对于同一个读写锁来说有如下规则。&nbsp; 在写锁已被锁定的情况下再试图锁定写锁，会阻塞当前的 goroutine。 在写锁已被锁定的情况下试图锁定读锁，也会阻塞当前的 goroutine。 在读锁已被锁定的情况下试图锁定写锁，同样会阻塞当前的 goroutine。 在读锁已被锁定的情况下再试图锁定读锁，并不会阻塞当前的 goroutine。 &nbsp;换一个角度来说，对于某个受到读写锁保护的共享资源，多个写操作不能同时进行，写操作和读操作也不能同时进行，但多个读操作却可以同时进行。&nbsp;当然了，只有在我们正确使用读写锁的情况下，才能达到这种效果。还是那句话，我们需要让每一个锁都只保护一个临界区，或者一组相关临界区，并以此尽量减少误用的可能性。顺便说一句，我们通常把这种不能同时进行的操作称为互斥操作。&nbsp;再来看另一个方面。对写锁进行解锁，会唤醒“所有因试图锁定读锁，而被阻塞的 goroutine”，并且，这通常会使它们都成功完成对读锁的锁定。&nbsp;然而，对读锁进行解锁，只会在没有其他读锁锁定的前提下，唤醒“因试图锁定写锁，而被阻塞的 goroutine”；并且，最终只会有一个被唤醒的 goroutine 能够成功完成对写锁的锁定，其他的 goroutine 还要在原处继续等待。至于是哪一个 goroutine，那就要看谁的等待时间最长了。&nbsp;除此之外，读写锁对写操作之间的互斥，其实是通过它内含的一个互斥锁实现的。因此，也可以说，Go 语言的读写锁是互斥锁的一种扩展。&nbsp;最后，需要强调的是，与互斥锁类似，解锁“读写锁中未被锁定的写锁”，会立即引发 panic，对于其中的读锁也是如此，并且同样是不可恢复的。&nbsp;总之，读写锁与互斥锁的不同，都源于它把对共享资源的写操作和读操作区别对待了。这也使得它实现的互斥规则要更复杂一些。&nbsp;不过，正因为如此，我们可以使用它对共享资源的操作，实行更加细腻的控制。另外，由于这里的读写锁是互斥锁的一种扩展，所以在有些方面它还是沿用了互斥锁的行为模式。比如，在解锁未锁定的写锁或读锁时的表现，又比如，对写操作之间互斥的实现方式。&nbsp; 条件变量&nbsp;我们常常会把条件变量（conditional variable）这个同步工具拿来与互斥锁一起讨论。实际上，条件变量是基于互斥锁的，它必须有互斥锁的支撑才能发挥作用。&nbsp;条件变量并不是被用来保护临界区和共享资源的，它是用于协调想要访问共享资源的那些线程的。当共享资源的状态发生变化时，它可以被用来通知被互斥锁阻塞的线程。&nbsp;比如说，我们两个人在共同执行一项秘密任务，这需要在不直接联系和见面的前提下进行。我需要向一个信箱里放置情报，你需要从这个信箱中获取情报。这个信箱就相当于一个共享资源，而我们就分别是进行写操作的线程和进行读操作的线程。&nbsp;如果我在放置的时候发现信箱里还有未被取走的情报，那就不再放置，而先返回。另一方面，如果你在获取的时候发现信箱里没有情报，那也只能先回去了。这就相当于写的线程或读的线程阻塞的情况。&nbsp;虽然我们俩都有信箱的钥匙，但是同一时刻只能有一个人插入钥匙并打开信箱，这就是锁的作用了。更何况咱们俩是不能直接见面的，所以这个信箱本身就可以被视为一个临界区。&nbsp;尽管没有协调好，咱们俩仍然要想方设法的完成任务啊。所以，如果信箱里有情报，而你却迟迟未取走，那我就需要每过一段时间带着新情报去检查一次，若发现信箱空了，我就需要及时地把新情报放到里面。&nbsp;另一方面，如果信箱里一直没有情报，那你也要每过一段时间去打开看看，一旦有了情报就及时地取走。这么做是可以的，但就是太危险了，很容易被敌人发现。&nbsp;后来，我们又想了一个计策，各自雇佣了一个不起眼的小孩儿。如果早上七点有一个戴红色帽子的小孩儿从你家楼下路过，那么就意味着信箱里有了新情报。另一边，如果上午九点有一个戴蓝色帽子的小孩儿从我家楼下路过，那就说明你已经从信箱中取走了情报。&nbsp;这样一来，咱们执行任务的隐蔽性高多了，并且效率的提升非常显著。这两个戴不同颜色帽子的小孩儿就相当于条件变量，在共享资源的状态产生变化的时候，起到了通知的作用。&nbsp;当然了，我们是在用 Go 语言编写程序，而不是在执行什么秘密任务。因此，条件变量在这里的最大优势就是在效率方面的提升。当共享资源的状态不满足条件的时候，想操作它的线程再也不用循环往复地做检查了，只要等待通知就好了。&nbsp;条件变量的初始化离不开互斥锁，并且它的方法有的也是基于互斥锁的。&nbsp;条件变量提供的方法有三个：等待通知（wait）、单发通知（signal）和广播通知（broadcast）。&nbsp;我们在利用条件变量等待通知的时候，需要在它基于的那个互斥锁保护下进行。而在进行单发通知或广播通知的时候，却是恰恰相反的，也就是说，需要在对应的互斥锁解锁之后再做这两种操作。&nbsp;先来创建如下几个变量。&nbsp;1234var mailbox uint8var lock sync.RWMutexsendCond := sync.NewCond(&amp;lock)recvCond := sync.NewCond(lock.RLocker())&nbsp; 变量mailbox代表信箱，是uint8类型的。 若它的值为0则表示信箱中没有情报，而当它的值为1时则说明信箱中有情报。lock是一个类型为sync.RWMutex的变量，是一个读写锁，也可以被视为信箱上的那把锁。 &nbsp;另外，基于这把锁，我还创建了两个代表条件变量的变量，名字分别叫sendCond和recvCond。 它们都是*sync.Cond类型的，同时也都是由sync.NewCond函数来初始化的。&nbsp;与sync.Mutex类型和sync.RWMutex类型不同，sync.Cond类型并不是开箱即用的。我们只能利用sync.NewCond函数创建它的指针值。这个函数需要一个sync.Locker类型的参数值。&nbsp;条件变量是基于互斥锁的，它必须有互斥锁的支撑才能够起作用。因此，这里的参数值是不可或缺的，它会参与到条件变量的方法实现当中。&nbsp;sync.Locker其实是一个接口，在它的声明中只包含了两个方法定义，即：Lock()和Unlock()。sync.Mutex类型和sync.RWMutex类型都拥有Lock方法和Unlock方法，只不过它们都是指针方法。因此，这两个类型的指针类型才是sync.Locker接口的实现类型。&nbsp;我在为sendCond变量做初始化的时候，把基于lock变量的指针值传给了sync.NewCond函数。&nbsp;原因是，lock变量的Lock方法和Unlock方法分别用于对其中写锁的锁定和解锁，它们与sendCond变量的含义是对应的。sendCond是专门为放置情报而准备的条件变量，向信箱里放置情报，可以被视为对共享资源的写操作。&nbsp;相应的，recvCond变量代表的是专门为获取情报而准备的条件变量。 虽然获取情报也会涉及对信箱状态的改变，但是好在做这件事的人只会有你一个，而且我们也需要借此了解一下，条件变量与读写锁中的读锁的联用方式。所以，在这里，我们暂且把获取情报看做是对共享资源的读操作。&nbsp;因此，为了初始化recvCond这个条件变量，我们需要的是lock变量中的读锁，并且还需要是sync.Locker类型的。&nbsp;可是，lock变量中用于对读锁进行锁定和解锁的方法却是RLock和RUnlock，它们与sync.Locker接口中定义的方法并不匹配。&nbsp;好在sync.RWMutex类型的RLocker方法可以实现这一需求。我们只要在调用sync.NewCond函数时，传入调用表达式lock.RLocker()的结果值，就可以使该函数返回符合要求的条件变量了。&nbsp;为什么说通过lock.RLocker()得来的值就是lock变量中的读锁呢？实际上，这个值所拥有的Lock方法和Unlock方法，在其内部会分别调用lock变量的RLock方法和RUnlock方法。也就是说，前两个方法仅仅是后两个方法的代理而已。&nbsp;好了，我们现在有四个变量。一个是代表信箱的mailbox，一个是代表信箱上的锁的lock。还有两个是，代表了蓝帽子小孩儿的sendCond，以及代表了红帽子小孩儿的recvCond。&nbsp;&nbsp;我，现在是一个 goroutine（携带的go函数），想要适时地向信箱里放置情报并通知你，应该怎么做呢？&nbsp;1234567lock.Lock()for mailbox == 1 &#123; sendCond.Wait()&#125;mailbox = 1lock.Unlock()recvCond.Signal()&nbsp; 我肯定需要先调用lock变量的Lock方法。注意，这个Lock方法在这里意味的是：持有信箱上的锁，并且有打开信箱的权利，而不是锁上这个锁。 &nbsp;然后，我要检查mailbox变量的值是否等于1，也就是说，要看看信箱里是不是还存有情报。如果还有情报，那么我就回家去等蓝帽子小孩儿了。&nbsp;这就是那条for语句以及其中的调用表达式sendCond.Wait()所表示的含义了。你可能会问，为什么这里是for语句而不是if语句呢？我在后面会对此进行解释的。&nbsp;我们再往后看，如果信箱里没有情报，那么我就把新情报放进去，关上信箱、锁上锁，然后离开。用代码表达出来就是mailbox = 1和lock.Unlock()。&nbsp;离开之后我还要做一件事，那就是让红帽子小孩儿准时去你家楼下路过。也就是说，我会及时地通知你“信箱里已经有新情报了”，我们调用recvCond的Signal方法就可以实现这一步骤。&nbsp;另一方面，你现在是另一个 goroutine，想要适时地从信箱中获取情报，然后通知我。&nbsp;1234567lock.RLock()for mailbox == 0 &#123; recvCond.Wait()&#125;mailbox = 0lock.RUnlock()sendCond.Signal()&nbsp; 你跟我做的事情在流程上其实基本一致，只不过每一步操作的对象是不同的。你需要调用的是lock变量的RLock方法。因为你要进行的是读操作，并且会使用recvCond变量作为辅助。recvCond与lock变量的读锁是对应的。 &nbsp;在打开信箱后，你要关注的是信箱里是不是没有情报，也就是检查mailbox变量的值是否等于0。如果它确实等于0，那么你就需要回家去等红帽子小孩儿，也就是调用recvCond的Wait方法。这里使用的依然是for语句。&nbsp;如果信箱里有情报，那么你就应该取走情报，关上信箱、锁上锁，然后离开。对应的代码是mailbox = 0和lock.RUnlock()。之后，你还需要让蓝帽子小孩儿准时去我家楼下路过。这样我就知道信箱中的情报已经被你获取了。&nbsp;以上这些，就是对咱们俩要执行秘密任务的代码实现。其中的条件变量的用法需要你特别注意。&nbsp;再强调一下，只要条件不满足，我就会通过调用sendCond变量的Wait方法，去等待你的通知，只有在收到通知之后我才会再次检查信箱。&nbsp;另外，当我需要通知你的时候，我会调用recvCond变量的Signal方法。你使用这两个条件变量的方式正好与我相反。你可能也看出来了，利用条件变量可以实现单向的通知，而双向的通知则需要两个条件变量。这也是条件变量的基本使用规则。&nbsp; 条件变量的Wait方法&nbsp;条件变量的Wait方法做了什么？&nbsp;在了解了条件变量的使用方式之后，你可能会有这么几个疑问。&nbsp; 为什么先要锁定条件变量基于的互斥锁，才能调用它的Wait方法？ 为什么要用for语句来包裹调用其Wait方法的表达式，用if语句不行吗？ &nbsp; 你需要对这个Wait方法的内部机制有所了解才能回答上来。&nbsp; 条件变量的Wait方法主要做了四件事。&nbsp; 把调用它的 goroutine（也就是当前的 goroutine）加入到当前条件变量的通知队列中。 解锁当前的条件变量基于的那个互斥锁。 让当前的 goroutine 处于等待状态，等到通知到来时再决定是否唤醒它。此时，这个 goroutine 就会阻塞在调用这个Wait方法的那行代码上。 如果通知到来并且决定唤醒这个 goroutine，那么就在唤醒它之后重新锁定当前条件变量基于的互斥锁。自此之后，当前的 goroutine 就会继续执行后面的代码了。 &nbsp;因为条件变量的Wait方法在阻塞当前的 goroutine 之前，会解锁它基于的互斥锁，所以在调用该Wait方法之前，我们必须先锁定那个互斥锁，否则在调用这个Wait方法时，就会引发一个不可恢复的 panic。&nbsp;为什么条件变量的Wait方法要这么做呢？你可以想象一下，如果Wait方法在互斥锁已经锁定的情况下，阻塞了当前的 goroutine，那么又由谁来解锁呢？别的 goroutine 吗？&nbsp;先不说这违背了互斥锁的重要使用原则，即：成对的锁定和解锁，就算别的 goroutine 可以来解锁，那万一解锁重复了怎么办？由此引发的 panic 可是无法恢复的。&nbsp;如果当前的 goroutine 无法解锁，别的 goroutine 也都不来解锁，那么又由谁来进入临界区，并改变共享资源的状态呢？只要共享资源的状态不变，即使当前的 goroutine 因收到通知而被唤醒，也依然会再次执行这个Wait方法，并再次被阻塞。&nbsp;所以说，如果条件变量的Wait方法不先解锁互斥锁的话，那么就只会造成两种后果：不是当前的程序因 panic 而崩溃，就是相关的 goroutine 全面阻塞。&nbsp;再解释第二个疑问。很显然，if语句只会对共享资源的状态检查一次，而for语句却可以做多次检查，直到这个状态改变为止。那为什么要做多次检查呢？&nbsp;这主要是为了保险起见。如果一个 goroutine 因收到通知而被唤醒，但却发现共享资源的状态，依然不符合它的要求，那么就应该再次调用条件变量的Wait方法，并继续等待下次通知的到来。&nbsp;这种情况是很有可能发生的，具体如下面所示。&nbsp; 有多个 goroutine 在等待共享资源的同一种状态。比如，它们都在等mailbox变量的值不为0的时候再把它的值变为0，这就相当于有多个人在等着我向信箱里放置情报。虽然等待的 goroutine 有多个，但每次成功的 goroutine 却只可能有一个。别忘了，条件变量的Wait方法会在当前的 goroutine 醒来后先重新锁定那个互斥锁。在成功的 goroutine 最终解锁互斥锁之后，其他的 goroutine 会先后进入临界区，但它们会发现共享资源的状态依然不是它们想要的。这个时候，for循环就很有必要了。 共享资源可能有的状态不是两个，而是更多。比如，mailbox变量的可能值不只有0和1，还有2、3、4。这种情况下，由于状态在每次改变后的结果只可能有一个，所以，在设计合理的前提下，单一的结果一定不可能满足所有 goroutine 的条件。那些未被满足的 goroutine 显然还需要继续等待和检查。 有一种可能，共享资源的状态只有两个，并且每种状态都只有一个 goroutine 在关注，就像我们在主问题当中实现的那个例子那样。不过，即使是这样，使用for语句仍然是有必要的。原因是，在一些多 CPU 核心的计算机系统中，即使没有收到条件变量的通知，调用其Wait方法的 goroutine 也是有可能被唤醒的。这是由计算机硬件层面决定的，即使是操作系统（比如 Linux）本身提供的条件变量也会如此。 &nbsp;综上所述，在包裹条件变量的Wait方法的时候，我们总是应该使用for语句。&nbsp;条件变量的Signal方法和Broadcast方法有哪些异同？&nbsp;条件变量的Signal方法和Broadcast方法都是被用来发送通知的，不同的是，前者的通知只会唤醒一个因此而等待的 goroutine，而后者的通知却会唤醒所有为此等待的 goroutine。&nbsp;条件变量的Wait方法总会把当前的 goroutine 添加到通知队列的队尾，而它的Signal方法总会从通知队列的队首开始，查找可被唤醒的 goroutine。所以，因Signal方法的通知，而被唤醒的 goroutine 一般都是最早等待的那一个。&nbsp;这两个方法的行为决定了它们的适用场景。如果你确定只有一个 goroutine 在等待通知，或者只需唤醒任意一个 goroutine 就可以满足要求，那么使用条件变量的Signal方法就好了。&nbsp;否则，使用Broadcast方法总没错，只要你设置好各个 goroutine 所期望的共享资源状态就可以了。&nbsp;此外，再次强调一下，与Wait方法不同，条件变量的Signal方法和Broadcast方法并不需要在互斥锁的保护下执行。恰恰相反，我们最好在解锁条件变量基于的那个互斥锁之后，再去调用它的这两个方法。这更有利于程序的运行效率。&nbsp;最后，请注意，条件变量的通知具有即时性。也就是说，如果发送通知的时候没有 goroutine 为此等待，那么该通知就会被直接丢弃。在这之后才开始等待的 goroutine 只可能被后面的通知唤醒。&nbsp;&nbsp; 参考链接：https://time.geekbang.org/column/intro/112","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Go语言","slug":"Go语言","permalink":"http://wht6.github.io/tags/Go%E8%AF%AD%E8%A8%80/"}]},{"title":"测试的基本规则和流程","slug":"测试的基本规则和流程","date":"2022-03-05T02:00:00.000Z","updated":"2022-03-20T01:56:47.856Z","comments":true,"path":"posts/cd2d.html","link":"","permalink":"http://wht6.github.io/posts/cd2d.html","excerpt":"","text":"对于程序或软件的测试也分很多种，比如：单元测试、API 测试、集成测试、灰度测试，等等。在篇会主要针对单元测试进行讲解。 &nbsp; 单元测试的类别&nbsp;单元测试，它又称程序员测试。顾名思义，这就是程序员们本该做的自我检查工作之一。&nbsp;Go 语言的缔造者们从一开始就非常重视程序测试，并且为 Go 程序的开发者们提供了丰富的 API 和工具。利用这些 API 和工具，我们可以创建测试源码文件，并为命令源码文件和库源码文件中的程序实体，编写测试用例。&nbsp;在 Go 语言中，一个测试用例往往会由一个或多个测试函数来代表，不过在大多数情况下，每个测试用例仅用一个测试函数就足够了。测试函数往往用于描述和保障某个程序实体的某方面功能，比如，该功能在正常情况下会因什么样的输入，产生什么样的输出，又比如，该功能会在什么情况下报错或表现异常，等等。&nbsp;我们可以为 Go 程序编写三类测试，即：功能测试（test）、基准测试（benchmark，也称性能测试），以及示例测试（example）。&nbsp;对于前两类测试，从名称上你就应该可以猜到它们的用途。而示例测试严格来讲也是一种功能测试，只不过它更关注程序打印出来的内容。&nbsp;一般情况下，一个测试源码文件只会针对于某个命令源码文件，或库源码文件（以下简称被测源码文件）做测试，所以我们总会（并且应该）把它们放在同一个代码包内。&nbsp; 测试源码文件的主名称应该以被测源码文件的主名称为前导，并且必须以“_test”为后缀。例如，如果被测源码文件的名称为 demo52.go，那么针对它的测试源码文件的名称就应该是 demo52_test.go。 &nbsp; 每个测试源码文件都必须至少包含一个测试函数。并且，从语法上讲，每个测试源码文件中，都可以包含用来做任何一类测试的测试函数，即使把这三类测试函数都塞进去也没有问题。我通常就是这么做的，只要把控好测试函数的分组和数量就可以了。&nbsp;我们可以依据这些测试函数针对的不同程序实体，把它们分成不同的逻辑组，并且，利用注释以及帮助类的变量或函数来做分割。同时，我们还可以依据被测源码文件中程序实体的先后顺序，来安排测试源码文件中测试函数的顺序。&nbsp;此外，不仅仅对测试源码文件的名称，对于测试函数的名称和签名，Go 语言也是有明文规定的。&nbsp;Go 语言对测试函数的名称和签名都有哪些规定？&nbsp; 对于功能测试函数来说，其名称必须以Test为前缀，并且参数列表中只应有一个*testing.T类型的参数声明。 对于性能测试函数来说，其名称必须以Benchmark为前缀，并且唯一参数的类型必须是*testing.B类型的。 对于示例测试函数来说，其名称必须以Example为前缀，但对函数的参数列表没有强制规定。 &nbsp;首先需要记住一点，只有测试源码文件的名称对了，测试函数的名称和签名也对了，当我们运行go test命令的时候，其中的测试代码才有可能被运行。 &nbsp;go test命令在开始运行时，会先做一些准备工作，比如，确定内部需要用到的命令，检查我们指定的代码包或源码文件的有效性，以及判断我们给予的标记是否合法，等等。&nbsp;在准备工作顺利完成之后，go test命令就会针对每个被测代码包，依次地进行构建、执行包中符合要求的测试函数，清理临时文件，打印测试结果。这就是通常情况下的主要测试流程。&nbsp;请注意上述的“依次”二字。对于每个被测代码包，go test命令会串行地执行测试流程中的每个步骤。&nbsp;但是，为了加快测试速度，它通常会并发地对多个被测代码包进行功能测试，只不过，在最后打印测试结果的时候，它会依照我们给定的顺序逐个进行，这会让我们感觉到它是在完全串行地执行测试流程。&nbsp;另一方面，由于并发的测试会让性能测试的结果存在偏差，所以性能测试一般都是串行进行的。更具体地说，只有在所有构建步骤都做完之后，go test命令才会真正地开始进行性能测试。&nbsp;并且，下一个代码包性能测试的进行，总会等到上一个代码包性能测试的结果打印完成才会开始，而且性能测试函数的执行也都会是串行的。&nbsp;一旦清楚了 Go 程序测试的具体过程，我们的一些疑惑就自然有了答案。比如，那个名叫TestIntroduce的测试函数为什么没执行，又比如，为什么即使是简单的性能测试，执行起来也会比功能测试慢，等等。&nbsp; 测试结果&nbsp;怎样解释功能测试的测试结果？&nbsp;先来看下面的测试命令和结果：&nbsp; 12$ go test puzzlers&#x2F;article20&#x2F;q2ok puzzlers&#x2F;article20&#x2F;q2 0.008s &nbsp; 以$符号开头表明此行展现的是我输入的命令。在这里，我输入了go test puzzlers/article20/q2，这表示我想对导入路径为puzzlers/article20/q2的代码包进行测试。代码下面一行就是此次测试的简要结果。 &nbsp;这个简要结果有三块内容。最左边的ok表示此次测试成功，也就是说没有发现测试结果不如预期的情况。&nbsp;当然了，这里全由我们编写的测试代码决定，我们总是认定测试代码本身没有 Bug，并且忠诚地落实了我们的测试意图。在测试结果的中间，显示的是被测代码包的导入路径。&nbsp;而在最右边，展现的是此次对该代码包的测试所耗费的时间，这里显示的0.008s，即 8 毫秒。不过，当我们紧接着第二次运行这个命令的时候，输出的测试结果会略有不同，如下所示：&nbsp;12$ go test puzzlers&#x2F;article20&#x2F;q2ok puzzlers&#x2F;article20&#x2F;q2 (cached)&nbsp; 可以看到，结果最右边的不再是测试耗时，而是(cached)。这表明，由于测试代码与被测代码都没有任何变动，所以go test命令直接把之前缓存测试成功的结果打印出来了。 &nbsp;go 命令通常会缓存程序构建的结果，以便在将来的构建中重用。我们可以通过运行go env GOCACHE命令来查看缓存目录的路径。缓存的数据总是能够正确地反映出当时的各种源码文件、构建环境、编译器选项等等的真实情况。&nbsp;一旦有任何变动，缓存数据就会失效，go 命令就会再次真正地执行操作。所以我们并不用担心打印出的缓存数据不是实时的结果。go 命令会定期地删除最近未使用的缓存数据，但是，如果你想手动删除所有的缓存数据，运行一下go clean -cache命令就好了。&nbsp;对于测试成功的结果，go 命令也是会缓存的。运行go clean -testcache将会删除所有的测试结果缓存。不过，这样做肯定不会删除任何构建结果缓存。&nbsp; 此外，设置环境变量GODEBUG的值也可以稍稍地改变 go 命令的缓存行为。比如，设置值为gocacheverify=1将会导致 go 命令绕过任何的缓存数据，而真正地执行操作并重新生成所有结果，然后再去检查新的结果与现有的缓存数据是否一致。 &nbsp;总之，我们并不用在意缓存数据的存在，因为它们肯定不会妨碍go test命令打印正确的测试结果。 &nbsp;你可能会问，如果测试失败，命令打印的结果将会是怎样的？如果功能测试函数的那个唯一参数被命名为t，那么当我们在其中调用t.Fail方法时，虽然当前的测试函数会继续执行下去，但是结果会显示该测试失败。如下所示：&nbsp;12345$ go test puzzlers&#x2F;article20&#x2F;q2--- FAIL: TestFail (0.00s) demo53_test.go:49: Failed.FAILFAIL puzzlers&#x2F;article20&#x2F;q2 0.007s&nbsp; 我们运行的命令与之前是相同的，但是我新增了一个功能测试函数TestFail，并在其中调用了t.Fail方法。测试结果显示，对被测代码包的测试，由于TestFail函数的测试失败而宣告失败。 &nbsp;注意，对于失败测试的结果，go test命令并不会进行缓存，所以，这种情况下的每次测试都会产生全新的结果。另外，如果测试失败了，那么go test命令将会导致：失败的测试函数中的常规测试日志一并被打印出来。&nbsp;在这里的测试结果中，之所以显示了“demo53_test.go:49: Failed.”这一行，是因为我在TestFail函数中的调用表达式t.Fail()的下边编写了代码t.Log(&quot;Failed.&quot;)。&nbsp;t.Log方法以及t.Logf方法的作用，就是打印常规的测试日志，只不过当测试成功的时候，go test命令就不会打印这类日志了。如果你想在测试结果中看到所有的常规测试日志，那么可以在运行go test命令的时候加入标记-v。&nbsp;若我们想让某个测试函数在执行的过程中立即失败，则可以在该函数中调用t.FailNow方法。&nbsp;我在下面把TestFail函数中的t.Fail()改为t.FailNow()。&nbsp;与t.Fail()不同，在t.FailNow()执行之后，当前函数会立即终止执行。换句话说，该行代码之后的所有代码都会失去执行机会。在这样修改之后，我再次运行上面的命令，得到的结果如下：&nbsp;123--- FAIL: TestFail (0.00s)FAILFAIL puzzlers&#x2F;article20&#x2F;q2 0.008s&nbsp; 显然，之前显示在结果中的常规测试日志并没有出现在这里。 &nbsp;顺便说一下，如果你想在测试失败的同时打印失败测试日志，那么可以直接调用t.Error方法或者t.Errorf方法。&nbsp;前者相当于t.Log方法和t.Fail方法的连续调用，而后者也与之类似，只不过它相当于先调用了t.Logf方法。&nbsp;除此之外，还有t.Fatal方法和t.Fatalf方法，它们的作用是在打印失败错误日志之后立即终止当前测试函数的执行并宣告测试失败。更具体地说，这相当于它们在最后都调用了t.FailNow方法。&nbsp;怎样解释性能测试的测试结果？&nbsp;性能测试与功能测试的结果格式有很多相似的地方。我们在这里仅关注前者的特殊之处。请看下面的打印结果。&nbsp;1234567$ go test -bench&#x3D;. -run&#x3D;^$ puzzlers&#x2F;article20&#x2F;q3goos: darwingoarch: amd64pkg: puzzlers&#x2F;article20&#x2F;q3BenchmarkGetPrimes-8 500000 2314 ns&#x2F;opPASSok puzzlers&#x2F;article20&#x2F;q3 1.192s&nbsp; 我在运行go test命令的时候加了两个标记。第一个标记及其值为-bench=.，只有有了这个标记，命令才会进行性能测试。该标记的值.表明需要执行任意名称的性能测试函数，当然了，函数名称还是要符合 Go 程序测试的基本规则的。 &nbsp;第二个标记及其值是-run=^$，这个标记用于表明需要执行哪些功能测试函数，这同样也是以函数名称为依据的。该标记的值^$意味着：只执行名称为空的功能测试函数，换句话说，不执行任何功能测试函数。&nbsp;你可能已经看出来了，这两个标记的值都是正则表达式。实际上，它们只能以正则表达式为值。此外，如果运行go test命令的时候不加-run标记，那么就会使它执行被测代码包中的所有功能测试函数。&nbsp;再来看测试结果，重点说一下倒数第三行的内容。BenchmarkGetPrimes-8被称为单个性能测试的名称，它表示命令执行了性能测试函数BenchmarkGetPrimes，并且当时所用的最大 P 数量为8。&nbsp;最大 P 数量相当于可以同时运行 goroutine 的逻辑 CPU 的最大个数。这里的逻辑 CPU，也可以被称为 CPU 核心，但它并不等同于计算机中真正的 CPU 核心，只是 Go 语言运行时系统内部的一个概念，代表着它同时运行 goroutine 的能力。&nbsp;顺便说一句，一台计算机的 CPU 核心的个数，意味着它能在同一时刻执行多少条程序指令，代表着它并行处理程序指令的能力。&nbsp;我们可以通过调用 runtime.GOMAXPROCS函数改变最大 P 数量，也可以在运行go test命令时，加入标记-cpu来设置一个最大 P 数量的列表，以供命令在多次测试时使用。&nbsp;在性能测试名称右边的是，go test命令最后一次执行性能测试函数（即BenchmarkGetPrimes函数）的时候，被测函数（即GetPrimes函数）被执行的实际次数。这是什么意思呢？&nbsp;go test命令在执行性能测试函数的时候会给它一个正整数，若该测试函数的唯一参数的名称为b，则该正整数就由b.N代表。我们应该在测试函数中配合着编写代码，比如：&nbsp;123for i := 0; i &lt; b.N; i++ &#123; GetPrimes(1000)&#125;&nbsp; 我在一个会迭代b.N次的循环中调用了GetPrimes函数，并给予它参数值1000。go test命令会先尝试把b.N设置为1，然后执行测试函数。 &nbsp;如果测试函数的执行时间没有超过上限（此上限默认为 1 秒），那么命令就会改大b.N的值，然后再次执行测试函数，如此往复，直到这个时间大于或等于上限为止。&nbsp;当某次执行的时间大于或等于上限时，我们就说这是命令此次对该测试函数的最后一次执行。这时的b.N的值就会被包含在测试结果中，也就是上述测试结果中的500000。&nbsp;我们可以简称该值为执行次数，但要注意，它指的是被测函数的执行次数，而不是性能测试函数的执行次数。&nbsp;最后再看这个执行次数的右边，2314 ns/op表明单次执行GetPrimes函数的平均耗时为2314纳秒。这其实就是通过将最后一次执行测试函数时的执行时间，除以（被测函数的）执行次数而得出的。&nbsp; &nbsp; -cpu的功能&nbsp;go test命令的标记-cpu，它是用来设置测试执行最大 P 数量的列表的。&nbsp; P 是 processor 的缩写，每个 processor 都是一个可以承载若干个 G，且能够使这些 G 适时地与 M 进行对接并得到真正运行的中介。 正是由于 P 的存在，G 和 M 才可以呈现出多对多的关系，并能够及时、灵活地进行组合和分离。 这里的 G 就是 goroutine 的缩写，可以被理解为 Go 语言自己实现的用户级线程。M 即为 machine 的缩写，代表着系统级线程，或者说操作系统内核级别的线程。 &nbsp;Go 语言并发编程模型中的 P，正是 goroutine 的数量能够数十万计的关键所在。P 的数量意味着 Go 程序背后的运行时系统中，会有多少个用于承载可运行的 G 的队列存在。&nbsp;每一个队列都相当于一条流水线，它会源源不断地把可运行的 G 输送给空闲的 M，并使这两者对接。&nbsp;一旦对接完成，被对接的 G 就真正地运行在操作系统的内核级线程之上了。每条流水线之间虽然会有联系，但都是独立运作的。&nbsp;因此，最大 P 数量就代表着 Go 语言运行时系统同时运行 goroutine 的能力，也可以被视为其中逻辑 CPU 的最大个数。而go test命令的-cpu标记正是用于设置这个最大个数的。&nbsp;也许你已经知道，在默认情况下，最大 P 数量就等于当前计算机 CPU 核心的实际数量。&nbsp;当然了，前者也可以大于或者小于后者，如此可以在一定程度上模拟拥有不同的 CPU 核心数的计算机。&nbsp;所以，也可以说，使用-cpu标记可以模拟：被测程序在计算能力不同计算机中的表现。&nbsp;怎样设置-cpu标记的值，以及它会对测试流程产生什么样的影响？&nbsp;标记-cpu的值应该是一个正整数的列表，该列表的表现形式为：以英文半角逗号分隔的多个整数字面量，比如1,2,4。&nbsp;针对于此值中的每一个正整数，go test命令都会先设置最大 P 数量为该数，然后再执行测试函数。&nbsp;如果测试函数有多个，那么go test命令会依照此方式逐个执行。&nbsp; 以1,2,4为例，go test命令会先以1,2,4为最大 P 数量分别去执行第一个测试函数，之后再用同样的方式执行第二个测试函数，以此类推。 &nbsp;不论我们是否追加了-cpu标记，go test命令执行测试函数时流程都是相同的，只不过具体执行步骤会略有不同。&nbsp;go test命令在进行准备工作的时候会读取-cpu标记的值，并把它转换为一个以int为元素类型的切片，我们也可以称它为逻辑 CPU 切片。&nbsp;如果该命令发现我们并没有追加这个标记，那么就会让逻辑 CPU 切片只包含一个元素值，即最大 P 数量的默认值，也就是当前计算机 CPU 核心的实际数量。&nbsp;在准备执行某个测试函数的时候，无论该函数是功能测试函数，还是性能测试函数，go test命令都会迭代逻辑 CPU 切片，并且在每次迭代时，先依据当前的元素值设置最大 P 数量，然后再去执行测试函数。&nbsp;注意，对于性能测试函数来说，这里可能不只执行了一次。&nbsp;概括来讲，go test命令每一次对性能测试函数的执行，都是一个探索的过程。它会在测试函数的执行时间上限不变的前提下，尝试找到被测程序的最大执行次数。&nbsp;在这个过程中，性能测试函数可能会被执行多次。为了以后描述方便，我们把这样一个探索的过程称为：对性能测试函数的一次探索式执行，这其中包含了对该函数的若干次执行，当然，肯定也包括了对被测程序更多次的执行。&nbsp;说到多次执行测试函数，我们就不得不提及另外一个标记，即-count。-count标记是专门用于重复执行测试函数的。它的值必须大于或等于0，并且默认值为1。&nbsp;如果我们在运行go test命令的时候追加了-count 5，那么对于每一个测试函数，命令都会在预设的不同条件下（比如不同的最大 P 数量下）分别重复执行五次。&nbsp;如果我们把前文所述的-cpu标记、-count标记，以及探索式执行联合起来看，就可以用一个公式来描述单个性能测试函数，在go test命令的一次运行过程中的执行次数，即：&nbsp; 性能测试函数的执行次数 = -cpu标记的值中正整数的个数 x -count标记的值 x 探索式执行中测试函数的实际执行次数 &nbsp;对于功能测试函数来说，这个公式会更加简单一些，即：&nbsp; 功能测试函数的执行次数 = -cpu标记的值中正整数的个数 x -count标记的值 &nbsp;&nbsp;你也许遇到过这种情况，在对 Go 程序执行某种自动化测试的过程中，测试日志会显得特别多，而且好多都是重复的。&nbsp;这时，我们首先就应该想到，上面这些导致测试函数多次执行的标记和流程。我们往往需要检查这些标记的使用是否合理、日志记录是否有必要等等，从而对测试日志进行精简。&nbsp;比如，对于功能测试函数来说，我们通常没有必要重复执行它，即使是在不同的最大 P 数量下也是如此。注意，这里所说的重复执行指的是，在被测程序的输入（比如说被测函数的参数值）相同情况下的多次执行。&nbsp;有些时候，在输入完全相同的情况下，被测程序会因其他外部环境的不同，而表现出不同的行为。这时我们需要考虑的往往应该是：这个程序在设计上是否合理，而不是通过重复执行测试来检测风险。&nbsp;还有些时候，我们的程序会无法避免地依赖一些外部环境，比如数据库或者其他服务。这时，我们依然不应该让测试的反复执行成为检测手段，而应该在测试中通过仿造（mock）外部环境，来规避掉它们的不确定性。&nbsp;其实，单元测试的意思就是：对单一的功能模块进行边界清晰的测试，并且不掺杂任何对外部环境的检测。这也是“单元”二字要表达的主要含义。&nbsp;正好相反，对于性能测试函数来说，我们常常需要反复地执行，并以此试图抹平当时的计算资源调度的细微差别对被测程序性能的影响。通过-cpu标记，我们还能够模拟被测程序在计算能力不同计算机中的性能表现。&nbsp;不过要注意，这里设置的最大 P 数量，最好不要超过当前计算机 CPU 核心的实际数量。因为一旦超出计算机实际的并行处理能力，Go 程序在性能上就无法再得到显著地提升了。&nbsp;这就像一个漏斗，不论我们怎样灌水，水的漏出速度总是有限的。更何况，为了管理过多的 P，Go 语言运行时系统还会耗费额外的计算资源。&nbsp;显然，上述模拟得出的程序性能一定是不准确的。不过，这或多或少可以作为一个参考，因为，这样模拟出的性能一般都会低于程序在计算环境中的实际性能。&nbsp;-parallel标记的作用是什么？&nbsp;在运行go test命令的时候，可以追加标记-parallel，该标记的作用是：设置同一个被测代码包中的功能测试函数的最大并发执行数。该标记的默认值是测试运行时的最大 P 数量（这可以通过调用表达式runtime.GOMAXPROCS(0)获得）。&nbsp;对于功能测试，为了加快测试速度，命令通常会并发地测试多个被测代码包。&nbsp;但是，在默认情况下，对于同一个被测代码包中的多个功能测试函数，命令会串行地执行它们。除非我们在一些功能测试函数中显式地调用t.Parallel方法。&nbsp;这个时候，这些包含了t.Parallel方法调用的功能测试函数就会被go test命令并发地执行，而并发执行的最大数量正是由-parallel标记值决定的。不过要注意，同一个功能测试函数的多次执行之间一定是串行的。&nbsp;强调一下，-parallel标记对性能测试是无效的。当然了，对于性能测试来说，也是可以并发进行的，不过机制上会有所不同。&nbsp;性能测试函数中的计时器是做什么用的?&nbsp;testing包的testing.B类型有这么几个指针方法：StartTimer、StopTimer和ResetTimer。这些方法都是用于操作当前的性能测试函数专属的计时器的。&nbsp;所谓的计时器，是一个逻辑上的概念，它其实是testing.B类型中一些字段的统称。这些字段用于记录：当前测试函数在当次执行过程中耗费的时间、分配的堆内存的字节数以及分配次数。&nbsp;下面会以测试函数的执行时间为例，来说明此计时器的用法。不过，你需要知道的是，这三个方法在开始记录、停止记录或重新记录执行时间的同时，也会对堆内存分配字节数和分配次数的记录起到相同的作用。&nbsp;实际上，go test命令本身就会用到这样的计时器。当准备执行某个性能测试函数的时候，命令会重置并启动该函数专属的计时器。一旦这个函数执行完毕，命令又会立即停止这个计时器。&nbsp;如此一来，命令就能够准确地记录下（我们在前面多次提到的）测试函数执行时间了。然后，命令就会将这个时间与执行时间上限进行比较，并决定是否在改大b.N的值之后，再次执行测试函数。&nbsp;这就是对性能测试函数的探索式执行。显然，如果我们在测试函数中自行操作这个计时器，就一定会影响到这个探索式执行的结果。也就是说，这会让命令找到被测程序的最大执行次数有所不同。&nbsp;12345678910func BenchmarkGetPrimes(b *testing.B) &#123; b.StopTimer() time.Sleep(time.Millisecond * 500) // 模拟某个耗时但与被测程序关系不大的操作。 max := 10000 b.StartTimer() for i := 0; i &lt; b.N; i++ &#123; GetPrimes(max) &#125;&#125;&nbsp; 需要注意的是该函数体中的前四行代码。我先停止了当前测试函数的计时器，然后通过调用time.Sleep函数，模拟了一个比较耗时的额外操作，并且在给变量max赋值之后又启动了该计时器。 &nbsp;你可以想象一下，我们需要耗费额外的时间去确定max变量的值，虽然在后面它会被传入GetPrimes函数，但是，针对GetPrimes函数本身的性能测试并不应该包含确定参数值的过程。&nbsp;因此，我们需要把这个过程所耗费的时间，从当前测试函数的执行时间中去除掉。这样就能够避免这一过程对测试结果的不良影响了。&nbsp;每当这个测试函数执行完毕后，go test命令拿到的执行时间都只应该包含调用GetPrimes函数所耗费的那些时间。只有依据这个时间做出的后续判断，以及找到被测程序的最大执行次数才是准确的。&nbsp;在性能测试函数中，我们可以通过对b.StartTimer和b.StopTimer方法的联合运用，再去除掉任何一段代码的执行时间。&nbsp;相比之下，b.ResetTimer方法的灵活性就要差一些了，它只能用于：去除在调用它之前那些代码的执行时间。不过，无论在调用它的时候，计时器是不是正在运行，它都可以起作用。&nbsp;扩展：-benchmem标记的作用是在性能测试完成后打印内存分配统计信息。-benchtime标记的作用是设定测试函数的执行时间上限。 &nbsp;&nbsp; 参考链接：https://time.geekbang.org/column/intro/112","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Go语言","slug":"Go语言","permalink":"http://wht6.github.io/tags/Go%E8%AF%AD%E8%A8%80/"}]},{"title":"Go语言的程序异常","slug":"Go语言的程序异常","date":"2022-03-04T07:00:00.000Z","updated":"2022-03-20T01:54:39.761Z","comments":true,"path":"posts/c175.html","link":"","permalink":"http://wht6.github.io/posts/c175.html","excerpt":"","text":"本篇展示 Go 语言的另外一种错误处理方式。不过，严格来说，它处理的不是错误，而是异常，并且是一种在我们意料之外的程序异常。 &nbsp; 运行时恐慌panic&nbsp;这种程序异常被叫做 panic，我把它翻译为运行时恐慌。其中的“恐慌”二字是由 panic 直译过来的，而之所以前面又加上了“运行时”三个字，是因为这种异常只会在程序运行的时候被抛出来。&nbsp;比如说，一个 Go 程序里有一个切片，它的长度是 5，也就是说该切片中的元素值的索引分别为0、1、2、3、4，但是，我在程序里却想通过索引5访问其中的元素值，显而易见，这样的访问是不正确的。&nbsp;Go 程序，确切地说是程序内嵌的 Go 语言运行时系统，会在执行到这行代码的时候抛出一个“index out of range”的 panic，用以提示你索引越界了。&nbsp;当然了，这不仅仅是个提示。当 panic 被抛出之后，如果我们没有在程序里添加任何保护措施的话，程序（或者说代表它的那个进程）就会在打印出 panic 的详细情况（以下简称 panic 详情）之后，终止运行。&nbsp;现在，就让我们来看一下这样的 panic 详情中都有什么。&nbsp;123456panic: runtime error: index out of range goroutine 1 [running]:main.main() &#x2F;Users&#x2F;haolin&#x2F;GeekTime&#x2F;Golang_Puzzlers&#x2F;src&#x2F;puzzlers&#x2F;article19&#x2F;q0&#x2F;demo47.go:5 +0x3dexit status 2&nbsp; 这份详情的第一行是“panic: runtime error: index out of range”。其中的“runtime error”的含义是，这是一个runtime代码包中抛出的 panic。在这个 panic 中，包含了一个runtime.Error接口类型的值。runtime.Error接口内嵌了error接口，并做了一点点扩展，runtime包中有不少它的实现类型。 &nbsp;实际上，此详情中的“panic：”右边的内容，正是这个 panic 包含的runtime.Error类型值的字符串表示形式。&nbsp;此外，panic 详情中，一般还会包含与它的引发原因有关的 goroutine 的代码执行信息。正如前述详情中的“goroutine 1 [running]”，它表示有一个 ID 为1的 goroutine 在此 panic 被引发的时候正在运行。&nbsp;注意，这里的 ID 其实并不重要，因为它只是 Go 语言运行时系统内部给予的一个 goroutine 编号，我们在程序中是无法获取和更改的。&nbsp;&nbsp;我们再看下一行，“main.main()”表明了这个 goroutine 包装的go函数就是命令源码文件中的那个main函数，也就是说这里的 goroutine 正是主 goroutine。再下面的一行，指出的就是这个 goroutine 中的哪一行代码在此 panic 被引发时正在执行。&nbsp;这包含了此行代码在其所属的源码文件中的行数，以及这个源码文件的绝对路径。这一行最后的+0x3d代表的是：此行代码相对于其所属函数的入口程序计数偏移量。不过，一般情况下它的用处并不大。&nbsp;最后，“exit status 2”表明我的这个程序是以退出状态码2结束运行的。在大多数操作系统中，只要退出状态码不是0，都意味着程序运行的非正常结束。在 Go 语言中，因 panic 导致程序结束运行的退出状态码一般都会是2。&nbsp;综上所述，我们从上边的这个 panic 详情可以看出，作为此 panic 的引发根源的代码处于 demo47.go 文件中的第 5 行，同时被包含在main包（也就是命令源码文件所在的代码包）的main函数中。&nbsp;从 panic 被引发到程序终止运行的大致过程是什么？&nbsp;我们先说一个大致的过程：某个函数中的某行代码有意或无意地引发了一个 panic。这时，初始的 panic 详情会被建立起来，并且该程序的控制权会立即从此行代码转移至调用其所属函数的那行代码上，也就是调用栈中的上一级。&nbsp;这也意味着，此行代码所属函数的执行随即终止。紧接着，控制权并不会在此有片刻的停留，它又会立即转移至再上一级的调用代码处。控制权如此一级一级地沿着调用栈的反方向传播至顶端，也就是我们编写的最外层函数那里。&nbsp;这里的最外层函数指的是go函数，对于主 goroutine 来说就是main函数。但是控制权也不会停留在那里，而是被 Go 语言运行时系统收回。&nbsp;随后，程序崩溃并终止运行，承载程序这次运行的进程也会随之死亡并消失。与此同时，在这个控制权传播的过程中，panic 详情会被逐渐地积累和完善，并会在程序终止之前被打印出来。&nbsp;panic 可能是我们在无意间（或者说一不小心）引发的，如前文所述的索引越界。这类 panic 是真正的、在我们意料之外的程序异常。不过，除此之外，我们还是可以有意地引发 panic。&nbsp;Go 语言的内建函数panic是专门用于引发 panic 的。panic函数使程序开发者可以在程序运行期间报告异常。&nbsp;注意，这与从函数返回错误值的意义是完全不同的。当我们的函数返回一个非nil的错误值时，函数的调用方有权选择不处理，并且不处理的后果往往是不致命的。&nbsp;这里的“不致命”的意思是，不至于使程序无法提供任何功能（也可以说僵死）或者直接崩溃并终止运行（也就是真死）。&nbsp;但是，当一个 panic 发生时，如果我们不施加任何保护措施，那么导致的直接后果就是程序崩溃，就像前面描述的那样，这显然是致命的。&nbsp;panic 详情会在控制权传播的过程中，被逐渐地积累和完善，并且，控制权会一级一级地沿着调用栈的反方向传播至顶端。&nbsp;因此，在针对某个 goroutine 的代码执行信息中，调用栈底端的信息会先出现，然后是上一级调用的信息，以此类推，最后才是此调用栈顶端的信息。&nbsp;比如，main函数调用了caller1函数，而caller1函数又调用了caller2函数，那么caller2函数中代码的执行信息会先出现，然后是caller1函数中代码的执行信息，最后才是main函数的信息。&nbsp; 12345678goroutine 1 [running]:main.caller2() &#x2F;Users&#x2F;haolin&#x2F;GeekTime&#x2F;Golang_Puzzlers&#x2F;src&#x2F;puzzlers&#x2F;article19&#x2F;q1&#x2F;demo48.go:22 +0x91main.caller1() &#x2F;Users&#x2F;haolin&#x2F;GeekTime&#x2F;Golang_Puzzlers&#x2F;src&#x2F;puzzlers&#x2F;article19&#x2F;q1&#x2F;demo48.go:15 +0x66main.main() &#x2F;Users&#x2F;haolin&#x2F;GeekTime&#x2F;Golang_Puzzlers&#x2F;src&#x2F;puzzlers&#x2F;article19&#x2F;q1&#x2F;demo48.go:9 +0x66exit status 2 &nbsp; &nbsp;深入地了解此过程，以及正确地解读 panic 详情应该是我们的必备技能，这在调试 Go 程序或者为 Go 程序排查错误的时候非常重要。&nbsp;如果一个 panic 是我们在无意间引发的，那么其中的值只能由 Go 语言运行时系统给定。但是，当我们使用panic函数有意地引发一个 panic 的时候，却可以自行指定其包含的值。&nbsp;怎样让 panic 包含一个值，以及应该让它包含什么样的值？&nbsp;这其实很简单，在调用panic函数时，把某个值作为参数传给该函数就可以了。由于panic函数的唯一一个参数是空接口（也就是interface&#123;&#125;）类型的，所以从语法上讲，它可以接受任何类型的值。&nbsp;但是，我们最好传入error类型的错误值，或者其他的可以被有效序列化的值。这里的“有效序列化”指的是，可以更易读地去表示形式转换。&nbsp;还记得吗？对于fmt包下的各种打印函数来说，error类型值的Error方法与其他类型值的String方法是等价的，它们的唯一结果都是string类型的。&nbsp;我们在通过占位符%s打印这些值的时候，它们的字符串表示形式分别都是这两种方法产出的。&nbsp;一旦程序异常了，我们就一定要把异常的相关信息记录下来，这通常都是记到程序日志里。&nbsp;我们在为程序排查错误的时候，首先要做的就是查看和解读程序日志；而最常用也是最方便的日志记录方式，就是记下相关值的字符串表示形式。&nbsp;所以，如果你觉得某个值有可能会被记到日志里，那么就应该为它关联String方法。如果这个值是error类型的，那么让它的Error方法返回你为它定制的字符串表示形式就可以了。&nbsp;对于此，你可能会想到fmt.Sprintf，以及fmt.Fprintf这类可以格式化并输出参数的函数。&nbsp;是的，它们本身就可以被用来输出值的某种表示形式。不过，它们在功能上，肯定远不如我们自己定义的Error方法或者String方法。因此，为不同的数据类型分别编写这两种方法总是首选。&nbsp;可是，这与传给panic函数的参数值又有什么关系呢？其实道理是相同的。至少在程序崩溃的时候，panic 包含的那个值字符串表示形式会被打印出来。&nbsp;另外，我们还可以施加某种保护措施，避免程序的崩溃。这个时候，panic 包含的值会被取出，而在取出之后，它一般都会被打印出来或者记录到日志里。&nbsp; panic恢复&nbsp;怎样施加应对panic的保护措施，从而避免程序崩溃？&nbsp;Go 语言的内建函数recover专用于恢复 panic，或者说平息运行时恐慌。recover函数无需任何参数，并且会返回一个空接口类型的值。&nbsp;如果用法正确，这个值实际上就是即将恢复的 panic 包含的值。并且，如果这个 panic 是因我们调用panic函数而引发的，那么该值同时也会是我们此次调用panic函数时，传入的参数值副本。请注意，这里强调用法的正确。我们先来看看什么是不正确的用法。&nbsp;123456789101112131415package main import ( &quot;fmt&quot; &quot;errors&quot;) func main() &#123; fmt.Println(&quot;Enter function main.&quot;) // 引发 panic。 panic(errors.New(&quot;something wrong&quot;)) p := recover() fmt.Printf(&quot;panic: %s\\n&quot;, p) fmt.Println(&quot;Exit function main.&quot;)&#125;&nbsp; 在上面这个main函数中，我先通过调用panic函数引发了一个 panic，紧接着想通过调用recover函数恢复这个 panic。可结果呢？你一试便知，程序依然会崩溃，这个recover函数调用并不会起到任何作用，甚至都没有机会执行。 &nbsp;还记得吗？我提到过 panic 一旦发生，控制权就会讯速地沿着调用栈的反方向传播。所以，在panic函数调用之后的代码，根本就没有执行的机会。&nbsp;那如果我把调用recover函数的代码提前呢？也就是说，先调用recover函数，再调用panic函数会怎么样呢？&nbsp;这显然也是不行的，因为，如果在我们调用recover函数时未发生 panic，那么该函数就不会做任何事情，并且只会返回一个nil。&nbsp;换句话说，这样做毫无意义。那么，到底什么才是正确的recover函数用法呢？这就不得不提到defer语句了。&nbsp;顾名思义，defer语句就是被用来延迟执行代码的。延迟到什么时候呢？这要延迟到该语句所在的函数即将执行结束的那一刻，无论结束执行的原因是什么。&nbsp;这与go语句有些类似，一个defer语句总是由一个defer关键字和一个调用表达式组成。&nbsp;这里存在一些限制，有一些调用表达式是不能出现在这里的，包括：针对 Go 语言内建函数的调用表达式，以及针对unsafe包中的函数的调用表达式。&nbsp;顺便说一下，对于go语句中的调用表达式，限制也是一样的。另外，在这里被调用的函数可以是有名称的，也可以是匿名的。我们可以把这里的函数叫做defer函数或者延迟函数。注意，被延迟执行的是defer函数，而不是defer语句。&nbsp;我刚才说了，无论函数结束执行的原因是什么，其中的defer函数调用都会在它即将结束执行的那一刻执行。即使导致它执行结束的原因是一个 panic 也会是这样。正因为如此，我们需要联用defer语句和recover函数调用，才能够恢复一个已经发生的 panic。&nbsp;我们来看一下经过修正的代码。&nbsp;1234567891011121314151617181920package main import ( &quot;fmt&quot; &quot;errors&quot;) func main() &#123; fmt.Println(&quot;Enter function main.&quot;) defer func()&#123; fmt.Println(&quot;Enter defer function.&quot;) if p := recover(); p != nil &#123; fmt.Printf(&quot;panic: %s\\n&quot;, p) &#125; fmt.Println(&quot;Exit defer function.&quot;) &#125;() // 引发 panic。 panic(errors.New(&quot;something wrong&quot;)) fmt.Println(&quot;Exit function main.&quot;)&#125;&nbsp; 在这个main函数中，我先编写了一条defer语句，并在defer函数中调用了recover函数。仅当调用的结果值不为nil时，也就是说只有 panic 确实已发生时，我才会打印一行以“panic:”为前缀的内容。 &nbsp;紧接着，我调用了panic函数，并传入了一个error类型值。这里一定要注意，我们要尽量把defer语句写在函数体的开始处，因为在引发 panic 的语句之后的所有语句，都不会有任何执行机会。&nbsp;也只有这样，defer函数中的recover函数调用才会拦截，并恢复defer语句所属的函数，及其调用的代码中发生的所有 panic。&nbsp;至此，我向你展示了两个很典型的recover函数的错误用法，以及一个基本的正确用法。&nbsp;我希望你能够记住错误用法背后的缘由，同时也希望你能真正地理解联用defer语句和recover函数调用的真谛。&nbsp;如果一个函数中有多条defer语句，那么那几个defer函数调用的执行顺序是怎样的？&nbsp;如果只用一句话回答的话，那就是：在同一个函数中，defer函数调用的执行顺序与它们分别所属的defer语句的出现顺序（更严谨地说，是执行顺序）完全相反。&nbsp;当一个函数即将结束执行时，其中的写在最下边的defer函数调用会最先执行，其次是写在它上边、与它的距离最近的那个defer函数调用，以此类推，最上边的defer函数调用会最后一个执行。&nbsp;如果函数中有一条for语句，并且这条for语句中包含了一条defer语句，那么，显然这条defer语句的执行次数，就取决于for语句的迭代次数。&nbsp;并且，同一条defer语句每被执行一次，其中的defer函数调用就会产生一次，而且，这些函数调用同样不会被立即执行。&nbsp;那么问题来了，这条for语句中产生的多个defer函数调用，会以怎样的顺序执行呢？&nbsp;为了彻底搞清楚，我们需要弄明白defer语句执行时发生的事情。&nbsp;其实也并不复杂，在defer语句每次执行的时候，Go 语言会把它携带的defer函数及其参数值另行存储到一个队列中。&nbsp;这个队列与该defer语句所属的函数是对应的，并且，它是先进后出（FILO）的，相当于一个栈。&nbsp;在需要执行某个函数中的defer函数调用的时候，Go 语言会先拿到对应的队列，然后从该队列中一个一个地取出defer函数及其参数值，并逐个执行调用。&nbsp;这正是我说“defer函数调用与其所属的defer语句的执行顺序完全相反”的原因了。&nbsp;1234567891011package mainimport &quot;fmt&quot;func main() &#123; defer fmt.Println(&quot;first defer&quot;) for i := 0; i &lt; 3; i++ &#123; defer fmt.Printf(&quot;defer in for [%d]\\n&quot;, i) &#125; defer fmt.Println(&quot;last defer&quot;)&#125;&nbsp; 这段代码的输出结果如下： &nbsp;12345last deferdefer in for [2]defer in for [1]defer in for [0]first defer&nbsp; 同一条defer语句每被执行一次，就会产生一个延迟执行的defer函数调用。 &nbsp;defer 函数的执行时刻是在直接包含它的那个函数即将执行完毕的时候，也可以理解为下一刻就要返回结果值（如果有的话）的时候。 &nbsp;&nbsp; 参考链接：https://time.geekbang.org/column/intro/112","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Go语言","slug":"Go语言","permalink":"http://wht6.github.io/tags/Go%E8%AF%AD%E8%A8%80/"}]},{"title":"错误处理","slug":"错误处理","date":"2022-03-04T02:00:00.000Z","updated":"2022-03-20T01:54:20.249Z","comments":true,"path":"posts/3d09.html","link":"","permalink":"http://wht6.github.io/posts/3d09.html","excerpt":"","text":"error类型其实是一个接口类型，也是一个 Go 语言的内建类型。在这个接口类型的声明中只包含了一个方法Error。这个方法不接受任何参数，但是会返回一个string类型的结果。 &nbsp; 它的作用是返回错误信息的字符串表示形式。我们使用error类型的方式通常是，在函数声明的结果列表的最后，声明一个该类型的结果，同时在调用这个函数之后，先判断它返回的最后一个结果值是否“不为nil”。&nbsp;如果这个值“不为nil”，那么就进入错误处理流程，否则就继续进行正常的流程。下面是一个例子。&nbsp;123456789101112131415161718192021222324252627package main import ( &quot;errors&quot; &quot;fmt&quot;) func echo(request string) (response string, err error) &#123; if request == &quot;&quot; &#123; err = errors.New(&quot;empty request&quot;) return &#125; response = fmt.Sprintf(&quot;echo: %s&quot;, request) return&#125; func main() &#123; for _, req := range []string&#123;&quot;&quot;, &quot;hello!&quot;&#125; &#123; fmt.Printf(&quot;request: %s\\n&quot;, req) resp, err := echo(req) if err != nil &#123; fmt.Printf(&quot;error: %s\\n&quot;, err) continue &#125; fmt.Printf(&quot;response: %s\\n&quot;, resp) &#125;&#125;&nbsp; 我们先看echo函数的声明。echo函数接受一个string类型的参数request，并会返回两个结果。 &nbsp;这两个结果都是有名称的，第一个结果response也是string类型的，它代表了这个函数正常执行后的结果值。第二个结果err就是error类型的，它代表了函数执行出错时的结果值，同时也包含了具体的错误信息。&nbsp;当echo函数被调用时，它会先检查参数request的值。如果该值为空字符串，那么它就会通过调用errors.New函数，为结果err赋值，然后忽略掉后边的操作并直接返回。&nbsp;此时，结果response的值也会是一个空字符串。如果request的值并不是空字符串，那么它就为结果response赋一个适当的值，然后返回，此时的结果err的值会是nil。&nbsp;再来看main函数中的代码。我在每次调用echo函数之后都会把它返回的结果值赋给变量resp和err，并且总是先检查err的值是否“不为nil”，如果是，就打印错误信息，否则就打印常规的响应信息。&nbsp;这里值得注意的地方有两个。第一，在echo函数和main函数中，我都使用到了卫述语句。我在前面讲函数用法的时候也提到过卫述语句。简单地讲，它就是被用来检查后续操作的前置条件并进行相应处理的语句。&nbsp;对于echo函数来说，它进行常规操作的前提是：传入的参数值一定要符合要求。而对于调用echo函数的程序来说，进行后续操作的前提就是echo函数的执行不能出错。&nbsp;我们在进行错误处理的时候经常会用到卫述语句，以至于有些人会吐槽说：“我的程序满屏都是卫述语句，简直是太难看了！”不过，我倒认为这有可能是程序设计上的问题。每个编程语言的理念和风格几乎都会有明显的不同，我们常常需要顺应它们的纹理去做设计，而不是用其他语言的编程思想来编写当下语言的程序。&nbsp;再来说第二个值得注意的地方。我在生成error类型值的时候用到了errors.New函数。这是一种最基本的生成错误值的方式。我们调用它的时候传入一个由字符串代表的错误信息，它会给返回给我们一个包含了这个错误信息的error类型值。该值的静态类型当然是error，而动态类型则是一个在errors包中的，包级私有的类型*errorString。&nbsp;显然，errorString类型拥有的一个指针方法实现了error接口中的Error方法。这个方法在被调用后，会原封不动地返回我们之前传入的错误信息。实际上，error类型值的Error方法就相当于其他类型值的String方法。&nbsp;我们已经知道，通过调用fmt.Printf函数，并给定占位符%s就可以打印出某个值的字符串表示形式。对于其他类型的值来说，只要我们能为这个类型编写一个String方法，就可以自定义它的字符串表示形式。而对于error类型值，它的字符串表示形式则取决于它的Error方法。&nbsp;在上述情况下，fmt.Printf函数如果发现被打印的值是一个error类型的值，那么就会去调用它的Error方法。fmt包中的这类打印函数其实都是这么做的。&nbsp;顺便提一句，当我们想通过模板化的方式生成错误信息，并得到错误值时，可以使用fmt.Errorf函数。该函数所做的其实就是先调用fmt.Sprintf函数，得到确切的错误信息；再调用errors.New函数，得到包含该错误信息的error类型值，最后返回该值。&nbsp; 判断错误值的类型&nbsp;由于error是一个接口类型，所以即使同为error类型的错误值，它们的实际类型也可能不同。怎样判断一个错误值具体代表的是哪一类错误？&nbsp; 对于类型在已知范围内的一系列错误值，一般使用类型断言表达式或类型switch语句来判断； 对于已有相应变量且类型相同的一系列错误值，一般直接使用判等操作来判断； 对于没有相应变量且类型未知的一系列错误值，只能使用其错误信息的字符串表示形式来做判断。&nbsp; 类型在已知范围内的错误值其实是最容易分辨的。就拿os包中的几个代表错误的类型os.PathError、os.LinkError、os.SyscallError和os/exec.Error来说，它们的指针类型都是error接口的实现类型，同时它们也都包含了一个名叫Err，类型为error接口类型的代表潜在错误的字段。 &nbsp;如果我们得到一个error类型值，并且知道该值的实际类型肯定是它们中的某一个，那么就可以用类型switch语句去做判断。例如：&nbsp;12345678910111213func underlyingError(err error) error &#123; switch err := err.(type) &#123; case *os.PathError: return err.Err case *os.LinkError: return err.Err case *os.SyscallError: return err.Err case *exec.Error: return err.Err &#125; return err&#125;&nbsp; 函数underlyingError的作用是：获取和返回已知的操作系统相关错误的潜在错误值。其中的类型switch语句中有若干个case子句，分别对应了上述几个错误类型。当它们被选中时，都会把函数参数err的Err字段作为结果值返回。如果它们都未被选中，那么该函数就会直接把参数值作为结果返回，即放弃获取潜在错误值。 &nbsp;只要类型不同，我们就可以如此分辨。但是在错误值类型相同的情况下，这些手段就无能为力了。在 Go 语言的标准库中也有不少以相同方式创建的同类型的错误值。&nbsp;我们还拿os包来说，其中不少的错误值都是通过调用errors.New函数来初始化的，比如：os.ErrClosed、os.ErrInvalid以及os.ErrPermission，等等。&nbsp;注意，与前面讲到的那些错误类型不同，这几个都是已经定义好的、确切的错误值。os包中的代码有时候会把它们当做潜在错误值，封装进前面那些错误类型的值中。&nbsp;如果我们在操作文件系统的时候得到了一个错误值，并且知道该值的潜在错误值肯定是上述值中的某一个，那么就可以用普通的switch语句去做判断，当然了，用if语句和判等操作符也是可以的。例如：&nbsp;123456789101112131415printError := func(i int, err error) &#123; if err == nil &#123; fmt.Println(&quot;nil error&quot;) return &#125; err = underlyingError(err) switch err &#123; case os.ErrClosed: fmt.Printf(&quot;error(closed)[%d]: %s\\n&quot;, i, err) case os.ErrInvalid: fmt.Printf(&quot;error(invalid)[%d]: %s\\n&quot;, i, err) case os.ErrPermission: fmt.Printf(&quot;error(permission)[%d]: %s\\n&quot;, i, err) &#125;&#125;&nbsp; 这个由printError变量代表的函数会接受一个error类型的参数值。该值总会代表某个文件操作相关的错误，这是我故意地以不正确的方式操作文件后得到的。 &nbsp;虽然我不知道这些错误值的类型的范围，但却知道它们或它们的潜在错误值一定是某个已经在os包中定义的值。&nbsp;所以，我先用underlyingError函数得到它们的潜在错误值，当然也可能只得到原错误值而已。然后，我用switch语句对错误值进行判等操作，三个case子句分别对应我刚刚提到的那三个已存在于os包中的错误值。如此一来，我就能分辨出具体错误了。&nbsp;对于上面这两种情况，我们都有明确的方式去解决。但是，如果我们对一个错误值可能代表的含义知之甚少，那么就只能通过它拥有的错误信息去做判断了。&nbsp;好在我们总是能通过错误值的Error方法，拿到它的错误信息。其实os包中就有做这种判断的函数，比如：os.IsExist、os.IsNotExist和os.IsPermission。&nbsp; 构建错误值体系&nbsp;怎样根据实际情况给予恰当的错误值？&nbsp;构建错误值体系的基本方式有两种，即：创建立体的错误类型体系和创建扁平的错误值列表。&nbsp;先说错误类型体系。由于在 Go 语言中实现接口是非侵入式的，所以我们可以做得很灵活。比如，在标准库的net代码包中，有一个名为Error的接口类型。它算是内建接口类型error的一个扩展接口，因为error是net.Error的嵌入接口。&nbsp;net.Error接口除了拥有error接口的Error方法之外，还有两个自己声明的方法：Timeout和Temporary。&nbsp;net包中有很多错误类型都实现了net.Error接口，比如：&nbsp; *net.OpError； *net.AddrError； net.UnknownNetworkError等等。&nbsp; 你可以把这些错误类型想象成一棵树，内建接口error就是树的根，而net.Error接口就是一个在根上延伸的第一级非叶子节点。&nbsp;同时，你也可以把这看做是一种多层分类的手段。当net包的使用者拿到一个错误值的时候，可以先判断它是否是net.Error类型的，也就是说该值是否代表了一个网络相关的错误。&nbsp;如果是，那么我们还可以再进一步判断它的类型是哪一个更具体的错误类型，这样就能知道这个网络相关的错误具体是由于操作不当引起的，还是因为网络地址问题引起的，又或是由于网络协议不正确引起的。&nbsp;当我们细看net包中的这些具体错误类型的实现时，还会发现，与os包中的一些错误类型类似，它们也都有一个名为Err、类型为error接口类型的字段，代表的也是当前错误的潜在错误。&nbsp;所以说，这些错误类型的值之间还可以有另外一种关系，即：链式关系。比如说，使用者调用net.DialTCP之类的函数时，net包中的代码可能会返回给他一个*net.OpError类型的错误值，以表示由于他的操作不当造成了一个错误。&nbsp;同时，这些代码还可能会把一个*net.AddrError或net.UnknownNetworkError类型的值赋给该错误值的Err字段，以表明导致这个错误的潜在原因。如果，此处的潜在错误值的Err字段也有非nil的值，那么将会指明更深层次的错误原因。如此一级又一级就像链条一样最终会指向问题的根源。&nbsp;把以上这些内容总结成一句话就是，用类型建立起树形结构的错误体系，用统一字段建立起可追根溯源的链式错误关联。这是 Go 语言标准库给予我们的优秀范本，非常有借鉴意义。&nbsp;不过要注意，如果你不想让包外代码改动你返回的错误值的话，一定要小写其中字段的名称首字母。你可以通过暴露某些方法让包外代码有进一步获取错误信息的权限，比如编写一个可以返回包级私有的err字段值的公开方法Err。&nbsp;相比于立体的错误类型体系，扁平的错误值列表就要简单得多了。当我们只是想预先创建一些代表已知错误的错误值时候，用这种扁平化的方式就很恰当了。错误列表其实就是若干个名称不同但类型相同的错误值集合。&nbsp;不过，由于error是接口类型，所以通过errors.New函数生成的错误值只能被赋给变量，而不能赋给常量，又由于这些代表错误的变量需要给包外代码使用，所以其访问权限只能是公开的。&nbsp;这就带来了一个问题，如果有恶意代码改变了这些公开变量的值，那么程序的功能就必然会受到影响。因为在这种情况下我们往往会通过判等操作来判断拿到的错误值具体是哪一个错误，如果这些公开变量的值被改变了，那么相应的判等操作的结果也会随之改变。&nbsp;这里有两个解决方案。第一个方案是，先私有化此类变量，也就是说，让它们的名称首字母变成小写，然后编写公开的用于获取错误值以及用于判等错误值的函数。&nbsp;比如，对于错误值os.ErrClosed，先改写它的名称，让其变成os.errClosed，然后再编写ErrClosed函数和IsErrClosed函数。&nbsp;当然了，这不是说让你去改动标准库中已有的代码，这样做的危害会很大，甚至是致命的。我只能说，对于你可控的代码，最好还是要尽量收紧访问权限。&nbsp;再来说第二个方案，此方案存在于syscall包中。该包中有一个类型叫做Errno，该类型代表了系统调用时可能发生的底层错误。这个错误类型是error接口的实现类型，同时也是对内建类型uintptr的再定义类型。&nbsp;由于uintptr可以作为常量的类型，所以syscall.Errno自然也可以。syscall包中声明有大量的Errno类型的常量，每个常量都对应一种系统调用错误。syscall包外的代码可以拿到这些代表错误的常量，但却无法改变它们。&nbsp;我们可以仿照这种声明方式来构建我们自己的错误值列表，这样就可以保证错误值的只读特性了。&nbsp;&nbsp; 参考链接：https://time.geekbang.org/column/intro/112","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Go语言","slug":"Go语言","permalink":"http://wht6.github.io/tags/Go%E8%AF%AD%E8%A8%80/"}]},{"title":"Go语言的基本流程控制语句","slug":"Go语言的基本流程控制语句","date":"2022-03-03T10:00:00.000Z","updated":"2022-03-20T01:54:03.969Z","comments":true,"path":"posts/b742.html","link":"","permalink":"http://wht6.github.io/posts/b742.html","excerpt":"","text":"if语句、for语句和switch语句都属于 Go 语言的基本流程控制语句。 &nbsp; 携带range子句的for语句&nbsp;1234567numbers1 := []int&#123;1, 2, 3, 4, 5, 6&#125;for i := range numbers1 &#123; if i == 3 &#123; numbers1[i] |= i &#125;&#125;fmt.Println(numbers1)&nbsp; 先声明了一个元素类型为int的切片类型的变量numbers1，在该切片中有 6 个元素值，分别是从1到6的整数。用一条携带range子句的for语句去迭代numbers1变量中的所有元素值。 &nbsp;在这条for语句中，只有一个迭代变量i。我在每次迭代时，都会先去判断i的值是否等于3，如果结果为true，那么就让numbers1的第i个元素值与i本身做按位或的操作，再把操作结果作为numbers1的新的第i个元素值。最后我会打印出numbers1的值。&nbsp;这段代码打印的内容是[1 2 3 7 5 6]。&nbsp;当for语句被执行的时候，在range关键字右边的numbers1会先被求值。&nbsp;这个位置上的代码被称为range表达式。range表达式的结果值可以是数组、数组的指针、切片、字符串、字典或者允许接收操作的通道中的某一个，并且结果值只能有一个。&nbsp;对于不同种类的range表达式结果值，for语句的迭代变量的数量可以有所不同。&nbsp;就拿我们这里的numbers1来说，它是一个切片，那么迭代变量就可以有两个，右边的迭代变量代表当次迭代对应的某一个元素值，而左边的迭代变量则代表该元素值在切片中的索引值。&nbsp;那么，如果像本题代码中的for语句那样，只有一个迭代变量的情况意味着什么呢？这意味着，该迭代变量只会代表当次迭代对应的元素值的索引值。&nbsp;更宽泛地讲，当只有一个迭代变量的时候，数组、数组的指针、切片和字符串的元素值都是无处安放的，我们只能拿到按照从小到大顺序给出的一个个索引值。&nbsp;因此，这里的迭代变量i的值会依次是从0到5的整数。当i的值等于3的时候，与之对应的是切片中的第 4 个元素值4。对4和3进行按位或操作得到的结果是7。这就是答案中的第 4 个整数是7的原因了。&nbsp;稍稍修改一下上面的代码。&nbsp;12345678910numbers2 := [...]int&#123;1, 2, 3, 4, 5, 6&#125;maxIndex2 := len(numbers2) - 1for i, e := range numbers2 &#123; if i == maxIndex2 &#123; numbers2[0] += e &#125; else &#123; numbers2[i+1] += e &#125;&#125;fmt.Println(numbers2)&nbsp; 注意，我把迭代的对象换成了numbers2。numbers2中的元素值同样是从1到6的 6 个整数，并且元素类型同样是int，但它是一个数组而不是一个切片。 &nbsp;在for语句中，我总是会对紧挨在当次迭代对应的元素后边的那个元素，进行重新赋值，新的值会是这两个元素的值之和。当迭代到最后一个元素时，我会把此range表达式结果值中的第一个元素值，替换为它的原值与最后一个元素值的和，最后，我会打印出numbers2的值。&nbsp;这段代码打印的内容是[7 3 5 7 9 11]。&nbsp;当for语句被执行的时候，在range关键字右边的numbers2会先被求值。&nbsp;这里需要注意两点：&nbsp; range表达式只会在for语句开始执行时被求值一次，无论后边会有多少次迭代； range表达式的求值结果会被复制，也就是说，被迭代的对象是range表达式结果值的副本而不是原值。 &nbsp;基于这两个规则，我们接着往下看。在第一次迭代时，我改变的是numbers2的第二个元素的值，新值为3，也就是1和2之和。 &nbsp;但是，被迭代的对象的第二个元素却没有任何改变，毕竟它与numbers2已经是毫不相关的两个数组了。因此，在第二次迭代时，会把numbers2的第三个元素的值修改为5，即被迭代对象的第二个元素值2和第三个元素值3的和。 以此类推，之后的numbers2的元素值依次会是7、9和11。当迭代到最后一个元素时，我会把numbers2的第一个元素的值修改为1和6之和。&nbsp;把numbers2的值由一个数组改成一个切片，其中的元素值都不要变。打印的结果又会是什么？&nbsp;打印的结果是[22 3 6 10 15 21]。原因是切片与数组是不同的，前者是引用类型的，而后者是值类型的。（我的理解：引用类型可以看做指针，对于切片，其指向的是底层数组，因为range表达式的求值结果会被复制，迭代对象是结果值的副本，所以指针也会被复制，但是指针的副本仍然是指向底层数组的，所以对切片副本的修改，会影响到底层数组）&nbsp; switch表达式和case表达式&nbsp;123456789value1 := [...]int8&#123;0, 1, 2, 3, 4, 5, 6&#125;switch 1 + 3 &#123;case value1[0], value1[1]: fmt.Println(&quot;0 or 1&quot;)case value1[2], value1[3]: fmt.Println(&quot;2 or 3&quot;)case value1[4], value1[5], value1[6]: fmt.Println(&quot;4 or 5 or 6&quot;)&#125;&nbsp; 先声明了一个数组类型的变量value1，该变量的元素类型是int8。在后边的switch语句中，被夹在switch关键字和左花括号&#123;之间的是1 + 3，这个位置上的代码被称为switch表达式。这个switch语句还包含了三个case子句，而每个case子句又各包含了一个case表达式和一条打印语句。 &nbsp;所谓的case表达式一般由case关键字和一个表达式列表组成，表达式列表中的多个表达式之间需要有英文逗号,分割，比如，上面代码中的case value1[0], value1[1]就是一个case表达式，其中的两个子表达式都是由索引表达式表示的。&nbsp;另外的两个case表达式分别是case value1[2], value1[3]和case value1[4], value1[5], value1[6]。&nbsp;此外，在这里的每个case子句中的那些打印语句，会分别打印出不同的内容，这些内容用于表示case子句被选中的原因，比如，打印内容0 or 1表示当前case子句被选中是因为switch表达式的结果值等于0或1中的某一个。另外两条打印语句会分别打印出2 or 3和4 or 5 or 6。&nbsp;只要switch表达式的结果值与某个case表达式中的任意一个子表达式的结果值相等，该case表达式所属的case子句就会被选中。&nbsp;并且，一旦某个case子句被选中，其中的附带在case表达式后边的那些语句就会被执行。与此同时，其他的所有case子句都会被忽略。&nbsp;当然了，如果被选中的case子句附带的语句列表中包含了fallthrough语句，那么紧挨在它下边的那个case子句附带的语句也会被执行。&nbsp;正因为存在上述判断相等的操作（以下简称判等操作），switch语句对switch表达式的结果类型，以及各个case表达式中子表达式的结果类型都是有要求的。毕竟，在 Go 语言中，只有类型相同的值之间才有可能被允许进行判等操作。&nbsp;如果switch表达式的结果值是无类型的常量，比如1 + 3的求值结果就是无类型的常量4，那么这个常量会被自动地转换为此种常量的默认类型的值，比如整数4的默认类型是int，又比如浮点数3.14的默认类型是float64。&nbsp;因此，由于上述代码中的switch表达式的结果类型是int，而那些case表达式中子表达式的结果类型却是int8，它们的类型并不相同，所以这条switch语句是无法通过编译的。&nbsp;123456789value2 := [...]int8&#123;0, 1, 2, 3, 4, 5, 6&#125;switch value2[4] &#123;case 0, 1: fmt.Println(&quot;0 or 1&quot;)case 2, 3: fmt.Println(&quot;2 or 3&quot;)case 4, 5, 6: fmt.Println(&quot;4 or 5 or 6&quot;)&#125;&nbsp; 其中的变量value2与value1的值是完全相同的。但不同的是，我把switch表达式换成了value2[4]，并把下边那三个case表达式分别换为了case 0, 1、case 2, 3和case 4, 5, 6。 &nbsp;如此一来，switch表达式的结果值是int8类型的，而那些case表达式中子表达式的结果值却是无类型的常量了。这与之前的情况恰恰相反。那么，这样的switch语句可以通过编译吗？&nbsp;答案是肯定的。因为，如果case表达式中子表达式的结果值是无类型的常量，那么它的类型会被自动地转换为switch表达式的结果类型，又由于上述那几个整数都可以被转换为int8类型的值，所以对这些表达式的结果值进行判等操作是没有问题的。&nbsp;当然了，如果这里说的自动转换没能成功，那么switch语句照样通不过编译。&nbsp;&nbsp;通过上面这两道题，你应该可以搞清楚switch表达式和case表达式之间的联系了。由于需要进行判等操作，所以前者和后者中的子表达式的结果类型需要相同。&nbsp;switch语句会进行有限的类型转换，但肯定不能保证这种转换可以统一它们的类型。还要注意，如果这些表达式的结果类型有某个接口类型，那么一定要小心检查它们的动态值是否都具有可比性（或者说是否允许判等操作）。&nbsp;因为，如果答案是否定的，虽然不会造成编译错误，但是后果会更加严重：引发 panic（也就是运行时恐慌）。&nbsp;switch语句在case子句的选择上是具有唯一性的。&nbsp;正因为如此，switch语句不允许case表达式中的子表达式结果值存在相等的情况，不论这些结果值相等的子表达式，是否存在于不同的case表达式中，都会是这样的结果。具体请看这段代码：&nbsp;123456789value3 := [...]int8&#123;0, 1, 2, 3, 4, 5, 6&#125;switch value3[4] &#123;case 0, 1, 2: fmt.Println(&quot;0 or 1 or 2&quot;)case 2, 3, 4: fmt.Println(&quot;2 or 3 or 4&quot;)case 4, 5, 6: fmt.Println(&quot;4 or 5 or 6&quot;)&#125;&nbsp; 变量value3的值同value1，依然是由从0到6的 7 个整数组成的数组，元素类型是int8。switch表达式是value3[4]，三个case表达式分别是case 0, 1, 2、case 2, 3, 4和case 4, 5, 6。 &nbsp;由于在这三个case表达式中存在结果值相等的子表达式，所以这个switch语句无法通过编译。不过，好在这个约束本身还有个约束，那就是只针对结果值为常量的子表达式。&nbsp;比如，子表达式1+1和2不能同时出现，1+3和4也不能同时出现。有了这个约束的约束，我们就可以想办法绕过这个对子表达式的限制了。再看一段代码：&nbsp;123456789value5 := [...]int8&#123;0, 1, 2, 3, 4, 5, 6&#125;switch value5[4] &#123;case value5[0], value5[1], value5[2]: fmt.Println(&quot;0 or 1 or 2&quot;)case value5[2], value5[3], value5[4]: fmt.Println(&quot;2 or 3 or 4&quot;)case value5[4], value5[5], value5[6]: fmt.Println(&quot;4 or 5 or 6&quot;)&#125;&nbsp; 变量名换成了value5，但这不是重点。重点是，我把case表达式中的常量都换成了诸如value5[0]这样的索引表达式。 &nbsp;虽然第一个case表达式和第二个case表达式都包含了value5[2]，并且第二个case表达式和第三个case表达式都包含了value5[4]，但这已经不是问题了。这条switch语句可以成功通过编译。&nbsp;不过，这种绕过方式对用于类型判断的switch语句（以下简称为类型switch语句）就无效了。因为类型switch语句中的case表达式的子表达式，都必须直接由类型字面量表示，而无法通过间接的方式表示。代码如下：&nbsp;123456789value6 := interface&#123;&#125;(byte(127))switch t := value6.(type) &#123;case uint8, uint16: fmt.Println(&quot;uint8 or uint16&quot;)case byte: fmt.Printf(&quot;byte&quot;)default: fmt.Printf(&quot;unsupported type: %T&quot;, t)&#125;&nbsp; 变量value6的值是空接口类型的。该值包装了一个byte类型的值127。我在后面使用类型switch语句来判断value6的实际类型，并打印相应的内容。 &nbsp;这里有两个普通的case子句，还有一个default case子句。前者的case表达式分别是case uint8, uint16和case byte。你还记得吗？byte类型是uint8类型的别名类型。&nbsp;因此，它们两个本质上是同一个类型，只是类型名称不同罢了。在这种情况下，这个类型switch语句是无法通过编译的，因为子表达式byte和uint8重复了。&nbsp;普通case子句的编写顺序很重要，最上边的case子句中的子表达式总是会被最先求值，在判等的时候顺序也是这样。因此，如果某些子表达式的结果值有重复并且它们与switch表达式的结果值相等，那么位置靠上的case子句总会被选中。&nbsp;&nbsp; 参考链接：https://time.geekbang.org/column/intro/112","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Go语言","slug":"Go语言","permalink":"http://wht6.github.io/tags/Go%E8%AF%AD%E8%A8%80/"}]},{"title":"go语句及其执行规则","slug":"go语句及其执行规则","date":"2022-03-03T02:00:00.000Z","updated":"2022-03-20T01:53:47.297Z","comments":true,"path":"posts/fd28.html","link":"","permalink":"http://wht6.github.io/posts/fd28.html","excerpt":"","text":"Don’t communicate by sharing memory; share memory by communicating. &nbsp; 从 Go 语言编程的角度解释，这句话的意思就是：不要通过共享数据来通讯，恰恰相反，要以通讯的方式共享数据。&nbsp;我们已经知道，通道（也就是 channel）类型的值，可以被用来以通讯的方式共享数据。更具体地说，它一般被用来在不同的 goroutine 之间传递数据。那么 goroutine 到底代表着什么呢？&nbsp;简单来说，goroutine 代表着并发编程模型中的用户级线程。你可能已经知道，操作系统本身提供了进程和线程，这两种并发执行程序的工具。&nbsp; 进程与线程&nbsp;进程，描述的就是程序的执行过程，是运行着的程序的代表。换句话说，一个进程其实就是某个程序运行时的一个产物。如果说静静地躺在那里的代码就是程序的话，那么奔跑着的、正在发挥着既有功能的代码就可以被称为进程。&nbsp;我们的电脑为什么可以同时运行那么多应用程序？我们的手机为什么可以有那么多 App 同时在后台刷新？这都是因为在它们的操作系统之上有多个代表着不同应用程序或 App 的进程在同时运行。&nbsp;再来说说线程。首先，线程总是在进程之内的，它可以被视为进程中运行着的控制流（或者说代码执行的流程）。&nbsp;一个进程至少会包含一个线程。如果一个进程只包含了一个线程，那么它里面的所有代码都只会被串行地执行。每个进程的第一个线程都会随着该进程的启动而被创建，它们可以被称为其所属进程的主线程。&nbsp;相对应的，如果一个进程中包含了多个线程，那么其中的代码就可以被并发地执行。除了进程的第一个线程之外，其他的线程都是由进程中已存在的线程创建出来的。&nbsp;也就是说，主线程之外的其他线程都只能由代码显式地创建和销毁。这需要我们在编写程序的时候进行手动控制，操作系统以及进程本身并不会帮我们下达这样的指令，它们只会忠实地执行我们的指令。&nbsp;不过，在 Go 程序当中，Go 语言的运行时（runtime）系统会帮助我们自动地创建和销毁系统级的线程。这里的系统级线程指的就是我们刚刚说过的操作系统提供的线程。&nbsp;而对应的用户级线程指的是架设在系统级线程之上的，由用户（或者说我们编写的程序）完全控制的代码执行流程。用户级线程的创建、销毁、调度、状态变更以及其中的代码和数据都完全需要我们的程序自己去实现和处理。&nbsp;这带来了很多优势，比如，因为它们的创建和销毁并不用通过操作系统去做，所以速度会很快，又比如，由于不用等着操作系统去调度它们的运行，所以往往会很容易控制并且可以很灵活。&nbsp;但是，劣势也是有的，最明显也最重要的一个劣势就是复杂。如果我们只使用了系统级线程，那么我们只要指明需要新线程执行的代码片段，并且下达创建或销毁线程的指令就好了，其他的一切具体实现都会由操作系统代劳。&nbsp;但是，如果使用用户级线程，我们就不得不既是指令下达者，又是指令执行者。我们必须全权负责与用户级线程有关的所有具体实现。&nbsp;操作系统不但不会帮忙，还会要求我们的具体实现必须与它正确地对接，否则用户级线程就无法被并发地，甚至正确地运行。毕竟我们编写的所有代码最终都需要通过操作系统才能在计算机上执行。这听起来就很麻烦，不是吗？&nbsp;不过别担心，Go 语言不但有着独特的并发编程模型，以及用户级线程 goroutine，还拥有强大的用于调度 goroutine、对接系统级线程的调度器。&nbsp;这个调度器是 Go 语言运行时系统的重要组成部分，它主要负责统筹调配 Go 并发编程模型中的三个主要元素，即：G（goroutine 的缩写）、P（processor 的缩写）和 M（machine 的缩写）。&nbsp;其中的 M 指代的就是系统级线程。而 P 指的是一种可以承载若干个 G，且能够使这些 G 适时地与 M 进行对接，并得到真正运行的中介。&nbsp;从宏观上说，G 和 M 由于 P 的存在可以呈现出多对多的关系。当一个正在与某个 M 对接并运行着的 G，需要因某个事件（比如等待 I/O 或锁的解除）而暂停运行的时候，调度器总会及时地发现，并把这个 G 与那个 M 分离开，以释放计算资源供那些等待运行的 G 使用。&nbsp;而当一个 G 需要恢复运行的时候，调度器又会尽快地为它寻找空闲的计算资源（包括 M）并安排运行。另外，当 M 不够用时，调度器会帮我们向操作系统申请新的系统级线程，而当某个 M 已无用时，调度器又会负责把它及时地销毁掉。&nbsp;正因为调度器帮助我们做了很多事，所以我们的 Go 程序才总是能高效地利用操作系统和计算机资源。程序中的所有 goroutine 也都会被充分地调度，其中的代码也都会被并发地运行，即使这样的 goroutine 有数以十万计，也仍然可以如此。&nbsp;&nbsp;Go 语言实现了一套非常完善的运行时系统，保证了我们的程序在高并发的情况下依旧能够稳定、高效地运行。&nbsp; 1234567891011package main import &quot;fmt&quot; func main() &#123; for i := 0; i &lt; 10; i++ &#123; go func() &#123; fmt.Println(i) &#125;() &#125;&#125; &nbsp; 在main函数中写了一条for语句。这条for语句中的代码会迭代运行 10 次，并有一个局部变量i代表着当次迭代的序号，该序号是从0开始的。 &nbsp;在这条for语句中仅有一条go语句，这条go语句中也仅有一条语句。这条最里面的语句调用了fmt.Println函数并想要打印出变量i的值。&nbsp;这个程序很简单，三条语句逐条嵌套。我的具体问题是：这个命令源码文件被执行后会打印出什么内容？&nbsp;答案是：不会有任何内容被打印出来。&nbsp;与一个进程总会有一个主线程类似，每一个独立的 Go 程序在运行时也总会有一个主 goroutine。这个主 goroutine 会在 Go 程序的运行准备工作完成后被自动地启用，并不需要我们做任何手动的操作。&nbsp;想必你已经知道，每条go语句一般都会携带一个函数调用，这个被调用的函数常常被称为go函数。而主 goroutine 的go函数就是那个作为程序入口的main函数。&nbsp;一定要注意，go函数真正被执行的时间，总会与其所属的go语句被执行的时间不同。当程序执行到一条go语句的时候，Go 语言的运行时系统，会先试图从某个存放空闲的 G 的队列中获取一个 G（也就是 goroutine），它只有在找不到空闲 G 的情况下才会去创建一个新的 G。&nbsp;这也是为什么我总会说“启用”一个 goroutine，而不说“创建”一个 goroutine 的原因。已存在的 goroutine 总是会被优先复用。&nbsp;然而，创建 G 的成本也是非常低的。创建一个 G 并不会像新建一个进程或者一个系统级线程那样，必须通过操作系统的系统调用来完成，在 Go 语言的运行时系统内部就可以完全做到了，更何况一个 G 仅相当于为需要并发执行代码片段服务的上下文环境而已。&nbsp;在拿到了一个空闲的 G 之后，Go 语言运行时系统会用这个 G 去包装当前的那个go函数（或者说该函数中的那些代码），然后再把这个 G 追加到某个存放可运行的 G 的队列中。&nbsp;这类队列中的 G 总是会按照先入先出的顺序，很快地由运行时系统内部的调度器安排运行。虽然这会很快，但是由于上面所说的那些准备工作还是不可避免的，所以耗时还是存在的。&nbsp;因此，go函数的执行时间总是会明显滞后于它所属的go语句的执行时间。当然了，这里所说的“明显滞后”是对于计算机的 CPU 时钟和 Go 程序来说的。我们在大多数时候都不会有明显的感觉。&nbsp;在说明了原理之后，我们再来看这种原理下的表象。请记住，只要go语句本身执行完毕，Go 程序完全不会等待go函数的执行，它会立刻去执行后边的语句。这就是所谓的异步并发地执行。&nbsp;这里“后边的语句”指的一般是for语句中的下一个迭代。然而，当最后一个迭代运行的时候，这个“后边的语句”是不存在的。&nbsp;上面程序中的那条for语句会以很快的速度执行完毕。当它执行完毕时，那 10 个包装了go函数的 goroutine 往往还没有获得运行的机会。&nbsp;请注意，go函数中的那个对fmt.Println函数的调用是以for语句中的变量i作为参数的。你可以想象一下，如果当for语句执行完毕的时候，这些go函数都还没有执行，那么它们引用的变量i的值将会是什么？&nbsp;它们都会是10，对吗？那么这道题的答案会是“打印出 10 个10”，是这样吗？&nbsp;在确定最终的答案之前，你还需要知道一个与主 goroutine 有关的重要特性，即：一旦主 goroutine 中的代码（也就是main函数中的那些代码）执行完毕，当前的 Go 程序就会结束运行。&nbsp;如此一来，如果在 Go 程序结束的那一刻，还有 goroutine 未得到运行机会，那么它们就真的没有运行机会了，它们中的代码也就不会被执行了。&nbsp;我们刚才谈论过，当for语句的最后一个迭代运行的时候，其中的那条go语句即是最后一条语句。所以，在执行完这条go语句之后，主 goroutine 中的代码也就执行完了，Go 程序会立即结束运行。那么，如果这样的话，还会有任何内容被打印出来吗？&nbsp;严谨地讲，Go 语言并不会去保证这些 goroutine 会以怎样的顺序运行。由于主 goroutine 会与我们手动启用的其他 goroutine 一起接受调度，又因为调度器很可能会在 goroutine 中的代码只执行了一部分的时候暂停，以期所有的 goroutine 有更公平的运行机会。&nbsp;所以哪个 goroutine 先执行完、哪个 goroutine 后执行完往往是不可预知的，除非我们使用了某种 Go 语言提供的方式进行了人为干预。然而，在这段代码中，我们并没有进行任何人为干预。 &nbsp; 一旦主 goroutine 中的代码执行完毕，当前的 Go 程序就会结束运行，无论其他的 goroutine 是否已经在运行了。那么，怎样才能做到等其他的 goroutine 运行完毕之后，再让主 goroutine 结束运行呢？&nbsp;其实有很多办法可以做到这一点。其中，最简单粗暴的办法就是让主 goroutine“小睡”一会儿。&nbsp;123456for i := 0; i &lt; 10; i++ &#123; go func() &#123; fmt.Println(i) &#125;()&#125;time.Sleep(time.Millisecond * 500)&nbsp; 在for语句的后边，我调用了time包的Sleep函数，并把time.Millisecond * 500的结果作为参数值传给了它。time.Sleep函数的功能就是让当前的 goroutine（在这里就是主 goroutine）暂停运行一段时间，直到到达指定的恢复运行时间。 &nbsp;我们可以把一个相对的时间传给该函数，就像我在这里传入的“500 毫秒”那样。time.Sleep函数会在被调用时用当前的绝对时间，再加上相对时间计算出在未来的恢复运行时间。显然，一旦到达恢复运行时间，当前的 goroutine 就会从“睡眠”中醒来，并开始继续执行后边的代码。&nbsp;这个办法是可行的，只要“睡眠”的时间不要太短就好。不过，问题恰恰就在这里，我们让主 goroutine“睡眠”多长时间才是合适的呢？如果“睡眠”太短，则很可能不足以让其他的 goroutine 运行完毕，而若“睡眠”太长则纯属浪费时间，这个时间就太难把握了。&nbsp;你是否想到了通道呢？我们先创建一个通道，它的长度应该与我们手动启用的 goroutine 的数量一致。在每个手动启用的 goroutine 即将运行完毕的时候，我们都要向该通道发送一个值。&nbsp;注意，这些发送表达式应该被放在它们的go函数体的最后面。对应的，我们还需要在main函数的最后从通道接收元素值，接收的次数也应该与手动启用的 goroutine 的数量保持一致。&nbsp;123456789101112131415161718192021package mainimport ( &quot;fmt&quot;)func main() &#123; num := 10 sign := make(chan struct&#123;&#125;, num) for i := 0; i &lt; num; i++ &#123; go func() &#123; fmt.Println(i) sign &lt;- struct&#123;&#125;&#123;&#125; &#125;() &#125; for j := 0; j &lt; num; j++ &#123; &lt;-sign &#125;&#125;&nbsp; 其中有一个细节你需要注意。我在声明通道sign的时候是以chan struct&#123;&#125;作为其类型的。其中的类型字面量struct&#123;&#125;有些类似于空接口类型interface&#123;&#125;，它代表了既不包含任何字段也不拥有任何方法的空结构体类型。 &nbsp;注意，struct&#123;&#125;类型值的表示法只有一个，即：struct&#123;&#125;&#123;&#125;。并且，它占用的内存空间是0字节。确切地说，这个值在整个 Go 程序中永远都只会存在一份。虽然我们可以无数次地使用这个值字面量，但是用到的却都是同一个值。&nbsp;当我们仅仅把通道当作传递某种简单信号的介质的时候，用struct&#123;&#125;作为其元素类型是再好不过的了。&nbsp;有没有比使用通道更好的方法？如果你知道标准库中的代码包sync的话，那么可能会想到sync.WaitGroup类型。没错，这是一个更好的答案。&nbsp;怎样让我们启用的多个 goroutine 按照既定的顺序运行？&nbsp;怎样做到让从0到9这几个整数按照自然数的顺序打印出来？你可能会说，我不用 goroutine 不就可以了嘛。没错，这样是可以，但是如果我不考虑这样做呢。你应该怎么解决这个问题？&nbsp;首先，我们需要稍微改造一下for语句中的那个go函数，要让它接受一个int类型的参数，并在调用它的时候把变量i的值传进去。为了不改动这个go函数中的其他代码，我们可以把它的这个参数也命名为i。&nbsp;12345for i := 0; i &lt; 10; i++ &#123; go func(i int) &#123; fmt.Println(i) &#125;(i)&#125;&nbsp; 只有这样，Go 语言才能保证每个 goroutine 都可以拿到一个唯一的整数。其原因与go函数的执行时机有关。 &nbsp;我在前面已经讲过了。在go语句被执行时，我们传给go函数的参数i会先被求值，如此就得到了当次迭代的序号。之后，无论go函数会在什么时候执行，这个参数值都不会变。也就是说，go函数中调用的fmt.Println函数打印的一定会是那个当次迭代的序号。&nbsp;然后，我们在着手改造for语句中的go函数。&nbsp;12345678for i := uint32(0); i &lt; 10; i++ &#123; go func(i uint32) &#123; fn := func() &#123; fmt.Println(i) &#125; trigger(i, fn) &#125;(i)&#125;&nbsp; 我在go函数中先声明了一个匿名的函数，并把它赋给了变量fn。这个匿名函数做的事情很简单，只是调用fmt.Println函数以打印go函数的参数i的值。 &nbsp;在这之后，我调用了一个名叫trigger的函数，并把go函数的参数i和刚刚声明的变量fn作为参数传给了它。注意，for语句声明的局部变量i和go函数的参数i的类型都变了，都由int变为了uint32。至于为什么，我一会儿再说。&nbsp;再来说trigger函数。该函数接受两个参数，一个是uint32类型的参数i, 另一个是func()类型的参数fn。你应该记得，func()代表的是既无参数声明也无结果声明的函数类型。&nbsp;12345678910trigger := func(i uint32, fn func()) &#123; for &#123; if n := atomic.LoadUint32(&amp;count); n == i &#123; fn() atomic.AddUint32(&amp;count, 1) break &#125; time.Sleep(time.Nanosecond) &#125;&#125;&nbsp; trigger函数会不断地获取一个名叫count的变量的值（提前声明变量count，默认值为0），并判断该值是否与参数i的值相同。如果相同，那么就立即调用fn代表的函数，然后把count变量的值加1，最后显式地退出当前的循环。否则，我们就先让当前的 goroutine“睡眠”一个纳秒再进入下一个迭代。 &nbsp;注意，我操作变量count的时候使用的都是原子操作。这是由于trigger函数会被多个 goroutine 并发地调用，所以它用到的非本地变量count，就被多个用户级线程共用了。因此，对它的操作就产生了竞态条件（race condition），破坏了程序的并发安全性。&nbsp;所以，我们总是应该对这样的操作加以保护，在sync/atomic包中声明了很多用于原子操作的函数。另外，由于我选用的原子操作函数对被操作的数值的类型有约束，所以我才对count以及相关的变量和参数的类型进行了统一的变更（由int变为了uint32）。&nbsp;纵观count变量、trigger函数以及改造后的for语句和go函数，我要做的是，让count变量成为一个信号，它的值总是下一个可以调用打印函数的go函数的序号。&nbsp;这个序号其实就是启用 goroutine 时，那个当次迭代的序号。也正因为如此，go函数实际的执行顺序才会与go语句的执行顺序完全一致。此外，这里的trigger函数实现了一种自旋（spinning）。除非发现条件已满足，否则它会不断地进行检查。&nbsp;最后要说的是，因为我依然想让主 goroutine 最后一个运行完毕，所以还需要加一行代码。不过既然有了trigger函数，我就没有再使用通道。&nbsp;1trigger(10, func()&#123;&#125;)&nbsp; 调用trigger函数完全可以达到相同的效果。由于当所有我手动启用的 goroutine 都运行完毕之后，count的值一定会是10，所以我就把10作为了第一个参数值。又由于我并不想打印这个10，所以我把一个什么都不做的函数作为了第二个参数值。 &nbsp;总之，通过上述的改造，我使得异步发起的go函数得到了同步地（或者说按照既定顺序地）执行，你也可以动手自己试一试，感受一下。 &nbsp;&nbsp; 参考链接：https://time.geekbang.org/column/intro/112","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Go语言","slug":"Go语言","permalink":"http://wht6.github.io/tags/Go%E8%AF%AD%E8%A8%80/"}]},{"title":"Golang的指针","slug":"Golang的指针","date":"2022-03-02T02:00:00.000Z","updated":"2022-03-20T01:56:31.363Z","comments":true,"path":"posts/8fcc.html","link":"","permalink":"http://wht6.github.io/posts/8fcc.html","excerpt":"","text":"对于基本类型Dog来说，*Dog就是它的指针类型。而对于一个Dog类型，值不为nil的变量dog，取址表达式&amp;dog的结果就是该变量的值（也就是基本值）的指针值。 &nbsp; 1234567type Dog struct &#123; name string&#125; func (dog *Dog) SetName(name string) &#123; dog.name = name&#125; &nbsp; 如果一个方法的接收者是*Dog类型的，那么该方法就是基本类型Dog的一个指针方法。 &nbsp;在这种情况下，这个方法的接收者实际上就是当前的基本值的指针值。我们可以通过指针值无缝地访问到基本值包含的任何字段，以及调用与之关联的任何方法。这应该就是我们在编写 Go 程序的过程中，用得最频繁的“指针”了。&nbsp;从传统意义上说，指针是一个指向某个确切的内存地址的值。这个内存地址可以是任何数据或代码的起始地址，比如，某个变量、某个字段或某个函数。&nbsp;在 Go 语言中还有其他几样东西可以代表“指针”。其中最贴近传统意义的当属uintptr类型了。该类型实际上是一个数值类型，也是 Go 语言内建的数据类型之一。&nbsp;根据当前计算机的计算架构的不同，它可以存储 32 位或 64 位的无符号整数，可以代表任何指针的位（bit）模式，也就是原始的内存地址。&nbsp;再来看 Go 语言标准库中的unsafe包。unsafe包中有一个类型叫做Pointer，也代表了“指针”。&nbsp;unsafe.Pointer可以表示任何指向可寻址的值的指针，同时它也是前面提到的指针值和uintptr值之间的桥梁。也就是说，通过它，我们可以在这两种值之上进行双向的转换。这里有一个很关键的词——可寻址的（addressable）。在我们继续说unsafe.Pointer之前，需要先要搞清楚这个词的确切含义。&nbsp; 不可寻址的值&nbsp;以下列表中的值都是不可寻址的。&nbsp; 常量的值。 基本类型值的字面量。 算术操作的结果值。 对各种字面量的索引表达式和切片表达式的结果值。不过有一个例外，对切片字面量的索引结果值却是可寻址的。 对字符串变量的索引表达式和切片表达式的结果值。 对字典变量的索引表达式的结果值。 函数字面量和方法字面量，以及对它们的调用表达式的结果值。 结构体字面量的字段值，也就是对结构体字面量的选择表达式的结果值。 类型转换表达式的结果值。 类型断言表达式的结果值。 接收表达式的结果值。&nbsp; 常量的值总是会被存储到一个确切的内存区域中，并且这种值肯定是不可变的。基本类型值的字面量也是一样，其实它们本就可以被视为常量，只不过没有任何标识符可以代表它们罢了。 &nbsp;第一个关键词：不可变的。由于 Go 语言中的字符串值也是不可变的，所以对于一个字符串类型的变量来说，基于它的索引或切片的结果值也都是不可寻址的，因为即使拿到了这种值的内存地址也改变不了什么。&nbsp;算术操作的结果值属于一种临时结果。在我们把这种结果值赋给任何变量或常量之前，即使能拿到它的内存地址也是没有任何意义的。&nbsp;第二个关键词：临时结果。这个关键词能被用来解释很多现象。我们可以把各种对值字面量施加的表达式的求值结果都看做是临时结果。&nbsp;我们都知道，Go 语言中的表达式有很多种，其中常用的包括以下几种。&nbsp; 用于获得某个元素的索引表达式。 用于获得某个切片（片段）的切片表达式。 用于访问某个字段的选择表达式。 用于调用某个函数或方法的调用表达式。 用于转换值的类型的类型转换表达式。 用于判断值的类型的类型断言表达式。 向通道发送元素值或从通道那里接收元素值的接收表达式。&nbsp; 我们把以上这些表达式施加在某个值字面量上一般都会得到一个临时结果。比如，对数组字面量和字典字面量的索引结果值，又比如，对数组字面量和切片字面量的切片结果值。它们都属于临时结果，都是不可寻址的。 &nbsp;一个需要特别注意的例外是，对切片字面量的索引结果值是可寻址的。因为不论怎样，每个切片值都会持有一个底层数组，而这个底层数组中的每个元素值都是有一个确切的内存地址的。&nbsp;你可能会问，那么对切片字面量的切片结果值为什么却是不可寻址的？这是因为切片表达式总会返回一个新的切片值，而这个新的切片值在被赋给变量之前属于临时结果。&nbsp;你可能已经注意到了，我一直在说针对数组值、切片值或字典值的字面量的表达式会产生临时结果。如果针对的是数组类型或切片类型的变量，那么索引或切片的结果值就都不属于临时结果了，是可寻址的。&nbsp;这主要因为变量的值本身就不是“临时的”。对比而言，值字面量在还没有与任何变量（或者说任何标识符）绑定之前是没有落脚点的，我们无法以任何方式引用到它们。这样的值就是“临时的”。&nbsp;再说一个例外。我们通过对字典类型的变量施加索引表达式，得到的结果值不属于临时结果，可是，这样的值却是不可寻址的。原因是，字典中的每个键 - 元素对的存储位置都可能会变化，而且这种变化外界是无法感知的。&nbsp;我们都知道，字典中总会有若干个哈希桶用于均匀地储存键 - 元素对。当满足一定条件时，字典可能会改变哈希桶的数量，并适时地把其中的键 - 元素对搬运到对应的新的哈希桶中。&nbsp;在这种情况下，获取字典中任何元素值的指针都是无意义的，也是不安全的。我们不知道什么时候那个元素值会被搬运到何处，也不知道原先的那个内存地址上还会被存放什么别的东西。所以，这样的值就应该是不可寻址的。&nbsp;第三个关键词：不安全的。“不安全的”操作很可能会破坏程序的一致性，引发不可预知的错误，从而严重影响程序的功能和稳定性。&nbsp;再来看函数。函数在 Go 语言中是一等公民，所以我们可以把代表函数或方法的字面量或标识符赋给某个变量、传给某个函数或者从某个函数传出。但是，这样的函数和方法都是不可寻址的。一个原因是函数就是代码，是不可变的。&nbsp;另一个原因是，拿到指向一段代码的指针是不安全的。此外，对函数或方法的调用结果值也是不可寻址的，这是因为它们都属于临时结果。&nbsp;至于典型回答中最后列出的那几种值，由于都是针对值字面量的某种表达式的结果值，所以都属于临时结果，都不可寻址。&nbsp;总结一下。&nbsp; 不可变的值不可寻址。常量、基本类型的值字面量、字符串变量的值、函数以及方法的字面量都是如此。其实这样规定也有安全性方面的考虑。 绝大多数被视为临时结果的值都是不可寻址的。算术操作的结果值属于临时结果，针对值字面量的表达式结果值也属于临时结果。但有一个例外，对切片字面量的索引结果值虽然也属于临时结果，但却是可寻址的。 若拿到某值的指针可能会破坏程序的一致性，那么就是不安全的，该值就不可寻址。由于字典的内部机制，对字典的索引结果值的取址操作都是不安全的。另外，获取由字面量或标识符代表的函数或方法的地址显然也是不安全的。&nbsp; 最后说一句，如果我们把临时结果赋给一个变量，那么它就是可寻址的了。如此一来，取得的指针指向的就是这个变量持有的那个值了。 &nbsp; 不可寻址的值使用上的限制&nbsp;首当其冲的当然是无法使用取址操作符&amp;获取它们的指针了。不过，对不可寻址的值施加取址操作都会使编译器报错，所以倒是不用太担心，你只要记住我在前面讲述的那几条规律，并在编码的时候提前注意一下就好了。&nbsp;123func New(name string) Dog &#123; return Dog&#123;name&#125;&#125;&nbsp; 编写一个函数New。这个函数会接受一个名为name的string类型的参数，并会用这个参数初始化一个Dog类型的值，最后返回该值。我现在要问的是：如果我调用该函数，并直接以链式的手法调用其结果值的指针方法SetName，那么可以达到预期的效果吗？ &nbsp;1New(&quot;little pig&quot;).SetName(&quot;monster&quot;)&nbsp; 首先，调用New函数所得到的结果值属于临时结果，是不可寻址的。 &nbsp;其次，我们可以在一个基本类型的值上调用它的指针方法，这是因为 Go 语言会自动地帮我们转译。&nbsp;更具体地说，对于一个Dog类型的变量dog来说，调用表达式dog.SetName(&quot;monster&quot;)会被自动地转译为(&amp;dog).SetName(&quot;monster&quot;)，即：先取dog的指针值，再在该指针值上调用SetName方法。&nbsp;由于New函数的调用结果值是不可寻址的，所以无法对它进行取址操作。因此，上边这行链式调用会让编译器报告两个错误，一个是果，即：不能在New(&quot;little pig&quot;)的结果值上调用指针方法。一个是因，即：不能取得New(&quot;little pig&quot;)的地址。&nbsp;除此之外，我们都知道，Go 语言中的++和--并不属于操作符，而分别是自增语句和自减语句的重要组成部分。&nbsp;虽然 Go 语言规范中的语法定义是，只要在++或--的左边添加一个表达式，就可以组成一个自增语句或自减语句，但是，它还明确了一个很重要的限制，那就是这个表达式的结果值必须是可寻址的。这就使得针对值字面量的表达式几乎都无法被用在这里。&nbsp;不过这有一个例外，虽然对字典字面量和字典变量索引表达式的结果值都是不可寻址的，但是这样的表达式却可以被用在自增语句和自减语句中。&nbsp;与之类似的规则还有两个。一个是，在赋值语句中，赋值操作符左边的表达式的结果值必须可寻址的，但是对字典的索引结果值也是可以的。&nbsp;另一个是，在带有range子句的for语句中，在range关键字左边的表达式的结果值也都必须是可寻址的，不过对字典的索引结果值同样可以被用在这里。以上这三条规则我们合并起来记忆就可以了。&nbsp; 通过unsafe.Pointer操纵可寻址的值&nbsp;unsafe.Pointer是像*Dog类型的值这样的指针值和uintptr值之间的桥梁，那么我们怎样利用unsafe.Pointer的中转和uintptr的底层操作来操纵像dog这样的值呢？&nbsp;首先说明，这是一项黑科技。它可以绕过 Go 语言的编译器和其他工具的重重检查，并达到潜入内存修改数据的目的。这并不是一种正常的编程手段，使用它会很危险，很有可能造成安全隐患。&nbsp;我们总是应该优先使用常规代码包中提供的 API 去编写程序，当然也可以把像reflect以及go/ast这样的代码包作为备选项。作为上层应用的开发者，请谨慎地使用unsafe包中的任何程序实体。&nbsp;不过既然说到这里了，我们还是要来一探究竟的。请看下面的代码：&nbsp;123dog := Dog&#123;&quot;little pig&quot;&#125;dogP := &amp;dogdogPtr := uintptr(unsafe.Pointer(dogP))&nbsp; 这里先声明了一个Dog类型的变量dog，然后用取址操作符&amp;，取出了它的指针值，并把它赋给了变量dogP。 &nbsp;最后，我使用了两个类型转换，先把dogP转换成了一个unsafe.Pointer类型的值，然后紧接着又把后者转换成了一个uintptr的值，并把它赋给了变量dogPtr。这背后隐藏着一些转换规则，如下：&nbsp; 一个指针值（比如*Dog类型的值）可以被转换为一个unsafe.Pointer类型的值，反之亦然。 一个uintptr类型的值也可以被转换为一个unsafe.Pointer类型的值，反之亦然。 一个指针值无法被直接转换成一个uintptr类型的值，反过来也是如此。&nbsp; 所以，对于指针值和uintptr类型值之间的转换，必须使用unsafe.Pointer类型的值作为中转。那么，我们把指针值转换成uintptr类型的值有什么意义吗？ &nbsp;12namePtr := dogPtr + unsafe.Offsetof(dogP.name)nameP := (*string)(unsafe.Pointer(namePtr))&nbsp; 这里需要与unsafe.Offsetof函数搭配使用才能看出端倪。unsafe.Offsetof函数用于获取两个值在内存中的起始存储地址之间的偏移量，以字节为单位。 &nbsp;这两个值一个是某个字段的值，另一个是该字段值所属的那个结构体值。我们在调用这个函数的时候，需要把针对字段的选择表达式传给它，比如dogP.name。&nbsp;有了这个偏移量，又有了结构体值在内存中的起始存储地址（这里由dogPtr变量代表），把它们相加我们就可以得到dogP的name字段值的起始存储地址了。这个地址由变量namePtr代表。&nbsp;此后，我们可以再通过两次类型转换把namePtr的值转换成一个*string类型的值，这样就得到了指向dogP的name字段值的指针值。&nbsp;你可能会问，我直接用取址表达式&amp;(dogP.name)不就能拿到这个指针值了吗？干嘛绕这么大一圈呢？你可以想象一下，如果我们根本就不知道这个结构体类型是什么，也拿不到dogP这个变量，那么还能去访问它的name字段吗？&nbsp;答案是，只要有namePtr就可以。它就是一个无符号整数，但同时也是一个指向了程序内部数据的内存地址。它可能会给我们带来一些好处，比如可以直接修改埋藏得很深的内部数据。&nbsp;但是，一旦我们有意或无意地把这个内存地址泄露出去，那么其他人就能够肆意地改动dogP.name的值，以及周围的内存地址上存储的任何数据了。&nbsp;引用类型的值的指针值是有意义的吗？从存储和传递的角度看，没有意义。因为引用类型的值已经相当于指向某个底层数据结构的指针了。当然，引用类型的值不只是指针那么简单。 &nbsp; &nbsp; 参考链接：https://time.geekbang.org/column/intro/112","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Go语言","slug":"Go语言","permalink":"http://wht6.github.io/tags/Go%E8%AF%AD%E8%A8%80/"}]},{"title":"接口类型的合理使用","slug":"接口类型的合理使用","date":"2022-03-01T08:00:00.000Z","updated":"2022-03-20T01:53:30.093Z","comments":true,"path":"posts/874b.html","link":"","permalink":"http://wht6.github.io/posts/874b.html","excerpt":"","text":"在 Go 语言的语境中，当我们在谈论“接口”的时候，一定指的是接口类型。因为接口类型与其他数据类型不同，它是没法被实例化的。 &nbsp; 更具体地说，我们既不能通过调用new函数或make函数创建出一个接口类型的值，也无法用字面量来表示一个接口类型的值。&nbsp;对于某一个接口类型来说，如果没有任何数据类型可以作为它的实现，那么该接口的值就不可能存在。&nbsp;通过关键字type和interface，我们可以声明出接口类型。&nbsp;接口类型的类型字面量与结构体类型的看起来有些相似，它们都用花括号包裹一些核心信息。只不过，结构体类型包裹的是它的字段声明，而接口类型包裹的是它的方法定义。&nbsp;这里要注意的是：接口类型声明中的这些方法所代表的就是该接口的方法集合。一个接口的方法集合就是它的全部特征。&nbsp;对于任何数据类型，只要它的方法集合中完全包含了一个接口的全部特征（即全部的方法），那么它就一定是这个接口的实现类型。比如下面这样：&nbsp;12345type Pet interface &#123; SetName(name string) Name() string Category() string&#125;&nbsp; 这里声明了一个接口类型Pet，它包含了 3 个方法定义，方法名称分别为SetName、Name和Category。这 3 个方法共同组成了接口类型Pet的方法集合。 &nbsp;只要一个数据类型的方法集合中有这 3 个方法，那么它就一定是Pet接口的实现类型。这是一种无侵入式的接口实现方式。这种方式还有一个专有名词，叫“Duck typing”，中文常译作“鸭子类型”。&nbsp;怎样判定一个数据类型的某一个方法实现的就是某个接口类型中的某个方法呢？&nbsp;这有两个充分必要条件，一个是“两个方法的签名需要完全一致”，另一个是“两个方法的名称要一模一样”。显然，这比判断一个函数是否实现了某个函数类型要更加严格一些。&nbsp;123456789101112131415type Dog struct &#123; name string // 名字。&#125;func (dog *Dog) SetName(name string) &#123; dog.name = name&#125;func (dog Dog) Name() string &#123; return dog.name&#125;func (dog Dog) Category() string &#123; return &quot;dog&quot;&#125;&nbsp; 声明的类型Dog附带了 3 个方法。其中有 2 个值方法，分别是Name和Category，另外还有一个指针方法SetName。 &nbsp;这就意味着，Dog类型本身的方法集合中只包含了 2 个方法，也就是所有的值方法。而它的指针类型*Dog方法集合却包含了 3 个方法，&nbsp;也就是说，它拥有Dog类型附带的所有值方法和指针方法。又由于这 3 个方法恰恰分别是Pet接口中某个方法的实现，所以*Dog类型就成为了Pet接口的实现类型。&nbsp;12dog := Dog&#123;&quot;little pig&quot;&#125;var pet Pet = &amp;dog&nbsp; 正因为如此，可以声明并初始化一个Dog类型的变量dog，然后把它的指针值赋给类型为Pet的变量pet。 &nbsp;对于一个接口类型的变量来说，例如上面的变量pet，我们赋给它的值可以被叫做它的实际值（也称动态值），而该值的类型可以被叫做这个变量的实际类型（也称动态类型）。&nbsp;比如，我们把取址表达式&amp;dog的结果值赋给了变量pet，这时这个结果值就是变量pet的动态值，而此结果值的类型*Dog就是该变量的动态类型。&nbsp;动态类型这个叫法是相对于静态类型而言的。对于变量pet来讲，它的静态类型就是Pet，并且永远是Pet，但是它的动态类型却会随着我们赋给它的动态值而变化。&nbsp;比如，只有我把一个*Dog类型的值赋给变量pet之后，该变量的动态类型才会是*Dog。如果还有一个Pet接口的实现类型*Fish，并且我又把一个此类型的值赋给了pet，那么它的动态类型就会变为*Fish。&nbsp;还有，在我们给一个接口类型的变量赋予实际的值之前，它的动态类型是不存在的。&nbsp; 接口变量赋值&nbsp;当我们为一个接口变量赋值时会发生什么？&nbsp;把Pet接口的声明简化了一下。从中去掉了Pet接口的那个名为SetName的方法。这样一来，Dog类型也就变成Pet接口的实现类型了。&nbsp;1234type Pet interface &#123; Name() string Category() string&#125;&nbsp; 声明并初始化了一个Dog类型的变量dog，这时它的name字段的值是&quot;little pig&quot;。然后，把该变量赋给了一个Pet类型的变量pet。最后我通过调用dog的方法SetName把它的name字段的值改成了&quot;monster&quot;。 &nbsp;123dog := Dog&#123;&quot;little pig&quot;&#125;var pet Pet = dogdog.SetName(&quot;monster&quot;)&nbsp; 在以上代码执行后，pet变量的字段name的值依然是&quot;little pig&quot;。原因是： &nbsp;首先，由于dog的SetName方法是指针方法，所以该方法持有的接收者就是指向dog的指针值的副本，因而其中对接收者的name字段的设置就是对变量dog的改动。那么当dog.SetName(&quot;monster&quot;)执行之后，dog的name字段的值就一定是&quot;monster&quot;。如果你理解到了这一层，那么请小心前方的陷阱。&nbsp;为什么dog的name字段值变了，而pet的却没有呢？这里有一条通用的规则需要你知晓：如果我们使用一个变量给另外一个变量赋值，那么真正赋给后者的，并不是前者持有的那个值，而是该值的一个副本。&nbsp;例如，我声明并初始化了一个Dog类型的变量dog1，这时它的name是&quot;little pig&quot;。然后，我在把dog1赋给变量dog2之后，修改了dog1的name字段的值。这时，dog2的name字段的值是什么？&nbsp;123dog1 := Dog&#123;&quot;little pig&quot;&#125;dog2 := dog1dog1.name = &quot;monster&quot;&nbsp; 这个问题与前面那道题几乎一样，只不过这里没有涉及接口类型。这时的dog2的name仍然会是&quot;little pig&quot;。这就是我刚刚告诉你的那条通用规则的又一个体现。 &nbsp;当你知道了这条通用规则之后，确实可以把前面那道题做对。不过，如果当我问你为什么的时候你只说出了这一个原因，那么，我只能说你仅仅答对了一半。&nbsp;那么另一半是什么？这就需要从接口类型值的存储方式和结构说起了。我在前面说过，接口类型本身是无法被值化的。在我们赋予它实际的值之前，它的值一定会是nil，这也是它的零值。&nbsp;反过来讲，一旦它被赋予了某个实现类型的值，它的值就不再是nil了。不过要注意，即使我们像前面那样把dog的值赋给了pet，pet的值与dog的值也是不同的。这不仅仅是副本与原值的那种不同。&nbsp;当我们给一个接口变量赋值的时候，该变量的动态类型会与它的动态值一起被存储在一个专用的数据结构中。&nbsp;严格来讲，这样一个变量的值其实是这个专用数据结构的一个实例，而不是我们赋给该变量的那个实际的值。所以我才说，pet的值与dog的值肯定是不同的，无论是从它们存储的内容，还是存储的结构上来看都是如此。不过，我们可以认为，这时pet的值中包含了dog值的副本。&nbsp;我们就把这个专用的数据结构叫做iface吧，在 Go 语言的runtime包中它其实就叫这个名字。&nbsp;iface的实例会包含两个指针，一个是指向类型信息的指针，另一个是指向动态值的指针。这里的类型信息是由另一个专用数据结构的实例承载的，其中包含了动态值的类型，以及使它实现了接口的方法和调用它们的途径，等等。&nbsp;总之，接口变量被赋予动态值的时候，存储的是包含了这个动态值的副本的一个结构更加复杂的值。&nbsp;接口变量的值在什么情况下才真正为nil？&nbsp;12345678910var dog1 *Dogfmt.Println(&quot;The first dog is nil. [wrap1]&quot;)dog2 := dog1fmt.Println(&quot;The second dog is nil. [wrap1]&quot;)var pet Pet = dog2if pet == nil &#123; fmt.Println(&quot;The pet is nil. [wrap1]&quot;)&#125; else &#123; fmt.Println(&quot;The pet is not nil. [wrap1]&quot;)&#125;&nbsp; 我先声明了一个*Dog类型的变量dog1，并且没有对它进行初始化。这时该变量的值是什么？显然是nil。然后我把该变量赋给了dog2，后者的值此时也必定是nil，对吗？ &nbsp;现在问题来了：当我把dog2赋给Pet类型的变量pet之后，变量pet的值会是什么？答案是nil吗？&nbsp;如果你真正理解了我在上一个问题的解析中讲到的知识，尤其是接口变量赋值及其值的数据结构那部分，那么这道题就不难回答。你可以先思考一下，然后再接着往下看。&nbsp;当我们把dog2的值赋给变量pet的时候，dog2的值会先被复制，不过由于在这里它的值是nil，所以就没必要复制了。&nbsp;然后，Go 语言会用我上面提到的那个专用数据结构iface的实例包装这个dog2的值的副本，这里是nil。&nbsp;虽然被包装的动态值是nil，但是pet的值却不会是nil，因为这个动态值只是pet值的一部分而已。&nbsp;顺便说一句，这时的pet的动态类型就存在了，是*Dog。我们可以通过fmt.Printf函数和占位符%T来验证这一点，另外reflect包的TypeOf函数也可以起到类似的作用。&nbsp;在 Go 语言中，我们把由字面量nil表示的值叫做无类型的nil。这是真正的nil，因为它的类型也是nil的。虽然dog2的值是真正的nil，但是当我们把这个变量赋给pet的时候，Go 语言会把它的类型和值放在一起考虑。&nbsp;也就是说，这时 Go 语言会识别出赋予pet的值是一个*Dog类型的nil。然后，Go 语言就会用一个iface的实例包装它，包装后的产物肯定就不是nil了。&nbsp;只要我们把一个有类型的nil赋给接口变量，那么这个变量的值就一定不会是那个真正的nil。因此，当我们使用判等符号==判断pet是否与字面量nil相等的时候，答案一定会是false。&nbsp;那么，怎样才能让一个接口变量的值真正为nil呢？要么只声明它但不做初始化，要么直接把字面量nil赋给它。&nbsp; 接口类型的嵌入&nbsp;接口类型间的嵌入也被称为接口的组合。结构体类型的嵌入字段，这其实就是在说结构体类型间的嵌入。&nbsp;接口类型间的嵌入要更简单一些，因为它不会涉及方法间的“屏蔽”。只要组合的接口之间有同名的方法就会产生冲突，从而无法通过编译，即使同名方法的签名彼此不同也会是如此。因此，接口的组合根本不可能导致“屏蔽”现象的出现。&nbsp;与结构体类型间的嵌入很相似，我们只要把一个接口类型的名称直接写到另一个接口类型的成员列表中就可以了。比如：&nbsp;123456789type Animal interface &#123; ScientificName() string Category() string&#125; type Pet interface &#123; Animal Name() string&#125;&nbsp; 接口类型Pet包含了两个成员，一个是代表了另一个接口类型的Animal，一个是方法Name的定义。它们都被包含在Pet的类型声明的花括号中，并且都各自独占一行。此时，Animal接口包含的所有方法也就成为了Pet接口的方法。 &nbsp;Go 语言团队鼓励我们声明体量较小的接口，并建议我们通过这种接口间的组合来扩展程序、增加程序的灵活性。&nbsp;这是因为相比于包含很多方法的大接口而言，小接口可以更加专注地表达某一种能力或某一类特征，同时也更容易被组合在一起。&nbsp;Go 语言标准库代码包io中的ReadWriteCloser接口和ReadWriter接口就是这样的例子，它们都是由若干个小接口组合而成的。以io.ReadWriteCloser接口为例，它是由io.Reader、io.Writer和io.Closer这三个接口组成的。&nbsp;这三个接口都只包含了一个方法，是典型的小接口。它们中的每一个都只代表了一种能力，分别是读出、写入和关闭。我们编写这几个小接口的实现类型通常都会很容易。并且，一旦我们同时实现了它们，就等于实现了它们的组合接口io.ReadWriteCloser。&nbsp;即使我们只实现了io.Reader和io.Writer，那么也等同于实现了io.ReadWriter接口，因为后者就是前两个接口组成的。可以看到，这几个io包中的接口共同组成了一个接口矩阵。它们既相互关联又独立存在。 &nbsp;&nbsp; 参考链接：https://time.geekbang.org/column/intro/112","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Go语言","slug":"Go语言","permalink":"http://wht6.github.io/tags/Go%E8%AF%AD%E8%A8%80/"}]},{"title":"结构体及其方法的使用","slug":"结构体及其方法的使用","date":"2022-03-01T02:00:00.000Z","updated":"2022-03-20T01:56:15.858Z","comments":true,"path":"posts/6ae0.html","link":"","permalink":"http://wht6.github.io/posts/6ae0.html","excerpt":"","text":"结构体类型表示的是实实在在的数据结构。一个结构体类型可以包含若干个字段，每个字段通常都需要有确切的名字和类型。 &nbsp; 结构体类型也可以不包含任何字段，这样并不是没有意义的，因为我们还可以为类型关联上一些方法，这里你可以把方法看做是函数的特殊版本。&nbsp;函数是独立的程序实体。我们可以声明有名字的函数，也可以声明没名字的函数，还可以把它们当做普通的值传来传去。我们能把具有相同签名的函数抽象成独立的函数类型，以作为一组输入、输出（或者说一类逻辑组件）的代表。&nbsp;方法却不同，它需要有名字，不能被当作值来看待，最重要的是，它必须隶属于某一个类型。方法所属的类型会通过其声明中的接收者（receiver）声明体现出来。&nbsp;接收者声明就是在关键字func和方法名称之间的圆括号包裹起来的内容，其中必须包含确切的名称和类型字面量。&nbsp;接收者的类型其实就是当前方法所属的类型，而接收者的名称，则用于在当前方法中引用它所属的类型的当前值。&nbsp;我们举个例子来看一下。&nbsp;12345678910111213141516// AnimalCategory 代表动物分类学中的基本分类法。type AnimalCategory struct &#123; kingdom string // 界。 phylum string // 门。 class string // 纲。 order string // 目。 family string // 科。 genus string // 属。 species string // 种。&#125; func (ac AnimalCategory) String() string &#123; return fmt.Sprintf(&quot;%s%s%s%s%s%s%s&quot;, ac.kingdom, ac.phylum, ac.class, ac.order, ac.family, ac.genus, ac.species)&#125;&nbsp; 结构体类型AnimalCategory代表了动物的基本分类法，其中有 7 个string类型的字段，分别表示各个等级的分类。 &nbsp;下边有个名叫String的方法，从它的接收者声明可以看出它隶属于AnimalCategory类型。&nbsp;通过该方法的接收者名称ac，我们可以在其中引用到当前值的任何一个字段，或者调用到当前值的任何一个方法（也包括String方法自己）。&nbsp;这个String方法的功能是提供当前值的字符串表示形式，其中的各个等级分类会按照从大到小的顺序排列。使用时，我们可以这样表示：&nbsp;12category := AnimalCategory&#123;species: &quot;cat&quot;&#125;fmt.Printf(&quot;The animal category: %s\\n&quot;, category)&nbsp; 这里，我用字面量初始化了一个AnimalCategory类型的值，并把它赋给了变量category。只为其中的species字段指定了字符串值&quot;cat&quot;，该字段代表最末级分类“种”。 &nbsp;在 Go 语言中，我们可以通过为一个类型编写名为String的方法，来自定义该类型的字符串表示形式。这个String方法不需要任何参数声明，但需要有一个string类型的结果声明。&nbsp;正因为如此，我在调用fmt.Printf函数时，使用占位符%s和category值本身就可以打印出后者的字符串表示形式，而无需显式地调用它的String方法。&nbsp;fmt.Printf函数会自己去寻找它。此时的打印内容会是The animal category: cat。显而易见，category的String方法成功地引用了当前值的所有字段。&nbsp; 方法隶属的类型其实并不局限于结构体类型，但必须是某个自定义的数据类型，并且不能是任何接口类型。 一个数据类型关联的所有方法，共同组成了该类型的方法集合。同一个方法集合中的方法不能出现重名。并且，如果它们所属的是一个结构体类型，那么它们的名称与该类型中任何字段的名称也不能重复。 我们可以把结构体类型中的一个字段看作是它的一个属性或者一项数据，再把隶属于它的一个方法看作是附加在其中数据之上的一个能力或者一项操作。将属性及其能力（或者说数据及其操作）封装在一起，是面向对象编程（object-oriented programming）的一个主要原则。 Go 语言摄取了面向对象编程中的很多优秀特性，同时也推荐这种封装的做法。从这方面看，Go 语言其实是支持面向对象编程的，但它选择摒弃了一些在实际运用过程中容易引起程序开发者困惑的特性和规则。 &nbsp;现在，让我们再把目光放到结构体类型的字段声明上。 &nbsp;1234type Animal struct &#123; scientificName string // 学名。 AnimalCategory // 动物基本分类。&#125;&nbsp; 这里声明了一个结构体类型，名叫Animal。它有两个字段。一个是string类型的字段scientificName，代表了动物的学名。而另一个字段声明中只有AnimalCategory，它正是前面编写的那个结构体类型的名字。 &nbsp;字段声明AnimalCategory代表了Animal类型的一个嵌入字段。Go 语言规范规定，如果一个字段的声明中只有字段的类型名而没有字段的名称，那么它就是一个嵌入字段，也可以被称为匿名字段。我们可以通过此类型变量的名称后跟“.”，再后跟嵌入字段类型的方式引用到该字段。也就是说，嵌入字段的类型既是类型也是名称。&nbsp;123func (a Animal) Category() string &#123; return a.AnimalCategory.String()&#125;&nbsp; Category是Animal的一个方法，Category方法的接收者类型是Animal，接收者名称是a。在该方法中，我通过表达式a.AnimalCategory选择到了a的这个嵌入字段，然后又选择了该字段的String方法并调用了它。 &nbsp;顺便提一下，在某个代表变量的标识符的右边加“.”，再加上字段名或方法名的表达式被称为选择表达式，它用来表示选择了该变量的某个字段或者方法。&nbsp;实际上，把一个结构体类型嵌入到另一个结构体类型中的意义不止如此。嵌入字段的方法集合会被无条件地合并进被嵌入类型的方法集合中。例如下面这种：&nbsp;12345animal := Animal&#123; scientificName: &quot;American Shorthair&quot;, AnimalCategory: category,&#125;fmt.Printf(&quot;The animal: %s\\n&quot;, animal)&nbsp; 我声明了一个Animal类型的变量animal并对它进行初始化。我把字符串值&quot;American Shorthair&quot;赋给它的字段scientificName，并把前面声明过的变量category赋给它的嵌入字段AnimalCategory。 &nbsp;我在后面使用fmt.Printf函数和%s占位符试图打印animal的字符串表示形式，相当于调用animal的String方法。虽然我们还没有为Animal类型编写String方法，但这样做是没问题的。因为在这里，嵌入字段AnimalCategory的String方法会被当做animal的方法调用。&nbsp;那如果我也为Animal类型编写一个String方法呢？这里会调用哪一个呢？&nbsp;答案是，animal的String方法会被调用。这时，我们说，嵌入字段AnimalCategory的String方法被“屏蔽”了。注意，只要名称相同，无论这两个方法的签名是否一致，被嵌入类型的方法都会“屏蔽”掉嵌入字段的同名方法。&nbsp;类似的，由于我们同样可以像访问被嵌入类型的字段那样，直接访问嵌入字段的字段，所以如果这两个结构体类型里存在同名的字段，那么嵌入字段中的那个字段一定会被“屏蔽”。这与可重名变量之间可能存在的“屏蔽”现象很相似。&nbsp;正因为嵌入字段的字段和方法都可以“嫁接”到被嵌入类型上，所以即使在两个同名的成员一个是字段，另一个是方法的情况下，这种“屏蔽”现象依然会存在。&nbsp;不过，即使被屏蔽了，我们仍然可以通过链式的选择表达式，选择到嵌入字段的字段或方法，就像我在Category方法中所做的那样。这种“屏蔽”其实还带来了一些好处。我们看看下面这个Animal类型的String方法的实现：&nbsp;1234func (a Animal) String() string &#123; return fmt.Sprintf(&quot;%s (category: %s)&quot;, a.scientificName, a.AnimalCategory)&#125;&nbsp; 在这里，我们把对嵌入字段的String方法的调用结果融入到了Animal类型的同名方法的结果中。这种将同名方法的结果逐层“包装”的手法是很常见和有用的，也算是一种惯用法了。 &nbsp;&nbsp;最后，我还要提一下多层嵌入的问题。也就是说，嵌入字段本身也有嵌入字段的情况。请看我声明的Cat类型：&nbsp;123456789type Cat struct &#123; name string Animal&#125; func (cat Cat) String() string &#123; return fmt.Sprintf(&quot;%s (category: %s, name: %q)&quot;, cat.scientificName, cat.Animal.AnimalCategory, cat.name)&#125;&nbsp; 结构体类型Cat中有一个嵌入字段Animal，而Animal类型还有一个嵌入字段AnimalCategory。 &nbsp;在这种情况下，“屏蔽”现象会以嵌入的层级为依据，嵌入层级越深的字段或方法越可能被“屏蔽”。&nbsp;例如，当我们调用Cat类型值的String方法时，如果该类型确有String方法，那么嵌入字段Animal和AnimalCategory的String方法都会被“屏蔽”。&nbsp;如果该类型没有String方法，那么嵌入字段Animal的String方法会被调用，而它的嵌入字段AnimalCategory的String方法仍然会被屏蔽。&nbsp;只有当Cat类型和Animal类型都没有String方法的时候，AnimalCategory的String方法才会被调用。&nbsp;最后的最后，如果处于同一个层级的多个嵌入字段拥有同名的字段或方法，那么从被嵌入类型的值那里，选择此名称的时候就会引发一个编译错误，因为编译器无法确定被选择的成员到底是哪一个。&nbsp;Go 语言是否是用嵌入字段实现了继承呢，答案是否，Go 语言中根本没有继承的概念，它所做的是通过嵌入字段的方式实现了类型之间的组合。&nbsp;简单来说，面向对象编程中的继承，其实是通过牺牲一定的代码简洁性来换取可扩展性，而且这种可扩展性是通过侵入的方式来实现的。&nbsp;类型之间的组合采用的是非声明的方式，我们不需要显式地声明某个类型实现了某个接口，或者一个类型继承了另一个类型。&nbsp;同时，类型组合也是非侵入式的，它不会破坏类型的封装或加重类型之间的耦合。&nbsp;我们要做的只是把类型当做字段嵌入进来，然后坐享其成地使用嵌入字段所拥有的一切。如果嵌入字段有哪里不合心意，我们还可以用“包装”或“屏蔽”的方式去调整和优化。&nbsp;另外，类型间的组合也是灵活的，我们总是可以通过嵌入字段的方式把一个类型的属性和能力“嫁接”给另一个类型。&nbsp;这时候，被嵌入类型也就自然而然地实现了嵌入字段所实现的接口。再者，组合要比继承更加简洁和清晰，Go 语言可以轻而易举地通过嵌入多个字段来实现功能强大的类型，却不会有多重继承那样复杂的层次结构和可观的管理成本。&nbsp;接口类型之间也可以组合。在 Go 语言中，接口类型之间的组合甚至更加常见，我们常常以此来扩展接口定义的行为或者标记接口的特征。&nbsp; 值方法和指针方法&nbsp;方法的接收者类型必须是某个自定义的数据类型，而且不能是接口类型或接口的指针类型。所谓的值方法，就是接收者类型是非指针的自定义数据类型的方法。&nbsp;比如，我们在前面为AnimalCategory、Animal以及Cat类型声明的那些方法都是值方法。就拿Cat来说，它的String方法的接收者类型就是Cat，一个非指针类型。那什么叫指针类型呢？请看这个方法：&nbsp;123func (cat *Cat) SetName(name string) &#123; cat.name = name&#125;&nbsp; 方法SetName的接收者类型是*Cat。Cat左边再加个*代表的就是Cat类型的指针类型。 &nbsp;这时，Cat可以被叫做*Cat的基本类型。你可以认为这种指针类型的值表示的是指向某个基本类型值的指针。&nbsp;我们可以通过把取值操作符*放在这样一个指针值的左边来组成一个取值表达式，以获取该指针值指向的基本类型值，也可以通过把取址操作符&amp;放在一个可寻址的基本类型值的左边来组成一个取址表达式，以获取该基本类型值的指针值。&nbsp;所谓的指针方法，就是接收者类型是上述指针类型的方法。&nbsp;那么值方法和指针方法之间有什么不同点呢？它们的不同如下所示。&nbsp; 值方法的接收者是该方法所属的那个类型值的一个副本。我们在该方法内对该副本的修改一般都不会体现在原值上，除非这个类型本身是某个引用类型（比如切片或字典）的别名类型。 而指针方法的接收者，是该方法所属的那个基本类型值的指针值的一个副本。我们在这样的方法内对该副本指向的值进行修改，却一定会体现在原值上。 一个自定义数据类型的方法集合中仅会包含它的所有值方法，而该类型的指针类型的方法集合却囊括了前者的所有方法，包括所有值方法和所有指针方法。 严格来讲，我们在这样的基本类型的值上只能调用到它的值方法。但是，Go 语言会适时地为我们进行自动地转译，使得我们在这样的值上也能调用到它的指针方法。 比如，在Cat类型的变量cat之上，之所以我们可以通过cat.SetName(&quot;monster&quot;)修改猫的名字，是因为 Go 语言把它自动转译为了(&amp;cat).SetName(&quot;monster&quot;)，即：先取cat的指针值，然后在该指针值上调用SetName方法。 在后边你会了解到，一个类型的方法集合中有哪些方法与它能实现哪些接口类型是息息相关的。如果一个基本类型和它的指针类型的方法集合是不同的，那么它们具体实现的接口类型的数量就也会有差异，除非这两个数量都是零。 比如，一个指针类型实现了某某接口类型，但它的基本类型却不一定能够作为该接口的实现类型。 &nbsp;&nbsp; 参考链接：https://time.geekbang.org/column/intro/112","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Go语言","slug":"Go语言","permalink":"http://wht6.github.io/tags/Go%E8%AF%AD%E8%A8%80/"}]},{"title":"Go语言的函数","slug":"Go语言的函数","date":"2022-02-28T09:00:00.000Z","updated":"2022-03-20T01:58:05.940Z","comments":true,"path":"posts/24dd.html","link":"","permalink":"http://wht6.github.io/posts/24dd.html","excerpt":"","text":"在 Go 语言中，函数可是一等的（first-class）公民，函数类型也是一等的数据类型。这是什么意思呢？&nbsp;简单来说，这意味着函数不但可以用于封装代码、分割功能、解耦逻辑，还可以化身为普通的值，在其他函数间传递、赋予变量、做类型判断和转换等等，就像切片和字典的值那样。 &nbsp; 而更深层次的含义就是：函数值可以由此成为能够被随意传播的独立逻辑组件（或者说功能模块）。&nbsp;对于函数类型来说，它是一种对一组输入、输出进行模板化的重要工具，它比接口类型更加轻巧、灵活，它的值也借此变成了可被热替换的逻辑组件。&nbsp; 123456789101112131415package main import &quot;fmt&quot; type Printer func(contents string) (n int, err error) func printToStd(contents string) (bytesNum int, err error) &#123; return fmt.Println(contents)&#125; func main() &#123; var p Printer p = printToStd p(&quot;something&quot;)&#125; &nbsp; 这里，我先声明了一个函数类型，名叫Printer。 &nbsp;注意这里的写法，在类型声明的名称右边的是func关键字，我们由此就可知道这是一个函数类型的声明。&nbsp;在func右边的就是这个函数类型的参数列表和结果列表。其中，参数列表必须由圆括号包裹，而只要结果列表中只有一个结果声明，并且没有为它命名，我们就可以省略掉外围的圆括号。&nbsp;在func右边的就是这个函数类型的参数列表和结果列表。其中，参数列表必须由圆括号包裹，而只要结果列表中只有一个结果声明，并且没有为它命名，我们就可以省略掉外围的圆括号。&nbsp;书写函数签名的方式与函数声明的是一致的。只是紧挨在参数列表左边的不是函数名称，而是关键字func。这里函数名称和func互换了一下位置而已。&nbsp; 函数的签名其实就是函数的参数列表和结果列表的统称，它定义了可用来鉴别不同函数的那些特征，同时也定义了我们与函数交互的方式。 &nbsp;注意，各个参数和结果的名称不能算作函数签名的一部分，甚至对于结果声明来说，没有名称都可以。 &nbsp;只要两个函数的参数列表和结果列表中的元素顺序及其类型是一致的，我们就可以说它们是一样的函数，或者说是实现了同一个函数类型的函数。&nbsp;严格来说，函数的名称也不能算作函数签名的一部分，它只是我们在调用函数时，需要给定的标识符而已。&nbsp;我在下面声明的函数printToStd的签名与Printer的是一致的，因此前者是后者的一个实现，即使它们的名称以及有的结果名称是不同的。&nbsp;通过main函数中的代码，我们就可以证实这两者的关系了，我顺利地把printToStd函数赋给了Printer类型的变量p，并且成功地调用了它。&nbsp; 高阶函数&nbsp;高阶函数可以满足下面的两个条件：&nbsp;1. 接受其他的函数作为参数传入；2. 把其他的函数作为结果返回。&nbsp;只要满足了其中任意一个特点，我们就可以说这个函数是一个高阶函数。高阶函数也是函数式（functional programming）编程中的重要概念和特征。&nbsp;下面编写calculate函数来实现两个整数间的加减乘除运算，且两个整数和具体的操作都由该函数的调用方给出。&nbsp;首先，我们来声明一个名叫operate的函数类型，它有两个参数和一个结果，都是int类型的。&nbsp;1type operate func(x, y int) int&nbsp; 然后，我们编写calculate函数的签名部分。这个函数除了需要两个int类型的参数之外，还应该有一个operate类型的参数。 &nbsp;该函数的结果应该有两个，一个是int类型的，代表真正的操作结果，另一个应该是error类型的，因为如果那个operate类型的参数值为nil，那么就应该直接返回一个错误。&nbsp;函数类型属于引用类型，它的值可以为nil，而这种类型的零值恰恰就是nil。&nbsp;123456func calculate(x int, y int, op operate) (int, error) &#123; if op == nil &#123; return 0, errors.New(&quot;invalid operation&quot;) &#125; return op(x, y), nil&#125;&nbsp; calculate函数实现起来就很简单了。我们需要先用卫述语句检查一下参数，如果operate类型的参数op为nil，那么就直接返回0和一个代表了具体错误的error类型值。 &nbsp; 卫述语句是指被用来检查关键的先决条件的合法性，并在检查未通过的情况下立即终止当前代码块执行的语句。在 Go 语言中，if 语句常被作为卫述语句。 &nbsp;如果检查无误，那么就调用op并把那两个操作数传给它，最后返回op返回的结果和代表没有错误发生的nil。 &nbsp;calculate函数的其中一个参数是operate类型的，而且后者是一个函数类型。在调用calculate函数的时候，我们需要传入一个operate类型的函数值。这个函数值应该怎么写？&nbsp;只要它的签名与operate类型的签名一致，并且实现得当就可以了。我们可以像上一个例子那样先声明好一个函数，再把它赋给一个变量，也可以直接编写一个实现了operate类型的匿名函数。&nbsp;123op := func(x, y int) int &#123; return x + y&#125;&nbsp; calculate函数就是一个高阶函数。但是我们说高阶函数的特点有两个，而该函数只展示了其中一个特点，即：接受其他的函数作为参数传入。 &nbsp;那另一个特点，把其他的函数作为结果返回。&nbsp;12345678910type calculateFunc func(x int, y int) (int, error)func genCalculator(op operate) calculateFunc &#123; return func(x int, y int) (int, error) &#123; if op == nil &#123; return 0, errors.New(&quot;invalid operation&quot;) &#125; return op(x, y), nil &#125;&#125;&nbsp; 这里声明的函数类型是calculateFunc和函数genCalculator。其中，genCalculator函数的唯一结果的类型就是calculateFunc。 &nbsp;12345x, y = 56, 78add := genCalculator(op)result, err = add(x, y)fmt.Printf(&quot;The result: %d (error: %v)\\n&quot;, result, err)&nbsp; 闭包&nbsp; 闭包又是什么？你可以想象一下，在一个函数中存在对外来标识符的引用。所谓的外来标识符，既不代表当前函数的任何参数或结果，也不是函数内部声明的，它是直接从外边拿过来的。&nbsp;还有个专门的术语称呼它，叫自由变量，可见它代表的肯定是个变量。实际上，如果它是个常量，那也就形成不了闭包了，因为常量是不可变的程序实体，而闭包体现的却是由“不确定”变为“确定”的一个过程。&nbsp;我们说的这个函数（以下简称闭包函数）就是因为引用了自由变量，而呈现出了一种“不确定”的状态，也叫“开放”状态。&nbsp;也就是说，它的内部逻辑并不是完整的，有一部分逻辑需要这个自由变量参与完成，而后者到底代表了什么在闭包函数被定义的时候却是未知的。&nbsp;即使对于像 Go 语言这种静态类型的编程语言而言，我们在定义闭包函数的时候最多也只能知道自由变量的类型。&nbsp;在我们刚刚提到的genCalculator函数内部，实际上就实现了一个闭包，而genCalculator函数也是一个高阶函数。&nbsp;genCalculator函数只做了一件事，那就是定义一个匿名的、calculateFunc类型的函数并把它作为结果值返回。&nbsp;而这个匿名的函数就是一个闭包函数。它里面使用的变量op既不代表它的任何参数或结果也不是它自己声明的，而是定义它的genCalculator函数的参数，所以是一个自由变量。&nbsp;这个自由变量究竟代表了什么，这一点并不是在定义这个闭包函数的时候确定的，而是在genCalculator函数被调用的时候确定的。&nbsp;只有给定了该函数的参数op，我们才能知道它返回给我们的闭包函数可以用于什么运算。&nbsp;看到if op == nil &#123;那一行了吗？Go 语言编译器读到这里时会试图去寻找op所代表的东西，它会发现op代表的是genCalculator函数的参数，然后，它会把这两者联系起来。这时可以说，自由变量op被“捕获”了。&nbsp;当程序运行到这里的时候，op就是那个参数值了。如此一来，这个闭包函数的状态就由“不确定”变为了“确定”，或者说转到了“闭合”状态，至此也就真正地形成了一个闭包。&nbsp;看出来了吗？我们在用高阶函数实现闭包。这也是高阶函数的一大功用。&nbsp;&nbsp;那么，实现闭包的意义又在哪里呢？表面上看，我们只是延迟实现了一部分程序逻辑或功能而已，但实际上，我们是在动态地生成那部分程序逻辑。&nbsp;我们可以借此在程序运行的过程中，根据需要生成功能不同的函数，继而影响后续的程序行为。这与 GoF 设计模式中的“模板方法”模式有着异曲同工之妙，不是吗？&nbsp; 传入函数的那些参数值&nbsp;让我们把目光再次聚焦到函数本身。我们先看一个示例。&nbsp;12345678910111213141516package main import &quot;fmt&quot; func main() &#123; array1 := [3]string&#123;&quot;a&quot;, &quot;b&quot;, &quot;c&quot;&#125; fmt.Printf(&quot;The array: %v\\n&quot;, array1) array2 := modifyArray(array1) fmt.Printf(&quot;The modified array: %v\\n&quot;, array2) fmt.Printf(&quot;The original array: %v\\n&quot;, array1)&#125; func modifyArray(a [3]string) [3]string &#123; a[1] = &quot;x&quot; return a&#125;&nbsp; 这个命令源码文件在运行之后会输出什么？ &nbsp;main函数中声明了一个数组array1，然后把它传给了函数modify，modify对参数值稍作修改后将其作为结果值返回。main函数中的代码拿到这个结果之后打印了它（即array2），以及原来的数组array1。关键问题是，原数组会因modify函数对参数值的修改而改变吗？&nbsp;答案是：原数组不会改变。为什么呢？原因是，所有传给函数的参数值都会被复制，函数在其内部使用的并不是参数值的原值，而是它的副本。&nbsp;由于数组是值类型，所以每一次复制都会拷贝它，以及它的所有元素值。我在modify函数中修改的只是原数组的副本而已，并不会对原数组造成任何影响。&nbsp;注意，对于引用类型，比如：切片、字典、通道，像上面那样复制它们的值，只会拷贝它们本身而已，并不会拷贝它们引用的底层数据。也就是说，这时只是浅表复制，而不是深层复制。&nbsp;以切片值为例，如此复制的时候，只是拷贝了它指向底层数组中某一个元素的指针，以及它的长度值和容量值，而它的底层数组并不会被拷贝。&nbsp;另外还要注意，就算我们传入函数的是一个值类型的参数值，但如果这个参数值中的某个元素是引用类型的，那么我们仍然要小心。&nbsp;比如：&nbsp;12345complexArray1 := [3][]string&#123; []string&#123;&quot;d&quot;, &quot;e&quot;, &quot;f&quot;&#125;, []string&#123;&quot;g&quot;, &quot;h&quot;, &quot;i&quot;&#125;, []string&#123;&quot;j&quot;, &quot;k&quot;, &quot;l&quot;&#125;,&#125;&nbsp; 变量complexArray1是[3][]string类型的，也就是说，虽然它是一个数组，但是其中的每个元素又都是一个切片。这样一个值被传入函数的话，函数中对该参数值的修改会影响到它的原值吗？答案：如果对complexArray1中的元素进行增减，那么原值就不会受到影响。但若要修改它已有的元素值，那么原值也会跟着改变。 &nbsp; 函数真正拿到的参数值其实只是它们的副本，那么函数返回给调用方的结果值也会被复制吗？答：函数返回给调用方的结果值也会被复制。不过，在一般情况下，我们不用太在意。但如果函数在返回结果值之后依然保持执行并会对结果值进行修改，那么我们就需要注意了。 &nbsp;&nbsp; 参考链接：https://time.geekbang.org/column/intro/112","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Go语言","slug":"Go语言","permalink":"http://wht6.github.io/tags/Go%E8%AF%AD%E8%A8%80/"}]},{"title":"Go语言的通道","slug":"Go语言的通道","date":"2022-02-28T03:00:00.000Z","updated":"2022-03-20T01:56:00.127Z","comments":true,"path":"posts/461c.html","link":"","permalink":"http://wht6.github.io/posts/461c.html","excerpt":"","text":"作为 Go 语言最有特色的数据类型，通道（channel）完全可以与 goroutine（也可称为 go 程）并驾齐驱，共同代表 Go 语言独有的并发编程模式和编程哲学。 &nbsp; 01|通道的基础知识&nbsp;通道类型的值本身就是并发安全的，这也是 Go 语言自带的、唯一一个可以满足并发安全性的类型。&nbsp;在声明并初始化一个通道的时候，我们需要用到 Go 语言的内建函数make。就像用make初始化切片那样，我们传给这个函数的第一个参数应该是代表了通道的具体类型的类型字面量。&nbsp;在声明一个通道类型变量的时候，我们首先要确定该通道类型的元素类型，这决定了我们可以通过这个通道传递什么类型的数据。&nbsp;比如，类型字面量chan int，其中的chan是表示通道类型的关键字，而int则说明了该通道类型的元素类型。又比如，chan string代表了一个元素类型为string的通道类型。&nbsp;在初始化通道的时候，make函数除了必须接收这样的类型字面量作为参数，还可以接收一个int类型的参数用于表示该通道的容量。所谓通道的容量，就是指通道最多可以缓存多少个元素值。由此，虽然这个参数是int类型的，但是它是不能小于0的。&nbsp;当容量为0时，我们可以称通道为非缓冲通道，也就是不带缓冲的通道。而当容量大于0时，我们可以称为缓冲通道，也就是带有缓冲的通道。非缓冲通道和缓冲通道有着不同的数据传递方式。&nbsp;一个通道相当于一个先进先出（FIFO）的队列。也就是说，通道中的各个元素值都是严格地按照发送的顺序排列的，先被发送通道的元素值一定会先被接收。元素值的发送和接收都需要用到操作符&lt;-。我们也可以叫它接送操作符。一个左尖括号紧接着一个减号形象地代表了元素值的传输方向。&nbsp; 12345678910111213package main import &quot;fmt&quot; func main() &#123; ch1 := make(chan int, 3) ch1 &lt;- 2 ch1 &lt;- 1 ch1 &lt;- 3 elem1 := &lt;-ch1 fmt.Printf(&quot;The first element received from channel ch1: %v\\n&quot;, elem1)&#125; &nbsp; 这里声明并初始化了一个元素类型为int、容量为3的通道ch1，并用三条语句，向该通道先后发送了三个元素值2、1和3。 &nbsp;这里的语句需要这样写：依次敲入通道变量的名称（比如ch1）、接送操作符&lt;-以及想要发送的元素值（比如2），并且这三者之间最好用空格进行分割。&nbsp;这显然表达了“这个元素值将被发送该通道”这个语义。由于该通道的容量为 3，所以，我可以在通道不包含任何元素值的时候，连续地向该通道发送三个值，此时这三个值都会被缓存在通道之中。&nbsp;当我们需要从通道接收元素值的时候，同样要用接送操作符&lt;-，只不过，这时需要把它写在变量名的左边，用于表达“要从该通道接收一个元素值”的语义。&nbsp;比如：&lt;-ch1，这也可以被叫做接收表达式。在一般情况下，接收表达式的结果将会是通道中的一个元素值。&nbsp;如果我们需要把如此得来的元素值存起来，那么在接收表达式的左边就需要依次添加赋值符号（=或:=）和用于存值的变量的名字。因此，语句elem1 := &lt;-ch1会将最先进入ch1的元素2接收来并存入变量elem1。&nbsp; 通道的基本特性&nbsp;对通道的发送和接收操作的基本特性如下。&nbsp; 对于同一个通道，发送操作之间是互斥的，接收操作之间也是互斥的。 发送操作和接收操作中对元素值的处理都是不可分割的。 发送操作在完全完成之前会被阻塞。接收操作也是如此。&nbsp;第一个基本特性。 在同一时刻，Go 语言的运行时系统（以下简称运行时系统）只会执行对同一个通道的任意个发送操作中的某一个。直到这个元素值被完全复制进该通道之后，其他针对该通道的发送操作才可能被执行。&nbsp;类似的，在同一时刻，运行时系统也只会执行，对同一个通道的任意个接收操作中的某一个。直到这个元素值完全被移出该通道之后，其他针对该通道的接收操作才可能被执行。即使这些操作是并发执行的也是如此。&nbsp;这里所谓的并发执行，你可以这样认为，多个代码块分别在不同的 goroutine 之中，并有机会在同一个时间段内被执行。&nbsp;另外，对于通道中的同一个元素值来说，发送操作和接收操作之间也是互斥的。例如，虽然会出现，正在被复制进通道但还未复制完成的元素值，但是这时它绝不会被想接收它的一方看到和取走。&nbsp;这里要注意的一个细节是，元素值从外界进入通道时会被复制。更具体地说，进入通道的并不是在接收操作符右边的那个元素值，而是它的副本。&nbsp;另一方面，元素值从通道进入外界时会被移动。这个移动操作实际上包含了两步，第一步是生成正在通道中的这个元素值的副本，并准备给到接收方，第二步是删除在通道中的这个元素值。&nbsp;第二个基本特性。 这里的“不可分割”的意思是，它们处理元素值时都是一气呵成的，绝不会被打断。&nbsp;例如，发送操作要么还没复制元素值，要么已经复制完毕，绝不会出现只复制了一部分的情况。&nbsp;又例如，接收操作在准备好元素值的副本之后，一定会删除掉通道中的原值，绝不会出现通道中仍有残留的情况。&nbsp;这既是为了保证通道中元素值的完整性，也是为了保证通道操作的唯一性。对于通道中的同一个元素值来说，它只可能是某一个发送操作放入的，同时也只可能被某一个接收操作取出。&nbsp;第三个基本特性。 一般情况下，发送操作包括了“复制元素值”和“放置副本到通道内部”这两个步骤。&nbsp;在这两个步骤完全完成之前，发起这个发送操作的那句代码会一直阻塞在那里。也就是说，在它之后的代码不会有执行的机会，直到这句代码的阻塞解除。&nbsp;更细致地说，在通道完成发送操作之后，运行时系统会通知这句代码所在的 goroutine，以使它去争取继续运行代码的机会。&nbsp;另外，接收操作通常包含了“复制通道内的元素值”“放置副本到接收方”“删掉原值”三个步骤。&nbsp;在所有这些步骤完全完成之前，发起该操作的代码也会一直阻塞，直到该代码所在的 goroutine 收到了运行时系统的通知并重新获得运行机会为止。&nbsp;如此阻塞代码其实就是为了实现操作的互斥和元素值的完整。&nbsp; 扩展&nbsp;发送操作和接收操作在什么时候可能被长时间的阻塞？&nbsp;先说针对缓冲通道的情况。如果通道已满，那么对它的所有发送操作都会被阻塞，直到通道中有元素值被接收走。这时，通道会优先通知最早因此而等待的、那个发送操作所在的 goroutine，后者会再次执行发送操作。&nbsp;由于发送操作在这种情况下被阻塞后，它们所在的 goroutine 会顺序地进入通道内部的发送等待队列，所以通知的顺序总是公平的。&nbsp;相对的，如果通道已空，那么对它的所有接收操作都会被阻塞，直到通道中有新的元素值出现。这时，通道会通知最早等待的那个接收操作所在的 goroutine，并使它再次执行接收操作。&nbsp;因此而等待的、所有接收操作所在的 goroutine，都会按照先后顺序被放入通道内部的接收等待队列。&nbsp;对于非缓冲通道，情况要简单一些。无论是发送操作还是接收操作，一开始执行就会被阻塞，直到配对的操作也开始执行，才会继续传递。由此可见，非缓冲通道是在用同步的方式传递数据。也就是说，只有收发双方对接上了，数据才会被传递。&nbsp;并且，数据是直接从发送方复制到接收方的，中间并不会用非缓冲通道做中转。相比之下，缓冲通道则在用异步的方式传递数据。&nbsp;在大多数情况下，缓冲通道会作为收发双方的中间件。正如前文所述，元素值会先从发送方复制到缓冲通道，之后再由缓冲通道复制给接收方。但是，当发送操作在执行的时候发现空的通道中，正好有等待的接收操作，那么它会直接把元素值复制给接收方。&nbsp;特别说明一下，由于错误使用通道而造成的阻塞。&nbsp;对于值为nil的通道，不论它的具体类型是什么，对它的发送操作和接收操作都会永久地处于阻塞状态。它们所属的 goroutine 中的任何代码，都不再会被执行。&nbsp;注意，由于通道类型是引用类型，所以它的零值就是nil。换句话说，当我们只声明该类型的变量但没有用make函数对它进行初始化时，该变量的值就会是nil。我们一定不要忘记初始化通道！&nbsp;发送操作和接收操作在什么时候会引发 panic？&nbsp;对于一个已初始化，但并未关闭的通道来说，收发操作一定不会引发 panic。但是通道一旦关闭，再对它进行发送操作，就会引发 panic。&nbsp;另外，如果我们试图关闭一个已经关闭了的通道，也会引发 panic。注意，接收操作是可以感知到通道的关闭的，并能够安全退出。&nbsp;更具体地说，当我们把接收表达式的结果同时赋给两个变量时，第二个变量的类型就是一定bool类型。它的值如果为false就说明通道已经关闭，并且再没有元素值可取了。&nbsp;注意，如果通道关闭时，里面还有元素值未被取出，那么接收表达式的第一个结果，仍会是通道中的某一个元素值，而第二个结果值一定会是true。&nbsp;因此，通过接收表达式的第二个结果值，来判断通道是否关闭是可能有延时的。&nbsp;由于通道的收发操作有上述特性，所以除非有特殊的保障措施，我们千万不要让接收方关闭通道，而应当让发送方做这件事。 &nbsp; 通道的长度代表它当前包含的元素值的个数。当通道已满时，其长度会与容量相同。 &nbsp; 02|通道的进阶使用&nbsp; 单向通道&nbsp;所谓单向通道就是，只能发不能收，或者只能收不能发的通道。一个通道是双向的，还是单向的是由它的类型字面量体现的。&nbsp;还记得我们在上篇文章中说过的接收操作符&lt;-吗？如果我们把它用在通道的类型字面量中，那么它代表的就不是“发送”或“接收”的动作了，而是表示通道的方向。&nbsp;1var uselessChan = make(chan&lt;- int, 1) &nbsp; uselessChan变量的类型是chan&lt;- int，容量是1。 &nbsp;请注意紧挨在关键字chan右边的那个&lt;-，这表示了这个通道是单向的，并且只能发而不能收。&nbsp;类似的，如果这个操作符紧挨在chan的左边，那么就说明该通道只能收不能发。所以，前者可以被简称为发送通道，后者可以被简称为接收通道。&nbsp;注意，与发送操作和接收操作对应，这里的“发”和“收”都是站在操作通道的代码的角度上说的。&nbsp;从上述变量的名字上你也能猜到，这样的通道是没用的。通道就是为了传递数据而存在的，声明一个只有一端（发送端或者接收端）能用的通道没有任何意义。那么，单向通道的用途究竟在哪儿呢？&nbsp;概括地说，单向通道最主要的用途就是约束其他代码的行为。&nbsp;123func SendInt(ch chan&lt;- int) &#123; ch &lt;- rand.Intn(1000)&#125;&nbsp; 我用func关键字声明了一个叫做SendInt的函数。这个函数只接受一个chan&lt;- int类型的参数。在这个函数中的代码只能向参数ch发送元素值，而不能从它那里接收元素值。这就起到了约束函数行为的作用。 &nbsp;你可能会问，我自己写的函数自己肯定能确定操作通道的方式，为什么还要再约束？好吧，这个例子可能过于简单了。在实际场景中，这种约束一般会出现在接口类型声明中的某个方法定义上。请看这个叫Notifier的接口类型声明：&nbsp;123type Notifier interface &#123; SendInt(ch chan&lt;- int)&#125;&nbsp; 在接口类型声明的花括号中，每一行都代表着一个方法的定义。接口中的方法定义与函数声明很类似，但是只包含了方法名称、参数列表和结果列表。 &nbsp;一个类型如果想成为一个接口类型的实现类型，那么就必须实现这个接口中定义的所有方法。因此，如果我们在某个方法的定义中使用了单向通道类型，那么就相当于在对它的所有实现做出约束。&nbsp;在这里，Notifier接口中的SendInt方法只会接受一个发送通道作为参数，所以，在该接口的所有实现类型中的SendInt方法都会受到限制。这种约束方式还是很有用的，尤其是在我们编写模板代码或者可扩展的程序库的时候。&nbsp;顺便说一下，我们在调用SendInt函数的时候，只需要把一个元素类型匹配的双向通道传给它就行了，没必要用发送通道，因为 Go 语言在这种情况下会自动地把双向通道转换为函数所需的单向通道。&nbsp;12intChan1 := make(chan int, 3)SendInt(intChan1)&nbsp; 在另一个方面，我们还可以在函数声明的结果列表中使用单向通道。如下所示： &nbsp;123456789func getIntChan() &lt;-chan int &#123; num := 5 ch := make(chan int, num) for i := 0; i &lt; num; i++ &#123; ch &lt;- i &#125; close(ch) return ch&#125;&nbsp; 函数getIntChan会返回一个&lt;-chan int类型的通道，这就意味着得到该通道的程序，只能从通道中接收元素值。这实际上就是对函数调用方的一种约束了。 &nbsp;另外，我们在 Go 语言中还可以声明函数类型，如果我们在函数类型中使用了单向通道，那么就相等于在约束所有实现了这个函数类型的函数。&nbsp;1234intChan2 := getIntChan()for elem := range intChan2 &#123; fmt.Printf(&quot;The element in intChan2: %v\\n&quot;, elem)&#125;&nbsp; 我把调用getIntChan得到的结果值赋给了变量intChan2，然后用for语句循环地取出了该通道中的所有元素值，并打印出来。 &nbsp;这里的for语句也可以被称为带有range子句的for语句。它的用法我在后面讲for语句的时候专门说明。现在你只需要知道关于它的三件事。&nbsp; 一、这样一条for语句会不断地尝试从intChan2种取出元素值，即使intChan2被关闭，它也会在取出所有剩余的元素值之后再结束执行。 二、当intChan2中没有元素值时，它会被阻塞在有for关键字的那一行，直到有新的元素值可取。 三、假设intChan2的值为nil，那么它会被永远阻塞在有for关键字的那一行。 &nbsp; 这就是带range子句的for语句与通道的联用方式。不过，它是一种用途比较广泛的语句，还可以被用来从其他一些类型的值中获取元素。除此之外，Go 语言还有一种专门为了操作通道而存在的语句：select语句。&nbsp; select语句&nbsp; select语句与通道联用&nbsp;select语句只能与通道联用，它一般由若干个分支组成。每次执行这种语句的时候，一般只有一个分支中的代码会被运行。&nbsp;select语句的分支分为两种，一种叫做候选分支，另一种叫做默认分支。候选分支总是以关键字case开头，后跟一个case表达式和一个冒号，然后我们可以从下一行开始写入当分支被选中时需要执行的语句。&nbsp;默认分支其实就是 default case，因为，当且仅当没有候选分支被选中时它才会被执行，所以它以关键字default开头并直接后跟一个冒号。同样的，我们可以在default:的下一行写入要执行的语句。&nbsp;由于select语句是专为通道而设计的，所以每个case表达式中都只能包含操作通道的表达式，比如接收表达式。&nbsp;当然，如果我们需要把接收表达式的结果赋给变量的话，还可以把这里写成赋值语句或者短变量声明。下面展示一个简单的例子。&nbsp;123456789101112131415161718192021// 准备好几个通道。intChannels := [3]chan int&#123; make(chan int, 1), make(chan int, 1), make(chan int, 1),&#125;// 随机选择一个通道，并向它发送元素值。index := rand.Intn(3)fmt.Printf(&quot;The index: %d\\n&quot;, index)intChannels[index] &lt;- index// 哪一个通道中有可取的元素值，哪个对应的分支就会被执行。select &#123;case &lt;-intChannels[0]: fmt.Println(&quot;The first candidate case is selected.&quot;)case &lt;-intChannels[1]: fmt.Println(&quot;The second candidate case is selected.&quot;)case elem := &lt;-intChannels[2]: fmt.Printf(&quot;The third candidate case is selected, the element is %d.\\n&quot;, elem)default: fmt.Println(&quot;No candidate case is selected!&quot;)&#125;&nbsp; 我先准备好了三个类型为chan int、容量为1的通道，并把它们存入了一个叫做intChannels的数组。 &nbsp;然后，我随机选择一个范围在 [0, 2] 的整数，把它作为索引在上述数组中选择一个通道，并向其中发送一个元素值。&nbsp;最后，我用一个包含了三个候选分支的select语句，分别尝试从上述三个通道中接收元素值，哪一个通道中有值，哪一个对应的候选分支就会被执行。后面还有一个默认分支，不过在这里它是不可能被选中的。&nbsp;在使用select语句的时候，我们首先需要注意下面几个事情。&nbsp; 如果像上述示例那样加入了默认分支，那么无论涉及通道操作的表达式是否有阻塞，select语句都不会被阻塞。如果那几个表达式都阻塞了，或者说都没有满足求值的条件，那么默认分支就会被选中并执行。 如果没有加入默认分支，那么一旦所有的case表达式都没有满足求值条件，那么select语句就会被阻塞。直到至少有一个case表达式满足条件为止。 还记得吗？我们可能会因为通道关闭了，而直接从通道接收到一个其元素类型的零值。所以，在很多时候，我们需要通过接收表达式的第二个结果值来判断通道是否已经关闭。一旦发现某个通道关闭了，我们就应该及时地屏蔽掉对应的分支或者采取其他措施。这对于程序逻辑和程序性能都是有好处的。 select语句只能对其中的每一个case表达式各求值一次。所以，如果我们想连续或定时地操作其中的通道的话，就往往需要通过在for语句中嵌入select语句的方式实现。但这时要注意，简单地在select语句的分支中使用break语句，只能结束当前的select语句的执行，而并不会对外层的for语句产生作用。这种错误的用法可能会让这个for语句无休止地运行下去。&nbsp; 12345678910111213intChan := make(chan int, 1)// 一秒后关闭通道。time.AfterFunc(time.Second, func() &#123; close(intChan)&#125;)select &#123;case _, ok := &lt;-intChan: if !ok &#123; fmt.Println(&quot;The candidate case is closed.&quot;) break &#125; fmt.Println(&quot;The candidate case is selected.&quot;)&#125; &nbsp; 我先声明并初始化了一个叫做intChan的通道，然后通过time包中的AfterFunc函数约定在一秒钟之后关闭该通道。 &nbsp;后面的select语句只有一个候选分支，我在其中利用接收表达式的第二个结果值对intChan通道是否已关闭做了判断，并在得到肯定结果后，通过break语句立即结束当前select语句的执行。&nbsp; select语句的分支选择规则&nbsp;规则如下面所示。&nbsp; 对于每一个case表达式，都至少会包含一个代表发送操作的发送表达式或者一个代表接收操作的接收表达式，同时也可能会包含其他的表达式。比如，如果case表达式是包含了接收表达式的短变量声明时，那么在赋值符号左边的就可以是一个或两个表达式，不过此处的表达式的结果必须是可以被赋值的。当这样的case表达式被求值时，它包含的多个表达式总会以从左到右的顺序被求值。 select语句包含的候选分支中的case表达式都会在该语句执行开始时先被求值，并且求值的顺序是依从代码编写的顺序从上到下的。结合上一条规则，在select语句开始执行时，排在最上边的候选分支中最左边的表达式会最先被求值，然后是它右边的表达式。仅当最上边的候选分支中的所有表达式都被求值完毕后，从上边数第二个候选分支中的表达式才会被求值，顺序同样是从左到右，然后是第三个候选分支、第四个候选分支，以此类推。 对于每一个case表达式，如果其中的发送表达式或者接收表达式在被求值时，相应的操作正处于阻塞状态，那么对该case表达式的求值就是不成功的。在这种情况下，我们可以说，这个case表达式所在的候选分支是不满足选择条件的。 仅当select语句中的所有case表达式都被求值完毕后，它才会开始选择候选分支。这时候，它只会挑选满足选择条件的候选分支执行。如果所有的候选分支都不满足选择条件，那么默认分支就会被执行。如果这时没有默认分支，那么select语句就会立即进入阻塞状态，直到至少有一个候选分支满足选择条件为止。一旦有一个候选分支满足选择条件，select语句（或者说它所在的 goroutine）就会被唤醒，这个候选分支就会被执行。 如果select语句发现同时有多个候选分支满足选择条件，那么它就会用一种伪随机的算法在这些分支中选择一个并执行。注意，即使select语句是在被唤醒时发现的这种情况，也会这样做。 一条select语句中只能够有一个默认分支。并且，默认分支只在无候选分支可选时才会被执行，这与它的编写位置无关。 select语句的每次执行，包括case表达式求值和分支选择，都是独立的。不过，至于它的执行是否是并发安全的，就要看其中的case表达式以及分支中，是否包含并发不安全的代码了。 &nbsp; &nbsp; 参考链接：https://time.geekbang.org/column/intro/112","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Go语言","slug":"Go语言","permalink":"http://wht6.github.io/tags/Go%E8%AF%AD%E8%A8%80/"}]},{"title":"字典的操作和约束","slug":"字典的操作和约束","date":"2022-02-27T03:00:00.000Z","updated":"2022-03-20T01:55:43.852Z","comments":true,"path":"posts/69aa.html","link":"","permalink":"http://wht6.github.io/posts/69aa.html","excerpt":"","text":"字典（map）存储的不是单一值的集合，而是键值对的集合。 &nbsp; 在 Go 语言规范中，应该是为了避免歧义，他们将键值对换了一种称呼，叫做：“键 - 元素对”。&nbsp;Go 语言的字典类型其实是一个哈希表（hash table）的特定实现，在这个实现中，键和元素的最大不同在于，键的类型是受限的，而元素却可以是任意类型的。&nbsp;如果要探究限制的原因，我们就先要了解哈希表中最重要的一个过程：映射。&nbsp;你可以把键理解为元素的一个索引，我们可以在哈希表中通过键查找与它成对的那个元素。&nbsp;键和元素的这种对应关系，在数学里就被称为“映射”，这也是“map”这个词的本意，哈希表的映射过程就存在于对键 - 元素对的增、删、改、查的操作之中。&nbsp;123456789101112aMap := map[string]int&#123; &quot;one&quot;: 1, &quot;two&quot;: 2, &quot;three&quot;: 3,&#125;k := &quot;two&quot;v, ok := aMap[k]if ok &#123; fmt.Printf(&quot;The element of key %q: %d\\n&quot;, k, v)&#125; else &#123; fmt.Println(&quot;Not found!&quot;)&#125;&nbsp; 比如，我们要在哈希表中查找与某个键值对应的那个元素值，那么我们需要先把键值作为参数传给这个哈希表。 &nbsp;哈希表会先用哈希函数（hash function）把键值转换为哈希值。哈希值通常是一个无符号的整数。一个哈希表会持有一定数量的桶（bucket），我们也可以叫它哈希桶，这些哈希桶会均匀地储存其所属哈希表收纳的键 - 元素对。&nbsp;因此，哈希表会先用这个键哈希值的低几位去定位到一个哈希桶，然后再去这个哈希桶中，查找这个键。&nbsp;由于键 - 元素对总是被捆绑在一起存储的，所以一旦找到了键，就一定能找到对应的元素值。随后，哈希表就会把相应的元素值作为结果返回。&nbsp;映射过程的第一步就是：把键值转换为哈希值。&nbsp;在 Go 语言的字典中，每一个键值都是由它的哈希值代表的。也就是说，字典不会独立存储任何键的值，但会独立存储它们的哈希值。&nbsp;Go 语言字典的键类型不可以是函数类型、字典类型和切片类型。&nbsp;Go 语言规范规定，在键类型的值之间必须可以施加操作符==和!=。换句话说，键类型的值必须要支持判等操作。由于函数类型、字典类型和切片类型的值并不支持判等操作，所以字典的键类型不能是这些类型。&nbsp;另外，如果键的类型是接口类型的，那么键值的实际类型也不能是上述三种类型，否则在程序运行过程中会引发 panic（即运行时恐慌）。&nbsp;12345var badMap2 = map[interface&#123;&#125;]int&#123; &quot;1&quot;: 1, []int&#123;2&#125;: 2, // 这里会引发 panic。 3: 3,&#125;&nbsp; 这里的变量badMap2的类型是键类型为interface&#123;&#125;、值类型为int的字典类型。这样声明并不会引起什么错误。或者说，我通过这样的声明躲过了 Go 语言编译器的检查。 &nbsp;注意，我用字面量在声明该字典的同时对它进行了初始化，使它包含了三个键 - 元素对。其中第二个键 - 元素对的键值是[]int&#123;2&#125;，元素值是2。这样的键值也不会让 Go 语言编译器报错，因为从语法上说，这样做是可以的。&nbsp;但是，当我们运行这段代码的时候，Go 语言的运行时（runtime）系统就会发现这里的问题，它会抛出一个 panic，并把根源指向字面量中定义第二个键 - 元素对的那一行。我们越晚发现问题，修正问题的成本就会越高，所以最好不要把字典的键类型设定为任何接口类型。如果非要这么做，请一定确保代码在可控的范围之内。&nbsp;比如，由于类型[1][]string的元素类型是[]string，所以它就不能作为字典类型的键类型。另外，如果键的类型是结构体类型，那么还要保证其中字段的类型的合法性。无论不合法的类型被埋藏得有多深，比如map[[1][2][3][]string]int，Go 语言编译器都会把它揪出来。&nbsp;首先，每个哈希桶都会把自己包含的所有键的哈希值存起来。Go 语言会用被查找键的哈希值与这些哈希值逐个对比，看看是否有相等的。如果一个相等的都没有，那么就说明这个桶中没有要查找的键值，这时 Go 语言就会立刻返回结果了。&nbsp;如果有相等的，那就再用键值本身去对比一次。为什么还要对比？原因是，不同值的哈希值是可能相同的。这有个术语，叫做“哈希碰撞”。&nbsp;&nbsp;所以，即使哈希值一样，键值也不一定一样。如果键类型的值之间无法判断相等，那么此时这个映射的过程就没办法继续下去了。最后，只有键的哈希值和键值都相等，才能说明查找到了匹配的键 - 元素对。&nbsp;应该优先考虑哪些类型作为字典的键类型？&nbsp;这里先抛开我们使用字典时的上下文，只从性能的角度看。在前文所述的映射过程中，“把键值转换为哈希值”以及“把要查找的键值与哈希桶中的键值做对比”， 明显是两个重要且比较耗时的操作。&nbsp;因此，可以说，求哈希和判等操作的速度越快，对应的类型就越适合作为键类型。&nbsp;对于所有的基本类型、指针类型，以及数组类型、结构体类型和接口类型，Go 语言都有一套算法与之对应。这套算法中就包含了哈希和判等。以求哈希的操作为例，宽度越小的类型速度通常越快。对于布尔类型、整数类型、浮点数类型、复数类型和指针类型来说都是如此。对于字符串类型，由于它的宽度是不定的，所以要看它的值的具体长度，长度越短求哈希越快。&nbsp;类型的宽度是指它的单个值需要占用的字节数。比如，bool、int8和uint8类型的一个值需要占用的字节数都是1，因此这些类型的宽度就都是1。&nbsp;以上说的都是基本类型，再来看高级类型。对数组类型的值求哈希实际上是依次求得它的每个元素的哈希值并进行合并，所以速度就取决于它的元素类型以及它的长度。细则同上。&nbsp;与之类似，对结构体类型的值求哈希实际上就是对它的所有字段值求哈希并进行合并，所以关键在于它的各个字段的类型以及字段的数量。而对于接口类型，具体的哈希算法，则由值的实际类型决定。&nbsp;不建议你使用这些高级数据类型作为字典的键类型，不仅仅是因为对它们的值求哈希，以及判等的速度较慢，更是因为在它们的值中存在变数。&nbsp;那么，在那些基本类型中应该优先选择哪一个？答案是，优先选用数值类型和指针类型，通常情况下类型的宽度越小越好。如果非要选择字符串类型的话，最好对键值的长度进行额外的约束。&nbsp;Go 语言有时会对字典的增、删、改、查操作做一些优化。比如，在字典的键类型为字符串类型的情况下；又比如，在字典的键类型为宽度为4或8的整数类型的情况下。&nbsp;当我们仅声明而不初始化一个字典类型的变量的时候，它的值会是nil。&nbsp;除了添加键 - 元素对，我们在一个值为nil的字典上做任何操作都不会引起错误。当我们试图在一个值为nil的字典中添加键 - 元素对的时候，Go 语言的运行时系统就会立即抛出一个 panic。&nbsp;字典类型的值是并发安全的吗？&nbsp;字典类型的值不是并发安全的，即使我们只是增减其中的键值对也是如此。其根本原因是，字典值内部有时候会根据需要进行存储方面的调整。 &nbsp;&nbsp; 参考链接：https://time.geekbang.org/column/intro/112","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Go语言","slug":"Go语言","permalink":"http://wht6.github.io/tags/Go%E8%AF%AD%E8%A8%80/"}]},{"title":"container包中的容器-链表","slug":"container包中的容器-链表","date":"2022-02-26T06:00:00.000Z","updated":"2022-03-20T01:53:08.885Z","comments":true,"path":"posts/60b9.html","link":"","permalink":"http://wht6.github.io/posts/60b9.html","excerpt":"","text":"Go 语言的链表实现在标准库的container/list代码包中。这个代码包中有两个公开的程序实体——List和Element，List 实现了一个双向链表（以下简称链表），而 Element 则代表了链表中元素的结构。 &nbsp; 我们在这里用到了List的四种方法。&nbsp;MoveBefore方法和MoveAfter方法，它们分别用于把给定的元素移动到另一个元素的前面和后面。&nbsp;MoveToFront方法和MoveToBack方法，分别用于把给定的元素移动到链表的最前端和最后端。&nbsp;在这些方法中，“给定的元素”都是*Element类型的，*Element类型是Element类型的指针类型，*Element的值就是元素的指针。&nbsp;12345func (l *List) MoveBefore(e, mark *Element)func (l *List) MoveAfter(e, mark *Element) func (l *List) MoveToFront(e *Element)func (l *List) MoveToBack(e *Element)&nbsp; 具体问题是，如果我们自己生成这样的值，然后把它作为“给定的元素”传给链表的方法，那么会发生什么？链表会接受它吗？ &nbsp;答案是不会接受，这些方法将不会对链表做出任何改动。因为我们自己生成的Element值并不在链表中，所以也就谈不上“在链表中移动元素”。更何况链表不允许我们把自己生成的Element值插入其中。&nbsp;在List包含的方法中，用于插入新元素的那些方法都只接受interface&#123;&#125;类型的值。这些方法在内部会使用Element值，包装接收到的新元素。&nbsp;这样做正是为了避免直接使用我们自己生成的元素，主要原因是避免链表的内部关联，遭到外界破坏，这对于链表本身以及我们这些使用者来说都是有益的。&nbsp;List的方法还有下面这几种：&nbsp;Front和Back方法分别用于获取链表中最前端和最后端的元素，InsertBefore和InsertAfter方法分别用于在指定的元素之前和之后插入新元素，PushFront和PushBack方法则分别用于在链表的最前端和最后端插入新元素。&nbsp;12345678func (l *List) Front() *Elementfunc (l *List) Back() *Element func (l *List) InsertBefore(v interface&#123;&#125;, mark *Element) *Elementfunc (l *List) InsertAfter(v interface&#123;&#125;, mark *Element) *Element func (l *List) PushFront(v interface&#123;&#125;) *Elementfunc (l *List) PushBack(v interface&#123;&#125;) *Element&nbsp; 这些方法都会把一个Element值的指针作为结果返回，它们就是链表留给我们的安全“接口”。拿到这些内部元素的指针，我们就可以去调用前面提到的用于移动元素的方法了。 &nbsp;List和Element都是结构体类型。结构体类型有一个特点，那就是它们的零值都会是拥有特定结构，但是没有任何定制化内容的值，相当于一个空壳。值中的字段也都会被分别赋予各自类型的零值。&nbsp; 广义来讲，所谓的零值就是只做了声明，但还未做初始化的变量被给予的缺省值。每个类型的零值都会依据该类型的特性而被设定。 比如，经过语句var a [2]int声明的变量a的值，将会是一个包含了两个0的整数数组。又比如，经过语句var s []int声明的变量s的值将会是一个[]int类型的、值为nil的切片。 &nbsp; 那么经过语句var l list.List声明的变量l的值将会是什么呢？这个零值将会是一个长度为0的链表。这个链表持有的根元素也将会是一个空壳，其中只会包含缺省的内容。那这样的链表我们可以直接拿来使用吗？&nbsp; 答案是，可以的。这被称为“开箱即用”。Go 语言标准库中很多结构体类型的程序实体都做到了开箱即用。这也是在编写可供别人使用的代码包（或者说程序库）时，我们推荐遵循的最佳实践之一。那么，语句var l list.List声明的链表l可以直接使用，这是怎么做到的呢？&nbsp;关键在于它的“延迟初始化”机制。&nbsp;所谓的延迟初始化，你可以理解为把初始化操作延后，仅在实际需要的时候才进行。延迟初始化的优点在于“延后”，它可以分散初始化操作带来的计算量和存储空间消耗。&nbsp;例如，如果我们需要集中声明非常多的大容量切片的话，那么那时的 CPU 和内存空间的使用量肯定都会一个激增，并且只有设法让其中的切片及其底层数组被回收，内存使用量才会有所降低。&nbsp;如果数组是可以被延迟初始化的，那么计算量和存储空间的压力就可以被分散到实际使用它们的时候。这些数组被实际使用的时间越分散，延迟初始化带来的优势就会越明显。&nbsp; 实际上，Go 语言的切片就起到了延迟初始化其底层数组的作用。 延迟初始化的缺点恰恰也在于“延后”。你可以想象一下，如果我在调用链表的每个方法的时候，它们都需要先去判断链表是否已经被初始化，那这也会是一个计算量上的浪费。在这些方法被非常频繁地调用的情况下，这种浪费的影响就开始显现了，程序的性能将会降低。 &nbsp;又比如，在用于删除元素、移动元素，以及一些用于插入元素的方法中，只要判断一下传入的元素中指向所属链表的指针，是否与当前链表的指针相等就可以了。 &nbsp;如果不相等，就一定说明传入的元素不是这个链表中的，后续的操作就不用做了。反之，就一定说明这个链表已经被初始化了。&nbsp;原因在于，链表的PushFront方法、PushBack方法、PushBackList方法以及PushFrontList方法总会先判断链表的状态，并在必要时进行初始化，这就是延迟初始化。&nbsp;而且，我们在向一个空的链表中添加新元素的时候，肯定会调用这四个方法中的一个，这时新元素中指向所属链表的指针，一定会被设定为当前链表的指针。所以，指针相等是链表已经初始化的充分必要条件。&nbsp;明白了吗？List利用了自身以及Element在结构上的特点，巧妙地平衡了延迟初始化的优缺点，使得链表可以开箱即用，并且在性能上可以达到最优。&nbsp;补充：List这个结构体类型有两个字段，一个是Element类型的字段root，另一个是int类型的字段len。顾名思义，前者代表的就是那个根元素，而后者用于存储链表的长度。注意，它们都是包级私有的，也就是说使用者无法查看和修改它们。&nbsp;像前面那样声明的l，其字段root和len都会被赋予相应的零值。len的零值是0，正好可以表明该链表还未包含任何元素。由于root是Element类型的，所以它的零值就是该类型的空壳，用字面量表示的话就是Element&#123;&#125;。&nbsp;Element类型包含了几个包级私有的字段，分别用于存储前一个元素、后一个元素以及所属链表的指针值。另外还有一个名叫Value的公开的字段，该字段的作用就是持有元素的实际值，它是interface&#123;&#125;类型的。在Element类型的零值中，这些字段的值都会是nil。&nbsp; 循环链表&nbsp;container/ring包中的Ring类型实现的是一个循环链表，也就是我们俗称的环。其实List在内部就是一个循环链表。它的根元素永远不会持有任何实际的元素值，而该元素的存在就是为了连接这个循环链表的首尾两端。&nbsp;所以也可以说，List的零值是一个只包含了根元素，但不包含任何实际元素值的空链表。那么，既然Ring和List在本质上都是循环链表，那它们到底有什么不同呢？&nbsp;最主要的不同有下面几种。&nbsp; Ring类型的数据结构仅由它自身即可代表，而List类型则需要由它以及Element类型联合表示。这是表示方式上的不同，也是结构复杂度上的不同。 一个Ring类型的值严格来讲，只代表了其所属的循环链表中的一个元素，而一个List类型的值则代表了一个完整的链表。这是表示维度上的不同。 在创建并初始化一个Ring值的时候，我们可以指定它包含的元素的数量，但是对于一个List值来说却不能这样做（也没有必要这样做）。循环链表一旦被创建，其长度是不可变的。这是两个代码包中的New函数在功能上的不同，也是两个类型在初始化值方面的第一个不同。 仅通过var r ring.Ring语句声明的r将会是一个长度为1的循环链表，而List类型的零值则是一个长度为0的链表。别忘了List中的根元素不会持有实际元素值，因此计算长度时不会包含它。这是两个类型在初始化值方面的第二个不同。 Ring值的Len方法的算法复杂度是 O(N) 的，而List值的Len方法的算法复杂度则是 O(1) 的。这是两者在性能方面最显而易见的差别。 &nbsp;其他的不同基本上都是方法方面的了。比如，循环链表也有用于插入、移动或删除元素的方法，不过用起来都显得更抽象一些，等等。 &nbsp; 切片、数组和链表的比较&nbsp;切片本身有着占用内存少和创建便捷等特点，但它的本质上还是数组。切片的一大好处是可以让我们通过窗口快速地定位并获取，或者修改底层数组中的元素。&nbsp;不过，当我们想删除切片中的元素的时候就没那么简单了。元素复制一般是免不了的，就算只删除一个元素，有时也会造成大量元素的移动。这时还要注意空出的元素槽位的“清空”，否则很可能会造成内存泄漏。&nbsp;另一方面，在切片被频繁“扩容”的情况下，新的底层数组会不断产生，这时内存分配的量以及元素复制的次数可能就很可观了，这肯定会对程序的性能产生负面的影响。&nbsp;尤其是当我们没有一个合理、有效的”缩容“策略的时候，旧的底层数组无法被回收，新的底层数组中也会有大量无用的元素槽位。过度的内存浪费不但会降低程序的性能，还可能会使内存溢出并导致程序崩溃。&nbsp;由此可见，正确地使用切片是多么的重要。不过，一个更重要的事实是，任何数据结构都不是银弹。不是吗？数组的自身特点和适用场景都非常鲜明，切片也是一样。它们都是 Go 语言原生的数据结构，使用起来也都很方便. 不过，你的集合类工具箱中不应该只有它们。这就是我们使用链表的原因。&nbsp;不过，对比来看，一个链表所占用的内存空间，往往要比包含相同元素的数组所占内存大得多。这是由于链表的元素并不是连续存储的，所以相邻的元素之间需要互相保存对方的指针。不但如此，每个元素还要存有它所属链表的指针。&nbsp;有了这些关联，链表的结构反倒更简单了。它只持有头部元素（或称为根元素）基本上就可以了。当然了，为了防止不必要的遍历和计算，链表的长度记录在内也是必须的。&nbsp;&nbsp; 参考链接：https://time.geekbang.org/column/intro/112","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Go语言","slug":"Go语言","permalink":"http://wht6.github.io/tags/Go%E8%AF%AD%E8%A8%80/"}]},{"title":"Golang的数组和切片","slug":"Golang的数组和切片","date":"2022-02-25T09:00:00.000Z","updated":"2022-03-20T01:52:54.103Z","comments":true,"path":"posts/4dc9.html","link":"","permalink":"http://wht6.github.io/posts/4dc9.html","excerpt":"","text":"数组（array）和切片（slice）的共同点是都属于集合类的类型，并且，它们的值也都可以用来存储某一种类型的值（或者说元素）。&nbsp;不过，它们最重要的不同是：数组类型的值的长度是固定的，而切片类型的值是可变长的。&nbsp;数组的长度在声明它的时候就必须给定，并且之后不会再改变。可以说，数组的长度是其类型的一部分。比如，[1]string和[2]string就是两个不同的数组类型。&nbsp;而切片的类型字面量中只有元素的类型，而没有长度。切片的长度可以自动地随着其中元素数量的增长而增长，但不会随着元素数量的减少而减小。&nbsp;&nbsp;我们其实可以把切片看做是对数组的一层简单的封装，因为在每个切片的底层数据结构中，一定会包含一个数组。数组可以被叫做切片的底层数组，而切片也可以被看作是对数组的某个连续片段的引用。&nbsp; 也正因为如此，Go 语言的切片类型属于引用类型，同属引用类型的还有字典类型、通道类型、函数类型等；而 Go 语言的数组类型则属于值类型，同属值类型的有基础数据类型以及结构体类型。 注意，Go 语言里不存在像 Java 等编程语言中令人困惑的“传值或传引用”问题。在 Go 语言中，我们判断所谓的“传值”或者“传引用”只要看被传递的值的类型就好了。如果传递的值是引用类型的，那么就是“传引用”。如果传递的值是值类型的，那么就是“传值”。从传递成本的角度讲，引用类型的值往往要比值类型的值低很多。 我们在数组和切片之上都可以应用索引表达式，得到的都会是某个元素。我们在它们之上也都可以应用切片表达式，也都会得到一个新的切片。 &nbsp;我们通过调用内建函数len，得到数组和切片的长度。通过调用内建函数cap，我们可以得到它们的容量。&nbsp;但要注意，数组的容量永远等于其长度，都是不可变的。切片的容量却不是这样，并且它的变化是有规律可寻的。&nbsp; 估算切片的长度和容量&nbsp;123456789101112131415package main import &quot;fmt&quot; func main() &#123; // 示例 1。 s1 := make([]int, 5) fmt.Printf(&quot;The length of s1: %d\\n&quot;, len(s1)) fmt.Printf(&quot;The capacity of s1: %d\\n&quot;, cap(s1)) fmt.Printf(&quot;The value of s1: %d\\n&quot;, s1) s2 := make([]int, 5, 8) fmt.Printf(&quot;The length of s2: %d\\n&quot;, len(s2)) fmt.Printf(&quot;The capacity of s2: %d\\n&quot;, cap(s2)) fmt.Printf(&quot;The value of s2: %d\\n&quot;, s2)&#125;&nbsp; 首先，我用内建函数make声明了一个[]int类型的变量s1。我传给make函数的第二个参数是5，从而指明了该切片的长度。我用几乎同样的方式声明了切片s2，只不过多传入了一个参数8以指明该切片的容量。 &nbsp;切片s1和s2的容量分别是5和8。当我们用make函数初始化切片时，如果不指明其容量，那么它就会和长度一致。如果在初始化时指明了容量，那么切片的实际容量也就是它了。&nbsp;可以把切片看做是对数组的一层简单的封装，因为在每个切片的底层数据结构中，一定会包含一个数组。数组可以被叫做切片的底层数组，而切片也可以被看作是对数组的某个连续片段的引用。切片的容量实际上代表了它的底层数组的长度。&nbsp;有一个窗口，你可以通过这个窗口看到一个数组，但是不一定能看到该数组中的所有元素，有时候只能看到连续的一部分元素。&nbsp;现在，这个数组就是切片s2的底层数组，而这个窗口就是切片s2本身。s2的长度实际上指明的就是这个窗口的宽度，决定了你透过s2，可以看到其底层数组中的哪几个连续的元素。&nbsp;由于s2的长度是5，所以你可以看到底层数组中的第 1 个元素到第 5 个元素，对应的底层数组的索引范围是 [0, 4]。s2中的索引从0到4所指向的元素恰恰就是其底层数组中索引从0到4代表的那 5 个元素。&nbsp;请记住，当我们用make函数或切片值字面量（比如[]int&#123;1, 2, 3&#125;）初始化一个切片时，该窗口最左边的那个小格子总是会对应其底层数组中的第 1 个元素。&nbsp;但是当我们通过切片表达式基于某个数组或切片生成新切片的时候，情况就变得复杂起来了。&nbsp;12345s3 := []int&#123;1, 2, 3, 4, 5, 6, 7, 8&#125;s4 := s3[3:6]fmt.Printf(&quot;The length of s4: %d\\n&quot;, len(s4))fmt.Printf(&quot;The capacity of s4: %d\\n&quot;, cap(s4))fmt.Printf(&quot;The value of s4: %d\\n&quot;, s4)&nbsp; 切片s3中有 8 个元素，分别是从1到8的整数。s3的长度和容量都是8。然后，我用切片表达式s3[3:6]初始化了切片s4。问题是，这个s4的长度和容量分别是多少？ &nbsp;这并不难，用减法就可以搞定。首先你要知道，切片表达式中的方括号里的那两个整数都代表什么。我换一种表达方式你也许就清楚了，即：[3, 6)。&nbsp;这是数学中的区间表示法，常用于表示取值范围，我其实已经在本专栏用过好几次了。由此可知，[3:6]要表达的就是透过新窗口能看到的s3中元素的索引范围是从3到5（注意，不包括6）。&nbsp;这里的3可被称为起始索引，6可被称为结束索引。那么s4的长度就是6减去3，即3。因此可以说，s4中的索引从0到2指向的元素对应的是s3及其底层数组中索引从3到5的那 3 个元素。&nbsp;&nbsp;在前面说过，切片的容量代表了它的底层数组的长度，但这仅限于使用make函数或者切片值字面量初始化切片的情况。&nbsp;更通用的规则是：一个切片的容量可以被看作是透过这个窗口最多可以看到的底层数组中元素的个数。&nbsp;由于s4是通过在s3上施加切片操作得来的，所以s3的底层数组就是s4的底层数组。&nbsp;又因为，在底层数组不变的情况下，切片代表的窗口可以向右扩展，直至其底层数组的末尾。&nbsp;所以，s4的容量就是其底层数组的长度8, 减去上述切片表达式中的那个起始索引3，即5。&nbsp;注意，切片代表的窗口是无法向左扩展的。也就是说，我们永远无法透过s4看到s3中最左边的那 3 个元素。&nbsp;最后，顺便提一下把切片的窗口向右扩展到最大的方法。对于s4来说，切片表达式s4[0:cap(s4)]就可以做到。该表达式的结果值（即一个新的切片）会是[]int&#123;4, 5, 6, 7, 8&#125;，其长度和容量都是5。&nbsp;估算切片容量的增长&nbsp;一旦一个切片无法容纳更多的元素，Go 语言就会想办法扩容。但它并不会改变原来的切片，而是会生成一个容量更大的切片，然后将把原有的元素和新元素一并拷贝到新切片中。在一般的情况下，你可以简单地认为新切片的容量（以下简称新容量）将会是原切片容量（以下简称原容量）的 2 倍。&nbsp;但是，当原切片的长度（以下简称原长度）大于或等于1024时，Go 语言将会以原容量的1.25倍作为新容量的基准（以下新容量基准）。新容量基准会被调整（不断地与1.25相乘），直到结果不小于原长度与要追加的元素数量之和（以下简称新长度）。最终，新容量往往会比新长度大一些，当然，相等也是可能的。&nbsp;另外，如果我们一次追加的元素过多，以至于使新长度比原容量的 2 倍还要大，那么新容量就会以新长度为基准。注意，与前面那种情况一样，最终的新容量在很多时候都要比新容量基准更大一些。&nbsp;切片的底层数组什么时候会被替换？&nbsp;确切地说，一个切片的底层数组永远不会被替换。为什么？虽然在扩容的时候 Go 语言一定会生成新的底层数组，但是它也同时生成了新的切片。&nbsp;它只是把新的切片作为了新底层数组的窗口，而没有对原切片，及其底层数组做任何改动。&nbsp;请记住，在无需扩容时，append函数返回的是指向原底层数组的新切片，而在需要扩容时，append函数返回的是指向新底层数组的新切片。所以，严格来讲，“扩容”这个词用在这里虽然形象但并不合适。不过鉴于这种称呼已经用得很广泛了，我们也没必要另找新词了。&nbsp;只要新长度不会超过切片的原容量，那么使用append函数对其追加元素的时候就不会引起扩容。这只会使紧邻切片窗口右边的（底层数组中的）元素被新的元素替换掉。&nbsp;&nbsp; 参考链接：https://time.geekbang.org/column/intro/112","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Go语言","slug":"Go语言","permalink":"http://wht6.github.io/tags/Go%E8%AF%AD%E8%A8%80/"}]},{"title":"Go的程序实体","slug":"Go的程序实体","date":"2022-02-24T02:00:00.000Z","updated":"2022-03-20T01:55:26.755Z","comments":true,"path":"posts/aea9.html","link":"","permalink":"http://wht6.github.io/posts/aea9.html","excerpt":"","text":"Go 语言中的程序实体包括变量、常量、函数、结构体和接口。 Go 语言是静态类型的编程语言，所以我们在声明变量或常量的时候，都需要指定它们的类型，或者给予足够的信息，这样才可以让 Go 语言能够推导出它们的类型。&nbsp;在 Go 语言中，变量的类型可以是其预定义的那些类型，也可以是程序自定义的函数、结构体或接口。常量的合法类型不多，只能是那些 Go 语言预定义的基本类型。它的声明方式也更简单一些。&nbsp; 01|变量&nbsp; 声明变量的方式&nbsp;方式一：&nbsp;12345678910111213package main import ( &quot;flag&quot; &quot;fmt&quot;) func main() &#123; var name string // [1] flag.StringVar(&amp;name, &quot;name&quot;, &quot;everyone&quot;, &quot;The greeting object.&quot;) // [2] flag.Parse() fmt.Printf(&quot;Hello, %v!\\n&quot;, name)&#125;&nbsp;方式二：[1]和[2]处代码合并:&nbsp;1var name = flag.String(&quot;name&quot;, &quot;everyone&quot;, &quot;The greeting object.&quot;)&nbsp; 注意，flag.String函数返回的结果值的类型是*string而不是string。类型*string代表的是字符串的指针类型，而不是字符串类型。因此，这里的变量name代表的是一个指向字符串值的指针。 &nbsp; 我们可以通过操作符*把这个指针指向的字符串值取出来了。因此，在这种情况下，那个被用来打印内容的函数调用就需要微调一下，把其中的参数name改为*name，即：fmt.Printf(&quot;Hello, %v!\\n&quot;, *name)。 &nbsp; 方式三： &nbsp;1name := flag.String(&quot;name&quot;, &quot;everyone&quot;, &quot;The greeting object.&quot;)&nbsp; Go的类型推断&nbsp;第二种方式在声明变量name的同时，还为它赋了值，而这时声明中并没有显式指定name的类型。之前的变量声明语句是var name string。这里利用了 Go 语言自身的类型推断，而省去了对该变量的类型的声明。&nbsp;类型推断是一种编程语言在编译期自动解释表达式类型的能力。表达式类型就是对表达式进行求值后得到结果的类型。&nbsp;第三种类型推断的方式是短变量声明。我们只能在函数体内部使用短变量声明来代替var声明。在编写if、for或switch语句的时候，我们经常把它安插在初始化子句中，并用来声明一些临时的变量。而相比之下，第二种方式更加通用，它可以被用在任何地方。&nbsp;&nbsp;类型推断的一个好处是方便进行代码重构：&nbsp;12345678910111213141516package main import ( &quot;flag&quot; &quot;fmt&quot;) func main() &#123; var name = getTheFlag() flag.Parse() fmt.Printf(&quot;Hello, %v!\\n&quot;, *name)&#125; func getTheFlag() *string &#123; return flag.String(&quot;name&quot;, &quot;everyone&quot;, &quot;The greeting object.&quot;)&#125;&nbsp;我们可以用getTheFlag函数包裹（或者说包装）那个对flag.String函数的调用，并把其结果直接作为getTheFlag函数的结果，结果的类型是*string。 &nbsp; 这样一来，var name =右边的表达式，可以变为针对getTheFlag函数的调用表达式了。这实际上是对“声明并赋值name变量的那行代码”的重构。 &nbsp; 我们通常把不改变某个程序与外界的任何交互方式和规则，而只改变其内部实现”的代码修改方式，叫做对该程序的重构。重构的对象可以是一行代码、一个函数、一个功能模块，甚至一个软件系统。 &nbsp;我们不显式地指定变量name的类型，使得它可以被赋予任何类型的值。也就是说，变量name的类型可以在其初始化时，由其他程序动态地确定。&nbsp;在你改变getTheFlag函数的结果类型之后，Go 语言的编译器会在你再次构建该程序的时候，自动地更新变量name的类型。如果你使用过Python或Ruby这种动态类型的编程语言的话，一定会觉得这情景似曾相识。&nbsp;没错，通过这种类型推断，你可以体验到动态类型编程语言所带来的一部分优势，即程序灵活性的明显提升。但在那些编程语言中，这种提升可以说是用程序的可维护性和运行效率换来的。&nbsp;Go 语言是静态类型的，所以一旦在初始化变量时确定了它的类型，之后就不可能再改变。这就避免了在后面维护程序时的一些问题。另外，请记住，这种类型的确定是在编译期完成的，因此不会对程序的运行效率产生任何影响。&nbsp;Go 语言的类型推断可以明显提升程序的灵活性，使得代码重构变得更加容易，同时又不会给代码的维护带来额外负担（实际上，它恰恰可以避免散弹式的代码修改），更不会损失程序的运行效率。&nbsp;Go 语言的类型推断只应用在了对变量或常量的初始化方面。&nbsp; 变量的重声明&nbsp;这涉及了短变量声明。通过使用它，我们可以对同一个代码块中的变量进行重声明。&nbsp; 在 Go 语言中，代码块一般就是一个由花括号括起来的区域，里面可以包含表达式和语句。Go 语言本身以及我们编写的代码共同形成了一个非常大的代码块，也叫全域代码块。 这主要体现在，只要是公开的全局变量，都可以被任何代码所使用。相对小一些的代码块是代码包，一个代码包可以包含许多子代码包，所以这样的代码块也可以很大。 接下来，每个源码文件也都是一个代码块，每个函数也是一个代码块，每个if语句、for语句、switch语句和select语句都是一个代码块。甚至，switch或select语句中的case子句也都是独立的代码块。 走个极端，我就在main函数中写一对紧挨着的花括号算不算一个代码块？当然也算，这甚至还有个名词，叫“空代码块”。 &nbsp;变量重声明的含义是对已经声明过的变量再次声明。变量重声明的前提条件如下。&nbsp; 由于变量的类型在其初始化时就已经确定了，所以对它再次声明时赋予的类型必须与其原本的类型相同，否则会产生编译错误。 变量的重声明只可能发生在某一个代码块中。如果与当前的变量重名的是外层代码块中的变量，那么就是另外一种含义了，我在下一篇文章中会讲到。 变量的重声明只有在使用短变量声明时才会发生，否则也无法通过编译。如果要在此处声明全新的变量，那么就应该使用包含关键字var的声明语句，但是这时就不能与同一个代码块中的任何变量有重名了。 被“声明并赋值”的变量必须是多个，并且其中至少有一个是新的变量。这时我们才可以说对其中的旧变量进行了重声明。&nbsp;变量重声明其实算是一个语法糖（或者叫便利措施）。它允许我们在使用短变量声明时不用理会被赋值的多个变量中是否包含旧变量。&nbsp;12var err errorn, err := io.WriteString(os.Stdout, &quot;Hello, everyone!\\n&quot;) &nbsp;我使用短变量声明对新变量n和旧变量err进行了“声明并赋值”，这时也是对后者的重声明。&nbsp;02|变量的作用域&nbsp;一个代码块可以有若干个子代码块；但对于每个代码块，最多只会有一个直接包含它的代码块（后者可以简称为前者的外层代码块）。这种代码块的划分，也间接地决定了程序实体的作用域。&nbsp;一个程序实体被创造出来，是为了让别的代码引用的。那么，哪里的代码可以引用它呢，这就涉及了它的作用域。&nbsp;程序实体的访问权限有三种：包级私有的、模块级私有的和公开的。这其实就是 Go 语言在语言层面，依据代码块对程序实体作用域进行的定义。&nbsp;一个程序实体的作用域总是会被限制在某个代码块中，而这个作用域最大的用处，就是对程序实体的访问权限的控制。对“高内聚，低耦合”这种程序设计思想的实践，恰恰可以从这里开始。&nbsp;1234567891011121314package main import &quot;fmt&quot; var block = &quot;package&quot; func main() &#123; block := &quot;function&quot; &#123; block := &quot;inner&quot; fmt.Printf(&quot;The block is %s.\\n&quot;, block) &#125; fmt.Printf(&quot;The block is %s.\\n&quot;, block)&#125; &nbsp;这个命令源码文件中有四个代码块，它们是：全域代码块、main包代表的代码块、main函数代表的代码块，以及在main函数中的一个用花括号包起来的代码块。&nbsp;运行后打印出的内容是：&nbsp;12The block is inner.The block is function. &nbsp;你可能会认为它无法通过编译，因为三处代码都声明了相同名称的变量。的确，声明重名的变量是无法通过编译的，用短变量声明对已有变量进行重声明除外，但这只是对于同一个代码块而言的。&nbsp;对于不同的代码块来说，其中的变量重名没什么大不了，照样可以通过编译。即使这些代码块有直接的嵌套关系也是如此，就像 demo10.go 中的main包代码块、main函数代码块和那个最内层的代码块那样。&nbsp;这样规定显然很方便也很合理，否则我们会每天为了选择变量名而烦恼。但是这会导致另外一个问题，我引用变量时到底用的是哪一个？&nbsp;这其实有一个很有画面感的查找过程。这个查找过程不只针对于变量，还适用于任何程序实体。如下面所示。&nbsp; 首先，代码引用变量的时候总会最优先查找当前代码块中的那个变量。注意，这里的“当前代码块”仅仅是引用变量的代码所在的那个代码块，并不包含任何子代码块。 其次，如果当前代码块中没有声明以此为名的变量，那么程序会沿着代码块的嵌套关系，从直接包含当前代码块的那个代码块开始，一层一层地查找。 一般情况下，程序会一直查到当前代码包代表的代码块。如果仍然找不到，那么 Go 语言的编译器就会报错了。 &nbsp;如果我们在当前源码文件中导入了其他代码包，那么引用其中的程序实体时，是需要以限定符为前缀的。所以程序在找代表变量未加限定符的名字（即标识符）的时候，是不会去被导入的代码包中查找的。&nbsp; 但有个特殊情况，如果我们把代码包导入语句写成import . XXX的形式（注意中间的那个“.”），那么就会让这个“XXX”包中公开的程序实体，被当前源码文件中的代码，视为当前代码包中的程序实体。 比如，如果有代码包导入语句import . fmt，那么我们在当前源码文件中引用fmt.Printf函数的时候直接用Printf就可以了。在这个特殊情况下，程序在查找当前源码文件后会先去查用这种方式导入的那些代码包。 &nbsp;不同代码块中的重名变量与变量重声明中的变量区别：&nbsp;(为了方便描述，就把不同代码块中的重名变量叫做“可重名变量”吧。注意，在同一个代码块中不允许出现重名的变量，这违背了 Go 语言的语法。)&nbsp; 变量重声明中的变量一定是在某一个代码块内的。注意，这里的“某一个代码块内”并不包含它的任何子代码块，否则就变成了“多个代码块之间”。而可重名变量指的正是在多个代码块之间由相同的标识符代表的变量。 变量重声明是对同一个变量的多次声明，这里的变量只有一个。而可重名变量中涉及的变量肯定是有多个的。 不论对变量重声明多少次，其类型必须始终一致，具体遵从它第一次被声明时给定的类型。而可重名变量之间不存在类似的限制，它们的类型可以是任意的。 如果可重名变量所在的代码块之间，存在直接或间接的嵌套关系，那么它们之间一定会存在“屏蔽”的现象。但是这种现象绝对不会在变量重声明的场景下出现。 &nbsp;&nbsp;下面看一种特殊情况：&nbsp;12345678910package main import &quot;fmt&quot; var container = []string&#123;&quot;zero&quot;, &quot;one&quot;, &quot;two&quot;&#125; func main() &#123; container := map[int]string&#123;0: &quot;zero&quot;, 1: &quot;one&quot;, 2: &quot;two&quot;&#125; fmt.Printf(&quot;The element is %q.\\n&quot;, container[1])&#125; &nbsp; 这里有两个都叫做container的变量，分别位于main包代码块和main函数代码块。main包代码块中的变量是切片（slice）类型的，另一个是字典（map）类型的。在main函数的最后，我试图打印出container变量的值中索引为1的那个元素。&nbsp;如果你熟悉这两个类型肯定会知道，在它们的值上我们都可以施加索引表达式，比如container[0]。只要中括号里的整数在有效范围之内（这里是 [0, 2]），它就可以把值中的某一个元素取出来。&nbsp;如果container的类型不是数组、切片或字典类型，那么索引表达式就会引发编译错误。这正是利用 Go 语言语法，帮我们约束程序的一个例子；但是当我们想知道 container 确切类型的时候，利用索引表达式的方式就不够了。&nbsp;当可重名变量的值被转换成某个接口类型值，或者它们的类型本身就是接口类型的时候，严格的类型检查就很有必要了。&nbsp; 03|变量的类型&nbsp; 类型断言&nbsp;接着上一段代码，怎么判断变量container的类型？&nbsp;答案是使用“类型断言”表达式。&nbsp;1value, ok := interface&#123;&#125;(container).([]string)&nbsp;在赋值符号的右边，是一个类型断言表达式。 &nbsp;它包括了用来把container变量的值转换为空接口值的interface&#123;&#125;(container)。以及一个用于判断前者的类型是否为切片类型 []string 的 .([]string)。&nbsp;这个表达式的结果可以被赋给两个变量，在这里由value和ok代表。变量ok是布尔（bool）类型的，它将代表类型判断的结果，true或false。如果是true，那么被判断的值将会被自动转换为[]string类型的值，并赋给变量value，否则value将被赋予nil（即“空”）。&nbsp;顺便提一下，这里的ok也可以没有。也就是说，类型断言表达式的结果，可以只被赋给一个变量，在这里是value。&nbsp;但是这样的话，当判断为否时就会引发异常。这种异常在 Go 语言中被叫做panic，我把它翻译为运行时恐慌。因为它是一种在 Go 程序运行期间才会被抛出的异常，而“恐慌”二字是英文 Panic 的中文直译。除非显式地“恢复”这种“恐慌”，否则它会使 Go 程序崩溃并停止。所以，在一般情况下，我们还是应该使用带ok变量的写法。&nbsp;类型断言表达式的语法形式是x.(T)。其中的x代表要被判断类型的值。这个值当下的类型必须是接口类型的，不过具体是哪个接口类型其实是无所谓的。所以，当这里的container变量类型不是任何的接口类型时，我们就需要先把它转成某个接口类型的值。&nbsp;如果container是某个接口类型的，那么这个类型断言表达式就可以是container.([]string)。这样看是不是清晰一些了？&nbsp;在 Go 语言中，interface&#123;&#125;代表空接口，任何类型都是它的实现类型。任何类型的值都可以很方便地被转换成空接口的值就行了。&nbsp;这里的具体语法是interface&#123;&#125;(x)，例如前面展示的interface&#123;&#125;(container)。&nbsp;你可能会对这里的&#123;&#125;产生疑惑，为什么在关键字interface的右边还要加上这个东西？&nbsp;请记住，一对不包裹任何东西的花括号，除了可以代表空的代码块之外，还可以用于表示不包含任何内容的数据结构（或者说数据类型）。&nbsp;比如你今后肯定会遇到的struct&#123;&#125;，它就代表了不包含任何字段和方法的、空的结构体类型。&nbsp;而空接口interface&#123;&#125;则代表了不包含任何方法定义的、空的接口类型。&nbsp;当然了，对于一些集合类的数据类型来说，&#123;&#125;还可以用来表示其值不包含任何元素，比如空的切片值[]string&#123;&#125;，以及空的字典值map[int]string&#123;&#125;。&nbsp;&nbsp;我们再向答案的最右边看。圆括号中[]string是一个类型字面量。所谓类型字面量，就是用来表示数据类型本身的若干个字符。&nbsp;比如，string是表示字符串类型的字面量，uint8是表示 8 位无符号整数类型的字面量。&nbsp;再复杂一些的就是我们刚才提到的[]string，用来表示元素类型为string的切片类型，以及map[int]string，用来表示键类型为int、值类型为string的字典类型。还有更复杂的结构体类型字面量、接口类型字面量，等等。&nbsp; 类型转换&nbsp;类型转换的语法形式是T(x)。其中的x可以是一个变量，也可以是一个代表值的字面量（比如1.23和struct&#123;&#125;），还可以是一个表达式。&nbsp;注意，如果是表达式，那么该表达式的结果只能是一个值，而不能是多个值。在这个上下文中，x可以被叫做源值，它的类型就是源类型，而那个T代表的类型就是目标类型。&nbsp;对于整数类型值、整数常量之间的类型转换，原则上只要源值在目标类型的可表示范围内就是合法的。&nbsp;比如，之所以uint8(255)可以把无类型的常量255转换为uint8类型的值，是因为255在 [0, 255] 的范围内。&nbsp;但需要特别注意的是，源整数类型的可表示范围较大，而目标类型的可表示范围较小的情况，比如把值的类型从int16转换为int8。请看下面这段代码：&nbsp;12var srcInt = int16(-255)dstInt := int8(srcInt)&nbsp;变量srcInt的值是int16类型的-255，而变量dstInt的值是由前者转换而来的，类型是int8。int16类型的可表示范围可比int8类型大了不少。问题是，dstInt的值是多少？ &nbsp;首先你要知道，整数在 Go 语言以及计算机中都是以补码的形式存储的。这主要是为了简化计算机对整数的运算过程。补码其实就是原码各位求反再加 1。&nbsp;比如，int16类型的值-255的补码是1111111100000001。如果我们把该值转换为int8类型的值，那么 Go 语言会把在较高位置（或者说最左边位置）上的 8 位二进制数直接截掉，从而得到00000001。&nbsp;又由于其最左边一位是0，表示它是个正整数，以及正整数的补码就等于其原码，所以dstInt的值就是1。&nbsp;一定要记住，当整数值的类型的有效范围由宽变窄时，只需在补码形式下截掉一定数量的高位二进制数即可。&nbsp;类似的快刀斩乱麻规则还有：当把一个浮点数类型的值转换为整数类型值时，前者的小数部分会被全部截掉。&nbsp;虽然直接把一个整数值转换为一个string类型的值是可行的，但值得关注的是，被转换的整数值应该可以代表一个有效的 Unicode 代码点，否则转换的结果将会是&quot;�&quot;（仅由高亮的问号组成的字符串值）。&nbsp;字符&#39;�&#39;的 Unicode 代码点是U+FFFD。它是 Unicode 标准中定义的 Replacement Character，专用于替换那些未知的、不被认可的以及无法展示的字符。&nbsp;1string(-1)&nbsp;由于-1肯定无法代表一个有效的 Unicode 代码点，所以得到的总会是&quot;�&quot;。在实际工作中，我们在排查问题时可能会遇到�，你需要知道这可能是由于什么引起的。 &nbsp;string类型与各种切片类型之间的互转的。&nbsp;一个值在从string类型向[]byte类型转换时代表着以 UTF-8 编码的字符串会被拆分成零散、独立的字节。&nbsp;除了与 ASCII 编码兼容的那部分字符集，以 UTF-8 编码的某个单一字节是无法代表一个字符的。&nbsp;1string([]byte&#123;&#x27;\\xe4&#x27;, &#x27;\\xbd&#x27;, &#x27;\\xa0&#x27;, &#x27;\\xe5&#x27;, &#x27;\\xa5&#x27;, &#x27;\\xbd&#x27;&#125;) // 你好&nbsp;比如，UTF-8 编码的三个字节\\xe4、\\xbd和\\xa0合在一起才能代表字符&#39;你&#39;，而\\xe5、\\xa5和\\xbd合在一起才能代表字符&#39;好&#39;。 &nbsp;其次，一个值在从string类型向[]rune类型转换时代表着字符串会被拆分成一个个 Unicode 字符。&nbsp;1string([]rune&#123;&#x27;\\u4F60&#x27;, &#x27;\\u597D&#x27;&#125;) // 你好&nbsp; 别名类型和潜在类型&nbsp;1type MyString = string&nbsp;这条声明语句表示，MyString是string类型的别名类型。顾名思义，别名类型与其源类型的区别恐怕只是在名称上，它们是完全相同的。源类型与别名类型是一对概念，是两个对立的称呼。别名类型主要是为了代码重构而存在的。 &nbsp;Go 语言内建的基本类型中就存在两个别名类型。byte是uint8的别名类型，而rune是int32的别名类型。&nbsp;一定要注意，如果我这样声明：&nbsp;1type MyString2 string // 注意，这里没有等号。&nbsp;MyString2和string就是两个不同的类型了。这里的MyString2是一个新的类型，不同于其他任何类型。这种方式也可以被叫做对类型的再定义。我们刚刚把string类型再定义成了另外一个类型MyString2。 &nbsp;&nbsp;对于这里的类型再定义来说，string可以被称为MyString2的潜在类型。潜在类型的含义是，某个类型在本质上是哪个类型。&nbsp;潜在类型相同的不同类型的值之间是可以进行类型转换的。因此，MyString2类型的值与string类型的值可以使用类型转换表达式进行互转。&nbsp;但对于集合类的类型[]MyString2与[]string来说这样做却是不合法的，因为[]MyString2与[]string的潜在类型不同，分别是[]MyString2和[]string。另外，即使两个不同类型的潜在类型相同，它们的值之间也不能进行判等或比较，它们的变量之间也不能赋值。&nbsp;如果通过import . XXX这种方式导入的代码包中的变量与当前代码包中的变量重名了，那么 Go 语言是会把它们当做“可重名变量”看待还是会报错呢？&nbsp;这两个变量会成为“可重名变量”。虽然这两个变量在这种情况下的作用域都是当前代码包的当前文件，但是它们所处的代码块是不同的。&nbsp;当前文件中的变量处在该文件所代表的代码块中，而被导入的代码包中的变量却处在声明它的那个文件所代表的代码块中。当然，我们也可以说被导入的代码包所代表的代码块包含了这个变量。&nbsp;在当前文件中，本地的变量会“屏蔽”掉被导入的变量。 &nbsp;&nbsp; 参考链接：https://time.geekbang.org/column/intro/112","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Go语言","slug":"Go语言","permalink":"http://wht6.github.io/tags/Go%E8%AF%AD%E8%A8%80/"}]},{"title":"Go语言基础知识","slug":"Go语言基础知识","date":"2022-02-21T00:00:00.000Z","updated":"2022-03-20T01:55:06.470Z","comments":true,"path":"posts/1094.html","link":"","permalink":"http://wht6.github.io/posts/1094.html","excerpt":"","text":"01|工作区与GOPATH&nbsp; 安装GO语言环境后存在三个环境变量： &nbsp; GOROOT：Go 语言安装根目录的路径，也就是 GO 语言的安装路径。 GOPATH：若干工作区目录的路径。是我们自己定义的工作空间。 GOBIN：GO 程序生成的可执行文件（executable file）的路径。 &nbsp; 你可以把 GOPATH 简单理解成 Go 语言的工作目录，它的值是一个目录的路径，也可以是多个目录路径，每个目录都代表 Go 语言的一个工作区（workspace）。 &nbsp; 我们需要利于这些工作区，去放置 Go 语言的源码文件（source file），以及安装（install）后的归档文件（archive file，也就是以“.a”为扩展名的文件）和可执行文件（executable file）。 &nbsp; Go源码的组织方式&nbsp; Go 语言的源码也是以代码包为基本组织单位的。在文件系统中，这些代码包其实是与目录一一对应的。由于目录可以有子目录，所以代码包也可以有子包。 &nbsp; 一个代码包中可以包含任意个以.go 为扩展名的源码文件，这些源码文件都需要被声明属于同一个代码包。 &nbsp; 代码包的名称一般会与源码文件所在的目录同名。如果不同名，那么在构建、安装的过程中会以代码包名称为准。 &nbsp; 每个代码包都会有导入路径。代码包的导入路径是其他代码在使用该包中的程序实体时，需要引入的路径。在实际使用程序实体之前，我们必须先导入其所在的代码包。具体的方式就是import该代码包的导入路径。就像这样： &nbsp; 1import &quot;github.com/labstack/echo&quot; &nbsp; 在工作区中，一个代码包的导入路径实际上就是从 src 子目录，到该包的实际存储位置的相对路径。 &nbsp; 所以说，Go 语言源码的组织方式就是以环境变量 GOPATH、工作区、src 目录和代码包为主线的。一般情况下，Go 语言的源码文件都需要被存放在环境变量 GOPATH 包含的某个工作区（目录）中的 src 目录下的某个代码包（目录）中。 &nbsp; 了解源码安装后的结果&nbsp; 在安装后如果产生了归档文件（以“.a”为扩展名的文件），就会放进该工作区的 pkg 子目录；如果产生了可执行文件，就可能会放进该工作区的 bin 子目录。 &nbsp; 归档文件存放的具体位置和规则&nbsp; 源码文件会以代码包的形式组织起来，一个代码包其实就对应一个目录。安装某个代码包而产生的归档文件是与这个代码包同名的。 &nbsp; 放置它的相对目录就是该代码包的导入路径的直接父级。比如，一个已存在的代码包的导入路径是 &nbsp; 1github.com/labstack/echo， &nbsp;那么执行命令&nbsp;1go install github.com/labstack/echo&nbsp;生成的归档文件的相对目录就是 github.com/labstack，文件名为 echo.a。 &nbsp; 顺便说一下，上面这个代码包导入路径还有另外一层含义，那就是：该代码包的源码文件存在于 GitHub 网站的 labstack 组的代码仓库 echo 中。 &nbsp; 再说回来，归档文件的相对目录与 pkg 目录之间还有一级目录，叫做平台相关目录。平台相关目录的名称是由 build（也称“构建”）的目标操作系统、下划线和目标计算架构的代号组成的。 &nbsp; 比如，构建某个代码包时的目标操作系统是 Linux，目标计算架构是 64 位的，那么对应的平台相关目录就是 linux_amd64。 &nbsp; 因此，上述代码包的归档文件就会被放置在当前工作区的子目录 pkg/linux_amd64/github.com/labstack 中。 &nbsp; &nbsp; 理解构建和安装Go程序的过程&nbsp; 构建使用命令go build，安装使用命令go install。构建和安装代码包的时候都会执行编译、打包等操作，并且，这些操作生成的任何文件都会先被保存到某个临时的目录中。 &nbsp; 如果构建的是库源码文件，那么操作后产生的结果文件只会存在于临时目录中。这里的构建的主要意义在于检查和验证。如果构建的是命令源码文件，那么操作的结果文件会被搬运到源码文件所在的目录中。 &nbsp; 安装操作会先执行构建，然后还会进行链接操作，并且把结果文件搬运到指定目录。进一步说，如果安装的是库源码文件，那么结果文件会被搬运到它所在工作区的 pkg 目录下的某个子目录中。如果安装的是命令源码文件，那么结果文件会被搬运到它所在工作区的 bin 目录中，或者环境变量GOBIN指向的目录中。 &nbsp; go build 命令一些可选项的用途和用法&nbsp; 在运行go build命令的时候，默认不会编译目标代码包所依赖的那些代码包。当然，如果被依赖的代码包的归档文件不存在，或者源码文件有了变化，那它还是会被编译。 &nbsp; 如果要强制编译它们，可以在执行命令的时候加入标记-a。此时，不但目标代码包总是会被编译，它依赖的代码包也总会被编译，即使依赖的是标准库中的代码包也是如此。 &nbsp; 另外，如果不但要编译依赖的代码包，还要安装它们的归档文件，那么可以加入标记-i。 &nbsp; 那么我们怎么确定哪些代码包被编译了呢？有两种方法。 &nbsp; 运行go build命令时加入标记-x，这样可以看到go build命令具体都执行了哪些操作。另外也可以加入标记-n，这样可以只查看具体操作而不执行它们。 运行go build命令时加入标记-v，这样可以看到go build命令编译的代码包的名称。它在与-a标记搭配使用时很有用。 &nbsp; 下面再说一说与 Go 源码的安装联系很紧密的一个命令：go get。 &nbsp; 命令go get会自动从一些主流公用代码仓库（比如 GitHub）下载目标代码包，并把它们安装到环境变量GOPATH包含的第 1 工作区的相应目录中。如果存在环境变量GOBIN，那么仅包含命令源码文件的代码包会被安装到GOBIN指向的那个目录。 &nbsp; 最常用的几个标记有下面几种。 &nbsp; -u：下载并安装代码包，不论工作区中是否已存在它们。 -d：只下载代码包，不安装代码包。 -fix：在下载代码包后先运行一个用于根据当前 Go 语言版本修正代码的工具，然后再安装代码包。 -t：同时下载测试所需的代码包。 -insecure：允许通过非安全的网络协议下载和安装代码包。HTTP 就是这样的协议。 &nbsp; 02|命令源码文件&nbsp; 命令源码文件是程序的运行入口，是每个可独立运行的程序必须拥有的。我们可以通过构建或安装，生成与其对应的可执行文件，后者一般会与该命令源码文件的直接父目录同名。 &nbsp; 如果一个源码文件声明属于main包，并且包含一个无参数声明且无结果声明的main函数，那么它就是命令源码文件。 &nbsp; 当需要模块化编程时，我们往往会将代码拆分到多个文件，甚至拆分到不同的代码包中。但无论怎样，对于一个独立的程序来说，命令源码文件永远只会也只能有一个。如果有与命令源码文件同包的源码文件，那么它们也应该声明属于main包。 &nbsp; 通过构建或安装命令源码文件，生成的可执行文件就可以被视为“命令”，既然是命令，那么就应该具备接收参数的能力。 &nbsp; 命令源码文件接收参数&nbsp; Go 语言标准库中有一个代码包专门用于接收和解析命令参数。这个代码包的名字叫flag。 &nbsp; 函数flag.StringVar接受 4 个参数。 第 1 个参数是用于存储该命令参数值的地址，具体到这里就是在前面声明的变量name的地址了，由表达式&amp;name表示。 第 2 个参数是为了指定该命令参数的名称，这里是name。 第 3 个参数是为了指定在未追加该命令参数时的默认值，这里是everyone。 至于第 4 个函数参数，即是该命令参数的简短说明了，这在打印命令说明时会用到。 &nbsp; 顺便说一下，还有一个与flag.StringVar函数类似的函数，叫flag.String。这两个函数的区别是，后者会直接返回一个已经分配好的用于存储命令参数值的地址。 &nbsp; 函数flag.Parse用于真正解析命令参数，并把它们的值赋给相应的变量。对该函数的调用必须在所有命令参数存储载体的声明（这里是对变量name的声明）和设置（对flag.StringVar函数的调用）之后，并且在读取任何命令参数值之前进行。 &nbsp; 123456789101112131415161718package mainimport ( &quot;flag&quot; &quot;fmt&quot;)var name stringfunc init() &#123; flag.StringVar(&amp;name, &quot;name&quot;, &quot;everyone&quot;, &quot;The greeting object.&quot;) //var name = flag.String(&quot;name&quot;, &quot;everyone&quot;, &quot;The greeting object.&quot;)&#125;func main() &#123; flag.Parse() fmt.Printf(&quot;Hello, %s!\\n&quot;, name)&#125; &nbsp; 运行下面的命令为name传值： &nbsp; 1$ go run demo.go -name=&quot;Robert&quot; &nbsp; 运行下面的命令查看该命令源码文件的参数说明： &nbsp; 1$ go run demo.go --help &nbsp; 其中的$表示我们是在命令提示符后运行go run命令的。运行后输出的内容会类似： &nbsp; 1234Usage of &#x2F;var&#x2F;folders&#x2F;ts&#x2F;7lg_tl_x2gd_k1lm5g_48c7w0000gn&#x2F;T&#x2F;go-build155438482&#x2F;b001&#x2F;exe&#x2F;demo: -name string The greeting object. (default &quot;everyone&quot;)exit status 2 &nbsp; 其中第一行是go run命令构建上述命令源码文件时临时生成的可执行文件的完整路径。 &nbsp; 如果我们先构建这个命令源码文件再运行生成的可执行文件，像这样： &nbsp; 12$ go build demo.go$ ./demo2 --help &nbsp; 那么输出就会是 &nbsp; 123Usage of .&#x2F;demo: -name string The greeting object. (default &quot;everyone&quot;) &nbsp; 自定义命令源码文件的参数使用说明&nbsp; 方法一：对变量flag.Usage重新赋值 &nbsp; 1234flag.Usage = func() &#123; fmt.Fprintf(os.Stderr, &quot;Usage of %s:\\n&quot;, &quot;question&quot;) flag.PrintDefaults()&#125; &nbsp; 方法二：对flag.CommandLine重新赋值，我们可以更深层次地定制当前命令源码文件的参数使用说明。（flag.CommandLine相当于默认情况下的命令参数容器。） &nbsp; 12345flag.CommandLine = flag.NewFlagSet(&quot;&quot;, flag.ExitOnError)flag.CommandLine.Usage = func() &#123; fmt.Fprintf(os.Stderr, &quot;Usage of %s:\\n&quot;, &quot;question&quot;) flag.PrintDefaults()&#125; &nbsp; 方法三：自己创建一个私有的命令参数容器。 &nbsp; 1var cmdLine = flag.NewFlagSet(&quot;question&quot;, flag.ExitOnError) &nbsp; 03|库源码文件&nbsp; 库源码文件是不能被直接运行的源码文件，它仅用于存放程序实体，这些程序实体可以被其他代码使用（只要遵从 Go 语言规范的话）。 &nbsp; 在 Go 语言中，程序实体是变量、常量、函数、结构体和接口的统称。 &nbsp; 库源码文件：demo4_lib.go &nbsp; 1234567package mainimport &quot;fmt&quot; func hello(name string) &#123; fmt.Printf(&quot;Hello, %s!\\n&quot;, name)&#125; &nbsp; 命令源码文件：demo4.go &nbsp; 12345678910111213141516package main import ( &quot;flag&quot;) var name string func init() &#123; flag.StringVar(&amp;name, &quot;name&quot;, &quot;everyone&quot;, &quot;The greeting object.&quot;)&#125; func main() &#123; flag.Parse() hello(name)&#125; &nbsp; 在同一个目录下的源码文件都需要被声明为属于同一个代码包。两个源文件的代码包声明语句都是package main。 &nbsp; 直接运行 &nbsp; 1$ go run demo4.go demo4_lib.go &nbsp; 或者，像下面这样先构建当前的代码包再运行。 &nbsp; 12$ go build puzzlers&#x2F;article3&#x2F;q1$ .&#x2F;q1 &nbsp; 如果构建失败，显示package不在GOROOT，可以运行go env -w GO111MODULE=off把go mod关闭。（编译器没有去gopath下找包，原因是GO111MODULE没有关， gomod 和 gopath 两个包管理方案，并且相互不兼容，在 gopath 查找包，按照 goroot 和多 gopath 目录下 src/xxx 依次查找。在 gomod 下查找包，解析 go.mod 文件查找包，mod 包名就是包的前缀，里面的目录就后续路径了。在 gomod 模式下，查找包就不会去 gopath 查找，只是 gomod 包缓存在 gopath/pkg/mod 里面。） &nbsp; 注意，demo4.go 和 demo4_lib.go 都声明自己属于main包。源码文件声明的包名可以与其所在目录的名称不同，只要这些文件声明的包名一致就可以。 &nbsp; demo4.go 另存为 demo5.go，并放到一个相对路径为puzzlers/article3/q2的目录中。再创建一个相对路径为puzzlers/article3/q2/lib的目录，再把 demo4_lib.go 复制一份并改名为 demo5_lib.go 放到该目录中。对 demo5_lib.go 文件进行修改。（为了不让该代码包的使用者产生困惑，我们总是应该让声明的包名与其父目录的名称一致。） &nbsp; 1234567package lib import &quot;fmt&quot; func Hello(name string) &#123; fmt.Printf(&quot;Hello, %s!\\n&quot;, name)&#125; &nbsp; （这里Hello首字母大写的原因：名称的首字母为大写的程序实体才可以被当前包外的代码引用，否则它就只能被当前包内的其他代码引用。通过名称，Go 语言自然地把程序实体的访问权限划分为了包级私有的和公开的。对于包级私有的程序实体，即使你导入了它所在的代码包也无法引用到它。） &nbsp; 我们在构建或者安装这个代码包的时候，提供给go命令的路径应该是目录的相对路径，就像这样： &nbsp; 1$ go install puzzlers&#x2F;article3&#x2F;q2&#x2F;lib &nbsp; 该命令会成功完成。之后，当前工作区的 pkg 子目录下会产生相应的归档文件，具体的相对路径是pkg/windows_amd64/puzzlers/article3/q2/lib.a &nbsp; demo5.go使用lib代码包的方法：导入puzzlers/article3/q2/lib，然后调用lib.Hello函数。 &nbsp; 如果你需要导入两个代码包，而这两个代码包的导入路径的最后一级是相同的，比如：dep/lib/flag和flag，那么会产生冲突。因为代表两个代码包的标识符重复了，都是flag。 &nbsp; 怎样解决这种冲突？导入代码包的时候给它起一个别名就可以了，比如： import libflag “dep/lib/flag”。或者，以本地化的方式导入代码包，如：import . “dep/lib/flag”。 &nbsp; &nbsp; 参考链接：https://time.geekbang.org/column/intro/112","categories":[{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Go语言","slug":"Go语言","permalink":"http://wht6.github.io/tags/Go%E8%AF%AD%E8%A8%80/"}]},{"title":"道家的睡方与睡功","slug":"道家的睡方与睡功","date":"2022-01-25T03:00:00.000Z","updated":"2022-03-28T06:57:34.790Z","comments":true,"path":"posts/925d.html","link":"","permalink":"http://wht6.github.io/posts/925d.html","excerpt":"","text":"花竹幽窗午梦长，此中与世暂相忘。华山处士如容见，不觅仙方觅睡方。 &nbsp; 据道家养生学著作，卧处不可以首近火，不可当风，不可露天而睡。睡前必作轻微运动，揉眼、擦面、摩腹、刷牙、漱口、濯足、梳发、静心，令食物消化，再入寝。不可醉饱入睡，不可烛灯而睡，不可悬足，不可张口，不可覆首，要将一切计虑营谋消释，清心入睡。睡宜暖腹(丹家多穿兜肚护脐)、护肩颈，温足冻脑，食后右侧而卧，食远则左右皆宜。老年人要睡午觉，青年人寝不过午。因老年人气弱，故寝以养之，少壮阳气盛，昼寝反阳亢而致目昏头重之疾。 &nbsp; 愚谓寐有操、纵二法。操者，如贯想头顶，默数鼻息，返观丹田之类，使心有所着，乃不纷驰，应可获寐。纵者，任其心游思于杳渺无朕之区，亦可渐入朦胧之境。最忌者，心欲求寐，则寐愈难。盖醒与寐交界关头，断非意想所及。惟忘乎寐，则心之操或纵，皆通睡乡之路。坐而假寐，醒时弥觉神清气爽，较之就枕而卧，更为受益。然有坐不能寐者，但使缄其口，闭其目，收摄其心神，休息片时，足当昼眠，亦堪遣日。 &nbsp; 夫学道修真之士若习睡功玄诀者，于日间及夜静无事之时，或一阳来复之候，端身正坐，叩齿三十六通，逐一唤集身中诸神，然后松宽衣带而侧卧之。诀在闭兑，目半垂帘，赤龙头抵上腭，并膝，收一足，十指如钩，阴阳归窍，是外日月交光也。然后一手掐剑诀掩生门，一手掐剑诀曲肱而枕之，以眼对鼻，鼻对生门，合齿，开天门闭地户，心目内视，坎离会合，是内日月交精也。功法如鹿之运督，鹤之养胎，龟之喘息。夫人之昼夜有一万三千五百息，气行八万四千里，是应天地造化，悉在玄关橐龠。使思虑神归于元神，内药也。内为体，外为用。体则合精于内，用则法光于外，使内外打成一片，方是入道工夫。行到此际，六贼自然消灭，五行自然攒簇，火候自然升降，酿就真液，浇养灵根。故曰：‘玄牝通一口，睡之饮春酒，朝暮勤行持，真阳永不走’。凡睡之功毕，起时揩摩心地，次揩两眼，则心身舒畅。 &nbsp; 东首而寝，侧身而卧，如龙之蟠，如犬之曲，一手曲肱枕头，一手直摩腹脐，一只脚伸，一只脚缩，未睡心，先睡目，致虚极，守静笃，神气自然归根，呼吸自然含育，不调息而息自调，不伏气而气自伏。 &nbsp; 开心宗之性，示不动之体，悟梦觉之真，入闻思之寂。 &nbsp; 元神夜夜宿丹田，云满黄庭月满天。两个鸳鸯浮绿水，水心一朵紫金莲。 &nbsp; 龙归元海，阳潜于阴。人曰蛰龙，我却蛰心。默藏其用，息之深深。白云高卧，世无知音。 &nbsp;","categories":[{"name":"个人兴趣","slug":"个人兴趣","permalink":"http://wht6.github.io/categories/%E4%B8%AA%E4%BA%BA%E5%85%B4%E8%B6%A3/"}],"tags":[{"name":"道家","slug":"道家","permalink":"http://wht6.github.io/tags/%E9%81%93%E5%AE%B6/"}]},{"title":"阿里云重要知识点","slug":"阿里云重要知识点","date":"2022-01-21T02:00:00.000Z","updated":"2022-03-26T02:43:09.873Z","comments":true,"path":"posts/fd04.html","link":"","permalink":"http://wht6.github.io/posts/fd04.html","excerpt":"","text":"健康检查失败时间窗=响应超时时间×不健康阈值+检查间隔×（不健康阈值-1），健康检查成功时间窗= （健康检查成功响应时间×健康阈值）+检查间隔×（健康阈值-1）。 在阿里云上开通安骑士功能可以减少密码被暴力破解的可能。 DDoS基础防护阀值只有5GB，无法保证业务需要保持在99.9%以上，高防IP可以。 公网IP是购买负载均衡SLB时候系统分配的，或者你单独购买EIP后单独给负载均衡SLB绑定。并不是在你在负载均衡的配置和管理里面可以设定的。 “最新创建的实例”不管是自动创建还是手动创建，都会被移出，而“最早伸缩配置对应的实例”会优先移除系统自动创建的实例，跳过手动创建的实例。 VPC实例的状态变为Available之后,表示VPC创建成功,可以进行下一步的管理操作 在OSS的控制台的属性设置里面，是没有设置OSS文件被访问时的HTTP头（Header）这个操作 ECS外部系统可以通过API在请求时传入参数来指定返回的数据格式,默认XML格式 防敏感信息泄露是WAF的功能，收费。 SLB的UploadServerCertificate接口一次只能上传一份服务器证书和对应的私钥。 OSS目前不具备OCR文字识别的处理能力。 单表的有效最大表尺寸通常受限于操作系统的文件尺寸限制，而不是受MySQL内部机制的限制。 由于RDS MySQL实例的最大尺寸为 2TB， 因此单表的最大尺寸为略小于2TB（因为会有些元数据等的开销）。若RDS MySQL实例有多张表，多张表的总和也不能超过2TB。单表的最大记录数在2000万条以内。 阿里云CDN支持对同名更新的实时更新，用户只要做相关配置后，在用户不主动提交请求的时候，CDN不会自动去实现刷新请求。 开通ECS实例后，ddos基础防护和阿里绿网和安骑士都是免费的，服务器安全托管是要收费的。 OPDS即MaxCompute不能创建为专有网络类型。 ECS创建之后，系统盘的设备名应该是/dev/xvda，所以挂载到数据盘不能再使用这个名字。 OSS支持文件读取，创建和删除，不支持修改。 同一个负载均衡SLB实例的后端服务器池中可以包含多个伸缩组。 Channel 是IMG（图片处理服务）上的命名空间，也是计费、权限控制、日志记录等高级功能的管理实体。IMG名称在整个图片处理服务中具有全局唯一性，且不能修改。一个用户最多可创建10个Channel，但每个Channel中存放的object的数量没有限制，所以每个Channel的容量是没有上限的。 将VPC中ECS服务器切换/迁移到同VPC下的其他交换机的步骤：1）打开云服务器管理控制台；2）找到对应的需要切换/迁移的云服务器；3）修改云服务器的私网地址；4）选择您所需的交换机,同时指定新交换机下的IP。 安骑士可以进行木马文件检查、高危漏洞修复、防密码暴力破解和异地登录报警，但是不能防web应用系统密码破解。 ECS支持强制停止，但是会丢失内存中的数据。 如果在配置阿里云的负载均衡SLB实例的监听时,开启了“获取真实访问IP”,针对7层服务可以通过http头部中的X-Forwarded-For字段获取来访者真实IP。 ECS带宽临时升级：可以按天进行升级,升级后如果云服务器ECS续费,仍然按照原基础带宽进行续费。 目前阿里云的负载均衡SLB只支持PEM格式的证书。 用户在阿里云以外的服务器上安装“安骑士客户端”后,通过“在管理控制台生成的安装验证key”的方式与指定的阿里云官网帐号关联。 弹性伸缩目前只支持ECS及其数据盘的弹性伸缩,不支持云数据库RDS、负载均衡等云产品的弹性伸缩。 修改云服务器ECS的私网IP地址需要云服务器ECS处于停止的状态。 ECS只有在稳定( 运行中, 已停止) 状态才能挂载磁盘, 其他状态都不行。 HTTPDNS是面向移动开发者推出的一款域名解析产品,具有域名防劫持、精准调度等特性。主要是用在客户端的时候请求URL防止域名劫持的情况。 升级云服务器ECS实例的CPU和内存后,必须通过阿里云的管理控制台重启ECS实例才能生效,在ECS实例内重启无效。 回滚磁盘必须要求云盘必须已经挂载到某台ECS实例上,而且已经停止实例。 用户可以卸载阿里云的云服务器ECS实例上的云盾安骑士客户端,在需要的时候可以再次安装。 阿里云对象存储OSS的存储空间Bucket支持删除操作,在删除Bucket前必须先删除Bucket中的所有文件,包括未完成的分片文件。 在安全管理方面，云计算服务网络安全管理的基本要求，提出了“安全管理责任不变，数据归属关系不变，安全管理标准不变，敏感信息不出境”四条基本要求。不包含”运维管理方式不变”。 使用阿里云OSS产品实现在线的音视频内容直播时,必须要和阿里云的多媒体转码服务MTS产品一起配合实现。 AccessKeySecret是用于加密签名字符串和服务器端验证签名字符串的密钥，AccessKeySecret并不支持通过控制台直接查看，AccessKeySecret只能一次生成，后续不支持再次查看。如果忘记AccessKeySecret，只能在授权登录后在控制台重新生成。 您可以将不希望被移出伸缩组的ECS实例转为保护状态，处于保护状态的ECS实例负载均衡权重不受影响。AS不会检查处于保护状态的ECS实例健康状态，也不会释放ECS实例。需要用户手动管理该台ECS实例生命周期。 扩容云盘只是扩大存储容量，但不会扩容ECS实例的文件系统（应该是扩容的那部分容量并没有以磁盘的形式进行挂载）。您还需要登录实例，然后进行扩容文件系统的操作。 Windows系统盘扩容后磁盘可用空间反而变少：因为虚拟内存被开启且设置的是系统自动管理。 linux系统的服务器不支持开启Selinux服务,如果开启了Selinux服务,会导致系统异常并无法启动。 在使用部署集之前，您需要注意：部署集之间不支持相互合并。部署集内不能创建抢占式实例。部署集不支持创建专有宿主机。 四层是通过SLB中设定的转发策略和规则和报文中的目标IP地址和端口分发流量，七层是通过报文中真正有意义的应用层内容和负载均衡SLB中设定的转发策略和规则分发流量。负载均衡SLB的四层服务的会话保持是基于源IP实现的，七层服务的会话保持是基于Cookie实现的。 存储空间创建成功后，其名称、所处地域、存储类型不能修改。 在阿里云上创建专有网络VPC时，VPC会自动为用户创建1条系统路由，这条路由的作用是用于专有网络内的云产品实例访问专有网络外的云服务（该云服务支持VPC内的云产品实例直接访问）。 阿里云的云盾数据风控可以很好地解决WEB应用中常见的垃圾注册、刷库等业务风险识别的难题， 要想使用这项服务首先得进行业务数据的采集，对于WEB应用系统，可以采用JavaScript方式来采集信息。（数据风控目前只支持在Web中插入指定的JS代码，其他的暂时还不支持） 出于改善性能的考虑，将正在使用的1核2G云服务器的配置提升至2核8G，这种操作在云计算中被称为垂直扩展。升级ECS的配置，所以称之为垂直扩展，通过弹性伸缩来完成的拓展，称之为水平扩展。 定时任务独立于伸缩组存在，不依赖伸缩组的生命周期管理，删除伸缩组不会删除定时任务；云监控报警任务独立于伸缩组存在，不依赖伸缩组的生命周期管理，删除伸缩组不会删除报警任务。 伸缩组中包含的云服务器ECS实例有两种类型，一种是根据用户的伸缩配置和伸缩规则由弹性伸缩服务自动创建的云服务器ECS实例，另外一种是由用户手工添加到伸缩组中的ECS实例。当ECS实例被弹性伸缩从伸缩组中移出时，对于自动创建的ECS实例会停止和释放，对于手工添加的ECS实例则不会停止和释放。 在使用阿里云弹性伸缩(Auto Scaling)时,希望能根据计算资源的使用情况来增加或者减少云服务器ECS实例,如当CPU利用率小于等于30%时则减少一台云服务器ECS实例,首先配置伸缩规则为“减少1台ECS”,然后还需要（创建报警任务）来实现。 自动快照是保存在OSS里面，但是是保存在独立于用户自己的OSS Bucket里面，而不能保存在用户的Bucket里面。 Aliyun Linux和Centos都属于RedHat一家的。兼容Red Hat。其中包括（Red Hat Enterprise Linux， Fedora，CentOS，Scientific Linux， Oracle Linux） OSS每小时结算一次调用 OSS API 的请求费用。目前只支持按量付费：每万次请求的单价 * 每小时实际请求次数/10000。 阿里云负载均衡服务SLB支持用户可以同时设置实例维度上的“后端服务器”、监听维度上的“虚拟服务器组”和“转发规则”，那么当用户流量经过负载均衡某端口时，我们首先判断其是否能够匹配上某条“转发规则”，如果匹配，则将流量转发到该规则的后端服务器组上；若不匹配并且在该监听上设置了虚拟服务器组，那么将流量转发到该虚拟服务器组上；若用户没有在该监听上设置虚拟服务器组，即将流量转发到实例级别添加的各后端服务器中。 如果您使用OSS自带域名，如http://bucketname.oss.aliyuncs.com/objcet访问静态文件时（文件类型包括：txt、html、htm、图片格式、视频格式、音频格式等），均限制在浏览器中以“另存为”下载的方式打开文件，而不能直接浏览该文件。因此您需要将自定义的域名访问绑定在属于自己的Bucket上面，即CNAME。域名绑定成功后，为了使用域名正常访问 OSS，还需要添加 CNAME 记录指向存储空间对应的外网域名。 在使用阿里云负载均衡SLB时后端服务器可以设置主备服务器组,当主机工作正常时，流量将直接走主机；当主机宕机时，流量将走到备机。主备服务器组是在监听维度上维护的，并且只支持四层监听。 健康检查四层是通过端口检查是否超时，七层则是检查服务器端返回的状态码。 专用网络VPC下面的ECS，不管是否绑定了EIP，在设置安全组的时候，只可以设置内网规则，外网规则是不可以选的。因为对于其来说，内网规则等同于外网规则。 伸缩活动中，最后一个ECS实例加入或移出完成后，整个伸缩组冷却时间才开始计时，伸缩活动结束并不代表最后一个ECS实例已经加入或移出完成。 数据风控由阿里聚安全提供，是基于阿里大数据计算能力，通过业内领先的风险决策引擎，解决企业账号、活动、交在的易等关键业务环节存欺诈威胁，降低企业经济损失。 云服务器ECS实例与OSS之间的请求次数，不分内外网都会计费。走内网流量是不收费的，但是每次的请求次数还是收费。 当文件所在的Bucket的读写权限为“私有”时，OSS分享链接采用的安全机制是在管理控制台中获取文件访问URL时设置分享链接有效的时间，超过设定时间就无法下载。出于安全考虑，目前控制台针对私有bucket的获取URL链接签名操作做了优化，使用的AccessKey是临时生成的密钥对，主账号用户最长有效时间是64800秒（18小时），RAM子账号用户以及sts用户最长有效时间是3600秒（1小时），超时后链接就无法访问了。 云监控的http提交指令为post。 停用伸缩组以后，之前的冷却时间即失效。所以后面伸缩活动不会受到冷却时间的影响。 管理云盾加密服务的密钥时，必须通过身份卡(USB Key)方式的认证。 针对7层（HTTP协议）服务，由于采取替换HTTP头文件IP地址的方式来进行请求转发，所以后端云服务器看到的访问IP是SLB系统的本地IP而不是实际来访者的真实IP。所以系统支持用户采用X-Forwarded-For的方式获取访问者真实IP，前提是用户必须在配置7层（HTTP协议）服务监听时开启了“获取真实访问IP”功能。 先知计划为企业提供的是为企业收集情报（漏洞）服务。 操作系统级别监控指标包含内存使用率、平均负载、磁盘 IO 读/写、磁盘使用率、TCP 连接数、进程总数等。请注意CPU使用率不属于操作系统级别监控。 安全组只允许公网TCP 80端口和25端口访问并不能达到禁止用户pingECS是否在线的效果。选项”先将ECS IP解析到一个不常用的四级域名，然后将对外推广的域名通过CNAME指向以上四级域名”可以隐藏了ECS的真实IP地址，所以一定程度上可以防止ECS被ping到。 阿里云云安全中心提供的是一种SaaS类型的服务。 加速域名日志中记录的流量数据，是我们应用层日志统计出的流量，但是实际产生的网络流量却要比应用层统计到的流量要高出7%-15%；这个主要的原因有两个：1、TCP/IP包头的消耗，2、TCP重传。 在创建伸缩组时候可以配置RDS的实例，但是并不能指定RDS的实例的配置，RDS的实例的配置需要在购买RDS的时候来指定的。在创建伸缩组时只支持指定ECS的指定配置，不支持指定ECS的最大配置。 OSS中，用户只有通过URL签名或者匿名访问Object时，才会做防盗链验证。请求Header中有Authorization字段时，不会做防盗链验证。 若SLB未结合弹性伸缩一起使用，后端ECS实例宕机SLB会将其隔离而不是移除（不再给其分发请求），直到该ECS健康检查恢复正常后，还会从隔离区移出，继续分发请求。 回滚磁盘必须要求云盘必须已经 挂载到某台ECS实例上，而且已经 停止实例。 SLB中的四层负载均衡采用开源软件LVS，并根据云计算的需求对其官方进行了定制化，下列哪些属于阿里云在LVS官方问题上进行了定制化？答：DDoS攻击防御功能+采用LVS集群部署方式+优化keepalived性能 简单上传适用情况：上传文件最大不超过5GB+在上传单个文件过程中可以携带meta信息+基于PUT方式或POST方式的http请求上传。简单上传指的是使用OSS API中的PutObject方法上传单个文件（Object）。简单上传不需要支持断点上传，也就是断点续传功能一定不是简单上传。简单上传适用于一次HTTP请求交互即可完成上传的场景，比如小文件（小于5GB）的上传。上传文件时支持设置Object Meta。 阿里云弹性伸缩（Auto Scaling）的伸缩配置（Scaling Configuration）中支持设置的镜像类型包含自定义镜像+公共镜像+共享镜像。弹性伸缩设置ECS配置的时候，不支持使用云市场的镜像，主要是因为部分云市场的镜像是收费的，阿里云控制台没有云市场镜像的选项。 在删除阿里云弹性伸缩(Auto Scaling)的伸缩组时有两种模式：强制删除和非强制删除。在非强制删除模式下，必须满足“伸缩组没有任何伸缩活动正在执行+伸缩组当前的ECS实例数量为0”的条件才可以删除。 负载均衡SLB不提供CNAME地址，需要直接将域名解析到负载约衡SLB提供的服务IP地址上。 CDN节点系统关键组件：LVS做四层均衡负载；Tengine做七层负载均衡；Swift做HTTP缓存。 .阿里云负载均衡服务SLB提供性能保障型实例，该类型实例提供了可保障的性能指标, 那么它的关键指标有：最大连接数-Max Connection、每秒新建连接数-Connection Per Second (CPS)、每秒查询数-Query Per Second (QPS)。 一台ECS实例最多能挂载16块云盘作数据盘用，且云盘只能挂载到同一地域下同一可用区内的实例上，不能跨可用区挂载。 自定义监控：用户可以对自己关心的业务进行监控，将采集到监控数据上报至云监控，由云监控进行数据的处理，并根据结果进行报警。自定义的监控项的数量是没有上限的，上报监控数据的程序可以部署在阿里云的云服务器以外的机器。 虽然用户是可以自己上传本地镜像的，但是上传的本地镜像需要用户把本地镜像制作为自定义镜像，所以在创建云服务器ECS的时候是没有用户上传的镜像的选项的。 云服务器ECS系统资源监控DashBoard页面内容有CPU使用率+磁盘IO+网络带宽。DashBoard不支持对TPS的监控 伸缩组中手工加入ECS实例的步骤：1）判断伸缩组的健康状态、边界条件和 ECS 实例的状态、类型。2）分配 ActivityId 和执行伸缩活动。3）加入 ECS 实例。4）修改 Total Capacity。5）添加 RDS 白名单。6）挂载负载均衡，将权重设为当前伸缩组中已激活的伸缩配置上指定的“负载均衡权重”。此处使用了伸缩配置上指定的“负载均衡权重”。7）伸缩活动完成，启动 cooldown。 “访客真实IP”保存在HTTP协议的“X—Forwarded-For”Header中，可以在Apache和Nginx的自定义LOG中直接获取到 ， Windows平台下，如果使用IIS，需要安装一个“F5XForwardedFor”的扩展模块，才能在日志里看到“访客真实IP” 。 CDN仅支持PEM格式的证书，更新HTTPS证书1分钟后全网生效。 查看CDN节点是否生效：方法一：通过ping或dig的方式查看所添加的加速域名；方法二：在CDN控制台中查看节点是否生效；方法三：获取对应加速域名资源的response查看节点是否生效。 OSS 提供服务端加密和客户端加密。服务端加密方式：使用KMS托管密钥进行加解密，使用OSS完全托管加密。客户端加密方式：使用KMS托管用户主密钥，使用用户自主管理密钥。客户端不支持OSS完全托管加密。 OSS跨区域复制可以指定文件前缀进行同步，可以进行写同步（增/改），可以进行增/删/改同步。不可以指定文件后缀进行同步。 网络ACL的规则是无状态的，即设置入方向规则的允许请求后，需要同时设置相应的出方向规则，否则可能会导致请求无法响应。网络ACL无任何规则时，会拒绝所有出入方向的访问。新创建的网络ACL，默认会在出方向和入方向分别生成一条规则，表示允许所有出、入方向流量。您可以删除默认规则。 阿里云的交换机是三层交换机，绑定路由表。 SLB后端ECS实例的两种状态区别：保护状态和备用状态的相同点是都会实现“弹性伸缩不会检查ECS实例健康状态,也不会释放ECS实例”，不同点是保护状态的ECS还会继续提供服务，备用状态的ECS的权重会被设置为0，不对外提供服务。 OSS的存储费用支持包年包月和按量付费，API请求费用只有按量付费。 普通快照是存储在OSS中，属于跨地域容灾，创建速度慢，本地快照是存储在云盘中，属于同城容灾，创建速度快。自动快照主要强调周期性，固定时间等，对时间有要求。 实例健康状况侧重于监视实例的健康状态，如异常活动、网络和软硬件问题，可以配合云监控使用。自助诊断系统是在你的资源出现问题的时候可以一键诊断，提交结果等。 性能保障型实例的关键指标：最大连接数，每秒新建连接数，每秒查询数。 专有网络VPC（Virtual Private Cloud）的高级功能包括网络ACL、自定义路由表和DHCP选项集。如果VPC中创建了ECS实例规格族限制中的ECS实例，则该VPC不支持使用高级功能。 伸缩组支持关联传统型负载均衡CLB（原SLB）实例，前提条件：1）您持有一个或多个处于运行中状态的CLB实例。2）CLB实例和伸缩组必须位于同一地域。3）如果CLB实例和伸缩组的网络类型均为专有网络，则必须位于同一专有网络。4）当CLB实例的网络类型为经典网络，伸缩组的网络类型为专有网络时，如果CLB实例的后端服务器组中包含专有网络ECS实例，该ECS实例必须与伸缩组位于同一专有网络。5）CLB实例配置至少一个监听。6）CLB实例必须开启健康检查。 TCP监听支持HTTP和TCP两种健康检查方式：1）TCP协议健康检查通过发送SYN握手报文，检测服务器端口是否存活。2）HTTP协议健康检查通过发送HEAD或GET请求，模拟浏览器的访问行为来检查服务器应用是否健康。 交换机创建完成之后,无法修改CIDRBlock,且新建交换机所使用的CIDRBlock不可以与已经存在的交换机的CIDRBlock重复。 伸缩配置包括：标签，SSH密钥对，实例RAM角色，实例自定义数据 伸缩组具有以下三种状态:Active、Inacitve和Deleting，伸缩配置具有以下两种状态:Active和Inacitve。 OSS图片处理限制：1）图片格式只支持JPG、PNG、BMP、GIF、WebP、TIFF。2）原图大小不能超过20 MB。3）图片旋转对应的原图高或者宽不能超过4,096 px。4）原图高或者宽不能超过30,000 px。","categories":[{"name":"云原生","slug":"云原生","permalink":"http://wht6.github.io/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"}],"tags":[{"name":"阿里云","slug":"阿里云","permalink":"http://wht6.github.io/tags/%E9%98%BF%E9%87%8C%E4%BA%91/"}]},{"title":"阿里云的一些重要概念","slug":"阿里云的一些重要概念","date":"2022-01-09T02:00:00.000Z","updated":"2022-03-26T02:42:45.847Z","comments":true,"path":"posts/da88.html","link":"","permalink":"http://wht6.github.io/posts/da88.html","excerpt":"","text":"弹性计算服务器ECSECS是阿里云的云服务器，单个云服务器被称为实例，一个实例即一个虚拟服务器，具有CPU、内存、操作系统、网络和磁盘。 地域和可用区阿里云在不同的地域建设许多机房，每个地域划分成多个可用区，一个可用区可以看成一个机房。地域内的所有可用区内网互联，地域之间通信要经过公网。跨地域部署会有网络延迟和经费问题，所以ECS的虚拟化是针对单个地域的，可用区之间可以迁移，但是ECS创建后不可以跨地域。 同样，阿里云的负载均衡、对象存储和数据库服务都是针对单个地域部署的，负载均衡只能在地域内做，对象存储创建好的Budget不能切换地域，对象存储和数据库跨地域迁移都要计费。 块存储块存储可以说就是虚拟磁盘，分为本地盘和云盘，本地盘应该就是物理服务器自带的磁盘虚拟化的结果，而云盘是将一堆磁盘放一起用来提供存储服务，类似于NAS。本地盘直接连接在主板上，所以访问速度快，云盘即使是内网连接也需要经过网线，所以稍微慢一些。 阿里云还提供了一个共享块存储，支持多个ECS实例并发读写访问，这个主要用于共享访问的场景，可以防止单点故障。 云盘分为普通云盘、高效云盘、SSD云盘、ESSD云盘，速度由慢到快。 安全组安全组是一组实例集合，这些实例使用同样规则的虚拟防火墙，用于网络访问控制。创建一个安全组，配置一套ACL规则，将实例加入该安全组，那么这个实例的就会配置一个具有上述规则的防火墙。 虚拟专有网络VPCVPC底层用到的是网络虚拟化和软件定义网络SDN，目的是提供隔离的网络环境。每一个VPC都由一个私有网段、一个路由器和至少一个交换机组成。 弹性IP阿里云的弹性IP简称EIP，购买之后会得到一个公网IP，弹性提现在该公网IP不与实例绑定而是与账号绑定，就是可以把该公网IP切换到任意一个实例上，具体怎么做到的咱也不知道。 云企业网云企业网（Cloud Enterprise Network）的作用就是提供一个跨越公网的安全环境，比如两个不同地域的VPC的通信，以及混合云的部署。VPN网关也可以做到。 负载均衡SLB 监听监听支持的协议有TCP、UDP、HTTP和HTTPS，目的是监听这些基于这四种协议的请求，比如HTTP的请求，每次监听到HTTP的一个请求，就做一次转发，基于配置负载均衡的策略转发到特定的服务器。还可以根据cookie还进行会话保持，将相同cookie的请求转发到同一个服务器。 弹性伸缩AS使用弹性伸缩（Auto Scaling）可以根据业务需求和策略设置伸缩规则，在业务需求增长时自动为您增加ECS实例以保证服务端计算能力，在业务需求下降时自动减少ECS实例数量以节省成本。例如触发条件：平均vCPU使用率 &gt; 80%时，添加一台实例。平均vCPU使用率 &lt; 30%时，减少一台实例。 伸缩组这个概念有点类似于安全组，也是将一组实例划分成一个伸缩组，但是安全组中的安全规则是针对每个实例的，而伸缩组的规则是针对所有实例的。伸缩组包括伸缩配置，伸缩规则和伸缩活动，伸缩配置就是针对每个实例的配置，伸缩规则是具体扩展或收缩的规则，伸缩活动就是实际伸缩情况，伸缩规则成功触发后就会产生一条伸缩活动。 除了自定义规则来触发伸缩之外，还可以任务触发，如定时任务，报警任务。 对象存储服务OSS对象（Object）由元信息(Metadata)、用户数据(Data)和文件名(Key)组成。对象由存储空间内部唯一的Key来标识。对象元信息是是一组键值对，表示了对象的一些属性，比如最后修改时间、大小等信息，同时也可以在元信息中存储一些自定义的信息。 存储空间存储空间（Budget）是用户用于存储对象(Object)的容器，所有的对象都必须隶属于某个存储空间。存储空间具有各种配置属性，包括地域、访问权限、存储类型等。每个存储空间属于某个地域，存储空间创建之后不能修改地域。 生命周期对象的生命周期是从上传到删除为止。可以创建生命周期规则来批量转换或批量删除。 访问域名和访问密钥Endpoint（访问域名）：OSS对外服务的访问域名。不同地域下的域名不一样。内网和外网的域名也不一样。 AccessKey（访问密钥）：用于身份验证。 下载方式OSS中的对象可以在控制台下载，也可以用URL下载。 防盗链 对象存储OSS是按照使用量收费的服务，为了减少存储于OSS的数据被其他人盗链而产生额外费用，OSS支持设置基于HTTP和HTTPS header中表头字段Referer的防盗链方法。可以通过控制台为存储空间设置Referer字段的白名单和是否允许Refer字段为空的请求访问。 参数：Refer白名单：仅允许指定域名访问OSS资源。是否允许空Referer：如果不允许空Referer，则只有HTTP和HTTPS header中包含Referer字段的请求才能访问OSS资源。 云数据库RDS阿里云关系型数据库(Relational Database Service，简称RDS)是一种稳定可靠的、可弹性伸缩的在线数据库服务。支持市场上主流的数据库系统和引擎。 读写分离主实例和只读实例都有独立的连接地址，当开启读写分离功能后，系统会额外提供一个读写分离地址，联动主实例及其下的所有只读实例，实现了自动的读写分离。应用程序连接读写分离地址，读写分离模块会自动将写入请求发往主实例，将读请求发往只读实例。 主要满足特定的业务场景，有些业务场景写很少，大部分都是读，读写分离主要适用于这种场景。 内容分发网络CDN阿里云内容分发网络(Alibaba Cloud Content Delivery Network，简称CDN)将用户源站资源缓存到阿里云遍布全球的加速节点上。当终端用户请求访问和获取这些资源时，无需回源，系统将就近调用CDN节点上已经缓存的资源。 加速域名你自己首先有个域名，开通CDN服务后，会得到一个加速域名，然后你在域名服务器上添加CNAME记录，将你的域名映射到加速域名，那么别人访问你的域名的时候就会解析到CDN服务器，CDN服务器再通过一定的策略将距离用户最近的CDN节点的IP地址返回。 回源策略回源就是不去访问CDN节点，而去直接访问你的服务器。回源策略是什么情况下回源，回源的时候访问哪个IP（对于你有多个IP域名的情况）。","categories":[{"name":"云原生","slug":"云原生","permalink":"http://wht6.github.io/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"}],"tags":[{"name":"阿里云","slug":"阿里云","permalink":"http://wht6.github.io/tags/%E9%98%BF%E9%87%8C%E4%BA%91/"}]},{"title":"Linux系统配置","slug":"Linux系统配置","date":"2021-12-30T02:00:00.000Z","updated":"2022-03-20T01:51:31.276Z","comments":true,"path":"posts/a302.html","link":"","permalink":"http://wht6.github.io/posts/a302.html","excerpt":"","text":"环境变量 环境变量的配置文件是/etc/profile，它的子配置文件夹是/etc/profile.d/。配置文件profile的作用是为每个用户配置环境信息。当用户第一次登录时，读取该配置文件并生效。也可以手动执行该文件使其生效：source /etc/profile。 source命令就是点命令，也就是一个点符号(.)，source（或点）命令通常用于重新执行刚修改的初始化文件，使之立即生效，而不必注销并重新登录。source /etc/profile等价于. /etc/profile。source（或点）作用与命令或脚本文件，会影响当前shell。扩展：这里与./区分，./ filename用于执行可执行文件，代替的是sh filename，. /filename就是source用于执行脚本。 使用source按顺序执行命令。方法：新建一个文件，每一行写入命令+&amp;&amp;，写完保存，然后用source执行这个文件，就可以从第一行的命令往下顺序执行每条命令。 ~/.bash_profile是单个用户的环境信息的配置文件，该配置文件也是登录时读取并生效，但是这对该用户自己生效，对别的用户不生效。在debian中对应的文件是~/.profile。 /etc/bashrc，为每一个运行 bash shell 的用户执行此文件。当 bash shell 被打开时，/etc/bashrc被读取。如果你想对所有使用 bash shell的用户修改某个配置，并在以后打开的 bash shell都生效的话，可以修改/etc/bashrc文件，修改后不用重启linux或source一下，只需重新打开一个 bash shell即可生效。 ~/.bashrc包含专属于你的 bash shell 信息，当登录时以及每次打开新的 shell 时，该文件被读取。每个用户都有一个 ~/.bashrc文件，在用户目录下。~/.bashrc类似于 /etc/bashrc，不需要重启linux或source一下，只需重新打开一个 bash shell即可生效。/etc/bashrc 对所有用户新打开的 bash 都生效，但 ~/.bashrc 只对当前用户新打开的 bash 生效。 扩展：~/.bash_profile会调用~/.bashrc，~/.bashrc会调用 /etc/bashrc文件，所以登录shell时文件的执行顺序：/etc/profile ——&gt; ~/.bash_profile或~/.bash_login或~/.profile（不同系统文件名不一样） ——&gt; ~/.bashrc ——&gt; /etc/bashrc","categories":[{"name":"Linux","slug":"Linux","permalink":"http://wht6.github.io/categories/Linux/"}],"tags":[{"name":"系统配置","slug":"系统配置","permalink":"http://wht6.github.io/tags/%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE/"}]},{"title":"Linux网站服务","slug":"Linux网站服务","date":"2021-12-28T02:00:00.000Z","updated":"2022-03-20T01:51:13.738Z","comments":true,"path":"posts/c49a.html","link":"","permalink":"http://wht6.github.io/posts/c49a.html","excerpt":"","text":"网站架构LAMP：Linux+Apache+MySQL+PHP。 静态站点 静态站点大多是纯HTML格式的网页，没有后台程序和数据支撑，上面的图片以及文字都是固定好的。 Apache对应的软件包是httpd，http协议端口80，https协议端口443。配置文件：/etc/httpd/conf/httpd.conf，子配置文件：/etc/httpd/conf.d/*.conf。 systemctl start httpd，systemctl status httpd，systemctl enable httpd，systemctl stop firewalld，setenforce 0，启动，查看，开机自启，关防火墙。最后浏览器测试。 firewalld是保护互联网对服务器的影响，selinux是保护服务器内部程序对内部文件的访问，selinux限制了每个程序只能访问特定的文件夹。getenforce，查看selinux状态（enforcing开启，permissive放行（临时关闭），disable永久关闭）。永久关闭：vim /etc/selinux/config，enforcing改成disable。 Apache的网页主目录是/var/www/html/（网站源码默认位置）。测试：echo 20211228 &gt; index.html。 Apache支持虚拟主机（VirtualHost），即在一台物理服务器上运行多个网站。 准备网站源码（网页）目录：mkdir /var/www/html/a.org，vim /var/www/html/a.org/index.html。创建a.org的网站配置文件，vim /etc/httpd/conf.d/a.org.conf。写入： 1234&lt;VirtualHost *:80\\&gt;ServerName www.a.orgDocumentRoot /var/www/html/a.org&lt;/VirtualHost&gt; httpd -t，检查服务器是否配置有错误，syntax ok表示没有语法错误。重启更新配置：systemctl restart httpd。 客户端上需要配置域名解析，vim /etc/hosts ，写入：192.168.142.138 www.a.org。然后用浏览器访问www.a.org或用elink访问www.a.org。 配置完成第一个网站后可以继续配置第二个网站，mkdir /b.org，vim /b.org/index.html。创建b.org的网站配置文件，vim /etc/httpd/conf.d/b.org.conf。写入：(因为路径不在网页主目录下面，所以需要配置Directory选项，对目录进行授权) 1234567&lt;VirtualHost *:80\\&gt;ServerName www.b.orgDocumentRoot /b.org&lt;/VirtualHost&gt;&lt;Directory &quot;/b.org&quot;&gt;Require all granted&lt;/Directory&gt; httpd -t，检查服务器是否配置有错误，syntax ok表示没有语法错误。重启更新配置：systemctl restart httpd。客户端上需要配置域名解析，vim /etc/hosts ，写入：192.168.142.138 www.b.org。然后用浏览器访问www.b.org或用elink访问www.b.org。 动态站点 动态站点就是能够为用户提供交互的网站，动态页面通常可以通过网站后台管理系统对网站的内容进行更新管理。动态页面，上面的图片和文字都可以设置成变量。用后台程序给变量赋值，就能展示不一样的文字和图片。 安装LAMP(用mariadb代替MySQL，gd是图形库)：yum install -y httpd mariadb-server mariadb php php-mysql gd php-gd。 启动httpd和mariaDB，systemctl start httpd mariaDB。 开机自启：systemctl enable httpd mariaDB。 下载开源论坛源码discuz。wget 。。。。新建一个文件夹，并把压缩包解压进去。mkdir -p /webroot/discuz，unzip xxx.zip，cp -rf upload/* /webroot/discuz/，给Apache授权，chown -R apache.apache /webroot/discuz。 vim /etc/httpd/conf.d/discuz.conf。写入： 1234567&lt;VirtualHost *:80\\&gt;ServerName www.discuz.comDocumentRoot /webroot/discuz&lt;/VirtualHost&gt;&lt;Directory &quot;/webroot/discuz&quot;&gt;Require all granted&lt;/Directory&gt; httpd -t，检查服务器是否配置有错误，syntax ok表示没有语法错误。重启更新配置：systemctl restart httpd。 准备数据库：命令行输入mysql进入数据库，输入exit退出数据库。create database discuz; show database; \\q退出。 添加域名解析，vim /etc/hosts ，写入：192.168.142.138 www.discuz.com。然后用浏览器访问www.discuz.com，出现discuz的安装向导，然后一步一步安装discuz，同意，全新安装，配置数据库（localhost,discuz,root,没有密码，创建站长帐号） 扩展：命令行输入history可以查看之前敲过的命令。 架设站点 真实架设站点只需要购买一台可以运行Linux系统的云服务器，其他配置都一样。开启Apache服务，下载网页模板源码，解压放入网页默认主目录，授权，安装。 注册一个域名，添加域名记录，设置主机名，测试，域名备案。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://wht6.github.io/categories/Linux/"}],"tags":[{"name":"网站搭建","slug":"网站搭建","permalink":"http://wht6.github.io/tags/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/"}]},{"title":"Linux文件服务","slug":"Linux文件服务","date":"2021-11-13T02:00:00.000Z","updated":"2022-03-20T01:49:46.831Z","comments":true,"path":"posts/57c3.html","link":"","permalink":"http://wht6.github.io/posts/57c3.html","excerpt":"","text":"FTP FTP（File Transfer Protocol，文件传输协议）是一个应用层协议，用于文件服务。 FTP在Linux中对应的软件包是vsftpd。控制端口：21，数据端口20，基于tcp。 安装vsftp，yum -y install vsftpd。 准备分发的文件。touch /var/ftp/abc.txt。（FTP服务器的主目录：/var/ftp，是FTP程序分享内容的本机目录。） 启动FTP服务。systemctl start vsftpd。设置为开机启动：systemctl enable vsftpd。 然后把防火墙关闭。systemctl stop firewall是临时关闭防火墙，开机会还原。systemctl disable firewall是禁用防火墙，开机不会还原。可以用systemctl status firewall查看防火墙的状态。selinux是安全内置防火墙，临时关闭使用setenforce 0，永久关闭vim /etc/sysconfig/selinux修改SELINUX为disabled。 客户端访问FTP的方法一：通过浏览器来访问FTP服务器，输入ftp://192.168.43.129。 客户端访问FTP的方法二：安装lftp。yum -y install lftp。安装之后，lftp 192.168.43.129访问ftp服务器，ls查看文件。下载文件：get abc.txt，下载目录：mirror pub（下载位置都是当前目录）。上传文件：put 55.txt，将当前目录的55.txt上传到FTP服务器上，但是这里上传必须有上传的权限，否则无法使用上传功能。 通过FTP下载文件的方法三：wget ftp://192.168.43.129/abc.txt。wget ftp://192.168.43.129/abc.txt -O /home/444.txt，-O表示另存为。wget -m ftp://192.168.43.129/pub，这里m意识是mirror，表示下载文件夹。 FTP服务器允许上传。首先备份配置文件：cp /etc/vsftpd/vsftpd.conf /tmp/。 配置文件中，anonymous_enable=YES表示开启匿名访问，即不用输入用户名和密码。anon_upload_enable=YES表示开启文件上传功能，anon_mkdir_write_enable=YES表示启动创建目录的能力。创建上传目录：mkdir /var/ftp/upload，chmod 777 /var/ftp/upload。 上传之前需要先登录，然后cd到upload文件夹，然后put 234.txt，234.txt在客户端的当前目录。（如果要上传目录用） NFS NFS（Network File System，网络文件系统），NFS的客户端主要是Linux，支持多点同时挂载以及并发写入。NFS是NAS的一种。 举例一个NFS的应用场景，比如，一个web服务器，本来是一台主机，但是由于访问量太大，我需要多个主机来同时承载这个web服务器，将用户解析到不同的主机做一个负载均衡。那么每个主机上都要有同样的网站资源，但是当我要修改web资源的时候我就要同时修改多个主机，主机多的时候会很麻烦。NFS支持多点挂载，你可以将这些主机全部挂载到一个NFS服务器上，把所有的资源都放到这个NFS服务器上，提供web服务的主机通过NFS服务器获取web资源，再提供给访问web的用户。相当于对多台web服务器的一个集中式的管理。 搭建NFS服务器。第一步：安装NFS，yum -y install nfs-utils，创建一个发布资源的目录，mkdir /webdata，放置一个测试页面，echo “nfs test…” &gt; /webdata/index.html。第二步：配置NFS，修改NFS的主配置文件，vim /etc/exports，写入/webdata 192.168.142.0/24(rw)，公开webdata目录，给这个网段读写的权限（一般正常情况下只会给ro权限，也就是指读权限，不会给web服务器写的权限）。第三步：启动NFS服务器，systemctl start nfs-server，systemctl enable nfs-server设置开机自启。 检查NFS服务器的输出目录，exportfs -v。 创建NFS客户端。安装NFS客户端，yum install -y nfs-utils httpd，这里安装htttpd是搭建一个web服务器，查看NFS服务器所共享的目录，showmount -e 192.168.142.133，手动挂载，mount -t nfs 192.168.142.133:/webdata /var/www/html，(如果要取消挂载，umount /var/www/html)，查看挂载，cat /var/www/html/index.html或者输入df命令查看。 扩展：用shell测试一个web服务器是否能够访问，安装elinks，然后elinks http://192.168.142.133。 测试，浏览器访问web服务器，查看多个web服务器的内容是否一致，然后修改NFS的index文件，刷新浏览器的web页面，查看数据是否同步。 SSH SSH是一个远程管理工具，使用的方法，直接在命令行输入（ssh 账户名@IP地址）：ssh root@192.168.142.132。以root身份远程登录192.168.142.132这个主机，需要输入root密码。 查看ssh是否安装：rpm -qa | grep ssh，如果没有安装ssh，安装，yum install -y openssh-server。启动：systemctl start sshd。开机启动：systemctl enable sshd。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://wht6.github.io/categories/Linux/"}],"tags":[{"name":"文件系统","slug":"文件系统","permalink":"http://wht6.github.io/tags/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"}]},{"title":"Linux网络管理","slug":"Linux网络管理","date":"2021-11-11T02:00:00.000Z","updated":"2022-03-20T02:00:09.157Z","comments":true,"path":"posts/f714.html","link":"","permalink":"http://wht6.github.io/posts/f714.html","excerpt":"","text":"Linux网络配置 传统上，Linux网络接口被枚举为eth0、eth1、eth2，eth表示以太网。现在的命令规则是以太网以en开头，WLAN接口以wl开头，WWLAN接口以ww开头，接着下一个字符表示适配器的类型，o表示板载，s表示热插拔，p表示PCI。 /etc/sysconfig/network-scripts目录中是关于网卡的配置文件。（扩展：如果网卡配置文件未没保存就异常退出，这时候会导致网卡不工作，原因是系统自动为你创建了一个备份文件.swap文件，这是个隐藏文件，你需要ls -a去查看到，然后rm -rf删除之。） 网络管理器（NetworkManager）是一个动态网络的控制器与配置系统，作用是当网络设备可用时，保持设备和连接开启并激活。systemctl status NetworkManager是查看NetworkManager的运行状态，network是NetworkManager的一个子程序，查看network的状态用systemctl status network。 查看主机上的所有网卡：nmcli device。n是网络，m是管理。 用命令打开网卡配置的图形界面：nm-connection-editor，简易图形界面：nmtui。 在配置网卡的时候先备份一下，cp /etc/sysconfig/network-scripts/ifcfg-ens33 .，备份到当前目录。 配置网卡ens33，ONBOOT表示是否启动该设备，如果为no表示禁用该设备。BOOTPROTO表示启动的协议，协议有三种情况，dhcp自动、none手动和static静态，dhcp：dynamic host configuration protocal。IPADDR、NETMASK表示手动配置IP地址和子网掩码。GATEWAY表示手动配置网关地址。DNS表示域名服务器地址（正常是DNS1=xxx，DNS2=xxx）。NAME是网卡的名字。UUID是网卡的ID。 查看IP。ip a。 查看主机名。hostname。 配置主机名。hostnamectl set-hostname wht.example.com，主机名是写在文件/etc/hostname中的，所以也可以用vim /etc/hostname来修改主机名。配置之后重启生效。 查看网关。ip route。 查看邻居。ip neigh。 查看服务端口号。ss -tnl。t是tcp，n是number，l是list。 扩展：systemctl stop firewall是临时关闭防火墙，开机会还原。systemctl disable firewall是禁用防火墙，开机不会还原。可以用systemctl status firewall查看防火墙的状态。selinux是安全内置防火墙，临时关闭使用setenforce 0，永久关闭vim /etc/sysconfig/selinux修改SELINUX为disabled。 扩展：安装一些常用工具，上传下载工具lrzsz。sysstat。elinks。wget。net-tools。bash-completion。 扩展：IP地址可以看做是总地址、全球地址，Mac地址可以看做是分段地址，局部地址。应用层数据：APDU，传输层数据：segment，网络层数据：packet，数据链路层数据：frame，物理层：bit DU。 交换机和路由器配置 下面以CPT（Cisco Packet Tracer）为例，介绍交换机2960的配置过程。 VLAN（虚拟局域网），配置的方法是首先创建VLAN，VLAN的序号是0~1024。直接输入命令VLAN 10就创建了一个序号为10的VLAN。然后是接口与VLAN关联，F0/1~F0/10 VLAN10，表示将接口F0/1~F0/10加入VLAN 10。 具体步骤：enable进入特权模式(exit退出)，config t进入配置模式(exit退出)，VLAN 10创建VLAN，interface fastethernet0/1(简写int f0/1)进入接口，switch access VLAN 10将接口加入VLAN。特权模式下show vlan可以查看vlan。（扩展：一个从未创建vlan的交换机连接的所有主机默认属于VLAN 1。） VLAN如果需要跨越交换机，需要设置trunk(干道)，truck是连接两台交换机的一条线缆，需要将线缆两端的接口配置为trunk口，trunk可以识别帧中的vlan标签，发送到确定的vlan。配置：int f0/3，然后switch mode trunk。扩展：vlan标签只存在于trunk线路，从交换机的trunk口出加vlan标签，进入一台交换机的turnk口，先识别vlan标签，再去除vlan标签。 为什么需要网络层，只有物理层和数据链路层行不行？不行，原因是对于小的网络可以，但是网络一旦大了，广播域也会很大，交换机是透明的，如果有两万台主机，就相当于这两万台主机直接相连，同样也会有两万个mac地址，这带来了另一个问题，寻址不便，因为mac地址不是结构化的地址，想要所有的主机互联互通，就需要交换机的交换表存两万个地址。除此之外，还有安全问题，因为网络没有隔离，当然还有路由的问题，这么大的网络我的数据包怎么传过去也是个问题。 路由器需要给接口配置本网段IP地址，路由器接口默认不通电，需要手动打开。命令行输入show ip route查看路由表。 添加静态路由信息：ip route 192.168.2.0 255.255.255.0 f0/1。 扩展：虚拟机的网络配置 虚拟机的网络，配置方法，首先在外边将虚拟机的网卡设置为NAT模式，然后虚拟机里边网卡设置为dhcp，获取ip后查看并记住这个IP和网关，然后更改网卡配置为静态IP，并设置成刚才dhcp设置的那个IP，再重启虚拟机的网络，ping网关测试。所有虚拟机都能通信之后，在你的真机上重启NAT模式的虚拟网卡，让他重新获取一个地址。 真机上的虚拟机网卡代表的是真机的虚拟网络，注意此时，真机自己的硬件网卡会有一个不同的地址，并与这个虚拟网卡不在同一个网段。虚拟机会虚拟出一个虚拟的网关，这个网关可以共享主机的网络，但是没有网卡对应，也就是看不到，这个虚拟的网关就是你的虚拟机的网关。默认的NAT模式的虚拟网卡是vmnet8，这个vmnet8会同时虚拟出多个网卡，你有几个虚拟机就虚拟出几个网卡，同时为你的真机也虚拟出一个网卡，这些网卡都连接到一个看不见的NAT网关上，所以这些虚拟出来的网卡全部在一个网段中就对了。 扩展：虚拟机复制粘贴失败，vmware tools灰色的解决方法。在虚拟机设置的CDDVD中映像文件选择vmware安装路径中自带的linux.iso文件，在虚拟机中重新挂载dev中的cdrom，因为只能以只读的方式挂载，所以要把压缩包复制出去在解压，然后运行里面的pl文件重新安装vmware tools。 域名解析 hosts文件：Linux：/etc/hosts，Windows：C:\\Windows\\System32\\drivers\\etc\\hosts。hosts文件是Linux系统上一个负责ip地址与域名快速解析的文件，hosts文件是DNS没出现之前就已经使用的方式。 优先级：DNS缓存&gt;hosts文件&gt;DNS服务。DNS缓存在内存中，关机就没。 配置DNS服务器地址，可以在 /etc/sysconfig/network-scripts/ifcfg-ens33里面配置，也可以在/etc/resolv.conf配置（真正起作用的是/etc/resolv.conf）。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://wht6.github.io/categories/Linux/"}],"tags":[{"name":"网络配置","slug":"网络配置","permalink":"http://wht6.github.io/tags/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"}]},{"title":"Linux日志管理","slug":"Linux日志管理","date":"2021-11-05T02:00:00.000Z","updated":"2022-03-20T01:52:18.895Z","comments":true,"path":"posts/5580.html","link":"","permalink":"http://wht6.github.io/posts/5580.html","excerpt":"","text":"日志进程rsyslog日志概念 rsyslogd是系统专职日志程序，它会处理绝大部分的日志记录，也会记录操作系统有关的信息，如登录信息、程序启动关闭信息、错误信息。 除了系统自带的rsyslog，有些应用程序是可以自己记录自己的日志的，比如httpd、MySQL、nginx等。 扩展：有点程序后面会带一个d，这个d是deamon，这个程序通常持续运行，不会运行结束，即不会自动退出系统，需要人为手动停止。 日志文件 系统主日志文件：/var/log/messages。messages文件里面每一行是一段日志，分为若干个字段，第一个字段是日期和时间，第二个字段是主机名，第三个字段是消息，也就是具体发生的事件。扩展：tail -f /var/log/messages，-f表示锁定文件尾部，并动态展示，也就是实时更新查看的文件，和watch命令相似。 /var/log/secure是安全日志，/var/log/yum.log是YUM日志，/var/log/maillog是邮件日志，/var/log/cron是crond和at进程产生的日志，/var/log/dmesg是和系统启动相关的日志。 rsyslog是系统默认安装的，如果rsyslog程序有问题，可以重新安装，yum install -y rsyslog logrotate。 启动rsyslog程序，systemctl start rsyslog.service。 rpm -q是查询软件包的安装情况，rpm -qa是查询所有安装的的软件包（a是all），rpm -ql rsyslog表示列出rsyslog产生的所有文件（l是list），rpm -qc rsyslog表示查看rsyslog的配置文件（c是config）。 /etc/rsyslog.conf是rsyslogd的主配置文件（关键），/etc/sysconfig/rsyslog是rsyslogd相关文件，定义属性，/etc/logrotate.d/syslog和日志轮转相关。 扩展：查看命令的使用方法，除了用命令+—help之外，还可以用man+命令，表示查看帮助手册。 修改rsyslogd的主配置文件，告诉rsyslogd的进程，什么日志应该放在哪里。vim /etc/rsyslog.conf，打开文件后找RULES规则，规则分为3个字段，第一个字段Facility是设备（设备是一类程序的统称，设备表示的是一类程序），.后边是第二个字段Level级别，表示事件等级，第三个字段是日志存放的位置（如果前边带一个-，表示异步执行）。如果有多个设备级别，中间用;隔开。如果级别位置是none，则不表示级别，代表排除该设备。*.info;mail.none;authpriv.none;cron.none /var/log/messages表示存放所有设备的info信息，但是排除后边的三个设备。 扩展：怎么查看一个程序属于什么设备，例如，grep Facility /etc/ssh/sshd_config。设备类型有SYSLOG（syslogd自身），AUTHPRIV（安全认证），CRON（任务计划），MAIL（邮件系统），USER（用户相关），DEAMON（后台进程），FTP（文件服务器），KERN（内核），LPR（打印机），LOCAL0 到 LOCAL7（用户自定义设备） Level级别从高到低：EMERG（紧急，致命），ALERT（报警，需立即处理），CRIT（致命行为），ERR（错误行为），WARNING（警告信息），NOTICE（普通重要的标准信息），INFO（标准信息），DEBUG（调试信息）。 如果你修改了rsyslogd的主配置文件，则需要重启程序，让程序重新加载配置。systemctl restart rsyslog。 日志轮转logrotate 日志记录了程序产生的各种信息，但是磁盘空间有限，为了节省空间和方便，日志文件通常需要按时间或大小等分成多份，删除时间久远的日志文件。日志轮转就是只记录最近一段时间的发生的事，系统会根据你的要求删除你不想要的日志。 日志轮转的主配置文件/etc/logrotate.conf，子配置目录/etc/logrotate.d/*，子配置目录用于自定义配置，方便管理。 日志轮转的主配置文件，全局配置：weekly表示按周轮转，rotate 4表示保留4份日志，create表示轮转后创建新文件，dateext表示以时间作为文件的扩展名，compress表示压缩，这些功能可以开启也可以关闭，关闭就是注释掉。include /etc/logrotate.d表示包含该目录下的子配置文件。具体文件配置：/var/log/wtmp里边放的是用户登日志，123456&#x2F;var&#x2F;log&#x2F;wtmp&#123; monthly minsize&#x3D;1M create 0664 root utmp rotate 1 &#125; 这是对单个日志文件的轮转规则配置的格式，这个表示日志文件wtmp按月且最小达到1M才轮转，create是创建新日志文件并设置文件权限，其中root是属主，utmp是属组，rotate 1表示只保留一份，具体文件配置的优先级高于全局配置。（扩展：有一个命令叫w，作用是查看用户的登录情况，可以看到登录的终端是bash还是gnome图形界面）（扩展：配置规则中可能出现的其他字段：missingok表示丢失不执行，notifempty表示空文件不轮转，maxsize 30k表示只要到了30k就轮转） 重新加载新配置。/usr/sbin/logrotate /etc/logrotate.conf，直接调用logrotate程序加载主配置。 轮转过程。先给原来的日志重命名，重命名的方法是在原文件名后面加一个时间戳，然后再新建一个和原文件同名的文件。然后根据规则删除不要的日志文件。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://wht6.github.io/categories/Linux/"}],"tags":[{"name":"日志","slug":"日志","permalink":"http://wht6.github.io/tags/%E6%97%A5%E5%BF%97/"}]},{"title":"Linux计划任务","slug":"Linux计划任务","date":"2021-11-02T02:00:00.000Z","updated":"2022-03-20T01:50:56.350Z","comments":true,"path":"posts/6b0e.html","link":"","permalink":"http://wht6.github.io/posts/6b0e.html","excerpt":"","text":"部署一些服务器的新功能或者进行一些维护，往往选在大半夜，因为这时候用户访问量低。但是也不能总是大半夜去干活，头发都干没了，所以任务计划的作用就体现出来了。 一次性调度执行 一次性调度执行用到的命令是at。 语法格式：at TIMESPEC。TIMESPEC示例：now +5min，从先开始往后5分钟。teatime tomorrow，teatime是16:00，明天的下午茶。noon +4day，第四天中午。5pm august 3 2022。4:00 2020-11-27。 使用方法：1）输入now +2min回车，此时进入了一个交互命令模式。2）输入2min后要执行的命令。useradd uuu回车。如果有第二条命令继续输入并回车。3）Ctrl+D，输入完毕，提交任务。 查询任务。输入atq查询。第一列是任务编号，第二列是时间，第三列是执行的用户。 循环调度执行 循环调度执行用到的命令是crontab，tab是table，意思是循环任务表，用于设置周期性执行的命令。该命令从标准输入设备读取指令，并将其存放于contab文件中，以供以后读取和执行。 可以用命令ps -aux | grep crond来查看是否crond程序是否运行，也可以用systemctl status crond.service查看crond程序是否运行。 计划任务的存储位置在/var/spool/cron目录下。 创建计划。crontab -e，为当前用户创建任务计划。这里会打开一个文件，在这个文件中编辑命令，一条命令占一行，编辑完成保存。每条命令的格式是五个时间字段加执行的命令。min(0-59) hour(0-23) day(1-31) month(1-12) week(0-6) command。这五个时间字段如果要省略就用*代替。 时间字段举例：5 1 15 3 *标识每年的3月15日1时5分都会执行，5 1 15 * *表示每月的15日1时5分都会执行，5 1 * * *表示每天的1时5分都会执行，5 * * * *表示每小时的5分都会执行。*/5 * * * *表示每隔5分钟执行一次。 查看任务计划表：crontab -l。 命令要写绝对路径，先用which查找命令的路径，如which ls，得到/usr/bin/ls，正确写法示例：*/5 * * * * /usr/bin/ls /tmp，表示每隔5分钟执行一次ls tmp，每次任务执行系统会给你发一封邮件，输入编号回车是查看邮件，邮件里边就是执行的输出。 时间字段举例：0 2 1,4,6 * *表示每月的1日4日6日的2点执行。0 2 5-9 * *表示每月的5日至9日的2点执行。* * * * *表示每分钟执行一次。0 * * * *表示整点执行。特别的：0 2 * * 5表示每周5的2点执行（周里边0和7表示周日），00 02 * 6 5表示6月每周五的2点执行。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://wht6.github.io/categories/Linux/"}],"tags":[{"name":"计划任务","slug":"计划任务","permalink":"http://wht6.github.io/tags/%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/"}]},{"title":"Linux软件安装","slug":"Linux软件安装","date":"2021-11-01T02:00:00.000Z","updated":"2022-03-20T01:49:28.472Z","comments":true,"path":"posts/6b92.html","link":"","permalink":"http://wht6.github.io/posts/6b92.html","excerpt":"","text":"RPM包管理 RPM Package Manager（原Ret Hat Package Manager，是一个递归缩写）。RPM包是二进制包，无需编译，可直接使用。缺点是无法进行个人设置，也就是无法修改。 命名格式：软件包名+版本号+发布平台+系统平台+文件后缀。zip-3.0-11.el7.x86_64.rpm，3.0-11是版本号，el7是发布平台enterprise Linux 7。 RPM包有两种管理工具，YUM工具和RPM工具。 YUM全称yellow dog updater modified，基于RPM包管理，能够从指定的服务器自动下载RPM包并且安装，能够自动处理依赖关系，并且一次安装所有依赖的软件包，无须繁琐地一次次下载安装。 YUM使用首先设置国内源，因为yum需要下载包，而Linux提供的是官方地址，下载慢，所以需要设置国内源。 目的：通知Linux服务器，通过本机的系统光盘获得软件包，并安装软件。说白了下面的操作是配置本地源。 首先找到YUM仓库配置目录，/etc/yum.repos.d/，这个目录中的文件都包含了YUM的下载地址。直接打包移除这些文件，tar -cvf repo.tar *，mv repo.tar /tmp。然后新建一个repo文件，vim /ect/yum.repos.d/dvd.repo，下面是文件中需要写入的内容。12345[dvd] name=dvd123baseurl=file:///mnt/cdrom gpgcheck=0 enable=1 方括号是库的名字，name是描述，baseurl是下载地址，file://表示从本机上找，/mnt/cdrom表示路径。gpgcheck是包校验，等于0表示关闭校验。enable=1表示开启该源。 将光盘连接到服务器上。准备文件夹，mkdir /mnt/cdrom。挂载光盘，mount /dev/cdrom /mnt/cdrom。(这里的这个光盘是centos的镜像文件，在虚拟机创建系统写入了虚拟光盘)挂载之后你会看到/mnt/cdrom下有一个Packages的文件夹，这个文件夹下有四千多个RPM包。 扩展：将挂载命令写入bashrc中实现开机自动挂载。用到的文件就是/root/.bashrc。这个文件是隐藏文件用ls -a才能看到。直接在这个文件最上边添加一条命令mount /dev/cdrom /mnt/cdrom。 用YUM安装httpd包，yum install -y httpd，-y表示自动yes，可以看到显示信息指名源是dvd。（-y之后可以跟若干个包名，那么这些包会一起安装） YUM重新安装。yum -y reinstall httpd。YUM升级安装，yum -y update httpd。yum -y update，后边啥也不跟，这条命令的作用是升级系统。 yum list httpd，列出httpd相关的包，只打yum list是列出仓库里的所有包。显示信息中最后一列表示包所在地库，如果这个包已经安装，那么前边会有一个@。 yum卸载。yum -y remove httpd。 RPM工具是系统自带的rpm包管理工具。RPM没有YUM好用。RPM不会自动去安装依赖。 rpm -ivh wget-1.14-15.el7.x86_64.rpm，i是install，v是可视，h是百分比，rpm不能用包的简称，也不会自动下载，所以你的主机上必须有这个包才可以安装。 rpm -q wget，-q表示查询是否已安装。 卸载。rpm -evh wget-1.14-15.el7.x86_64。 上面YUM是配置的本地源，但是有时候本地源没有就需要配置网络的上的源。 1）清理原有YUM配置。mv * /tmp。2）找到阿里巴巴开源镜像站官网配置，找centos和epel，里面一个wget获取repo的命令。3）下载YUM仓库。一共两个包一个基础包，centos-base.repo，一个扩展包，epel.repo。4）更新YUM，执行安装。yum makecache。查看安装的源，yum repolist。 源码包管理 源码包，source code，需要经过GCC，C++编译环境编译才能运行，可以进行个人设置，修改源码参数。缺点是配置复杂。 源码包命令格式：包名+版本号+压缩格式，如nginx-1.81.tar.gz。 下面以Tengine的安装为例。 下载Tengine包，解压。tar xf tengine-2.3.3.tar.gz。进入cd tengine-2.3.3。 配置。可以配置也可以不配置。用到./configure。具体配置命令：./configure —user=www —group=www —prefix=/usr/local/nginx，(最后是安装位置) 编译，将源码翻译成二进制语言。make。 安装。make install。 测试。如果开启了httpd先把它关了，因为它会和Tengine起冲突。systemctl stop httpd。运行主程序：/usr/local/nginx/sbin/nginx。访问验证：http://127.0.0.1（如果无法访问，关闭防火墙systemctl stop firewalld。）","categories":[{"name":"Linux","slug":"Linux","permalink":"http://wht6.github.io/categories/Linux/"}],"tags":[{"name":"包管理","slug":"包管理","permalink":"http://wht6.github.io/tags/%E5%8C%85%E7%AE%A1%E7%90%86/"}]},{"title":"Linux文件查找和压缩","slug":"Linux文件查找和压缩","date":"2021-10-30T02:00:00.000Z","updated":"2022-03-20T01:47:49.275Z","comments":true,"path":"posts/4f3f.html","link":"","permalink":"http://wht6.github.io/posts/4f3f.html","excerpt":"","text":"文件查找 Linux中有三个查找命令，which、find、locate。 which用于命令查找，比如which ls，which pwd等等（alias是一个给命令起别名的命令，可以用来创建快捷命令，比如alias ls=‘ls —color=auto -l’，alias shuijiao=’init 0’当你用which查找命令的时候，如果命令有别名也会显示别名）。 locate也可以用于查找文件，但是依赖数据库，locate 7788.txt，查找7788.txt这个文件，如果这个文件是新建的需要刷新数据库，updatedb，另外系统重启会自动刷新数据库。 根据文件名查找。find /etc -name ‘7755.txt’，在目录/etc下查找文件名为7755.txt的文件，（命令 路径 选项 描述）。主要是学这个选项，-iname表示不区分大小写。 根据文件大小查找。find /etc -size +5M，查找5M以上的文件。看文件的时候需要用ls -lh /xxx来显示，-h表示人性化显示。find /etc -size 5M，查找5M左右的文件。find /etc -size -5M，查找5M以下的文件。 根据目录深度查找文件。find / -maxdepth 3 -a -name ifcfg-en*，查找目录深度为3，并且名字开头是 ifcfg-en的文件，-a表示and。这个目录深度从/开始数，/是一级目录。 按属主和属组查找文件。find /home -user jack，查找属主是jack的文件，find /home -group hr，查找属组是hr的文件。 根据文件的类型查找文件。补充：-普通文件，l链接文件，b块设备文件，d目录文件。Linux中文件后缀和文件类型没有关系（但是Linux中文件后缀的作用是为了方便人为区分的，系统不认识后缀），Windows中是以文件后缀区分文件类型的。find /tmp -type f，查找普通文件（f代替-），find /dev -type b，查找块设备文件。 根据权限查找文件。find ./ perm 644，查找当前目录下权限为644的文件。find ./ perm 644 -ls，长格式看。（命令 路径 选项 描述 动作）动作默认是看（省略了-print），-ls是长格式看，-delete是删除。查找并复制就比较复杂，find /etc -name ifcfg* -ok -cp -rvf {} /tmp \\;，将找到的文件复制到/tmp中，-ok是连接符，\\;是结束符。找到后会询问你是否拷贝，需要输入yes。 文件压缩和解压 tar命令是Linux中打包压缩文件的方法，建议只针对目录。 语法结构：tar 选项 压缩包名称 源文件。 tar -cf etc.tar /etc，-c表示create，-f表示filename，这里后缀是为了帮助人区分这是一个打包文件，这个命令只是打包，并未压缩，因为没有用到压缩工具。（扩展：数数，ls -l | wc -l，数当前目录一共多少个文件，-l表示数行数） tar -czf etc.tar.gz /etc，-z表示gzip，gzip是一种开源的压缩包工具，这里的后缀也是为了方便人区分。 解压tar包，tar -xf etc.tar，x表示解压，f文件名。tar -xf etc.tar.gz。所有解压都是xf。 tar -cjf etc.tar.bz /etc，使用bzip2压缩工具。 tar -cJf etc.tar.xz /etc，使用xzip压缩工具。 压缩工具对比，速度由快到慢：gzip,bzip2,xzip，压缩比例由小到大gzip,bzip2,xzip。gzip最快，xzip压缩的压缩包最小。 tar -xf etc.tar.bz -C /tmp，解压到/tmp目录下，-C指定解压的目录，默认不写是当前目录。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://wht6.github.io/categories/Linux/"}],"tags":[{"name":"文件系统","slug":"文件系统","permalink":"http://wht6.github.io/tags/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"}]},{"title":"Linux磁盘管理","slug":"Linux磁盘管理","date":"2021-10-29T02:00:00.000Z","updated":"2022-03-20T01:48:58.962Z","comments":true,"path":"posts/9232.html","link":"","permalink":"http://wht6.github.io/posts/9232.html","excerpt":"","text":"磁盘简介 机械磁盘的一个扇区等于512个字节。 机械磁盘由盘片、磁头、盘片转轴和控制电机、磁头控制器、接口等部分组成。 SATA接口的磁盘在Linux中对应/dev/sda，/dev是设备文件目录，sda是一个文件，s代表SATA就是串口（SCSI），d代表disk磁盘，a表示第一块。第二块就是/dev/sdb，第三块就是/dev/sdc。 分区方式有两种：MBR和GPT。MBR支持的最大磁盘容量是2T，最多支持划分4个主分区。MBR叫主引导记录，位于磁盘最前边，记录分区的结构信息。GPT支持大于2T的硬盘，支持128个主分区。 管理磁盘查看磁盘分区 管理磁盘流程：分区（MBR或者GPT），格式化/文件系统Filesystem，挂载mount。形象比喻，磁盘是毛坯房，通过分区分成不同的隔间，通过格式化放格子柜，文件系统用来记录和管理这些格子，而挂载就是给房子加个门，不然进不去，系统给它分配一个文件夹。 查看磁盘。ll /dev/sd*。可以看到第一个字母是b，也就是文件类型是b，b代表block。 磁盘是用第3个字母区分的，abcdefg…，分区是第四个数字区分的，1234…，例如，/dev/sda2是磁盘sda的第二个分区。 第二种查看磁盘的方式。lsblk，列出块设备。 创建分区 启动分区工具。fdisk /dev/sdb。 进入回话模式。1）欢迎界面，n回车开始分区。2）问你是划分主分区还是扩展分区，p回车选择主分区。3）设置分区号。MBR分区只能划分四个分区。从小到大设置，方便理解。1回车。4）问你起始扇区的位置，每次默认都是从上个分区结束的地方开始划分，默认回车。【可以发现分区的时候并不是从0号扇区开始分的，而是从2048号扇区开始分的，因为前2048个扇区记录了MBR的信息】5）问你分区结束的扇区。可以写扇区号，但是没必要，有更简单的方法。直接写+2G回车，就是给分区分2G，它会自动帮你算扇区。6）告诉你完成了2G分区的记录，但未生效。w回车，表示确认保存分区信息并将分区列表写入磁盘，然后自动会退出分区工具。也可以继续n回车，表示继续进行分区。（没有分区的部分不能使用） 刷新分区表。partprobe /dev/sdb。 查看分区结果。fdisk -l /dev/sdb。lsblk。 创建文件系统 创建文件系统/格式化：mkfs.ext4 /dev/sdb1，mk是mask，fs是文件系统，ext4是一种文件系统的类型（扩展文件系统第四代）。微软的文件系统叫NTFS，早期是FAT16、FAT32。 块大小就是一个格子的大小，叫block，一个块=4096B。 挂载分区 mount -t ext4 /dev/sdb1 /mnt/disk1，-t是文件系统类型（可以省略，会自动识别系统文件系统类型），将sdb1挂载到/nmt/disk1目录下。/mnt/disk就是分区的门。 df -hT，查看是否挂载成功。d是disk，f是free，h是显示单位，T是显示分区类型。 /dev/sda是系统盘，默认挂载在/。我创建/mnt/disk1文件夹的时候，如果往这个文件夹中放东西，其实是放到sda系统盘里边，但是我把/dev/sdb1挂载到/mnt/disk1之后，再往这个文件夹中放东西就放到了磁盘sdb中，和sda没有任何关系。 目录结构是统一的，都是从/开始，但是实际的存储内容在真实的硬盘上，所以磁盘的挂载点可以放在任何一个文件夹，文件夹一旦被挂载，数据就会存储到相应的磁盘中。 fdisk属于MBR分区模式，最多划4个主分区，超过4个分区就要用到逻辑分区。单从存储文件上看主分区与逻辑分区没有区别，区别在于操作系统只能装到主分区上。 想要划分4个以上的分区，就要放弃一个主分区，一般选第四个分区，然后把它划分为扩展分区。但是扩展分区不存数据，需要再将扩展分区划分成N个逻辑分区。只有4个分区号，但是我想要更多的分区，我就必须把一个分区设置成扩展分区，再在扩展分区中划分逻辑分区。扩展分区是为了扩展用的，不能直接格式化挂载存数据，需要在里边划分逻辑分区。 按n，再按e，选择所有剩余空间划分成扩展分区。再按n，就直接问你逻辑分区的起始和结束了，这时候在设置逻辑分区。 逻辑分区也需要格式化挂载才能用。 umount /dev/sdb5 ，卸载分区。卸载之后可以再挂载到别的目录，因为不经过格式化所以文件还在。 如果一个目录里面本来有文件，这个文件是存在sda中的，如果把新分区挂载到这个目录，原来的文件就看不见了，新分区把sda给挤掉了。如果在把这个分区卸载了，原来的文件就又出现了，这是因为，这个目录又自动被sda挂载。也就是说一个目录只能被一个分区挂载。 上述挂载方式都是临时挂载，重启时候还要重新挂载。 逻辑卷LVM 普通的磁盘分区如果存满了，就无法向挂载到目录继续写入文件，而一个目录又无法挂载多个硬盘，也就是无法实现随意扩容，这在实际生产环境中可能是致命的。 逻辑卷LVM是一种磁盘管理方式，特点是可以随意扩容，相当于把磁盘变成了抽象的分区。 创建逻辑卷的流程：1）将物理硬盘变成物理卷。 2）将物理卷加入卷组。 3）在卷组中抽调空间，制作逻辑卷。 4）格式化。 5）挂载。 只要卷组中有空间，逻辑卷就能够从卷组中抽调空间进行扩充，如果卷组中没有空间了，就需要购买新的物理硬盘变成物理卷加入到卷组。 简称：物理卷（PV），卷组（VG），逻辑卷（LV）。 步骤：1）pvcreate /dev/sdf，创建物理卷。2）vgcreate vg1 /dev/sdf，vg1是卷组名，sdf是成员。3）lvcreate -L 4G -n lv1 vg1，-L是大小，-n是逻辑卷的名字，vg1是所属的卷组。4）mkfs.ext4 /dev/vg1/lv1，格式化逻辑卷lv1，/dev/卷组名/逻辑卷名，这是标准命名方式。5）mkdir /mnt/lv1创建一个文件夹，mount /dev/vg1/lv1 /mnt/lv1将逻辑卷挂载到目录。 pvs，查看所有物理卷，Fmt是版本，Attr是属性（a表示可用），PSize是大小，PFree是空闲 给卷组扩容。先创建pv：pvcreate /dev/sdg，给指定的卷组扩容：vgextend vg1 /dev/sdg。 vgs，查看所有卷组，#PV是物理卷的个数，#LV是逻辑卷的个数，VSize是卷组总的大小，VFree是卷组总的空闲。 给逻辑卷扩容。1）LV扩容。lvextend -L +4G /dev/vg1/lv1。2）刷新目录。resize2fs /dev/vg1/lv1，重置文件系统大小。 交换分区管理Swap Swap分区即交换分区，也是一种普通分区，只是在功能上有些特殊。交换分区的作用是“提升”内存的容量，防止OOM（Out Of Memory） 内存经常访问的数据会放入SWAP分区，这个行为是系统做的，人为是不干预的。相当于我把经常用的东西放到一起，方便我平时使用。 SWAP分区通常大小设置为内存大小的2倍。 free -m，查看SWAP分区。 更改一个分区为SWAP分区。进入fdisk工具，按p查看已有分区，按t更改一个分区的ID，（swap分区对应的ID是82，可以按L查看所有ID），输入82，按w写入保存。 partprobe /dev/sdc刷新，mkswap /dev/sdc1格式化交换分区，swapon /dev/sdc1挂载交换分区，free -m查看交换分区大小。 （这里其实不改分区的ID，只执行后面的格式化挂载操作也是可以的） swapoff /dev/sdc2，卸载swap分区。 文件系统文件系统 文件系统的类型：Windows：FAT16、FAT32、NTFS。Linux：EXT3、EXT4、XFS。这些都是索引（index）文件系统。 文件系统将磁盘分成一个个的小格子，这个小格子可以存也可以取，就像超市的储物柜。这个小格子叫块（block），每个块的大小是固定的4096字节，它的作用是存储文件的实际数据。 一个大于4k的文件在存储是会占用多个块，一般情况下是一个块不够，依次存储到后面的块。但是有一种情况是，有些块存储数据之后又擦除数据了，这时候空闲块的分布是不连续的，在去存储一个大文件是可能会导致这个文件在实际存储位置上不连续，这就是文件碎片。文件碎片就是同一个文件在存储在不连续的存储位置，但是文件碎片对于实际使用是没有影响的。 文件系统还需要一个东西去记录一个文件所有的块，它就是索引节点（inode）。每个文件有一个索引节点，一个inode的大小是128比特，它记录着文件的元数据（metadata），metadata就是文件属性，包括大小、权限、属主、属组、链接数、块数量、块的编号。 文件系统还有一个东西是超级块(superblock)，记录了块和索引的总量，以及未使用与已使用的inode和block数量。 每次使用mkfs.ext4命令格式化都创建了一个独立的文件系统，所以一台主机上往往不只一个文件系统。 观察一个文件的inode信息：ll -i file1.txt，文件属性中的第一个数字就是inode号。 查看一个分区可以存储inode的数量：df -i，Inode就是可以存储inode的总量。（ls -l | wc -l，查看目录下文件的数量）而inode的数量决定了文件存储到个数，只要文件个数满了，不论你的存储空间有没有占满都不能再新建文件了，但是只要block没有满就可以往已有的文件里继续写东西。 总结：磁盘空间的限制取决于两方面，inode和block，inode决定了文件的数量，block决定了文件的大小。 文件链接 软链接(symbolic link)，可以让我们快速的找到一个文件，Windows中叫快捷方式。软链接可以存在不同位置，通过访问软链接就能访问原来的文件（文件夹也是一样）。 ln -s /file1 /root/桌面/file11，ln就是link，-s是symbolic，/file1是原文件，/root/桌面/file11是file1的软链接。ll查看软链接的文件属性会发现文件类型是l。修改和查看软链接就是修改和查看原文件。 扩展（硬链接用的很少）：创建硬链接，ln /file2 /file2-h1，修改和查看硬链接同样是修改和查看原文件。但是硬链接与软链接的区别在于，如果删除原文件，软链接就没用了，读不到原来的文件内容，而硬链接还保留着原文件的内容，还可以读。可以针对目录做软链接，但是无法针对目录做硬链接。并且硬链接只能在同分区做。可以把硬链接看成文件同步。 RAIDRAID简介 磁盘损坏会导致数据丢失，这在生产环境中是很严重的问题，RAID的出现解决了磁盘损坏的数据丢失问题，因为RAID的一个重要功能是自动备份。 RAID除了自动备份之外，还能提升磁盘IO的读写速度。 RAID（独立磁盘冗余阵列），类型上分为RAID0，RAID1，RAID5。 RAID0，2块以上磁盘，数据分成n份存储到n块磁盘中，速度提升，但是没有备份容错。 RAID1通常叫镜像集或镜像卷，2块磁盘，容量是50%。说白了就是一块磁盘是另一块磁盘的镜像。容错好，读写速度一般。 RAID5至少3块磁盘，数据分成n-1份分别放入n-1块磁盘中，剩余的一块磁盘放这n-1份数据的校验信息，如果一块数据盘损坏了，通过校验公式可以逆推出原数据。 扩展：热备盘，热备盘平时不放数据，当一块磁盘损坏的时候，热备盘会立即顶替上去。 总结：核心数据用RAID1，重要数据用RAID5，不重要的数据用RAID0。 RAID分为硬RAID和软RAID，硬RAID是需要RAID卡的，有自己的cpu，处理速度快，而软RAID是通过操作系统上的软件实现的。 软RAID5 创建RAID，mdadm -C /dev/md0 -l5 -n3 -x1 /dev/sd(b,c,d,e)，-C表示创建RAID，/dev/md0表示RAID设备，md0是起的名字，-l5表示RAID5（l是level的意思），-n表示RAID的成员数量，-x表示热备磁盘的数量。 格式化：mkfs.ext4 /dev/md0，挂载：mount /dev/md0 /mnt/raid5。拷贝数据：cp -rf /etc/ /mnt/raid5/etc1。查看df -hT。 查看RAID详细信息：mdadm -D /dev/md0。 模拟磁盘损坏。mdadm /dev/md0 -f /dev/sdb -r /dev/sdb，-f表示强制，-r表示移除。另开一个窗口，输入命令 watch -n0.5 ‘mdadm -D /dev/md0 | tail -10’可以查看RAID自动恢复的过程。然后再去查看文件，ls /mnt/raid5发现文件未丢失。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://wht6.github.io/categories/Linux/"}],"tags":[{"name":"磁盘管理","slug":"磁盘管理","permalink":"http://wht6.github.io/tags/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/"}]},{"title":"Linux管道和重定向","slug":"Linux管道和重定向","date":"2021-10-28T02:00:00.000Z","updated":"2022-03-20T01:48:25.668Z","comments":true,"path":"posts/f2cd.html","link":"","permalink":"http://wht6.github.io/posts/f2cd.html","excerpt":"","text":"重定向输出重定向 date，输出当前的时间。date &gt; time.txt，将date的输出重定向到文件time.txt中。 FD（file descriptor）文件描述符，也叫文件句柄。进程使用文件描述符来管理打开的文件。也就是说进程不是用文件名来识别文件的，而是通过FD来区分文件的。文件名还包含路径呢，又臭又长，哈哈！ FD是用数字表示的，范围是0-255。0、1、2非常特别，0是stdin，1是stdout，2是stderr。3-255都用来表示普通文件。 stdout是显示到显示器的终端，终端也是一个文件，像pts/0就是一个文件，在/dev/pts/0。 stderr也是输出显示，但是只输出错误。 stdin是标准输入，它也是一个文件。 总结：FD是访问文件的标识，即链接文件。省去了冗余的绝对路径。 新建一个文件，打开vim编辑文件，别关，然后新开一个终端，查看vim的PID，找到后再去/proc中找PID对应的文件，这里面有文件夹fd。比如pid是5912，ls -l /proc/5912/fd，发现里边有数字命名的文件，这些文件属性是l，表示链接文件（快捷方式）。（怎么创一个文件的快捷方式，命令：ln -s 原文件名 快捷方式名）键盘和显示器都指向终端pts/0，用012进行区分（如果输入echo 123 &gt; /dev/pts/0，123就输入到另一个终端中并显示）。 date 1&gt; /dev/pts/0，1&gt;表示将显示重定向到/dev/pts/0。 一个&gt;表示覆盖，不管原来文件中有没有内容都覆盖掉。&gt;&gt;表示追加。(1&gt;等价于&gt;，1&gt;&gt;等价于&gt;&gt;) 这里&gt;、1&gt;、&gt;&gt;、1&gt;&gt;都是调FD=1，标准输出文件，本来是要输出到屏幕上，但是通过&gt;重定向到另一个文件而不是stdout。 stderr错误输出，2&gt;和2&gt;&gt;。必须有错误输出才能重定向，也就是必须有错误写入stderr，才能重定向到其他文件中。 同时重定向标准输出和错误输出，使用&amp;&gt;进行重定向。ls /home /aaaaaa &amp;&gt; list.txt。ls /home是标准输出，ls /aaaaaa是错误输出，两个同时重定向到list.txt。如果要同时重定向到两个文件：ls /home /aaaaaa 1&gt; yes.txt 2&gt; no.txt。 生产环境中应用最多的：ls /home /aaaaaa &amp;&gt; /dev/null，/dev/null是黑洞文件，垃圾桶，回收站。 输入重定向 输入重定向：0&lt;或&lt;，两者等价。 举例，先新建一个文件，vim word.txt，将文件内容重定向到邮件中并发送：mail -s “ssss” alice &lt; word.txt（-s是邮件的标题）。然后切换到alice用户：su - alice，查看邮件：mail。 输入重定向目的是用文件内容来代替人为的输入。 cat &lt; /etc/hosts是可以的，也就是说cat /etc/hosts是省略了&lt;。 管道 进程管道piping。语法 command1 | command2 | command3 | …，”|”会将上一条命令的标准输出放入管道中，然后标准输入到下一条命令。 举例：cat /etc/passwd | grep “root” | head -1。 tee管道。当需要将中间的输出同时引导到文件中就用到了tee管道，可以理解为条命令的T型接口，一个三通管道。tee管道除了将输出输入到下一条命令，还会存一个副本，这个副本可以是文件，也可以输出到显示器上（stdout）。 举例：cat /etc/passwd | tee 888.txt | tail -1，保存cat的输出到888.txt，并将输出输入到tail -1中。 参数传递xargs，当前一条命令的输出是下一条命令的参数时就要用到 |xargs。 举例：touch /home/file{1..5}，创建5个文件。新建一个文件files.txt，vim files.txt，写入3个文件名：/home/file1 /home/file2 /home/file5。我想要利用cat files.txt | rm -rvf 来删除file1、file2、file5这三个文件是不成功的（v是可视的意思）。正确的删除方法是利用参数传递：cat files.txt |xargs rm -rvf。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://wht6.github.io/categories/Linux/"}],"tags":[{"name":"管道","slug":"管道","permalink":"http://wht6.github.io/tags/%E7%AE%A1%E9%81%93/"},{"name":"重定向","slug":"重定向","permalink":"http://wht6.github.io/tags/%E9%87%8D%E5%AE%9A%E5%90%91/"}]},{"title":"Linux进程管理","slug":"Linux进程管理","date":"2021-10-27T02:00:00.000Z","updated":"2022-03-20T01:48:06.293Z","comments":true,"path":"posts/630d.html","link":"","permalink":"http://wht6.github.io/posts/630d.html","excerpt":"","text":"进程管理概念 进程是已启动的可执行程序的运行实例，进程由以下组成部分：一个文件；被分配内存的地址空间；有权限限制；程序代码的一个或多个副本（也叫执行线程）；像人一样拥有状态。 所以进程除了文件之外还要由系统分配内存资源和cpu资源，单核的cpu一次只能处理一个进程，但是cpu使用时间分片技术，使得许多程序看起来像一起运行，这个cpu资源就是cpu分配的时间片资源。还有可能需要占用网络资源，因为所有的通信数据都要经过网卡发送，网卡是有带宽的。 在Linux中，每个进程都有自己的进程号PID。 静态查看进程ps ps（process status）进程状态管理器。 ps aux，查看进程。ps aux | head -2，只看头两行。（a是all，显示所有的程序。u是user，以用户为主的格式来显示程序状况。x表示不以终端划分。） USER（运行进程的用户） PID（进程ID） %CPU（cpu占用率） %MEM（内存占用率） VSZ（占用虚拟内存大小） RSS（占用实际内存大小） TTY（进程运行的终端） STAT（状态） START（进程启动时间） TIME（进程占用CPU的总时间） COMMAND（进程文件，进程名称） 父进程复制自己的地址空间（fork）创建一个新的（子）进程结构。任何进程都可以创建子进程。所有进程都是都是第一个系统进程的后代。 进程的生命周期： 由系统程序，fork出来的子程序，其具备一定父进程的资源（权利，内存空间，PID），直到运行完毕，退出系统。1、exec执行进入running运行状态，2、exit推出进入dead状态，3、程序不使用的（wait）时候进入sleeping状态，4、无法退出进入zombie状态僵尸进程。 进程的状态，主进程fork子进程，子进程获得系统资源之后就进入了run状态（R）。此时如果暂停进程，进程就进入stop状态（T）。进程未被使用将进入sleeping状态（S）。如果进程退出失败会进入zombie状态（Z）。 TTY是？表示本机打开的，没有终端。如果是远程登录，那么这个终端名是pts，pts的含义是虚拟终端。 排序。ps aux —sort %cpu，根据cpu占用率升序排序。ps aux —sort -%cpu，根据cpu占用率降序排序。 查看进程的父子关系。ps -ef。其中STIME是启动时间，PPID是父系程序的PID。PID=1的是系统进程，操作系统自身。有时候子进程杀不死可以杀死父进程来间接杀死子进程。 只查看部分字段。ps axo user,pid,ppid,%mem,command | head -3 ，其中的o表示自定义显示列。 动态查看进程top 查看动态进程。输入top，回车。 top的显示结果分为两部分，性能部分和进程状态部分。 第一行：top（程序名） - 08:56:29（系统时间） up 1 day, 17:10,（运行时间） 2 users,（登录用户数） load average（CPU负载：1分钟内，5分钟内，15分钟内）: 0.29, 0.14, 0.08 第二行：Tasks: 202 total（总进程数）, 3 running（运行数）, 199 sleeping（睡眠数）, 0 stopped（停止数）, 0 zombie（僵死数） 第三行：CPU占用率。%Cpu(s): 8.9 us（用户占用）, 4.4 sy（系统占用）, 0.0 ni（优先级占用）, 86.3 id（空闲）, 0.0 wa（CPU等待时间）, 0.0 hi（硬件占用）, 0.3 si（软件占用）, 0.0 st（虚拟机占用） 第四行：KiB Mem（内存） : 3060060 total（总量）, 456320 free（空闲）, 894136 used（使用）, 1709604 buff/cache（缓存硬盘内容） 第五行：KiB Swap（虚拟内存）: 3145724 total, 3145724 free, 0 used. 1926856 avail Mem 进程状态部分：VIRT（申请的内存） RES（实际占有的内存） SHR（共享的内存） S（状态） TIME+（占用时间）PR（系统优先级）NI（nice优先级） 按z设置彩色，&lt;&gt;向前翻页和向后翻页，q退出，p按CPU排序，m按内存排序。 top -d 3表示每3秒刷新一次。（top默认是每秒刷新一次） top -p 2160 只显示PID为2160的这一个进程的实时状态信息。 使用信号控制进程 kill -l，查看所有的信号。 1）SIGHUP 重新加载配置。2）SIGINT 键盘中断Ctrl+C。3）SIGQUIT 键盘退出Ctrl+\\，类似SIGINT。20）SIGTSTP 键盘暂停Ctrl+Z。9）SIGKILL 强制终止，无条件。15）SIGTERM 终止（正常结束），缺省信号。19）SIGSTOP 暂停。20）SIGCONT 继续。 这里除了用快捷键发信号的，别的用kill加信号的编号。比如，kill -9 9305，就是强制终止PID为9305的程序。缺省表示-15。 tty，显示当前窗口的终端名称。 free -m，以M为单位查看内存大小。 进程优先级nice 系统会给每个进程分配一个默认的优先级，优先级高的进程获得更多的资源。 优先级nice值得范围是-20~19，一共40个数。nice值越大，优先级越低。 系统优先级的范围是比nice值得范围要大，也就是说可以人为调整的优先级只是系统优先级的一部分。nice值0对应系统优先级20，也就是nice优先级的值需要加20才能和系统优先级一样。系统优先级中优先级大的一部分人为是无法调整的。 ps axo pid,command,nice —sort=-nice，查看nice，并根据nice排序。NI就是nice值。 启动程序时修改nice值。sleep是一个休眠工具，sleep 5表示休眠5s。sleep 6000 &amp;，表示休眠工具在后台运行，不占用前台。输入命令：nice -n -5 sleep 7000 &amp; （-n就是nice值得意思），表示启动sleep工具并设定优先级为-5。 直接修改进程的nice值。renice -20 2033，修改PID为2033的进程的nice值为-20。 通过top也可以查看进程的优先级，PR是系统优先级，NI是nice优先级。 作业控制 作业控制是一个命令行功能，也叫后台运行。作业指的就是后台进程。 前台进程：是终端中运行的命令，占领终端。后台进程：没有控制终端，它不需要终端的交互，看不见，但是在运行。 sleep 3000 &amp;，这里&amp;的作用就是将进程调到后台运行。 jobs，查看后台正在运行的程序。第一列是后台进程序号，旁边+表示最新的，-表示最老的。 fg 4，将序号为4的job调到前台运行，bg 4，将序号为4的job调到后台运行。 Ctrl+C是直接终止一个程序，Ctrl+Z是暂停程序。 kill %4，终止序号为4的job。 虚拟文件系统 /proc是/下的一个文件夹，proc是process的简写。proc里面存储的都是和进程有关的文件。每个进程在这里都有一个文件夹，文件夹的名称就是PID。 proc叫虚拟文件系统，作用是采集服务器自身、内核、进程运行的状态信息。 /proc/cpuinfo存储着cpu的参数，可以通过cat直接查看cpu的信息。 /proc/meminfo存储着内存的参数，cat查看内存信息。 /proc/cmdline存储着内核的信息，cat查看。内核文件在/boot里面。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://wht6.github.io/categories/Linux/"}],"tags":[{"name":"进程","slug":"进程","permalink":"http://wht6.github.io/tags/%E8%BF%9B%E7%A8%8B/"}]},{"title":"Linux用户权限","slug":"Linux用户权限","date":"2021-10-25T02:00:00.000Z","updated":"2022-03-20T01:47:14.890Z","comments":true,"path":"posts/187d.html","link":"","permalink":"http://wht6.github.io/posts/187d.html","excerpt":"","text":"基本权限UGO更改权限 权限的两个基本要素：权限对象和权限类型。 权限的对象有三类：u：用户，g：组，o：其他人。还有一个特殊对象a：all所有人。a=u+g+o。 权限的类型有三种：读：r=4，写：w=2，执行：x=1。在配置权限的时候可以用数字代替字母。u=7代替u=r+w+x，u=6代替u=r+w，u=5代替u=r+x。 授权时可以用符号授权，也可以用数字授权。 chmod u+r 1.txt，chmod是命令，中间是对象（u/g/o/a）赋值符（+/-/=）权限类型（r/w/x），最后是文件或目录（对目录下的所有文件授权需要加-R选项）。 ll是查看文件属性详细信息的，如下：-rw-r—r—. 1 root root 0 10月 23 16:39 file1。 这个文件属性一共分为7段。第一个字段是类型和权限（11个字符），除去第一个字符（文件类型）与最后一个字符，剩下的9个字符分为三组，三个字符一组分别是属主u，属组g，其他人o。三个位置的字符分别对应rwx，如果某个位置是-，说明没有此权限。rw-r—r-表示主人可以读和写，组只能读，其他人也只能读，至于是哪个主哪个组在后边的字段中。 第二个字段是文件链接的次数，链接就是创建快捷方式。 第三个字段是属主。第四个字段是属组。与第一个字段中对应起来就是root拥有读和写的权限，root组只能读，其他人也只能读。 第五个字段是文件的大小，单位是字节B。第6个字段是创建时间，第7个字段是文件名。 chmod u=rx file1与chmod u-x file1，这两条命令中的含义是分别是为用户赋予读和执行的权限，对用户移除执行的权限。 查看目录权限：ls -l -d /tmp/，查看目录的权限需要加-d选项，否则看到是目录里面的内容。 清空权限：chmod a=- file1，一次性给ugo赋权：chmod ug=rw,o=r file1。 更改属主和属组 chown user02 /tmp/file1.txt，只更改属主 chown user01.hr /tmp/file1.txt，同时更改属主与属组。 chown .user02 /tmp/file1.txt，只更改属组。 文件夹也可以授权，操作是一样的。但是如果要同时对文件夹下面的所有内容一块赋权，需要加-R，如：chown -R user01.hr /tmp/dir2020/。-R递归。 基本权限ACL ACL（Access Control List）访问控制列表，限制用户对文件的访问，是对UGO的补充，或者说加强版。 setfacl，f指代file。 setfcal -m g:hr:rwx /home/file1，设置文件访问控制 -设置 对象:对象名:权限 文件 getfacl /home/test.txt，查看文件的访问控制。 给文件设置ACL之后，在查看文件详细属性，会发现第一个字段的最后一个字符由.变成+，这里的+就表示出来UGO基础权限，该文件还有附加权限。而且设置ACL之后，中间的9个ugo权限字符就显示的是叠加权限。 setfacl -m o::rw /home/test.txt，给其他人设置读和写的权限。 清除acl权限。setfcal -x u:alice /home/test.txt。 清空所有ACL权限。setfacl -b /home/test.txt。 tip：反复输出结果。watch -n1 ‘ls -l /home/file1.txt’，每隔一秒输出一次引号中命令的结果，用此命令来查看文件权限的变化。 特殊权限特殊位suid suid是一个针对文件设置的权限，功能是使调用文件的用户，临时具备属主的权限。suid也是权限像rwx那样，不过它是一个特殊权限，加上这个权限之后，调用文件的用户就临时具备了属主的权限。 通过一个案例来了解suid功能是怎么生效的。首先在/root下新建一个file1.txt，随便写入一些内容。普通用户是无法通过cat来查看文件内容的，/root也进不去。cat是一个应用程序文件，位置在/usr/bin/cat，我们通过ll查看该文件的详细信息可以看到cat的权限是：rwxr-xr-x，所有用户都有执行的权限，但是执行的身份不一样导致有些文件只有管理员能运行，而普通无法执行。接着，用suid对cat进行设置，chmod u+s /usr/bin/cat，文件权限变为：rwsr-xr-x，此时普通用户就临时具备了管理员身份，也就是普通用户临时提权。经过suid设置之后，普通用户就可以通过cat来查看/root/file1.txt。 通过chmod u-s /bin/usr/cat来去除siud权限。 文件属性attr chattr用于配置文件的属性，其中i属性表示不能更改、重命名或删除，相当于把文件锁上了。 lsattr用于查看文件的属性。 chattr +i file100，给file100配置i属性，配置以后文件不能更改、重命名和删除。 chattr -i file100，去除file100的i属性。 出来i属性，还有许多别的属性，比如a属性表示只能对文件进行追加操作。通常会给日志加a属性。 进程掩码umask 新建文件、目录的默认权限都会受umask的影响，umask表示要减掉的权限。 输入umask命令，查看当前用户的umask权限。然后你会发现是四个权限位，这里其实才是完整的权限位，完整的权限位：特殊位，属主位，属组位，其他位。（特殊位里边的421并不表示rwx，其中的4就是suid。） root用户，输入umask，结果是0022，这个0022就是root的umask，但是真正的默认权限并非0022，真正的默认权限的计算方式是0777-umask，也就是0777-0022=0755。所以在创建目录和文件的时候默认权限是755，但是我们看到文件默认是644，这是因为系统为了保护自己去掉了所有的执行权限。 umask 0000，表示将进程掩码修改为0000，此时再创建文件默认权限就变成了0777和0666。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://wht6.github.io/categories/Linux/"}],"tags":[{"name":"权限管理","slug":"权限管理","permalink":"http://wht6.github.io/tags/%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/"}]},{"title":"Linux用户管理","slug":"Linux用户管理","date":"2021-10-24T02:00:00.000Z","updated":"2022-03-20T01:47:33.235Z","comments":true,"path":"posts/e894.html","link":"","permalink":"http://wht6.github.io/posts/e894.html","excerpt":"","text":"Linux用户/组基本概念用户基本信息文件passwd head -1 /etc/passwd，查看passwd的第一行。输出结果是root:x:0:0:root:/root:/bin/bashpasswd是一个7列的表格数据，用:来分割每一列。passwd中的每一行是一个用户的信息，每一行一共七个字段，这7个字段分别表示——用户名：x：uid：gid：描述：HOME：shell。其中x是密码占位符（具体的内容在另一个文件中），uid是用户的身份证号（系统约定 uid:0是特权用户，uid:1~499是系统用户，uid:1000+是普通用户），gid是组号。描述是补充一些用户信息，或起到说明的作用。HOME是家目录，也就是用户登录的时候所在的目录，管理员的家目录在/root，普通用户的家目录在/home/xxx。/bin/bash是登录shell命令解释器，如果是/sbin/nologin指的是不允许登录shell。用户密码信息文件shadow /etc/shadow存放的是用户的密码，也是每行一个用户，每一列用：隔开。 第一个字段依然是用户名，第二个字段是用户密码加密后的密文。密文中的前几个是有含义的，比如$6$DBd，$6$开头的，表明是使用SHA-512加密算法进行加密，$1$是MD5，$2$是Blowfish，$5$是SHA-256，也就是实际从第四位开始才是密文。 第三个字段是最后一次修改时间，单位是天，起始时间是1970.1.1。 第4个字段是最小间隔，第5个字段是最大时间间隔，这里的时间间隔指的是密码有效期，99999代表有效期无限。对于安全性要求高的系统，密码的最大时间间隔是很小的，比如有的系统需要一天修改一次密码。这个最小间隔指的是两次密码修改需要间隔的最小天数，0表示当天就可以修改，3表示这个密码3天后才能再次修改。 第6个字段是警告时间，比如7就是还剩7天的时候警告你该修改密码了。第7个字段是不活动时间，比如28表示你连着28天不登录系统就把你的账号给禁了。第8个字段是失效时间，比如30表示你这个账号的寿命就是30天，到了30天就不能用了。第9个字段是保留字段。用户组信息文件 /etc/group存放的是用户的组信息，每一行表示一个用户，冒号分割列，每一行4个字段。 这4个字段分别是组名：组密码：组ID：组成员。 系统在创建用户的时候，同时也会创建一个与用户同名的组。 同一个组里的用户具有相同的权限。 用户/组管理用户管理 创建用户。useradd user01，创建用户user01。id user01，查看user01的id信息。passwd user01，修改用户密码。创建用户之后，/var/spool/mail/下会多出一个文件user01。 删除用户。userdel -r user01，删除usesr01，-r表示将user01的家目录一块删除。 修改密码。passwd 修改自己的密码。passwd user01，修改用户密码，一般只有root才能修改别的用户的密码。 将用户加入组。 修改用户属性。usermod -s /sbin/nologin user03，该命令的作用是禁止user03登录shell，-s指的是shell。实际情况是系统直接登录不进去了。 组管理 组是为了方便统一管理用户权限而设定的具有具有特定权限的群组，用户加入组就获得了相应的权限，离开组就失去了对应的权限。 文件的权限可以授予用户，也可以授予组，但是通常将权限授予组，在将需要该权限的用户拉入对应的组中，方便对权限进行统一管理。 创建组。groupadd hr，创建一个hr组。通过查看文件/etc/group文件查看组信息。 删除组。groupdel hr，删除hr组。 组分为基本组和附加组。基本组随用户创建而创建，组名与用户同名，但是后期可以修改。用户加入的除基本组以外的其他组就叫附加组。附加组可以有多个，而基本组只能有一个。/etc/passwd中记录的GID是用户的基本组的ID。 附加组和基本组是相对用户来说的，我随便新建一个组，它既不是附加组也不是基本组。我只能说这个组是xx的基本组或xx的附加组，而不能只说它是基本组或附加组。 对于useradd和usermod，-g是为用户制定基本组，-G是为用户制定附加组。通过id A，A是用户名，用用来查看用户所在组。命令格式：usermod userA -g groupB。 gpasswd -d A GROUP，A是用户，GROUP是组，该命令的作用是把A从GROUP中移除。有一点需要注意，用户必须有一个基本组，也就是说用户组只能更换基本组而不能从基本组中移除。 提权 当普通用户想要具有管理员的权利的时候，就需要用到提权。 第一种提权的方法是直接切换到管理员身份，用su永久提权，具体命令：su - root，操作之后可以看到提示符从$变成了#。 再从管理员身份切换回原来普通用户的身份，输入exit回车。 su也可以用来切换其他用户，如su - userB，将用户切换到userB，当然都需要输入正确的用户密码。 第二种提权的方法是以管理员的方式运行命令，用sudo临时提权。sudo是需要root进行授权的，授权文件是/etc/sudoers，文件授权一些特殊用户来使用root权限运行一些特定的命令，被授权的用户在执行这些命令的时候无需输入root密码。 在sudoers文件的第107行有一句授权的命令：%wheel ALL=(ALL) ALL。这个命令格式：用户/组 机器=(像那个用户的权利) 命令。wheel是一个特权组，第一个ALL就是本机，第二个ALL就是root，第三个ALL指的是所有命令。（你装系统的时候随系统创建的第一个用户就是特权用户，wheel组是其附加组。） useradd userC -G wheel，用这条命令就可以创建一个特权用户，passwd userC给其设置一个密码，该特权用户就能用了。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://wht6.github.io/categories/Linux/"}],"tags":[{"name":"用户管理","slug":"用户管理","permalink":"http://wht6.github.io/tags/%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86/"}]},{"title":"Linux文件基本操作","slug":"Linux文件基本操作","date":"2021-10-22T02:00:00.000Z","updated":"2022-03-27T08:30:32.410Z","comments":true,"path":"posts/f51f.html","link":"","permalink":"http://wht6.github.io/posts/f51f.html","excerpt":"","text":"Linux文件管理Linux文件目录 Linux的文件是以文件树的形式存储的，一级目录是根目录，用“/”表示。二级目录包括bin（二进制文件（执行命令、用户密码等））、boot（启动文件）、dev（设备驱动）、etc（配置文件、控制台文件）、run（临时运行文件）、root（管理员文件）、home（用户文件）、tmp（临时文件）、var（日志、邮件等）、sbin（二进制特权命令）、usr（应用程序目录，类似programfile）。以用户身份登录，默认在/home/xxx下，xxx是你的用户名。以管理员身份登录，默认在/root下。 Linux命令 命令格式 ：命令+选项+参数（命令和选项都是系统设计好的，参数则是不固定的，选项一般是-+字母）ll（或ls -l）列出当前目录下文件的详细信息。列出信息的第一个字母是文件类型。-表示普通文件，d表示文件夹。具体格式：ll+路径pwd打印当前所在文件夹路径ls列出当前目录下文件的文件名。 touch创建文件，具体格式：touch+路径/文件名 mkdir创建文件夹，具体格式：mkdir+路径/文件夹名mkdir -p创建多级目录（创建的文件夹没有上一级时，自动创建，-p表示parent）。mkdir+路径/多级文件夹mkdir /home/{dir11,dir22}，这里表示在home下同时创建两个文件夹。mkdir -pv /home/{aaa/{111,222},bbb}表示在home下创建aaa和bbb，同时在aaa下创建111和222两个文件夹，在里的v表示显示创建过程。 cp拷贝文件，cp+源文件（包括完整路径）+目标文件夹-r，若给出的源文件是一个目录文件，此时将复制该目录下所有的子目录和文件。 -f，覆盖已经存在的目标文件而不给出提示。 -i，与 -f 选项相反，在覆盖目标文件之前给出提示，要求用户确认是否覆盖，回答 y 时目标文件将被覆盖。 mv移动文件，mv+源文件（包括完整路径）+目标文件夹。mv就相当于剪切粘贴的操作。mv移动文件并重命名，mv+源文件（包括完整路径）+目标文件夹/新文件名。此时如果路径不变，就做到了只重命名。 rm删除文件，rm -rf 文件或目录（完整路径）。其中-rf表示强制删除。删除某个目录下的所有文件，rm -rf 目录/。rm -rf 目录/删除不了隐藏文件，比如，mkdir -p /root/dir1/{file1,file2,.file3}，然后rm -rf /root/dir1/*只能删除file1和file2，而不能删除.file3。cat查看文件内容，cat 文件。more 文件，以翻页的形式查看，多用于大文件查看（空格是翻页，回车是一行一行移动）。head -n 文件，查看文件前n行的内容。tail -n 文件名，查看文件后n行的内容。grep 参数 文件，表示查找一行，带有参数里的关键字。 Linux快捷键 tab：补全，两次tab：打印所有补全内容。ctr+L：清屏。ctr+shift++：放大。 Linux修改文件 1、重定向，使用&gt;进行重定向。例如，ls / &gt; /1.txt，作用是将ls /的输出内容写入根下的1.txt。2、gedit，例如，gedit /1.txt，打开记事本编辑1.txt。3、vi，vim，vim是vi的升级版。i进入编辑模式（o是换行编辑），esc进入命令行模式。命令行模式下，yy复制光标当前所在行，p是粘贴到光标所在行的下一行（换行粘贴），dd删除光标所在行。3yy是复制三行的内容，从光标所在行开始往下数。4dd是删除4行内容，也是从光标所在行往下数。u是撤销。x删除光标处的文字。 命令行模式下，输入：就进入了默行模式。w是保存，q是推出，！是强制。set nu是显示行数，set list是显示控制字符，像换行那种。 按v进行可视化模式与命令行模式的切换，进入可视化模式之后，通过上下左右可以进行选中，y是复制，p是不换行粘贴，d是删除。 G将光标移动到页尾，gg将光标移动到页首。6G将光标移动到第6行。 /是进入末行模式，/amd是查找文档中所有的amd。按n是查找下一个，按N是查找上一个。 查找替换，：进入末行模式，输入命令——范围 s/原内容/新内容/g，范围是从第几行到第几行，比如1,5就是1行到5行，s是switch，交换的意思，g表示全局，功能是查找原内容并全局替换为新内容。 如果文件没有保存而意外推出，那么系统会自动备份，比如，/1.txt这个文件没有保存意外退出，那么系统会创建一个/.1.txt.swap这样一个隐藏文件，用ls看不到这个文件，想要看到此隐藏文件需要执行命令ls -a。 相对路径，.表示当前路径，..表示上一级路径。touch ./file1.txt表示在当前目录创建文件（./可以省略），touch ../file1.txt表示在上一级目录创建文件。ls ./查看当前目录，ls ../查看上一级目录。touch ../../file2.txt表示在上一级的上一级目录创建文件。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://wht6.github.io/categories/Linux/"}],"tags":[{"name":"文件系统","slug":"文件系统","permalink":"http://wht6.github.io/tags/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"}]},{"title":"生活中必须了解的思维","slug":"生活中必须了解的思维","date":"2021-08-19T11:00:00.000Z","updated":"2022-03-20T02:00:23.699Z","comments":true,"path":"posts/9674.html","link":"","permalink":"http://wht6.github.io/posts/9674.html","excerpt":"","text":"生活中必须了解的思维分而治之我们遇到解决不了的问题，一方面可能是能力不够，但是更多情况是我们不能看清形势。分而治之就是一个让我们看清形势的思维。分而治之的思维关键就是学会分，将问题分块，分步骤，分场景，分时间等。首先知道我要分解，然后思考怎么分。其实知道主动去分解问题已经不容易了，许多人碰到问题就是躲避，迷茫或者询问别人，孰不知主动才是一切成长的关键所在。具体怎么分，不同的问题有不同的分法，实践中学习。 金字塔结构第一，人是特别喜欢分类的，也很会分类，不管什么都要分类，所以人脑对分好类的信息是容易吸收的，其实就是归纳。第二，人容易记忆有结构的知识，而不擅长记忆零散的知识。金字塔结构是人最容易理解的结构。金字塔结构有两个特征，纵向和横向。纵向指的是任意层次上的思想必须是下一层次思想的概括。横向指的是层次内的思想必须属于同一逻辑范畴，并且思想必须按逻辑顺序组织，逻辑顺序主动包括归纳和演绎推理。金字塔结构思维的应用场景就是向别人输出信息的时候。 二阶思维什么是二阶思维？二阶思维就是遇事多想一步。生活中，我们很容易只思考当下的、短期的结果，但是事物充满变化，系统复杂多样，短期结果的出现极有可能会导致新的结果出现。怎么用？首先，遇到问题问这么做会出现什么结果，然后再问结果出现后，时间推移又会导致什么新的结果或可能。 系统思维把一定的元素，通过不同的结构、方式组合起来，使它门具备整体性，这就构成了一个系统。系统思维的关注的就在于系统是不断变化的，不断转换，不断更新的，否则它就不是一个系统。系统的存在能将某些不够好的、无序的状态转变成更优的、有序的状态。系统还有一个特点是有输入有输出，无序的输入经过一个系统之后会变得有序，同时输入的改变会造成输出的改变。从系统的视角看待问题我们能更看清整体，起点是什么，终点是什么，中间是怎么变化的，系统对输入的影响是什么，输入对系统的影响又是什么。","categories":[{"name":"个人兴趣","slug":"个人兴趣","permalink":"http://wht6.github.io/categories/%E4%B8%AA%E4%BA%BA%E5%85%B4%E8%B6%A3/"}],"tags":[{"name":"思维","slug":"思维","permalink":"http://wht6.github.io/tags/%E6%80%9D%E7%BB%B4/"}]},{"title":"frp远程访问","slug":"frp远程访问","date":"2021-06-22T01:00:00.000Z","updated":"2022-03-20T01:46:22.511Z","comments":true,"path":"posts/a3d2.html","link":"","permalink":"http://wht6.github.io/posts/a3d2.html","excerpt":"","text":"frp远程访问frp原理frp主要进行反向代理，将数据包定向转发，多用于内网穿透。 下图以SSH为例，说明frp是如何实现内网穿透的。 frp通过建立上图的三个通道，并把三个通道进行连通，即实现了ssh的内网穿透。 具体步骤如下： 1）frpc注册frps，两者建立TCP连接，frpc将端口映射信息发送给frps，frps根据端口映射信息建立连接池，监听固定端口的连接。 2）位于因特网的ssh客户端向frps发送连接请求，frps向frpc发送请求信息，frpc收到后请求ssh服务端建立连接，若连接失败，则frpc通过frps向ssh客户端发送连接失败的信息，否则ssh服务端通过frpc和frps发送验证请求到ssh客户端。 3）ssh客户端通过frps和frpc发送用户名和密码到ssh服务端，ssh服务段验证成功后返回连接成功的消息，并等待数据的发送，否则验证失败断开连接。 frp配置frp下载地址 下载之后解压： 1tar -zxvf frp_0.34.3_linux_amd64.tar.gz 配置frps修改配置文件frps.ini 1234567891011121314# 通用配置[common]# bind_addr = 0.0.0.0 # 指定监听的地址，默认监听所有网段bind_port = 7000 # frps的监听端口，用于与frpc连接dashboard_port = 7500 # frps的web控制面板的端口号，web界面用于查看和管理连接信息dashboard_user = user # web控制面板的用户名dashboard_pwd = pass # web控制面板的登陆密码authentication_method = token # 口令验证token = xxxxx # frpc连接时的验证密码# max_pool_count = 100 # 连接池最大连接数量 1./frps -c ./frps.ini # shell启动frps服务 通过浏览器输入（服务器IP:端口）可访问web控制面板。 配置frpc修改配置文件frpc.ini 1234567891011121314151617181920[common]server_addr = xx.xx.xx.xx # frps服务器的公网ipauthentication_method = token # 口令验证token = xxxxx # frps连接密码 server_port = 7000 # frps用于连接的服务端口# ssh映射[Fusion-ssh]type = tcplocal_ip = 127.0.0.1 local_port = 22remote_port = 20022 # rdp映射[Fusion-rdp]type = tcplocal_ip = 127.0.0.1local_port = 3389remote_port = 23389 1./frps -c ./frps.ini # shell启动frpc 内网服务器开启ssh： 1vim /etc/ssh/sshd_config # ssh的配置文件 修改30几行，permitrootlogin改成yes，允许root登录 pubkeyauthentication改成yes,允许公钥认证 12systemctl restart ssh # 或/etc/init.d/ssh restart 重启ssh服务update-rc.d ssh enable # 允许开机自启动ssh 此时，ssh客户端连接frps的20022端口，frps通过代理就可以访问ssh服务器的22端口，然后验证并建立连接。 rdp是远程桌面。 配置frp自启动1vim /lib/systemd/system/frps.service 12345678910111213[Unit]Description=fraps serviceAfter=network.target network-online.target syslog.targetWants=network.target network-online.target[Service]Type=simple# 启动服务的命令（此处写你的frps的实际安装目录）ExecStart=/your/path/frps -c /your/path/frps.ini[Install]WantedBy=multi-user.target 123systemctl start frps # 开启systemctl enable frps # 自启动systemctl status frps # 状态 1vim /etc/systemd/system/frps.service # etc或lib都行 12345678910111213141516[Fusion]Description=Frp Server DaemonAfter=syslog.target network.targetWants=network.target[Service]Type=simpleExecStart=/usr/local/bin/frp/frpc -c /usr/local/bin/frp/frpc.ini # 修改为你的frpc实际安装目录ExecStop=/usr/bin/killall frpcRestartSec=1min #启动失败1分钟后再次启动KillMode=control-groupRestart=always #重启控制：总是重启[Install]WantedBy=multi-user.target 123systemctl start frpc.service # 开启systemctl enable frpc.service # 自启动systemctl status frpc.service # 状态","categories":[{"name":"网络","slug":"网络","permalink":"http://wht6.github.io/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"工具","slug":"工具","permalink":"http://wht6.github.io/tags/%E5%B7%A5%E5%85%B7/"}]},{"title":"搭建ss服务器","slug":"搭建ss服务器","date":"2021-06-20T06:20:00.000Z","updated":"2022-03-20T01:46:36.914Z","comments":true,"path":"posts/486.html","link":"","permalink":"http://wht6.github.io/posts/486.html","excerpt":"","text":"搭建ss服务器准备工作首先需要有一台外网服务器和xshell等ssh远程连接工具。通过xshell连接服务器给定的ip和端口，登录验证，然后通过远程shell连接服务器，下面的配置过程一centos 7 x64为例。 配置ss123456789# 安装wgetyum -y install wget# 从github上下载sswget --no-check-certificate -O shadowsocks-all.sh https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-all.sh# 给予文件可执行权限chmod +x shadowsocks-all.sh# 开始安装./shadowsocks-all.sh 2&gt;&amp;1 | tee shadowsocks-all.log 安装的过程中会提示你选择哪个版本，选择 Shadowsocks-libev版本。 然后是让你设定一个连接密码。 接着设定一个监听的端口号。 然后选择一种加密方式，这里我选择的是aes-256-gcm。 接下来问你是否安装simeple-obfs，是y，然后选择tls。 安装成功后会显示你的ss的所有配置信息。 如果要修改配置，运行 1bash shadowsocks-libev.sh 然后选择第8项：修改 Shadowsocks 配置即可重新设置 Shadowsocks 的密码、端口以及加密方式。 选择第2项则是卸载ss。也可以运行 1./shadowsocks-all.sh uninstall 来卸载。 1/etc/init.d/shadowsocks-libev start | stop | restart | status # 启动、停止、重启、查看状态 /etc/shadowsocks-libev/config.json是ss的配置文件。 ss加速下载并执行91yun的一键安装锐速脚本： 1wget -N --no-check-certificate https://github.com/91yun/serverspeeder/raw/master/serverspeeder.sh &amp;&amp; bash serverspeeder.sh 但是这样直接安装的时候很可能出现内核版本不匹配的问题。因此需要修改系统内核为锐速支持的内核版本。 centos 6支持的内核版本：2.6.32-504.3.3.el6.x86_64 123rpm -ivh http://soft.91yun.org/ISO/Linux/CentOS/kernel/kernel-firmware-2.6.32-504.3.3.el6.noarch.rpmrpm -ivh http://soft.91yun.org/ISO/Linux/CentOS/kernel/kernel-2.6.32-504.3.3.el6.x86_64.rpm --force centos 7支持的内核版本：3.10.0-229.1.2.el7.x86_64 1rpm -ivh http://soft.91yun.org/ISO/Linux/CentOS/kernel/kernel-3.10.0-229.1.2.el7.x86_64.rpm --force 升级/降级系统内核后执行如下命令查看是否修改成功： 123rpm -qa | grep kernel # 查看内核rebootuname -r # 再次查看内核 锐速加速常用的命令： 123456789service serverSpeeder start #启动service serverSpeeder stop #停止service serverSpeeder reload #重新加载配置service serverSpeeder restart #重启service serverSpeeder status #状态service serverSpeeder stats #统计service serverSpeeder renewLic #更新许可文件service serverSpeeder update #更新chattr -i /serverspeeder/etc/apx* &amp;&amp; /serverspeeder/bin/serverSpeeder.sh uninstall -f #卸载 ss多端口先停止 ss-server 服务： 12345$ sudo service shadowsocks-libev status * shadowsocks-libev is running$ sudo service shadowsocks-libev stop$ sudo service shadowsocks-libev status * shadowsocks-libev is not running 然后，拷贝一份原来的配置文件，自定义新的文件名，只要保证扩展名为 .json 即可，我这里命名为 configuser1.json ： 123$ cd /etc/shadowsocks-libev$ sudo cp config.json configuser1.json$ sudo vi configuser1.json 修改配置参数中的端口号，密码等。 然后启动 ss-server 服务： 123$ sudo service shadowsocks-libev start$ sudo service shadowsocks-libev status * shadowsocks-libev is running 执行如下命令添加新的配置文件设置 ： 1$ setsid ss-server -c /etc/shadowsocks-libev/***.json -u 如果你嫌上面的“停止-拷贝已有配置文件-重启”操作太麻烦，也可以直接新建一个json配置文件，填入config.json文件的配置信息，修改端口号或密码。 然后直接执行如下命令即可： 1$ setsid ss-server -c /etc/shadowsocks-libev/***.json -u 查看启动信息： 1$ ps ax |grep ss-server 可以看到比之前多了一条后台服务。 通过 netstat -lnp 来查看 ss-server 是否监听了多个端口： 1$ netstat -lnp 这样，就实现了监听多个端口，实现多用户连接了。如果想要停止新增的监听端口，只需要重启shadowsocks服务就又恢复默认，只会监听的 config.json 中配置的端口了。","categories":[{"name":"网络","slug":"网络","permalink":"http://wht6.github.io/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"代理","slug":"代理","permalink":"http://wht6.github.io/tags/%E4%BB%A3%E7%90%86/"}]},{"title":"树莓派安装openwrt","slug":"树莓派安装openwrt","date":"2021-06-06T01:20:00.000Z","updated":"2022-03-20T01:45:49.558Z","comments":true,"path":"posts/a37c.html","link":"","permalink":"http://wht6.github.io/posts/a37c.html","excerpt":"","text":"树莓派安装openwrt写入镜像openwrt下载 选择openwrt-19.07.6-brcm2708-bcm2709-rpi-2-ext4-factory.img.gz。 SDFormatter格式化SD卡，Win32DiskManager将镜像写入SD卡。 硬件连接硬件：树莓派3B+，SD卡，网线，读卡器，PC。 第一步：用一根网线连接树莓派和PC。（目的是使之位于同一局域网） 第二步：插入SD卡，启动树莓派。192.168.1.1访问路由管理界面。 第三步：配置路由器无线功能。 第四步：拔掉树莓派与PC之间的网线，将提供宽带的网线接入树莓派。 第五步：PC或手机通过无线连接树莓派，192.168.1.1访问路由管理界面，进一步配置网络。 具体细节配置无线的时候，默认的mode不能改，改了之后会自动变成client模式，而非我们期望的master模式。（AP LAN分为master和client，master就是接入点，client就是无线站点）这个原因可能是默认的mode的频段是树莓派自身所支持的，其他频段可能不支持。 我们配置无线的目的是使你的无线设备加入到当前局域网中，所以需要在AP和无线站点创建一条虚拟线路。现在的无线局域网都是基于802.11协议，我们需要配置的就是频段，模式，SSID，加密方式和密码。 配置好AP之后，无线设备通过SSID访问AP，并通过密码连接AP，连接成功后无线设备和树莓派就在同一个局域网了，此时AP仅仅起到交换机的作用。如果宽带是类似校园网的登陆验证方式此时可以直接使用了。 如果是拨号宽带，还需要配置路由器功能。首先配置网卡（eth0），pppoe模式，需要输入用户和密码，认证通过后运营商才会分配一个IP。除此之外，还要将有线接口和无线AP接口连接起来，然后开启局域网DHCP服务器，用于给局域网的设备分配内网地址(家用路由器NAT功能是自动开启的)。","categories":[{"name":"嵌入式","slug":"嵌入式","permalink":"http://wht6.github.io/categories/%E5%B5%8C%E5%85%A5%E5%BC%8F/"}],"tags":[{"name":"路由器","slug":"路由器","permalink":"http://wht6.github.io/tags/%E8%B7%AF%E7%94%B1%E5%99%A8/"}]},{"title":"域名系统DNS","slug":"域名系统DNS","date":"2021-06-06T00:20:00.000Z","updated":"2022-03-20T01:43:26.739Z","comments":true,"path":"posts/a6cd.html","link":"","permalink":"http://wht6.github.io/posts/a6cd.html","excerpt":"","text":"域名系统DNSDNS查询DNS（domain name system）的作用是将域名解析为IP地址。 DNS的查询方式： 而实际的查询流程往往是： 1 浏览器缓存——2 系统缓存（host文件）——3 路由器缓存——4 ISP服务器（本地DNS服务器）的DNS缓存——5 根域名服务器——6 顶级域名服务器——7 主域名服务器——保存结果到缓存中。 DNS记录DNS的域名记录的几种形式： A记录（address）正向解析。主机名于ip关联起来，通过域名找ip。 PTR记录（Pointer）反向解析，主机名于ip关联起来，通过ip找域名。 CNAME记录（canonical name）别名。允许多个域名映射到同一台服务器。 MX记录（mail exchange）指向邮件服务器。根据邮箱地址定位mail服务器。 NS记录（name sever）指定该域名是由哪个域名服务器解析的。 HOST文件系统的host文件包括常用的域名和对应的ip（其中包括你之前访问过的域名），相当于本地DNS缓存，解析域名的时候会先去查找本地host文件中是否有域名对应的ip。修改host文件可以屏蔽一些网站，比如修改域名的ip为127.0.0.1。 windows的host文件在路径C:\\Windows\\System32\\drivers\\etc中。 修改示例：127.0.0.1 www.baidu.com。保存后，命令行输入：ipconfig /flushdns刷新dns缓存，再去访问www.baidu.com就访问不到了。","categories":[{"name":"网络","slug":"网络","permalink":"http://wht6.github.io/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"DNS","slug":"DNS","permalink":"http://wht6.github.io/tags/DNS/"}]},{"title":"LaTex常用命令","slug":"LaTex常用命令","date":"2021-05-13T07:00:00.000Z","updated":"2022-03-20T01:46:51.554Z","comments":true,"path":"posts/b9ca.html","link":"","permalink":"http://wht6.github.io/posts/b9ca.html","excerpt":"","text":"LaTex常用命令正文命令公式命令 字符 命令 字符 命令 向量 \\vec or \\\\boldsymbol 帽 \\hat or \\widehat 分式 \\frac{}{} 上横线 \\overline 根号 \\sqrt{} 上波浪 \\widetilde 度数 ^\\circ 大写字母空心 \\mathbb 一重积分 \\int_{}^{} 数字空心 \\mathbbm 极限 \\lim_{} or \\lim\\limits 乘号 \\times 到 \\to 无穷 \\infty 求和 \\sum_{}^{}","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://wht6.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[]},{"title":"实例分割框架：PolarMask解读","slug":"实例分割框架：PolarMask解读","date":"2021-05-13T07:00:00.000Z","updated":"2022-03-20T01:45:35.276Z","comments":true,"path":"posts/26fe.html","link":"","permalink":"http://wht6.github.io/posts/26fe.html","excerpt":"","text":"实例分割框架：PolarMask解读论文创新PolarMask将实例分割问题表述为通过实例中心分类和极坐标中的密集距离回归来预测实例轮廓。 图中显示了实例轮廓的两种表示方法，左边是笛卡尔表示法，右边是极坐标表示法。 选择极坐标系的原因： 1）极坐标原点可视为目标中心。 2）轮廓点可以由极坐标原点出发的距离和角度唯一确定。 3）角度是固定的，根据角度更容易复原出轮廓。 FCOS简介FCOS是一个box-free的目标检测框架。FCOS希望像FCN那样逐像素的预测边界框，它做法是选择真实框中的像素点为正样本，为每个正样本像素点预测一个4D的向量和一个类别标签。4D向量是像素点到边界框四条边的距离。如果一个像素点落在多个边界框中，则认为其是模糊样本。FCOS证明使用FPN可以极大的消除模糊样本带来的影响。论文发现这个方法会产生大量低质量的框，这些框所对应给像素点皆距离目标中心点较远。因此，FCOS添加了一个center-ness Branch来过滤低质量的框。 为每个属于正样本的像素点预测一个4D向量：$\\boldsymbol t=(l,t,r,b)$，这里$l,t,r,b$是像素点到预测边界框的距离。 除此之外，还需要为每个像素点预测一个类别标签，这个与FCN是一致的，即将类别放到通道维度上。COCO数据集有80类，所有预测类别的分支的输出是80维。 FCOS会使用更多的前景样本进行预测，而box based的方法会受限与锚框的数量。 FPN样本的分配方式，P3到P7每一层有一个最大回归距离，$ max(l’,t’,r’,b’) $介于$m_i$与$m_{i-1}$之间（$ l’,t’,r’,b’ $是像素点到真实边界框的距离），则会被设置为正样本。$m_i$是FPN每层的最大回归距离。 这样大部分重叠的框（即模糊样本）会被分散到不同的FPN层，如果经过FPN分配之后还有一个位置出现两个框的情况，则选择较小的框作为回归的目标。FPN权值共享来减少参数。由于回归的值必须是正值，论文使用exp(x)。虽然共享参数，但是论文给每个FPN的Level设置一个$s_i$，$exp(xs_i)$取代exp(x)，使之性能稍有提升。 此时还有一个问题是远离目标中心点的像素会产生大量低质量的框。 因为设计了一个中心度，其作用并非改善这些低质量的框，而是直接删除。 中心度目标的计算方法： centerness^*=\\sqrt{\\frac{min(l^*,r^*)}{max(l^*,r^*)}\\times \\frac{min(t^*,b^*)}{max(t^*,b^*)}}cennterness分支只有一层，与最终的分类并列。目的是希望像素学习一个正确的位置。在推断阶段，用centerness乘以类别得分来降低远离中心的预测框的得分，之后大概率会被NMS给剔除。centerness用的BCE损失，我觉得应该回归，但仔细想想分类也说的通，预测一个像素是不是中心点概率，对于正样本点其概率并不一定是1，而是centerness计算出来的，相当于一个软标签。 实现细节输入一个图像，在每个角度上预测一个正样本位置（候选实例中心）到实例轮廓的距离，得到若干预测点，组装之后形成最终的mask。网络框架基于FCOS。（看了PolarMask的框架后发现与FCOS几乎一样，似乎FCOS就是专门为PolarMask设计的） 采样方式是以中心点开始，以固定角度间隔发射n条射线。（如果角度间隔是$10^\\circ$，则一共得到36条射线，36个采样点。）因为角度已经预定义，所以只需考虑中心点与中心点到采样点的距离。 中心点为目标的质心。（论文中还对质心和框心进行了对比，结论是质心优于框心） 正样本选择：如果(x,y)落入任何实例质心的周围区域，则将其视为中心样本。正像素采样区域定义为特征图从质心到左、上、右和下的1.5倍步幅。因此，每个实例在质心附近有大约9-16个像素作为中心实例。 距离回归的两点说明：1）如果一条射线与实例的轮廓有多个相交点，则直接选择长度最大的一条作为回归目标。2）某条射线与轮廓没有相交的点，回归目标设置成最小值$10^{-6}$。论文认为这些极端情况是限制极坐标表示上限达到100%AP的主要障碍。论文解释了不应因此证明极坐标表示劣于二值图像表示。 However, it is not supposed to be seen as Polar Representation being inferior to the non-parametric Pixel-wise Representation. The evidence is two-fold. First, even the Pixel-wise Representation still has certain gap with the upper bound of 100% AP in practice, since some operation, such as down-sampling, is indispensable. Second, current performance is far away from the upper bound regardless of the Pixel-wise Representation or Polar Representation. Therefore, the research effort is suggested to better spend on improving the practical performance of models, rather than the theoretical upper bound. 直接对距离回归会出现一个问题，每个实例都有n条射线，可能会导致距离回归损失与分类损失之间的不平衡。其次，同一个实例的n条射线具有相关性，应该整体进行训练而不是看作一个独立的回归样本。 Polar Centerness:FCOS的centerness只适用于框的抑制。polar centerness的计算方式是 polarcenterness=\\sqrt{\\frac{min(\\{d_1,d_2,...d_n\\})}{max(\\{d_1,d_2,...d_n\\})}}polarness值越接近1，越靠近中心点。最后类别分支的得分会乘以polarcenterness的值来减小远离中心的预测mask的得分，从而在后边利用NMS过滤掉。 显然二值mask的IOU是便于计算的，但是结算轮廓的IOU则比较困难，所以论文给出了Polar IOU的计算方式。 在极坐标系中，Mask IOU可以这样计算： IOU=\\frac{\\int_{0}^{2\\pi}\\frac{1}{2}d_{min}^2d\\theta}{\\int_{0}^{2\\pi}\\frac{1}{2}d_{max}^2d\\theta}d是回归目标，$d’$是预测线长度，$\\theta$是角度。$d_{min}=min(d,d’)$，$d_{max}=max(d,d’)$下面是离散形式： IOU=\\lim_{N\\to \\infty}\\frac{\\sum_{i=1}^N\\frac{1}{2}d_{min}^2\\Delta \\theta_i}{\\sum_{i=1}^N\\frac{1}{2}d_{max}^2\\Delta \\theta_i}论文发现简化后的计算相较于完整的计算只有$\\pm0.1$AP的差异，使用的简化计算如下： Polar\\quad IOU=\\frac{\\sum_{i=1}^Nd_{min}}{\\sum_{i=1}^Nd_{max}} PolarMask的backbone和FPN与FCOS一样，FPN也是按回归距离分配到FPN不同的层次。 损失是类别分支与回归分支的联合损失。","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://wht6.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"实例分割","slug":"实例分割","permalink":"http://wht6.github.io/tags/%E5%AE%9E%E4%BE%8B%E5%88%86%E5%89%B2/"}]},{"title":"实例分割框架：SOLO解读","slug":"实例分割框架：SOLO解读","date":"2021-05-07T11:00:00.000Z","updated":"2022-03-20T01:46:05.700Z","comments":true,"path":"posts/c6fd.html","link":"","permalink":"http://wht6.github.io/posts/c6fd.html","excerpt":"","text":"实例分割框架：SOLO解读SOLOSOLO思想SOLO通过引入一个“实例类别”的概念，根据实例的位置和大小为实例中的每个像素分配一个“实例类别”，将实例分割任务转换成了一个单阶端的分类任务。 这里可能会难以理解“实例类别”的概念，这个概念其实并不难理解。首先对于图像中的每个目标，都有一个语义类别，比如猫或狗等。但是如果图像上有多只猫，我们就无法通过语义类别来分开不同的猫，因为它们具有相同的语义类别——猫。但是如果我们给每只猫加上一个位置和大小的标签呢，不同的猫显然具有不同的大小和位置。论文这里就把“语义类别+位置和大小”起了个名字，叫做实例类别。 这里作者为了证明图像中的大多数目标确实具有不同的位置和大小，也进行了调研。 Take the challenging MS COCO dataset [16] for example. There are in total 36; 780 objects in the validation subset, 98:3% of object pairs have center distance greater than 30 pixels. As for the rest 1:7% of object pairs, 40:5% of them have size ratio greater than 1.5×. To conclude, in most cases two instances in an image either have different center locations or have different object sizes. SOLO框架 SOLO将图像划分成S*S的网格，每个网格代表一个中心位置类。如同语义分割框架FCN那样，SOLO将中心位置类编码到通道轴上。其中每个通道负责一个中心位置类，相关的通道需要预测中心属于此位置的实例mask（如同FCN属于猫类的通道负责预测猫的mask那样）。 如图中所示，下边的Mask Branch即将中心位置类编码到通道轴的结果，每一个网格对应一个通道，所以一共有$S^2$个通道。 而上边的Category Branch则是和语义分割FCN相似，但是并非为每个像素分类而是为每个网格进行语义分类。（论文假设每个网格只属于一个单独的实例） 实现细节1）这时你可能会问为什么没考虑尺寸信息呢，当出现相同位置且不同尺寸的两个对象怎么办呢？ 这里SOLO使用了经典的FPN（特征金字塔网络）结构，通过将不同的尺寸的对象分配给不同FPN等级（level）来预测。此时，不同尺寸的对象就被分开处理了。具体做法是计算每个ground truth的面积，将不同面积的实例分配到不同的FPN等级预测。 FPN的不同层参数共享（7层），最后一层参数不共享。 Weights for the head are shared across different levels. Grid number may varies at different pyramids. Only the last conv is not shared in this scenario. 2）论文中网格和通道的对应方式：第k个通道对应第i*S+j个网格，如此就可以一一对应了。 3）如果像FCN那样对中心位置分类，则会因为卷积的空间不变性使得分割对位置不敏感。因此，论文使用了CoorConv的方法将归一化的坐标作为两个通道加入Mask Branch（其中一个通道是x坐标，一个通道是y坐标）。 4）最后，结合每个网格生成的结果得到一些实例掩码，在用NMS选出最好的分割结果。 5）正负样本的选择，如果网格落在真实掩膜（ground truth mask）的中心范围，那么视为正样本，其他的为负样本。在代码中，作者将gt_box缩小到1/5（以质心为中心），然后找出覆盖的网格，这些网格就是正样本。接着把类别标签与mask标签放到网格对应的通道上。 1234# mass center 计算质心gt_masks_pt = torch.from_numpy(gt_masks).to(device=device)center_ws, center_hs = center_of_mass(gt_masks_pt)valid_mask_flags = gt_masks_pt.sum(dim=-1).sum(dim=-1) &gt; 0 1234567891011# 计算质心范围覆盖的网格# left, top, right, downtop_box = max(0, int(((center_h - half_h) / upsampled_size[0]) // (1. / num_grid)))down_box = min(num_grid - 1, int(((center_h + half_h) / upsampled_size[0]) // (1. / num_grid)))left_box = max(0, int(((center_w - half_w) / upsampled_size[1]) // (1. / num_grid)))right_box = min(num_grid - 1, int(((center_w + half_w) / upsampled_size[1]) // (1. / num_grid)))top = max(top_box, coord_h-1)down = min(down_box, coord_h+1)left = max(coord_w-1, left_box)right = min(right_box, coord_w+1) 1234567891011121314# 放置真实标签# catecate_label[top:(down+1), left:(right+1)] = gt_label# insseg_mask = mmcv.imrescale(seg_mask, scale=1. / output_stride)seg_mask = torch.from_numpy(seg_mask).to(device=device)for i in range(top, down+1): for j in range(left, right+1): label = int(i * num_grid + j) ins_label[label, :seg_mask.shape[0], :seg_mask.shape[1]] = seg_mask # 存储在s*s的某个通道上 ins_ind_label[label] = True # 哪个通道有实例ins_label_list.append(ins_label)cate_label_list.append(cate_label)ins_ind_label_list.append(ins_ind_label) 6）损失函数： L=L_{cate}+\\lambda L_{mask}其中$L_{cate}$是类别分支的损失（Focal loss），$L_{mask}$是mask分支的损失（Dice loss）。 7）置信度分输计算： 对mask中所有得分大于0.5的像素求和取平均得到mask的置信度分数。 将mask的置信度分数乘以类别得分得到类别的置信度分数。 可以看出，SOLO将实例分割转变成两个分类任务，设计了一个无检测、无聚类的端到端学习框架。 作者给出的改进思路是可以借鉴最新的优秀语义分割方法来改进SOLO的两个分类任务 The proposed SOLO only needs to solve two pixel-level classification tasks, thus it may be possible to borrow some of therecent advances in semantic segmentation for improving SOLO. SOLO其实也存在一些缺点，不利于检测尺寸小的目标和目标密集的区域。 SOLOv2SOLOv2创新论文认为有三个瓶颈限制了SOLO的表现： 1）低效的掩膜预测。因为掩膜分支有S*S个通道，会消耗许多资源和算力。并且S在不同的fpn的level值是不同的，每个level的最后一层并不共享参数，这些都导致了掩膜预测效率的低下。 2）掩膜精细程度差。精细的掩膜需要更高分辨率的mask处理目标的边缘信息。但是大分辨率的mask以为了更复杂的计算。 3）Mask NMS速度慢。相比于box NMS，Mask NMS会消耗更多的时间。 However, three main bottlenecks limit the performance of SOLO: a) inefficient mask representation and learning; b) not high enough resolution for finer mask predictions; c) slow mask NMS. 因此，论文提出了两个创新： 1）使用动态卷积的方法预测掩膜。 2）设计能够并行计算的Matrix NMS代替传统的NMS。 实现方案SOLO在生成掩膜的过程中，最后一层的输入特征为$F \\in {\\mathbb{R}^{H \\times W \\times E}}$，通过一层卷积层输出为$S^2$个通道。这个过程可以建模为： {M_{i,j}} = {G_{i,j}} \\circledast F其中，${G_{i,j}} \\in {\\mathbb{R}^{1 \\times 1 \\times E}}$是卷积核，${M_{i,j}} \\in {\\mathbb{R}^{H \\times W}}$是位置在（i, j）处的实例掩膜。 M是很大的，消耗许多存储与算力。而实例的位置体现在网格中是稀疏的。所以在$S^2$个卷积核中只有很小一部分发挥作用，而其他的都是冗余的。 针对上面的问题，论文提出了动态卷积的方法，一个分支预测卷积核G，一个分支预测feature map，最后feature map与学习到的卷积核做卷积生成mask M。 Mask kernel G在给定backbone与FPN的情况下，为每个FPN的等级预测动态卷积核G。将FPN生成的$H\\times W\\times C$的feature map对齐到$S\\times S\\times C$，然后经过四层卷积，最后经过一个$3\\times 3\\times D$的卷积层得到动态卷积核G。为了保持位置敏感性，在第一个卷积层加入坐标通道。同样每个FPN等级共享参数。 Mask Feature FFPN每个level经过一个$3\\times 3$卷积层，组归一化，RELU和2次的双线性上采样后将P2到P5的特征融合。融合的过程是像素级求和，然后$1\\times 1$卷积，组归一化，RELU。在FPN的P5层加入了坐标通道提升位置敏感性。 在预测阶段，对于类别分支用0.1的阈值剔除得分低的网格。在用网格对应的动态卷积核去预测Mask。（减少计算量就体现在这里） Matrix NMS这里先简单介绍传统的NMS与改进的Soft NMS。 NMS1）对目标按照得分排序 2）保留得分最高的目标 3）删除与目标最相近的其他目标（通常是根据IOU，删除与目标IOU大于某个阈值的框） 4）复1-3直到目标结合中不存在目标 NMS有个很大的缺点，容易误删。特别是两个相似而又靠近的目标，容易删除较小的目标。 Soft NMSSoft NMS剔除的改进方法是将得分乘以一个惩罚项decay来降低相似目标的得分，而非直接暴力地删除。 原来的NMS可以描述如下：将IOU大于阈值的目标的得分全部置为0。 {s_i} = \\left\\{ {\\begin{array}{*{20}{c}} {{s_i},\\quad iou(M,{b_i}) < {N_t}} \\\\ {0,\\quad iou(M,{b_i}) \\geqslant {N_t}} \\end{array}} \\right.Soft NMS的改进，线性加权的方式，decay是与iou有关的线性函数$f(iou)=1-iou$： {s_i} = \\left\\{ {\\begin{array}{*{20}{c}} {{s_i},\\quad iou(M,{b_i}) < {N_t}} \\\\ {{s_i}(1 - iou(M,{b_i})),\\quad iou(M,{b_i}) \\geqslant {N_t}} \\end{array}} \\right.还有一种高斯加权的方式，这里不做过多介绍。 总之，思路都是IOU越大，得分降低的越多。 下面介绍Matrix NMS的思路。 Matrix NMS的思路是在Soft NMS的思路上延申。 论文认为一个给定Mask的惩罚项decay与两方面有关： 1）每个与它同类的得分比它高的预测Mask对它的惩罚。这个即$f(iou)$，iou越大，$f(iou)$越小，惩罚力度越强。 2）每个与它同类的且得分比它高的Mask自身被抑制的概率。而一个mask被抑制的概率与自身相关的最大IOU呈正相关。论文将其设置为$1/f(iou_{max})$，iou越大，越可能被抑制。 直观理解就是我会被得分高的Mask抑制，但是如果这个得分高的Mask自身被抑制，它很有可能就不是最优的mask，我受它的抑制就需要适当的减弱，就乘以一个与它自身最大IOU成正相关的一个系数，即其被抑制的概率。 因为要并行处理，所以Matrix NMS的计算全部是矩阵计算。 实现细节1）最后动态卷积核的生成并没有经过激活函数。 2）损失函数与SOLO的损失函数的计算方式一样。 3）Matirx NMS矩阵计算的详细过程： 筛选top-N的mask，按照得分排序，接着组成$N \\times N$的矩阵。 计算所有的IOU。将每一类得分最高的mask的那一列iou置为0。iou为0即可认为没有相似的mask，主要目的还是保留得分最高的mask。 计算一个label_matrix。其中同一类的为1，不同类为0。（这里可能会对0产生疑问，0即不被抑制，因为不同类吗，后边会在行最小中删除掉） 计算列的最大IOU。带入公式计算decay。 选择行最小的decay为行对应mask的decay。 decay*score更新score。选出top-k为最终结果。 4）SOLOv2类别分支改为了四层卷积加最后输出，原本SOLO的深度是7外加一层输出。 5）类别分支与kernel分支还是5个level的fpn，共享参数，不同level的feature map是S*S，S即网格数。依然是[40, 36, 24, 16, 12]。 6）Mask feature分支，融合了P2到P5的特征，并没有使用P6的特征。特征融合之后，输出256个通道，相当于网格划分成16*16，然后再与学习的动态卷积核卷积，接着与真实的mask计算loss。","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://wht6.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"实例分割","slug":"实例分割","permalink":"http://wht6.github.io/tags/%E5%AE%9E%E4%BE%8B%E5%88%86%E5%89%B2/"}]},{"title":"获得因特网的存在：拼好拼图","slug":"获得因特网的存在：拼好拼图","date":"2021-04-28T16:00:00.000Z","updated":"2022-03-20T01:44:46.142Z","comments":true,"path":"posts/9iyu.html","link":"","permalink":"http://wht6.github.io/posts/9iyu.html","excerpt":"","text":"获得因特网的存在：拼好拼图 假定你刚刚创建一个有一些服务器的小型公司网络，包括一个描述你所在公司产品和服务的公共web服务器、公司雇员获得电子邮件报文的电子邮件服务器和一台DNS服务器。你自然地希望整个世界能够在你的web站点上冲浪，知道你那些令人兴奋的产品和服务。此外，你将希望公司雇员能够向遍及全球的潜在用户发送和接收电子邮件。 为了满足这些目标，你先要获得因特网连通性。为做到这一点，要与一个本地ISP签订合同并与之连接。你的公司将要有一台网关路由器，将其与本地ISP相连接。这种连接可以是通过现有的电话基础设施的DSL连接、一条到ISP的租用线，或在第1章中描述的许多其他接入方案之一。你的本地ISP也将为你提供一个IP地址范围，例如由256个地址组成的/24地址范围。一旦有了自己的物理连接和IP地址范围，你将在该地址范围内分配IP地址：一个给你的web服务器，一个给你的邮件服务器，一个给你的DNS服务器，一个给你的网关路由器，其他IP地址给你公司网络中的其他服务器和网络设备。 除了与一个ISP签约外，你还需要与一个因特网注册机构签约，以便为你的公司获得一个域名，如第二章所述。例如，如果你的公司名为Xanadu公司，你当然试图获得域名xanadu.com。你的公司还必须在DNS系统中存在。特别是，因为外部要与你的DNS服务器联系以获得服务器的IP地址，你还需要注册你的DNS服务器的IP地址。你的注册机构将你的DNS服务器（域名和对应的地址）放入.com顶级域名服务器中的一个表项中，如在第二章中所述。完成这个步骤后，知道你域名(如xanadu.com)的任何用户将能够通过DNS系统获得你DNS服务器的IP地址。 为了使人们能够发现你web服务器的IP地址，你需要在你的DNS服务器中包括一个将你的web服务器名字（www.xanadu.com)映射为其IP地址的表项。你还要有用于其他公共可用的公司服务器的类似表项，包括你的邮件服务器。如此一来，如果Alice要浏览你的web服务器，DNS系统将联系你的DNS服务器，找出你的web服务器的IP地址，并将其提交Alice。Alice则能够与你的web服务器直接创建一条TCP连接。 然而，允许来自全世界的外部者接入你的web服务器仍存在其他必要的、决定性的步骤。考虑下列情况，假设Alice知道你的web服务器的IP地址，当她向那个IP地址发送一个IP数据报（如一个TCP SYN报文段）。这个报文段将通过因特网进行路由，访问位于许多不同AS中的一系列路由器，并最终达到你的web服务器。当这些路由器中的任一个接收到该报文段，将去其转发表中的查找表项，以决定它转发该报文段的出口。因此，每台路由器需要知道你公司的/24前缀（或某些聚合项）的存在。一台路由器怎样才能知道你公司的前缀呢？如我们刚才所见，它从BGP知道了前缀！特别是，当你的公司联系一个本地ISP并分配到一个前缀（如一个地址范围）时，你的本地ISP将使用BGP来向它连接的ISP通告该前缀（或包括你的前缀的某些聚合），因而能够以你的web和邮件服务器为目的地适当地转发数据报。 ————《计算机网络：自顶向下方法》","categories":[{"name":"网络","slug":"网络","permalink":"http://wht6.github.io/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[]},{"title":"两个好用的学术搜索网站","slug":"两个好用的学术搜索网站","date":"2021-03-27T16:00:00.000Z","updated":"2022-03-20T01:44:00.073Z","comments":true,"path":"posts/9a02.html","link":"","permalink":"http://wht6.github.io/posts/9a02.html","excerpt":"","text":"两个好用的学术搜索网站Semantic ScholarSemantic Scholar网站简洁的页面：找到论文后可方便查看论文摘要，参考文献以及引用的情况。此外还可以预览论文中的图片和表格，提供论文参考代码。网站排版很清晰，看着很舒服。 网站地址：https://www.semanticscholar.org/ Papers with codePapers with code提供的论文以及论文附带的代码。Semantic Scholar的代码就是从Papers with code获取的。Papers with code提供的代码更多，而且会显示代码star的数量。 论文所用到的数据集及使用的方法也都整理好了，帮助我们节省大量的时间。 此外，Papers with code还提供SODA的论文的对比分析。计算机视觉方面有关于各个数据集的AP排行榜，可以帮助我们快速了解领域内最优秀的方法。 网站地址：https://paperswithcode.com/","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://wht6.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"网站","slug":"网站","permalink":"http://wht6.github.io/tags/%E7%BD%91%E7%AB%99/"}]},{"title":"STM32实现德飞莱LED文字滚动效果","slug":"STM32实现德飞莱LED文字滚动效果","date":"2021-03-22T01:32:15.000Z","updated":"2022-03-20T01:44:33.480Z","comments":true,"path":"posts/dc68.html","link":"","permalink":"http://wht6.github.io/posts/dc68.html","excerpt":"","text":"STM32实现德飞莱LED文字滚动效果显示静止文字各个引脚功能：OE：使能端，输出高电平关闭屏幕，行选和列选切换的时候需要关闭一下屏幕，防止产生虚影。 D/C/B/A：每个引脚有0、1两个状态，四个引脚用于存储一个四位的二进制数，0/0/0/0是第一行，0/0/1/0是第三行。 R1/G1:R1是红色，G1是绿色，低电平点亮。 SCK：时钟信号。 LAT：锁存器。0打开，1关闭。 列选中原理：将一个16位的二进制串行输入到R1或G1，利用时钟脉冲信号触发寄存器存储当前值，然后通过 LATCH 锁存器将寄存器的值保存。 使用取字软件取出的C51格式的值。 例如：/— 文字: 中 —//— 宋体12; 此字体下对应的点阵为：宽x高=16x16 —/0x00,0x00,0x0F,0x08,0x08,0x08,0x08,0xFF,0x08,0x08,0x08,0x08,0x0F,0x00,0x00,0x00,0x00,0x00,0xF0,0x20,0x20,0x20,0x20,0xFF,0x20,0x20,0x20,0x20,0xF0,0x00,0x00,0x00, 其中第i位十六进制数和第i+16位十六进制数表示的是第i行的状态。i从0到15，逐次点亮16行。 12345678910111213141516171819202122232425void display_char()&#123;&#x2F;&#x2F;显示一个静止的汉字 int i&#x3D;0; int j&#x3D;0; int change; for(i&#x3D;0;i&lt;16;i++) &#123; change&#x3D;(zi[i]&lt;&lt;8)|zi[i+16];&#x2F;&#x2F;两个8位的二进制数组成一个16位的二进制数 LAT &#x3D; 0; for(j &#x3D; 0; j &lt; 16; j++)&#123; R1 &#x3D; ((~change)&gt;&gt;j)&amp;1; SCK &#x3D; 0; SCK &#x3D; 1; &#125; OE &#x3D; 1; get_row(i); LAT &#x3D; 1; OE &#x3D; 0; &#125;&#125;void get_row(int i)&#123;&#x2F;&#x2F;选中行 A&#x3D;i&amp;1; B&#x3D;(i&amp;2)&gt;&gt;1; C&#x3D;(i&amp;4)&gt;&gt;2; D&#x3D;(i&amp;8)&gt;&gt;3;&#125; 文字滚动显示方式选择：首先搞清楚，取模的方式有横向取模和纵向取模两种。 一般以C51格式取出来的16x16的汉字，由32个十六进制组成。 每个十六进制，0是白色的像素点，1是黑色的像素点，文字是由黑色的像素点组成。 我们需要指导每个十六进制对应汉字的哪个位置。 横向取模： /— 文字: 口 —//— 新宋体12; 此字体下对应的点阵为：宽x高=16x16 —/0x00,0x00,0x00,0x00,0x3F,0xF8,0x20,0x08,0x20,0x08,0x20,0x08,0x20,0x08,0x20,0x08,0x20,0x08,0x20,0x08,0x20,0x08,0x20,0x08,0x20,0x08,0x3F,0xF8,0x20,0x08,0x00,0x00, 其中第一行的前两个十六进制，代表的是最上边的16个像素点。每两个十六进制一组，自上而下表示完所有的像素点。 纵向取模： /— 文字: 口 —//— 新宋体12; 此字体下对应的点阵为：宽x高=16x16 —/0x00,0x00,0x3F,0x20,0x20,0x20,0x20,0x20,0x20,0x20,0x20,0x20,0x3F,0x00,0x00,0x00,0x00,0x00,0xFE,0x04,0x04,0x04,0x04,0x04,0x04,0x04,0x04,0x04,0xFE,0x00,0x00,0x00, 其中上边一行的16个十六进制，表示的是汉字的上半部分，第一行的第一个表示纵着的8个像素点，自左向右表示汉字的上半部分，第二行十六进制以同样的方式表示汉字的下半部分。 然后，需要根据LED显示的方式，选择合适的取模方式。（当然，也可以不这么麻烦，无非多试几次） R1或者G1 的寄存器，是要输入十六进制锁存的。因为一行或一列LED点有16个，所以需要输入两个字节大小的数据。 输入1，转换成连个16进制就是0x00,0x01。观察LED屏，发现亮点在一个角上。 根据上面取模的方式，需要直接把取模得到的16进制直接输入到R1或者G1 的寄存器，所以只能由两种摆放的方式，一个是把亮点放到右上角，对应横向取模，一个是把亮点放到左下角，对应纵向取模。 横向取模，每次把左右相邻的两个十六进制输入到寄存器，自上而下刷新显示。 纵向取模，每次把两行的同一列的两个十六进制输入到寄存器，自左向右刷新显示。 如果，不级联显示，这两种方式都是可以的，单个屏幕的滚动和静止显示都没问题。 但是，当你想要级联的时候，想要做一个较长屏幕的滚动显示，你会发现级联接口正好对应着横向取模的方式。 所以，放弃纵向取模的显示方式，改用横向取模的显示方式。 滚动效果原理其实很简单，若干个静止的状态连续的有规律地切换，就形成了滚动的效果。 而每次切换改变的仅仅是每块屏的最左边一列和最右边一列。 因此只需要，前一个字节左移n位|后一个字节右移8-n位, 但是，这个寄存器在输入的时候必须把bit流倒着输入，所以就需要倒序取模，前一个字节右移n位|后一个字节左移8-n位。 然后需要保持这个状态静止一段时间才完成一次的移动。保持的方法是每次刷新加一个细小的延时，延后循环n次。 当完成8次移动之后，需要取出一个新的字节。所以需要预先多取出两个字节，移动16次一个循环，循环完成后取出下一个汉字。","categories":[{"name":"嵌入式","slug":"嵌入式","permalink":"http://wht6.github.io/categories/%E5%B5%8C%E5%85%A5%E5%BC%8F/"}],"tags":[]},{"title":"CNN的三个重要性质","slug":"CNN的三个重要性质","date":"2021-03-22T00:48:44.000Z","updated":"2022-03-20T01:44:16.525Z","comments":true,"path":"posts/2c33.html","link":"","permalink":"http://wht6.github.io/posts/2c33.html","excerpt":"","text":"CNN的三个重要性质参数共享权值共享得益于卷积自身的性质，假设输入时$W \\times H$的图像，卷积核为$m\\times m$，进行权值共享时总共参数个数是$m\\times m\\times channels$；若不进行权值共享，每个像素需要一个单独的参数，则总参数数量则为$W\\times H\\times channels$。总参数大大增加，导致占用大量内存，模型训练缓慢。 局部连接对于局部连接而言：层间神经只有局部范围内的连接，在这个范围内采用全连接的方式，超过这个范围的神经元则没有连接；连接与连接之间独立参数，相比于全连接减少了感受域外的连接，有效减少参数规模。全连接：层间神经元完全连接，每个输出神经元可以获取到所有神经元的信息，有利于信息汇总，常置于网络末尾。 平移等变性卷积神经网络参数共享的特殊形式使得神经网络层具有平移等变性(equivariance)。对于图像而言，卷积产生一个 2 维映射来表明某些特征在输入中出现的位置。如果我们移动输入中的对象，它的表示也会在输出中移动同样的量。对于放缩和旋转等其他变换，卷积却不是天然等变的。关于池化，无论采用何种池化函数，当输入作出少量平移时，池化能帮助输入的表示近似不变(invariant)。对于平移的不变性是指当我们对输入进行少量平移时，经过池化函数后的大多数输出并不会发生改变。这意味着池化对特征位置不敏感，只有当我们不关心特征具体出现的位置时，池化才是合理的。CNN 中的卷积操作具有平移等变性，但池化操作具有局部平移不变性。两者矛盾地统一于 CNN 中。 参考： https://zhuanlan.zhihu.com/p/89109931 http://blog.sciencenet.cn/blog-3428464-1255252.html","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://wht6.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[]},{"title":"MathType使用技巧","slug":"MathType使用技巧","date":"2021-03-18T01:57:44.000Z","updated":"2022-03-20T01:45:12.117Z","comments":true,"path":"posts/a469.html","link":"","permalink":"http://wht6.github.io/posts/a469.html","excerpt":"","text":"MathType使用技巧安装下载官网下载 安装后免费使用30天 删除注册表30天结束之后，win+R 打开运行窗口，输入 regedit 打开注册表编辑器。 删除目录 HKEY_CURRENT_USER\\Software\\Install Options下的 Options6.9 文件。 重新获得30天的免费试用，不过需要每个月重新删除一次。 使用使用LaTex编辑公式点击MathType菜单中的“预置”—“工作区预置”，勾选“允许从键盘输入Tex语言”。 LaTex格式复制公式点击MathType菜单中的“预置”—“剪切和复制预置”，选中下面两项，点击确定。然后就可以以LaTex格式直接复制到LaTex或markdown中使用了。 使用空心字母空心字母还是比较常用，这里说明空心字母的使用。 “编辑”—“插入符号”—选择字体“Euclid Math Two”—“插入”。 如果要复制成LaTex，需要更改“剪切与复制预置”中的LaTex格式为AMSLaTex。","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://wht6.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"工具","slug":"工具","permalink":"http://wht6.github.io/tags/%E5%B7%A5%E5%85%B7/"}]},{"title":"ubuntu20.04配置pytorch环境","slug":"ubuntu20-04配置pytorch环境","date":"2021-03-17T06:17:44.000Z","updated":"2022-03-20T01:43:45.415Z","comments":true,"path":"posts/ee8d.html","link":"","permalink":"http://wht6.github.io/posts/ee8d.html","excerpt":"","text":"ubuntu20.04配置pytorch环境Linux相关命令cd /home 进入 ‘/ home’ 目录’cd .. 返回上一级目录cd ~ 进入个人的主目录cd - 返回上次所在的目录ls 查看目录中的文件ls -a 显示隐藏文件mkdir dir1 创建一个叫做 ‘dir1’ 的目录’rm -f file1 删除一个叫做 ‘file1’ 的文件’rm -rf dir1 删除一个叫做 ‘dir1’ 的目录并同时删除其内容cp -i file1 file2 将文档 file1复制成file2，复制后名称被改file2cp -i file1 dir1 将文档 file1复制到dir1目录下，复制后名称仍未file1cp -r dir1 dir2 将dir1下的所有文件及其子目录复制到dir2中locate 文件名 搜索文件sudo 管理员权限chmod a+x file 给file添加用户可执行权限chmod 777 file 或 chmod a=rwx file 设置所有人可以读写及执行unrar x file1.rar 解压rar包tar -zxvf archive.tar.gz 解压一个gzip格式的压缩包tar -jxvf archive.tar.bz2 解压一个bzip2格式的压缩包unzip file1.zip 解压一个zip格式压缩包dpkg -i package.deb 安装/更新一个 deb 包apt-get install package_name 安装/更新一个 deb 包apt-get update 升级列表中的软件包apt-get upgrade 升级所有已安装的软件cat file1 从第一个字节开始正向查看文件的内容ifconfig eth0 显示一个以太网卡的配置reboot 重启 准备工作如果需要远程，可以在控制端和本机上安装teamviewer，邮箱注册，邮箱会收到TeamViewer发过来的激活账户邮件，点击激活连接就能够登录客户端了。然后会再收到一封TeamViewer发过来的设备授权认证邮件，选择信任。连接的时候还要验证，需要手机号验证。如果感觉太繁琐，可以装VNC。 先用自带的编辑器更改apt源，不然后面下载和更新软件会很难受。清华镜像 vim安装 配置anaconda安装anacondaanaconda安装包选择最新版本安装，下载到本地后sudo sh xxx.sh执行。 添加anaconda源清华镜像也可以运行下面命令添加12345678910conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/menpo/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/pro/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/rconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2 创建虚拟conda环境选择需要的python版本，新建一个env虚拟conda环境1234conda create -n torch_1_7 python=3.7conda env listconda activate torch_1_7pip list 配置CUDA下载和安装nvidia-smi 查看本机显卡驱动、显存使用率和GPU利用率（显示的cuda version是驱动对应的cuda版本，而不是已经安装了该版本的cuda）查看本机显卡的算力显卡的受支持情况选择合适的cuda版本。下载cuda选择系统版本-runfile文件 可以直接用官方提供的命令安装（如果网络慢，可以先下载到本地在安装）安装的时候，驱动不要选（驱动已经有了），其他默认。（如果之前有装cuda，先卸载 cd /usr/local/cuda/bin sudo ./cuda-uninstaller） 配置环境变量12345678vim ~/.bashrcexport CUDA_HOME=/usr/local/cudaexport LD_LIBRARY_PATH=$&#123;LD_LIBRARY_PATH&#125;:$&#123;CUDA_HOME&#125;/lib64export PATH=$&#123;CUDA_HOME&#125;/bin:$&#123;PATH&#125;source ~/.bashrc 用nvcc -V或nvcc —version验证是否安装成功 安装对应版本的cudnncuDNN Archive 需要注册登录下载，解压，进入解压后文件夹。123sudo cp cuda/include/cudnn*.h /usr/local/cuda/includesudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64sudo chmod a+r /usr/local/cuda/include/cudnn*.h /usr/local/cuda/lib64/libcudnn*验证新版本：cat /usr/local/cuda/include/cudnn_version.h | grep CUDNN_MAJOR -A 2旧版本：cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2 配置pytorch环境旧版本最新版选择正确的版本，cudatoolkit的版本要和已经安装cuda版本一致（避免冲突）。感兴趣可以看cudatoolkit和cuda调用安装的时候去掉 -c pytorch(带上会影响下载速度)也可以从网上找对应的包（可以先用命令行获取包名，再退出，然后手动下载安装）（感兴趣移步：conda和pip安装库之间的区别）下面是几个提供免费下载的网站：https://www.lfd.uci.edu/~gohlke/pythonlibs/https://pypi.org/https://anaconda.org/pytorch/repo 配置需要的gcc版本如果需要构建框架，忽略这一步。 下载gcc解压后进入解压后的文件夹中运行./contrib/download_prerequisites（查看需要的依赖，手动下载，手动构建）下载依赖依赖构建过程（下边是个例子）12345tar -jxvf gmp-6.1.0.tar.bz2cd gmp-6.1.0./configuremakemake install构建gcc1234567mkdir gcc-build-7.3.0 cd gcc-build-7.3.0../configure --enable-checking=release --enable-languages=c,c++ --disable-multilibmakemake installgcc版本越高，构建的越慢。","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://wht6.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"pytorch","slug":"pytorch","permalink":"http://wht6.github.io/tags/pytorch/"}]},{"title":"深度学习的线性回归","slug":"深度学习的线性回归","date":"2021-03-17T06:14:48.000Z","updated":"2022-03-20T01:44:58.027Z","comments":true,"path":"posts/5620.html","link":"","permalink":"http://wht6.github.io/posts/5620.html","excerpt":"","text":"深度学习的线性回归线性回归定义线性回归（ Linear Regression） 是机器学习和统计学中最基础和最广泛应用的模型， 是一种对自变量和因变量之间关系进行建模的回归分析．线性回归模型的一般形式： \\hat{y}=\\omega^Tx+b其中权重向量$\\omega$与偏置b都是可学习的参数。给定一个训练集，每个样本包括特征向量x和标签y，我们希望能够学习到一组参数$\\omega$使模型估计的$\\hat{y}$能够很好的预测真实值y。这就引出了两个问题，如何训练以及如何评估。 模型的训练在模型训练中，我们需要衡量预测值与真实值之间的误差。通常我们会选取一个非负数作为误差，且数值越小表示误差越小。我们把衡量这些误差的函数称为损失函数。当模型和损失函数形式较为简单时，误差最小化问题的解可以直接用公式表达出来。这类解叫作解析解（analytical solution）。然而，大多数深度学习模型并没有解析解，只能通过优化算法有限次迭代模型参数来尽可能降低损失函数值。这类解叫作数值解（numerical solution）。 在求数值解的优化算法中，小批量随机梯度下降（mini-batch stochastic gradient descent）在深度学习中被广泛使用。它的算法很单：先选取一组模型参数的初始值，如随机选取；接下来对参数进行多次迭代，使每次迭代都可能降低损失函数的值。在每次迭代中，先随机均匀采样一个由固定数目训练数据样本所组成的小批量（mini-batch）$\\mathcal{B}$，然后求小批量中数据样本的平均损失有关模型参数的导数（梯度），最后用此结果与预先设定的一个正数（学习率）的乘积作为模型参数在本次迭代的减小量。 \\omega \\leftarrow \\omega - \\eta \\frac{1}{K}\\sum {\\frac{{\\partial L(y,\\hat y)}}{{\\partial \\omega }}}其中，$\\eta$是学习率，K是小批量样本的个数，L是损失函数。 神经网络图在深度学习中，我们可以使用神经网络图直观地表现模型结构。 线性回归模型：$\\hat{y}=x_1w_1+x_2w_2+b$ 为了更清晰地展示线性回归作为神经网络的结构，下图使用神经网络图表示上面的线性回归模型。神经网络图隐去了模型参数权重和偏差。 由于输入层并不涉及计算，上图神经网络的层数为1。其中，$x_1$和$x_2$是输入，输入个数为2，输入个数也叫特征数或特征向量维度。箭头指向输出节点表示加权求和的操作。输出层中的神经元和输入层中各个输入完全连接。因此，这里的输出层又叫全连接层（fully-connected layer）。 Softmax回归Logistic回归Logistic 回归（ Logistic Regression，LR） 是一种常用的处理二分类问题的线性模型． ${\\rm{y}} \\in \\{ 0,1\\}$是一个二分类问题，显然用单纯的线性模型无法解决。我们需要一个非线性的激活函数，这里选择Logistic函数作为激活函数，将线性函数的值域挤压的0到1之间来表示概率。那么标签$y = 1$的概率为 \\hat{y}=p(y = 1) = \\frac{1}{{1 + \\exp ( - \\omega x)}}当概率值大于0.5是认为$y = 1$，否则$y = 0$。 Logistic 回归采用交叉熵作为损失函数， 并使用梯度下降法来对参数进行优化。 Softmax回归Logistic 回归只使用二分类问题，放在神经网络中只有单一的输出。对于多分类问题就要用到Softmax回归。 o_1=x_1w_11+x_2w_21+x_3w_31+x_4w_41+b_1,\\\\\\\\ o_2=x_1w_12+x_2w_22+x_3w_32+x_4w_42+b_2,\\\\\\\\ o_3=x_1w_13+x_2w_23+x_3w_33+x_4w_43+b_3.我们需要将三个输出的至于压缩到0到1之间，并且三者之和为1，就能够表示成概率值，那么哪个输出的概率值大就分类成哪个标签。 {\\hat y_1} = \\frac{{exp({o_1})}}{{\\sum {exp({o_i})} }},{\\hat y_2} = \\frac{{exp({o_2})}}{{\\sum {exp({o_i})} }},{\\hat y_3} = \\frac{{exp({o_3})}}{{\\sum {exp({o_i})} }}经过上面的映射，${\\hat y_1}+{\\hat y_2}+{\\hat y_3}=1$且$0\\le{\\hat y_1},{\\hat y_2},{\\hat y_3}\\le1$。 可以看出，Softmax回归同线性回归一样也是单层的全连接网络。 Softmax回归采用的也是交叉熵损失函数， 并使用梯度下降法来对参数进行优化。 Softmax交叉熵损失函数的公式： Loss({{\\bf{y}}^{(i)}},{{\\bf{\\hat y}}^{(i)}}) = - \\sum\\limits_{j = 1}^c {{y_j}^{(i)}} \\log {\\hat y_j}^{(i)}其中，c是类别数，i表示样本i。 参考《神经网络与深度学习 》邱锡鹏 《动手学深度学习》","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://wht6.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[]}],"categories":[{"name":"云原生","slug":"云原生","permalink":"http://wht6.github.io/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"},{"name":"编程","slug":"编程","permalink":"http://wht6.github.io/categories/%E7%BC%96%E7%A8%8B/"},{"name":"运维","slug":"运维","permalink":"http://wht6.github.io/categories/%E8%BF%90%E7%BB%B4/"},{"name":"个人兴趣","slug":"个人兴趣","permalink":"http://wht6.github.io/categories/%E4%B8%AA%E4%BA%BA%E5%85%B4%E8%B6%A3/"},{"name":"Linux","slug":"Linux","permalink":"http://wht6.github.io/categories/Linux/"},{"name":"网络","slug":"网络","permalink":"http://wht6.github.io/categories/%E7%BD%91%E7%BB%9C/"},{"name":"嵌入式","slug":"嵌入式","permalink":"http://wht6.github.io/categories/%E5%B5%8C%E5%85%A5%E5%BC%8F/"},{"name":"深度学习","slug":"深度学习","permalink":"http://wht6.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://wht6.github.io/tags/Kubernetes/"},{"name":"集群","slug":"集群","permalink":"http://wht6.github.io/tags/%E9%9B%86%E7%BE%A4/"},{"name":"Docker","slug":"Docker","permalink":"http://wht6.github.io/tags/Docker/"},{"name":"容器","slug":"容器","permalink":"http://wht6.github.io/tags/%E5%AE%B9%E5%99%A8/"},{"name":"Shell","slug":"Shell","permalink":"http://wht6.github.io/tags/Shell/"},{"name":"负载均衡","slug":"负载均衡","permalink":"http://wht6.github.io/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"name":"高可用","slug":"高可用","permalink":"http://wht6.github.io/tags/%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"name":"Go语言","slug":"Go语言","permalink":"http://wht6.github.io/tags/Go%E8%AF%AD%E8%A8%80/"},{"name":"Python语言","slug":"Python语言","permalink":"http://wht6.github.io/tags/Python%E8%AF%AD%E8%A8%80/"},{"name":"道家","slug":"道家","permalink":"http://wht6.github.io/tags/%E9%81%93%E5%AE%B6/"},{"name":"阿里云","slug":"阿里云","permalink":"http://wht6.github.io/tags/%E9%98%BF%E9%87%8C%E4%BA%91/"},{"name":"系统配置","slug":"系统配置","permalink":"http://wht6.github.io/tags/%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE/"},{"name":"网站搭建","slug":"网站搭建","permalink":"http://wht6.github.io/tags/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/"},{"name":"文件系统","slug":"文件系统","permalink":"http://wht6.github.io/tags/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"name":"网络配置","slug":"网络配置","permalink":"http://wht6.github.io/tags/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"name":"日志","slug":"日志","permalink":"http://wht6.github.io/tags/%E6%97%A5%E5%BF%97/"},{"name":"计划任务","slug":"计划任务","permalink":"http://wht6.github.io/tags/%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/"},{"name":"包管理","slug":"包管理","permalink":"http://wht6.github.io/tags/%E5%8C%85%E7%AE%A1%E7%90%86/"},{"name":"磁盘管理","slug":"磁盘管理","permalink":"http://wht6.github.io/tags/%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/"},{"name":"管道","slug":"管道","permalink":"http://wht6.github.io/tags/%E7%AE%A1%E9%81%93/"},{"name":"重定向","slug":"重定向","permalink":"http://wht6.github.io/tags/%E9%87%8D%E5%AE%9A%E5%90%91/"},{"name":"进程","slug":"进程","permalink":"http://wht6.github.io/tags/%E8%BF%9B%E7%A8%8B/"},{"name":"权限管理","slug":"权限管理","permalink":"http://wht6.github.io/tags/%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/"},{"name":"用户管理","slug":"用户管理","permalink":"http://wht6.github.io/tags/%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86/"},{"name":"思维","slug":"思维","permalink":"http://wht6.github.io/tags/%E6%80%9D%E7%BB%B4/"},{"name":"工具","slug":"工具","permalink":"http://wht6.github.io/tags/%E5%B7%A5%E5%85%B7/"},{"name":"代理","slug":"代理","permalink":"http://wht6.github.io/tags/%E4%BB%A3%E7%90%86/"},{"name":"路由器","slug":"路由器","permalink":"http://wht6.github.io/tags/%E8%B7%AF%E7%94%B1%E5%99%A8/"},{"name":"DNS","slug":"DNS","permalink":"http://wht6.github.io/tags/DNS/"},{"name":"实例分割","slug":"实例分割","permalink":"http://wht6.github.io/tags/%E5%AE%9E%E4%BE%8B%E5%88%86%E5%89%B2/"},{"name":"网站","slug":"网站","permalink":"http://wht6.github.io/tags/%E7%BD%91%E7%AB%99/"},{"name":"pytorch","slug":"pytorch","permalink":"http://wht6.github.io/tags/pytorch/"}]}